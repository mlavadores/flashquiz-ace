Question 1 of 529
Una empresa necesita diseñar una solución DNS híbrida. Esta solución utilizará una zona alojada privada de Amazon Route 53 para el dominio cloud.example.com para los recursos almacenados dentro de las VPC.
La empresa cuenta con los siguientes requisitos de resolución de DNS:
Los sistemas locales deben ser capaces de resolver y conectarse a cloud.example.com.
Todas las VPC deben poder resolver cloud.example.com.
Ya existe una conexión AWS Direct Connect entre la red corporativa local y AWS Transit Gateway.
Qué arquitectura debe utilizar la empresa para cumplir con estos requisitos con el MÁS ALTO rendimiento?
A.
Asociar la zona privada alojada a todas las VPC. Cree un solucionador entrante Route 53 en la VPC de servicios compartidos. Adjunte todas las VPC a la puerta de enlace de tránsito y cree reglas de reenvío en el servidor DNS local para cloud.example.com que apunten al solucionador entrante.
B.
Asociar la zona privada alojada a todas las VPC. Implemente un reenviador condicional de Amazon EC2 en la VPC de servicios compartidos. Adjunte todas las VPC a la puerta de enlace de tránsito y cree reglas de reenvío en el servidor DNS local para cloud.example.com que apunten al reenviador condicional.
C.
Asocie la zona alojada privada a los servicios compartidos VPCrear un solucionador de salida Route 53 en los servicios compartidos VPAttAche todas las VPC a la puerta de enlace de tránsito y cree reglas de reenvío en el servidor DNS local para cloud.example.com que apunten al solucionador saliente.
D.
Asociar la zona hospedada privada a la VPC de servicios compartidos. Cree un solucionador entrante Route 53 en la VPC de servicios compartidos. Adjunte la VPC de servicios compartidos a la puerta de enlace de tránsito y cree reglas de reenvío en el servidor DNS local para cloud.example.com que apunten al solucionador entrante.
AnswerDiscussion
Correct Answer: A
Para lograr la solución DNS híbrida de mayor rendimiento, la compañía debe asociar la zona alojada privada Route 53 con todas las VPC, asegurando que todas las VPC puedan resolver cloud.example.com. Además, la creación de un solucionador entrante Route 53 en la VPC de servicios compartidos y la conexión de todas las VPC a la puerta de enlace de tránsito permitirá que los sistemas locales resuelvan el dominio cloud.example.com reenviando reglas en el servidor DNS local que apuntan al solucionador entrante. Esto garantiza una resolución de DNS perfecta tanto para los recursos locales como para los recursos de AWS.
Question 2 of 529
Una compañía está proporcionando datos meteorológicos a través de una API basada en REST a varios clientes. La API está alojada en Amazon API Gateway y está integrada con diferentes funciones de AWS Lambda para cada operación de API. La compañía utiliza Amazon Route 53 para DNS y ha creado un registro de recursos de weather.example.com. La compañía almacena datos para la API en tablas de Amazon DynamoDB. La compañía necesita una solución que le dé a la API la capacidad de fallar a otra región de AWS.
Qué solución cumplirá con estos requisitos?
A.
Despliegue un nuevo conjunto de funciones Lambda en una nueva Región. Actualice la API de API Gateway para usar un punto final de API optimizado para bordes con funciones Lambda de ambas regiones como destinos. Convierta las tablas de DynamoDB en tablas globales.
B.
Implementar una nueva API Gateway API y funciones Lambda en otra región. Cambie el registro DNS Route 53 a una respuesta multivalue. Agregue ambas API de API Gateway a la respuesta. Habilite el monitoreo de salud objetivo. Convierta las tablas de DynamoDB en tablas globales.
C.
Implementar una nueva API Gateway API y funciones Lambda en otra región. Cambie el registro DNS de Route 53 a un registro de conmutación por error. Habilite el monitoreo de salud objetivo. Convierta las tablas de DynamoDB en tablas globales.
D.
Implementar una nueva API de puerta de enlace API en una nueva región. Cambie las funciones de Lambda a funciones globales. Cambie el registro DNS Route 53 a una respuesta multivalue. Agregue ambas API de API Gateway a la respuesta. Habilite el monitoreo de salud objetivo. Convierta las tablas de DynamoDB en tablas globales.
AnswerDiscussion
Correct Answer: C
Para lograr la capacidad de conmutación por error para la API de datos meteorológicos, la compañía debe implementar una nueva API Gateway API y funciones Lambda en otra región de AWS. El registro DNS Route 53 se debe cambiar a un registro de conmutación por error, que permite que el tráfico se enrute a una región secundaria si la región primaria no está disponible. Habilitar la supervisión de estado de destino garantiza que el mecanismo de conmutación por error pueda detectar el estado de los endpoints de API e iniciar la conmutación por error cuando sea necesario. La conversión de las tablas de DynamoDB en tablas globales garantiza que los datos permanezcan coherentes y accesibles en varias regiones, lo que permite que la API funcione sin problemas durante un evento de conmutación por error.
Question 3 of 529
Una empresa utiliza AWS Organizations con una sola unidad organizativa llamada Producción para administrar varias cuentas. Todas las cuentas son miembros de la OU de Producción. Los administradores usan SCP de listas de denegar en la raíz de la organización para administrar el acceso a servicios restringidos.
La compañía adquirió recientemente una nueva unidad de negocio e invitó a la organización a la cuenta de AWS existente de la nueva unidad. Una vez incorporados, los administradores de la nueva unidad de negocio descubrieron que no pueden actualizar las reglas de AWS Config existentes para cumplir con las políticas de la compañía.
Qué opción permitirá a los administradores realizar cambios y continuar haciendo cumplir las políticas actuales sin introducir mantenimiento adicional a largo plazo?
A.
Elimine los SCP raíz de la organización que limitan el acceso a AWS Config. Cree productos de AWS Service Catalog para las reglas estándar de AWS Config de la compañía e impleméntelos en toda la organización, incluida la nueva cuenta.
B.
Crear una unidad organizativa temporal llamada Onboarding para la nueva cuenta. Aplique un SCP a la OU de incorporación para permitir acciones de AWS Config. Mueva la nueva cuenta a la unidad organizativa de producción cuando se completen los ajustes a AWS Config.
C.
Convierta los SCP raíz de la organización de los SCP de la lista de denegar para permitir que los SCP de la lista solo permitan los servicios requeridos. Aplique temporalmente un SCP a la raíz de la organización que permita acciones de AWS Config para los principales solo en la nueva cuenta.
D.
Crear una unidad organizativa temporal llamada Onboarding para la nueva cuenta. Aplique un SCP a la OU de incorporación para permitir acciones de AWS Config. Mover el SCP raíz de la organización a la unidad organizativa de producción. Mueva la nueva cuenta a la unidad organizativa de producción cuando se completen los ajustes a AWS Config.
AnswerDiscussion
Correct Answer: D
Para garantizar que los administradores puedan actualizar las reglas de AWS Config sin introducir el mantenimiento a largo plazo, el mejor enfoque sería crear una unidad organizativa temporal llamada Onboarding para la nueva cuenta. Aplique un SCP a la OU de incorporación para permitir acciones de AWS Config. Mover el SCP raíz de la organización a la unidad organizativa de producción. Una vez que se hayan completado los ajustes a AWS Config, la nueva cuenta se puede mover a la unidad organizativa de producción. Este método aborda los permisos necesarios sin alterar el marco SCP de la lista de denegaciones en la raíz, manteniendo así los protocolos de seguridad y administración existentes en toda la organización.
Question 4 of 529
Una empresa está ejecutando una aplicación basada en la web de dos niveles en un centro de datos local. La capa de aplicación consiste en un solo servidor que ejecuta una aplicación con estado. La aplicación se conecta a una base de datos PostgreSQL que se ejecuta en un servidor separado. Se espera que la base de usuarios de la aplicación crezca significativamente, por lo que la compañía está migrando la aplicación y la base de datos a AWS. La solución utilizará Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling y Elastic Load Balancing.
Qué solución proporcionará una experiencia de usuario consistente que permitirá escalar los niveles de aplicación y base de datos?
A.
Habilite el escalado automático de Aurora para réplicas de Aurora. Utilice un balanceador de carga de red con el algoritmo de enrutamiento de solicitudes menos pendientes y sesiones adhesivas habilitadas.
B.
Habilite Aurora Auto Scaling para escritores Aurora. Utilice un balanceador de carga de aplicaciones con el algoritmo de enrutamiento round robin y las sesiones adhesivas habilitadas.
C.
Habilite el escalado automático de Aurora para réplicas de Aurora. Utilice un balanceador de carga de aplicaciones con el enrutamiento round robin y las sesiones adhesivas habilitadas.
D.
Habilite Aurora Scaling para escritores Aurora. Utilice un balanceador de carga de red con el algoritmo de enrutamiento de solicitudes menos pendientes y sesiones adhesivas habilitadas.
AnswerDiscussion
Correct Answer: C
La compañía necesita una solución que pueda escalar tanto los niveles de la aplicación como de la base de datos y, al mismo tiempo, proporcionar una experiencia de usuario consistente. Habilitar Aurora Auto Scaling para réplicas Aurora permite que la base de datos se escale según la demanda agregando o eliminando réplicas de lectura automáticamente. El uso de un balanceador de carga de aplicaciones (ALB) con el algoritmo de enrutamiento round robin garantiza que el tráfico entrante se distribuya uniformemente en varias instancias de la capa de aplicación, lo que ayuda a mantener el equilibrio de carga y el rendimiento. Habilitar sesiones adhesivas garantiza que la sesión de cada usuario se mantenga con el mismo servidor backend, proporcionando una experiencia de usuario consistente. Esta combinación aborda de manera efectiva los requisitos de escalado y consistencia de la sesión del usuario.
Question 5 of 529
Una empresa utiliza un servicio para recopilar metadatos de las aplicaciones que la compañía aloja en las instalaciones. Los dispositivos de consumo como televisores y radios por internet acceden a las aplicaciones. Muchos dispositivos más antiguos no admiten ciertos encabezados HTTP y muestran errores cuando estos encabezados están presentes en las respuestas. La compañía ha configurado un equilibrador de carga local para eliminar los encabezados no compatibles de las respuestas enviadas a dispositivos más antiguos, que la compañía identificó por los encabezados User-Agent.
La compañía quiere migrar el servicio a AWS, adoptar tecnologías sin servidor y conservar la capacidad de soportar los dispositivos más antiguos. La compañía ya ha migrado las aplicaciones a un conjunto de funciones de AWS Lambda.
Qué solución cumplirá con estos requisitos?
A.
Cree una distribución de Amazon CloudFront para el servicio de metadatos. Cree un balanceador de carga de aplicaciones (ALB). Configure la distribución de CloudFront para reenviar solicitudes al ALB. Configure el ALB para invocar la función Lambda correcta para cada tipo de solicitud. Cree una función CloudFront para eliminar los encabezados problemáticos en función del valor del encabezado User-Agent.
B.
Cree una API REST de Amazon API Gateway para el servicio de metadatos. Configure API Gateway para invocar la función Lambda correcta para cada tipo de solicitud. Modifique las respuestas de puerta de enlace predeterminadas para eliminar los encabezados problemáticos en función del valor del encabezado User-Agent.
C.
Cree una API HTTP de Amazon API Gateway para el servicio de metadatos. Configure API Gateway para invocar la función Lambda correcta para cada tipo de solicitud. Cree una plantilla de asignación de respuestas para eliminar los encabezados problemáticos en función del valor del agente de usuario. Asociar el mapeo de datos de respuesta con la API HTTP.
D.
Cree una distribución de Amazon CloudFront para el servicio de metadatos. Cree un balanceador de carga de aplicaciones (ALB). Configure la distribución de CloudFront para reenviar solicitudes al ALB. Configure el ALB para invocar la función Lambda correcta para cada tipo de solicitud. Cree una función Lambda @Edge que eliminará los encabezados problemáticos en respuesta a las solicitudes del espectador en función del valor del encabezado User-Agent.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos de migrar el servicio a AWS, usar tecnologías sin servidor y admitir dispositivos más antiguos, la mejor solución consiste en usar una distribución de Amazon CloudFront junto con una función CloudFront. Las funciones de CloudFront están optimizadas para tareas livianas como inspeccionar encabezados HTTP y modificar solicitudes o respuestas. Esta configuración permite la eliminación eficiente de encabezados problemáticos basados en el encabezado User-Agent en las solicitudes, asegurando la compatibilidad con dispositivos más antiguos. Este enfoque se integra bien con las funciones existentes de AWS Lambda y evita la necesidad de alternativas más complejas y potencialmente costosas como Lambda @Edge o componentes no sin servidor como un balanceador de carga de aplicaciones.
Question 6 of 529
Una empresa minorista necesita proporcionar una serie de archivos de datos a otra empresa, que es su socio comercial. Estos archivos se guardan en un bucket de Amazon S3 bajo la Cuenta A, que pertenece a la empresa minorista. La empresa asociada de negocios quiere que uno de sus usuarios de IAM, User_DataProcessor, acceda a los archivos desde su propia cuenta de AWS (Cuenta B).
Qué combinación de pasos deben tomar las empresas para que User_DataProcessor pueda acceder correctamente al bucket S3? (Elija dos.)
A.
Active la función de uso compartido de recursos de origen cruzado (CORS) para el bucket S3 en la cuenta A.
B.
En la Cuenta A, establezca la política de bucket S3 en lo siguiente:
C.
En la Cuenta A, establezca la política de bucket S3 en lo siguiente:
D.
En la Cuenta B, establezca los permisos de User_DataProcessor en lo siguiente:
E.
En la Cuenta B, establezca los permisos de User_DataProcessor en lo siguiente:
AnswerDiscussion
Correct Answer: C, D
Para que User_DataProcessor en la Cuenta B acceda al bucket S3 en la Cuenta A, se necesitan dos pasos clave. En primer lugar, la Cuenta A necesita agregar una política al bucket S3 que permita explícitamente al usuario de IAM de la Cuenta B los permisos necesarios para acceder al bucket. Esto se logra especificando el principal como usuario de IAM y otorgando las acciones requeridas, como se muestra en la opción C. En segundo lugar, la Cuenta B debe asignar una política de IAM a User_DataProcessor que otorgue permiso para realizar las acciones requeridas (GetObject y ListBucket) en el bucket S3 en la Cuenta A, que se especifica en la opción D. Juntos, estos pasos aseguran que el acceso entre cuentas esté configurado correctamente.
Question 7 of 529
Una empresa está ejecutando una aplicación web tradicional en instancias de Amazon EC2. La empresa necesita refactorizar la aplicación como microservicios que se ejecutan en contenedores. Existen versiones separadas de la aplicación en dos entornos distintos: producción y pruebas. La carga para la aplicación es variable, pero se conocen la carga mínima y la carga máxima. Un arquitecto de soluciones necesita diseñar la aplicación actualizada con una arquitectura sin servidor que minimice la complejidad operativa.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cargue las imágenes del contenedor en AWS Lambda como funciones. Configure un límite de concurrencia para que las funciones Lambda asociadas manejen la carga máxima esperada. Configure dos integraciones Lambda separadas dentro de Amazon API Gateway: una para producción y otra para pruebas.
B.
Cargue las imágenes del contenedor en Amazon Elastic Container Registry (Amazon ECR). Configure dos clústeres de Amazon Elastic Container Service (Amazon ECS) escalados automáticamente con el tipo de lanzamiento Fargate para manejar la carga esperada. Desplegar tareas a partir de las imágenes ECR. Configure dos balanceadores de carga de aplicaciones independientes para dirigir el tráfico a los clústeres ECS.
C.
Cargue las imágenes del contenedor en Amazon Elastic Container Registry (Amazon ECR). Configure dos clústeres de Amazon Elastic Kubernetes Service (Amazon EKS) escalados automáticamente con el tipo de lanzamiento Fargate para manejar la carga esperada. Desplegar tareas a partir de las imágenes ECR. Configure dos balanceadores de carga de aplicaciones independientes para dirigir el tráfico a los clústeres de EKS.
D.
Cargue las imágenes del contenedor en AWS Elastic Beanstalk. En Elastic Beanstalk, cree entornos e implementaciones independientes para producción y pruebas. Configure dos balanceadores de carga de aplicaciones independientes para dirigir el tráfico a las implementaciones de Elastic Beanstalk.
AnswerDiscussion
Correct Answer: B
Para diseñar una arquitectura rentable sin servidor que minimice la complejidad operativa mientras se refactoriza una aplicación web tradicional como microservicios, usar Amazon Elastic Container Service (ECS) con el tipo de lanzamiento Fargate es una solución adecuada. ECS con Fargate permite el escalado automático de contenedores basado en la carga, lo que maneja la carga de trabajo variable de manera efectiva. Al cargar las imágenes de contenedor en Amazon Elastic Container Registry (ECR) e implementar tareas a partir de estas imágenes, se optimiza la administración operativa. La configuración de dos clústeres ECS escalados automáticamente garantiza entornos separados para la producción y las pruebas. Además, el uso de balanceadores de carga de aplicaciones para dirigir el tráfico a los clústeres ECS ayuda a distribuir la carga de manera eficiente. Esta solución aprovecha completamente los servicios administrados de AWS, lo que reduce la carga y el costo operativos generales.
Question 8 of 529
Una empresa tiene una aplicación web de varios niveles que se ejecuta en una flota de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). Las instancias están en un grupo de Auto Scaling. El ALB y el grupo Auto Scaling se replican en una región de AWS de respaldo. El valor mínimo y el valor máximo para el grupo Auto Scaling se establecen en cero. Una instancia de base de datos Multi-AZ de Amazon RDS almacena los datos de la aplicación. La instancia de base de datos tiene una réplica de lectura en la región de respaldo. La aplicación presenta un punto final a los usuarios finales mediante el uso de un registro Amazon Route 53.
La compañía necesita reducir su RTO a menos de 15 minutos dando a la aplicación la capacidad de fallar automáticamente a la región de backup. La compañía no tiene un presupuesto lo suficientemente grande para una estrategia activo-activa.
Qué debería recomendar un arquitecto de soluciones para cumplir con estos requisitos?
A.
Reconfigure el registro Route 53 de la aplicación con una política de enrutamiento basada en latencia que equilibre la carga del tráfico entre los dos ALB. Cree una función de AWS Lambda en la región de copia de seguridad para promover la réplica de lectura y modificar los valores del grupo Auto Scaling. Cree una alarma de Amazon CloudWatch basada en la métrica HttpCode_Target_5xx_count para el ALB en la región principal. Configure la alarma CloudWatch para invocar la función Lambda.
B.
Cree una función de AWS Lambda en la región de copia de seguridad para promover la réplica de lectura y modificar los valores del grupo Auto Scaling. Configure Route 53 con una comprobación de estado que supervise la aplicación web y envíe una notificación de Amazon Simple Notification Service (Amazon SNS) a la función Lambda cuando el estado de la comprobación de estado no sea saludable. Actualice el registro Route 53 de la aplicación con una política de conmutación por error que enruta el tráfico al ALB en la región de respaldo cuando ocurre una falla en la comprobación de estado.
C.
Configure el grupo Auto Scaling en la región de respaldo para que tenga los mismos valores que el grupo Auto Scaling en la región principal. Reconfigure el registro Route 53 de la aplicación con una política de enrutamiento basada en latencia que equilibre la carga del tráfico entre los dos ALB. Retire la réplica de lectura. Reemplace la réplica de lectura por una instancia de base de datos RDS independiente. Configure la replicación entre regiones entre las instancias de base de datos RDS mediante instantáneas y Amazon S3.
D.
Configure un punto final en AWS Global Accelerator con los dos ALB como objetivos ponderados iguales. Cree una función de AWS Lambda en la región de copia de seguridad para promover la réplica de lectura y modificar los valores del grupo Auto Scaling. Cree una alarma de Amazon CloudWatch basada en la métrica HttpCode_Target_5xx_count para el ALB en la región principal. Configure la alarma CloudWatch para invocar la función Lambda.
AnswerDiscussion
Correct Answer: B
Para lograr una conmutación por error automática a la región de backup y mantener un RTO de menos de 15 minutos dentro de un presupuesto limitado, la solución debe incluir mecanismos para monitorear la región primaria y tomar medidas rápidas si se vuelve insalubre. La configuración de una función de AWS Lambda en la región de backup para promover la réplica de lectura y modificar los valores de grupo de Auto Scaling de las instancias garantiza que los recursos se puedan aprovisionar rápidamente en la región de backup cuando sea necesario. El uso de Route 53 con una comprobación de estado para monitorear la aplicación web y enviar una notificación SNS para activar la función Lambda cuando la región primaria no es saludable permite que el tráfico se redirija rápidamente a la región de respaldo. Esta configuración evita la necesidad de una costosa estrategia activo-activa al tiempo que proporciona la capacidad de conmutación por error necesaria.
Question 9 of 529
Una empresa está alojando una aplicación crítica en una sola instancia de Amazon EC2. La aplicación utiliza un clúster de nodo único de Amazon ElastiCache para Redis para un data store en memoria. La aplicación utiliza una instancia de base de datos de Amazon RDS para MariaDB para una base de datos relacional. Para que la aplicación funcione, cada pieza de la infraestructura debe estar sana y debe estar en estado activo.
Un arquitecto de soluciones necesita mejorar la arquitectura de la aplicación para que la infraestructura pueda recuperarse automáticamente de fallas con el menor tiempo de inactividad posible.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Utilice un Elastic Load Balancer para distribuir el tráfico entre varias instancias EC2. Asegúrese de que las instancias EC2 formen parte de un grupo de Auto Scaling que tenga una capacidad mínima de dos instancias.
B.
Utilice un Elastic Load Balancer para distribuir el tráfico entre varias instancias EC2. Asegúrese de que las instancias EC2 estén configuradas en modo ilimitado.
C.
Modifique la instancia de base de datos para crear una réplica de lectura en la misma zona de disponibilidad. Promueva la réplica de lectura para que sea la instancia de base de datos principal en escenarios de falla.
D.
Modifique la instancia de base de datos para crear una implementación Multi-AZ que se extienda a través de dos zonas de disponibilidad.
E.
Cree un grupo de replicación para el clúster de ElastiCache para Redis. Configure el clúster para usar un grupo de Auto Scaling que tenga una capacidad mínima de dos instancias.
F.
Cree un grupo de replicación para el clúster de ElastiCache para Redis. Habilite Multi-AZ en el clúster.
AnswerDiscussion
Correct Answer: A, D, F
Para garantizar la recuperación automática de fallas con un tiempo de inactividad mínimo, se pueden tomar varios pasos. Primero, usar un Elastic Load Balancer para distribuir el tráfico entre varias instancias EC2 y garantizar que estas instancias formen parte de un grupo de Auto Scaling con una capacidad mínima de dos instancias puede ayudar a mantener la disponibilidad de las aplicaciones si una instancia falla. Luego, la modificación de la instancia de base de datos para crear una implementación Multi-AZ garantiza que la base de datos permanezca disponible al fallar automáticamente a una zona de disponibilidad secundaria en caso de un problema. Por último, la creación de un grupo de replicación para el clúster de ElastiCache para Redis y la habilitación de Multi-AZ en el clúster garantiza que el data store en memoria sea resiliente y pueda conmutar por error a otra zona de disponibilidad si es necesario. Esta combinación logra una arquitectura robusta y altamente disponible capaz de recuperarse automáticamente de fallas con un tiempo de inactividad mínimo.
Question 10 of 529
Una empresa minorista opera su aplicación de comercio electrónico en AWS. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). La compañía utiliza una instancia de base de datos de Amazon RDS como backend de base de datos. Amazon CloudFront se configura con un origen que apunta al ALB. El contenido estático se encuentra en caché. Amazon Route 53 se utiliza para alojar todas las zonas públicas.
Después de una actualización de la aplicación, el ALB ocasionalmente devuelve un error de código de estado 502 (Bad Gateway). La causa raíz son los encabezados HTTP mal formados que se devuelven al ALB. La página web regresa con éxito cuando un arquitecto de soluciones vuelve a cargar la página web inmediatamente después de que se produce el error.
Mientras la compañía está trabajando en el problema, el arquitecto de soluciones necesita proporcionar una página de error personalizada en lugar de la página de error ALB estándar a los visitantes.
Qué combinación de pasos cumplirá con este requisito con la MENOR cantidad de gastos generales operativos? (Elija dos.)
A.
Cree un bucket de Amazon S3. Configure el bucket S3 para alojar una página web estática. Cargue las páginas de error personalizadas en Amazon S3.
B.
Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si el objetivo de respuesta de comprobación de estado de ALB.FailedHealthChecks es mayor que 0. Configure la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web de acceso público.
C.
Modifique los registros existentes de Amazon Route 53 agregando verificaciones de estado. Configure un destino de reserva si falla la comprobación de estado. Modificar los registros DNS para que apunten a una página web de acceso público.
D.
Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de comprobación de estado de ALB elb.InternalError es mayor que 0. Configure la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web de acceso público.
E.
Agregue una respuesta de error personalizada configurando una página de error personalizada de CloudFront. Modificar los registros DNS para que apunten a una página web de acceso público.
AnswerDiscussion
Correct Answer: A, E
Para proporcionar una página de error personalizada en lugar de la página de error ALB estándar con la menor sobrecarga operativa, se necesitan dos pasos. Primero, cree un bucket de Amazon S3 para alojar una página web estática y cargue las páginas de error personalizadas en ese bucket de S3. Esto permite una ubicación de alta disponibilidad para almacenar las páginas de error. En segundo lugar, configure una página de error personalizada de CloudFront para manejar las respuestas de error personalizadas de manera efectiva. Esta configuración aprovecha los servicios existentes con una configuración adicional mínima, ofreciendo una solución eficiente y escalable sin la necesidad de cambios complejos de DNS o manejo de código personalizado para cada error.
Question 11 of 529
Una empresa tiene muchas cuentas de AWS y utiliza AWS Organizations para administrarlas todas. Un arquitecto de soluciones debe implementar una solución que la compañía pueda usar para compartir una red común a través de múltiples cuentas.
El equipo de infraestructura de la compañía tiene una cuenta de infraestructura dedicada que cuenta con una VPC. El equipo de infraestructura debe usar esta cuenta para administrar la red. Las cuentas individuales no pueden tener la capacidad de administrar sus propias redes. Sin embargo, las cuentas individuales deben poder crear recursos de AWS dentro de subredes.
Qué combinación de acciones debe realizar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Crear una puerta de enlace de tránsito en la cuenta de infraestructura.
B.
Habilite el uso compartido de recursos desde la cuenta de administración de AWS Organizations.
C.
Cree VPC en cada cuenta de AWS dentro de la organización en AWS Organizations. Configure las VPC para compartir el mismo rango de CIDR y subredes que la VPC en la cuenta de infraestructura. Peer las VPC en cada cuenta individual con la VPC en la cuenta de infraestructura.
D.
Cree un recurso compartido en AWS Resource Access Manager en la cuenta de infraestructura. Seleccione la unidad organizativa específica de AWS Organizations que utilizará la red compartida. Seleccione cada subred para asociarla con el recurso compartido.
E.
Cree un recurso compartido en AWS Resource Access Manager en la cuenta de infraestructura. Seleccione la unidad organizativa específica de AWS Organizations que utilizará la red compartida. Seleccione cada lista de prefijos para asociarla con el recurso compartido.
AnswerDiscussion
Correct Answer: B, D
Para compartir una red común entre varias cuentas de AWS administradas por AWS Organizations, la cuenta de infraestructura debe usar AWS Resource Access Manager (RAM) para compartir subredes con otras cuentas. Habilitar el uso compartido de recursos desde la cuenta de administración de AWS Organizations permite que los recursos se compartan en todas las cuentas de la organización. Al crear un recurso compartido en RAM dentro de la cuenta de infraestructura y asociar subredes específicas con el recurso compartido, el equipo de infraestructura puede administrar la red mientras permite que cuentas individuales creen recursos dentro de las subredes compartidas.
Question 12 of 529
Una empresa quiere utilizar una aplicación de software como servicio (SaaS) de terceros. La aplicación SaaS de terceros se consume a través de varias llamadas API. La aplicación SaaS de terceros también se ejecuta en AWS dentro de una VPC.
La compañía consumirá la aplicación SaaS de terceros desde dentro de una VPC. La compañía cuenta con políticas de seguridad interna que exigen el uso de conectividad privada que no atraviesa internet. No se permite acceder a los recursos que se ejecutan en la VPC de la empresa desde fuera de la VPC de la compañía. Todos los permisos deben ajustarse a los principios de menor privilegio.
Qué solución cumple con estos requisitos?
A.
Cree un punto de enlace de VPC de la interfaz AWS PrivateLink. Conecte este punto final al servicio de punto final que proporciona la aplicación SaaS de terceros. Cree un grupo de seguridad para limitar el acceso al punto final. Asociar el grupo de seguridad con el punto final.
B.
Cree una conexión VPN de sitio a sitio de AWS entre la aplicación SaaS de terceros y la VPC de la empresa. Configure las ACL de red para limitar el acceso a través de los túneles VPN.
C.
Cree una conexión de interconexión de VPC entre la aplicación SaaS de terceros y las tablas de rutas VPUpdate de la compañía agregando las rutas necesarias para la conexión de interconexión.
D.
Cree un servicio de endpoint de AWS PrivateLink. Solicite al proveedor SaaS externo que cree un punto final de VPC de interfaz para este servicio de punto final. Otorgar permisos para el servicio de punto final a la cuenta específica del proveedor externo de SaaS.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos de conectividad privada de la compañía que no atraviese internet, usar AWS PrivateLink es la solución más adecuada. Esta solución implica crear un endpoint de VPC de interfaz AWS PrivateLink y conectarlo al servicio de punto final proporcionado por la aplicación SaaS de terceros. Esta configuración permite a la empresa acceder a la aplicación SaaS de forma segura y privada dentro de la red de AWS, adhiriéndose a las políticas de seguridad internas. Adicionalmente, un grupo de seguridad puede limitar el acceso al punto final, asegurando el cumplimiento del principio de menor privilegio.
Question 13 of 529
Una empresa necesita implementar un proceso de parcheo para sus servidores. Los servidores locales y las instancias de Amazon EC2 utilizan una variedad de herramientas para realizar parches. La administración requiere un solo informe que muestre el estado de los parches de todos los servidores e instancias.
Qué conjunto de acciones debe tomar un arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice AWS Systems Manager para administrar parches en los servidores locales y en las instancias EC2. Utilice Systems Manager para generar informes de cumplimiento de parches.
B.
Utilice AWS OPSWorks para administrar parches en los servidores locales y en las instancias EC2. Utilice la integración de Amazon QuickSight con OPSWorks para generar informes de cumplimiento de parches.
C.
Utilice una regla de Amazon EventBridge para aplicar parches programando un trabajo de corrección de parches de AWS Systems Manager. Utilice Amazon Inspector para generar informes de cumplimiento de parches.
D.
Utilice AWS OPSWorks para administrar parches en los servidores locales y en las instancias EC2. Utilice AWS X-Ray para publicar el estado del parche en AWS Systems Manager OpsCenter para generar informes de cumplimiento de parches.
AnswerDiscussion
Correct Answer: A
AWS Systems Manager está diseñado para administrar parches tanto en servidores locales como en instancias EC2. También proporciona la capacidad de generar informes de cumplimiento de parches. Esto la convierte en la solución más adecuada para consolidar la información del estado de los parches en diversos entornos de servidores.
Question 14 of 529
Una empresa está ejecutando una aplicación en varias instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones. La carga en la aplicación varía a lo largo del día y las instancias EC2 se escalan de forma regular. Los archivos de registro de las instancias EC2 se copian en un bucket central de Amazon S3 cada 15 minutos. El equipo de seguridad descubre que faltan archivos de registro en algunas de las instancias EC2 terminadas.
Qué conjunto de acciones garantizará que los archivos de registro se copien en el bucket S3 central desde las instancias EC2 terminadas?
A.
Cree un script para copiar archivos de registro en Amazon S3 y almacene el script en un archivo en la instancia EC2. Cree un gancho de ciclo de vida de Auto Scaling y una regla de Amazon EventBridge para detectar eventos del ciclo de vida del grupo Auto Scaling. Invoque una función de AWS Lambda en la transición AutoScaling:EC2_instance_terminating para enviar ABANDON al grupo Auto Scaling para evitar la terminación, ejecute el script para copiar los archivos de registro y terminar la instancia con el SDK de AWS.
B.
Cree un documento de AWS Systems Manager con un script para copiar archivos de registro en Amazon S3. Cree un gancho de ciclo de vida de Auto Scaling y una regla de Amazon EventBridge para detectar eventos del ciclo de vida del grupo Auto Scaling. Invoque una función de AWS Lambda en la transición AutoScaling:EC2_instance_terminating para llamar a la operación SendCommand de la API de AWS Systems Manager para ejecutar el documento para copiar los archivos de registro y enviar CONTINUAR al grupo Auto Scaling para terminar la instancia.
C.
Cambie la tasa de entrega del registro a cada 5 minutos. Cree un script para copiar archivos de registro en Amazon S3 y agregue el script a los datos de usuario de la instancia EC2. Cree una regla de Amazon EventBridge para detectar la terminación de instancias EC2. Invoque una función de AWS Lambda desde la regla EventBridge que utiliza la CLI de AWS para ejecutar el script de datos de usuario para copiar los archivos de registro y terminar la instancia.
D.
Cree un documento de AWS Systems Manager con un script para copiar archivos de registro en Amazon S3. Cree un enlace de ciclo de vida de Auto Scaling que publique un mensaje en un tema de Amazon Simple Notification Service (Amazon SNS). Desde la notificación SNS, llame a la operación SendCommand de la API de AWS Systems Manager para ejecutar el documento para copiar los archivos de registro y enviar ABANDON al grupo Auto Scaling para terminar la instancia.
AnswerDiscussion
Correct Answer: B
Para garantizar que los archivos de registro se copien en el bucket central de S3 desde instancias EC2 terminadas, el mejor enfoque es utilizar los ganchos de ciclo de vida de AWS Systems Manager y Auto Scaling. Al crear un documento de Systems Manager con un script para copiar archivos de registro a S3 y emplear un gancho de ciclo de vida, las instancias pueden realizar las acciones necesarias antes de la terminación. El evento de transición EC2_INSTANCE_TERMINATING activa una función Lambda a través de EventBridge, que llama a la API de Systems Manager para ejecutar el documento, asegurando que los archivos de registro se copien antes de permitir que la terminación de la instancia continúe con una señal CONTINUAR. Este método maneja de manera eficiente la preservación del registro durante las actividades de escalado.
Question 15 of 529
Una empresa está utilizando varias cuentas de AWS. Los registros DNS se almacenan en una zona privada alojada para Amazon Route 53 en la Cuenta A. Las aplicaciones y bases de datos de la compañía se ejecutan en la Cuenta B.
Un arquitecto de soluciones implementará una aplicación de dos niveles en una nueva VPC. Para simplificar la configuración, se creó el conjunto de registros CNAME db.example.com para el endpoint de Amazon RDS en una zona alojada privada para Amazon Route 53.
Durante la implementación, la aplicación no pudo iniciarse. La solución de problemas reveló que db.example.com no se puede resolver en la instancia de Amazon EC2. El arquitecto de soluciones confirmó que el conjunto de registros fue creado correctamente en la Ruta 53.
Qué combinación de pasos debe tomar el arquitecto de soluciones para resolver este problema? (Elija dos.)
A.
Implemente la base de datos en una instancia EC2 separada en la nueva VPC. Crear un conjunto de registros para la IP privada de la instancia en la zona privada alojada.
B.
Utilice SSH para conectarse a la instancia EC2 de nivel de aplicación. Agregue una dirección IP de punto final de RDS al archivo /etc/resolv.conf.
C.
Crear una autorización para asociar la zona privada alojada en la Cuenta A con la nueva VPC en la Cuenta B.
D.
Cree una zona alojada privada para el dominio com de ejemplo en la cuenta B. Configure la replicación de Route 53 entre cuentas de AWS.
E.
Asociar una nueva VPC en la Cuenta B con una zona alojada en la Cuenta A. Eliminar la autorización de asociación en la Cuenta A.
AnswerDiscussion
Correct Answer: C, E
En una configuración de AWS multicuenta, son necesarios los pasos adecuados de autorización y asociación para garantizar la resolución de DNS en todas las VPC en diferentes cuentas. En primer lugar, se requiere crear una autorización para asociar la zona hospedada privada en la Cuenta A con la nueva VPC en la Cuenta B. Esto permite que la VPC en la Cuenta B esté autorizada para usar la zona alojada en la Cuenta A. En segundo lugar, después de la autorización, la nueva VPC en la Cuenta B necesita asociarse con la zona alojada privada en la Cuenta A. Eliminar posteriormente la autorización de asociación en la Cuenta A es una buena práctica para evitar la recreación involuntaria de la misma asociación. Esto asegura que el nombre DNS db.example.com se pueda resolver desde las instancias EC2 en la Cuenta B, resolviendo así el problema.
Question 16 of 529
Una empresa utilizó instancias de Amazon EC2 para implementar una flota web para alojar un sitio de blog. Las instancias EC2 están detrás de un balanceador de carga de aplicaciones (ALB) y se configuran en un grupo de Auto Scaling. La aplicación web almacena todo el contenido del blog en un volumen de Amazon EFS.
La compañía agregó recientemente una función para que los bloggers agreguen video a sus publicaciones, atrayendo 10 veces el tráfico de usuarios anterior. En las horas pico del día, los usuarios reportan problemas de almacenamiento en búfer y tiempo de espera mientras intentan llegar al sitio o ver videos.
Cuál es la implementación más rentable y escalable que resolverá los problemas para los usuarios?
A.
Reconfigure Amazon EFS para habilitar el máximo de E/S.
B.
Actualice el sitio del blog para usar volúmenes de almacén de instancias para el almacenamiento. Copie el contenido del sitio a los volúmenes en el momento del lanzamiento y a Amazon S3 en el momento del cierre.
C.
Configure una distribución de Amazon CloudFront. Apunte la distribución a un bucket S3 y migre los videos de EFS a Amazon S3.
D.
Configure una distribución de Amazon CloudFront para todos los contenidos del sitio y señale la distribución al ALB.
AnswerDiscussion
Correct Answer: C
Para abordar los problemas de almacenamiento en búfer y tiempo de espera debido al aumento del tráfico de usuarios y al contenido de video, el mejor enfoque es configurar una distribución de Amazon CloudFront y migrar los videos de EFS a Amazon S3. CloudFront, al ser una CDN, almacena en caché el contenido en ubicaciones perimetrales cercanas a los usuarios, reduciendo la latencia y mejorando los tiempos de carga. Amazon S3 proporciona almacenamiento escalable y de alto rendimiento adecuado para grandes cantidades de contenido de video, resolviendo así los problemas de rendimiento de manera más rentable y eficiente en comparación con otras opciones.
Question 17 of 529
Una empresa con oficinas globales tiene una única conexión AWS Direct Connect de 1 Gbps a una sola región de AWS. La red local de la compañía utiliza la conexión para comunicarse con los recursos de la compañía en la nube de AWS. La conexión tiene una única interfaz virtual privada que se conecta a una sola VPC.
Un arquitecto de soluciones debe implementar una solución que agregue una conexión Direct Connect redundante en la misma región. La solución también debe proporcionar conectividad a otras Regiones a través del mismo par de conexiones Direct Connect a medida que la compañía se expande a otras Regiones.
Qué solución cumple con estos requisitos?
A.
Aprovisione una puerta de enlace Direct Connect. Eliminar la interfaz virtual privada existente de la conexión existente. Cree la segunda conexión Direct Connect. Cree una nueva interfaz virtual privada en cada conexión y conecte ambas interfaces virtuales privadas a la puerta de enlace Direct Connect. Conecte la puerta de enlace Direct Connect a la única VPC.
B.
Mantener la interfaz virtual privada existente. Cree la segunda conexión Direct Connect. Cree una nueva interfaz virtual privada en la nueva conexión y conecte la nueva interfaz virtual privada a la única VPC.
C.
Mantener la interfaz virtual privada existente. Cree la segunda conexión Direct Connect. Cree una nueva interfaz virtual pública en la nueva conexión y conecte la nueva interfaz virtual pública a la única VPC.
D.
Aprovisione una puerta de enlace de tránsito. Eliminar la interfaz virtual privada existente de la conexión existente. Cree la segunda conexión Direct Connect. Cree una nueva interfaz virtual privada en cada conexión y conecte ambas interfaces virtuales privadas a la puerta de enlace de tránsito. Asocie la puerta de enlace de tránsito con la única VPC.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos de implementar una conexión Direct Connect redundante en la misma región y permitir la conectividad a otras regiones a través del mismo par de conexiones, la mejor solución es aprovisionar una puerta de enlace Direct Connect. Una puerta de enlace Direct Connect le permite conectar varias VPC y redes locales en diferentes cuentas y regiones a una sola conexión Direct Connect. Al eliminar la interfaz virtual privada existente de la conexión actual, crear la nueva conexión y establecer nuevas interfaces virtuales privadas en ambas conexiones que se conectan a la puerta de enlace Direct Connect, puede garantizar la redundancia y la capacidad de expandirse a otras regiones mientras mantiene la conectividad a través de la misma infraestructura. Este enfoque proporciona capacidades de conmutación por error automática y enrutamiento, lo que lo convierte en una solución robusta para los requisitos de la compañía.
Question 18 of 529
Una empresa cuenta con una aplicación web que permite a los usuarios subir videos cortos. Los videos se almacenan en volúmenes de Amazon EBS y se analizan mediante un software de reconocimiento personalizado para su categorización.
El sitio web contiene contenido estático que tiene tráfico variable con picos en ciertos meses. La arquitectura consiste en instancias de Amazon EC2 que se ejecutan en un grupo de Auto Scaling para la aplicación web e instancias EC2 que se ejecutan en un grupo de Auto Scaling para procesar una cola de Amazon SQS. La compañía quiere rediseñar la aplicación para reducir la sobrecarga operativa utilizando los servicios administrados de AWS cuando sea posible y eliminar las dependencias del software de terceros.
Qué solución cumple con estos requisitos?
A.
Utilice contenedores de Amazon ECS para la aplicación web e instancias puntuales para el grupo Auto Scaling que procesa la cola SQS. Reemplace el software personalizado con Amazon Rekognition para categorizar los videos.
B.
Almacene los videos cargados en Amazon EFS y monte el sistema de archivos en las instancias EC2 para la aplicación web. Procese la cola SQS con una función de AWS Lambda que llama a la API de Amazon Rekognition para categorizar los videos.
C.
Aloje la aplicación web en Amazon S3. Almacena los videos subidos en Amazon S3. Utilice la notificación de eventos S3 para publicar eventos en la cola SQS. Procese la cola SQS con una función de AWS Lambda que llama a la API de Amazon Rekognition para categorizar los videos.
D.
Utilice AWS Elastic Beanstalk para lanzar instancias EC2 en un grupo de Auto Scaling para la aplicación web y lanzar un entorno de trabajo para procesar la cola de SQS. Reemplace el software personalizado con Amazon Rekognition para categorizar los videos.
AnswerDiscussion
Correct Answer: C
La mejor solución es alojar la aplicación web en Amazon S3, que es ideal para contenido estático y puede escalar para manejar el tráfico variable de manera eficiente. Los videos subidos también deben almacenarse en Amazon S3. Mediante el uso de notificaciones de eventos S3 para publicar eventos en la cola SQS, los videos pueden ser procesados por una función de AWS Lambda que llama a la API de Amazon Rekognition para categorizar los videos. Esta solución aprovecha los servicios administrados de AWS, reduce la necesidad de administrar instancias EC2 y software personalizado, y cumple con el requisito de minimizar la sobrecarga operativa.
Question 19 of 529
Una empresa tiene una aplicación sin servidor compuesta por funciones de Amazon CloudFront, Amazon API Gateway y AWS Lambda. El proceso de implementación actual del código de la aplicación consiste en crear un nuevo número de versión de la función Lambda y ejecutar un script de AWS CLI para actualizar. Si la nueva versión de la función tiene errores, otro script CLI revierte desplegando la versión anterior de trabajo de la función. A la compañía le gustaría disminuir el tiempo para implementar nuevas versiones de la lógica de la aplicación que proporcionan las funciones de Lambda, y también reducir el tiempo para detectar y revertir cuando se identifican errores.
Cómo se puede lograr esto?
A.
Cree e implemente pilas anidadas de AWS CloudFormation con la pila principal que consiste en la distribución de AWS CloudFront y API Gateway, y la pila secundaria que contiene la función Lambda. Para los cambios en Lambda, cree un conjunto de cambios de AWS CloudFormation e implemente; si se activan errores, vuelva el conjunto de cambios de AWS CloudFormation a la versión anterior.
B.
Utilice AWS SAM y AWS CodeDeploy integrado para implementar la nueva versión de Lambda, cambiar gradualmente el tráfico a la nueva versión y usar funciones de prueba previas al tráfico y posteriores al tráfico para verificar el código. Reversión si se activan las alarmas de Amazon CloudWatch.
C.
Refactorizar los scripts de la CLI de AWS en un único script que despliega la nueva versión de Lambda. Cuando se completa la implementación, se ejecutan las pruebas de script. Si se detectan errores, vuelva a la versión anterior de Lambda.
D.
Cree e implemente una pila de AWS CloudFormation que consiste en un nuevo endpoint de API Gateway que haga referencia a la nueva versión de Lambda. Cambie el origen de CloudFront al nuevo punto final de API Gateway, supervise los errores y, si se detectan, cambie el origen de AWS CloudFront al endpoint de API Gateway anterior.
AnswerDiscussion
Correct Answer: B
El uso de AWS SAM (Serverless Application Model) junto con AWS CodeDeploy permite un proceso de implementación más ágil y eficiente. AWS SAM proporciona el marco para construir, probar e implementar aplicaciones sin servidor mientras aprovecha AWS CodeDeploy para administrar el despliegue de nuevas versiones de la función Lambda. Al cambiar gradualmente el tráfico a la nueva versión y usar las funciones de prueba previas al tráfico y posteriores al tráfico para verificar el código, reduce el tiempo de inactividad y garantiza la funcionalidad antes de comprometerse completamente con la nueva versión. Si se detectan errores, el sistema puede retroceder automáticamente a la versión anterior mediante alarmas CloudWatch. Este método disminuye significativamente el tiempo necesario para implementar nuevas versiones y acelera la detección de errores y la reversión, lo que hace que el proceso de implementación sea más rápido y confiable.
Question 20 of 529
Una empresa planea almacenar una gran cantidad de documentos archivados y poner los documentos a disposición de los empleados a través de la intranet corporativa. Los empleados accederán al sistema conectándose a través de un servicio VPN cliente que está conectado a una VPC. Los datos no deben ser accesibles al público.
Los documentos que la empresa está almacenando son copias de datos que se guardan en medios físicos en otros lugares. El número de solicitudes será bajo. La disponibilidad y la velocidad de recuperación no son preocupaciones de la empresa.
Qué solución cumplirá con estos requisitos al menor costo?
A.
Cree un bucket de Amazon S3. Configure el bucket S3 para usar la clase de almacenamiento S3 One Zone-Infrequent Access (S3 One Zone-IA) como predeterminada. Configure el bucket S3 para el alojamiento de sitios web. Cree un punto final de interfaz S3. Configure el bucket S3 para permitir el acceso solo a través de ese punto final.
B.
Inicie una instancia de Amazon EC2 que ejecute un servidor web. Adjunte un sistema de archivos de Amazon Elastic File System (Amazon EFS) para almacenar los datos archivados en la clase de almacenamiento EFS One Zone-Infrequent Access (EFS One Zone-IA) Configure los grupos de seguridad de instancias para permitir el acceso solo desde redes privadas.
C.
Inicie una instancia de Amazon EC2 que ejecute un servidor web Adjunte un volumen de Amazon Elastic Block Store (Amazon EBS) para almacenar los datos archivados. Utilice el tipo de volumen Cold HDD (sc1). Configure los grupos de seguridad de instancias para permitir el acceso solo desde redes privadas.
D.
Cree un bucket de Amazon S3. Configure el bucket S3 para usar la clase de almacenamiento S3 Glacier Deep Archive como predeterminada. Configure el bucket S3 para el alojamiento de sitios web. Cree un punto final de interfaz S3. Configure el bucket S3 para permitir el acceso solo a través de ese punto final.
AnswerDiscussion
Correct Answer: A
La mejor solución para almacenar una gran cantidad de documentos archivados, asegurando que solo se acceda a ellos a través de una VPN sin estar disponibles públicamente, es usar Amazon S3 con la clase de almacenamiento S3 One Zone-Infrequent Access (S3 One Zone-IA). Esta opción cumple con el requisito de almacenamiento de bajo costo ya que los datos se accede con poca frecuencia, y la disponibilidad y la velocidad no son preocupaciones. S3 One Zone-IA proporciona una solución rentable para datos a los que se accede con poca frecuencia que no requieren la alta disponibilidad de clases de almacenamiento estándar. La configuración del bucket para el acceso a través de un punto final de interfaz S3 garantiza que los datos permanezcan accesibles solo dentro de la VPC, manteniendo la seguridad y la privacidad.
Question 21 of 529
Una compañía está utilizando un servicio de Active Directory local para la autenticación de usuarios. La compañía quiere utilizar el mismo servicio de autenticación para iniciar sesión en las cuentas de AWS de la compañía, que están utilizando AWS Organizations. La conectividad VPN de sitio a sitio de AWS ya existe entre el entorno local y todas las cuentas de AWS de la compañía.
La política de seguridad de la compañía requiere el acceso condicional a las cuentas en función de grupos de usuarios y roles. Las identidades de usuario deben ser administradas en una sola ubicación.
Qué solución cumplirá con estos requisitos?
A.
Configure AWS IAM Identity Center (AWS Single Sign-On) para conectarse a Active Directory mediante SAML 2.0. Habilite el aprovisionamiento automático mediante el protocolo System for Cross-domain Identity Management (SCIM) v2.0. Otorgue acceso a las cuentas de AWS mediante controles de acceso basados en atributos (ABAC).
B.
Configure AWS IAM Identity Center (AWS Single Sign-On) mediante IAM Identity Center como fuente de identidad. Habilite el aprovisionamiento automático mediante el protocolo System for Cross-domain Identity Management (SCIM) v2.0. Otorgue acceso a las cuentas de AWS mediante conjuntos de permisos de IAM Identity Center.
C.
En una de las cuentas de AWS de la compañía, configure AWS Identity and Access Management (IAM) para usar un proveedor de identidad SAML 2.0. Aprovisione a los usuarios de IAM que están asignados a los usuarios federados. Otorgar acceso que corresponda a grupos apropiados en Active Directory. Otorgue acceso a las cuentas de AWS requeridas mediante el uso de usuarios de IAM entre cuentas.
D.
En una de las cuentas de AWS de la compañía, configure AWS Identity and Access Management (IAM) para usar un proveedor de identidad OpenID Connect (OIDC). Aprovisione roles de IAM que concedan acceso a la cuenta de AWS para los usuarios federados que corresponden a grupos apropiados en Active Directory. Otorgue acceso a las cuentas de AWS requeridas mediante roles de IAM entre cuentas.
AnswerDiscussion
Correct Answer: A
La solución correcta implica el uso de AWS IAM Identity Center (AWS Single Sign-On) para conectarse a Active Directory local a través de SAML 2.0. Esta configuración permite a la empresa utilizar su servicio de autenticación de usuario existente para cuentas de AWS. Al habilitar el aprovisionamiento automático mediante el protocolo System for Cross-domain Identity Management (SCIM) v2.0, garantiza que las identidades de los usuarios se administren en una sola ubicación. Otorgar acceso a cuentas de AWS mediante controles de acceso basados en atributos (ABAC) proporciona el acceso condicional requerido basado en grupos de usuarios y roles, alineándose con la política de seguridad de la compañía.
Question 22 of 529
Una compañía de software ha implementado una aplicación que consume una API REST mediante el uso de Amazon API Gateway, funciones de AWS Lambda y una tabla de Amazon DynamoDB. La aplicación está mostrando un incremento en el número de errores durante las solicitudes PUT. La mayoría de las llamadas PUT provienen de un pequeño número de clientes que se autentican con claves API específicas.
Un arquitecto de soluciones ha identificado que una gran cantidad de solicitudes PUT provienen de un cliente. La API no es crítica y los clientes pueden tolerar reintentos de llamadas fallidas. Sin embargo, los errores se muestran a los clientes y están causando daños a la reputación de la API.
Qué debería recomendar el arquitecto de soluciones para mejorar la experiencia del cliente?
A.
Implementar lógica de reintento con retroceso exponencial y variación irregular en la aplicación cliente. Asegúrese de que los errores sean capturados y manejados con mensajes de error descriptivos.
B.
Implemente la regulación de API a través de un plan de uso a nivel de API Gateway. Asegúrese de que la aplicación cliente maneja las respuestas del código 429 sin errores.
C.
Active el almacenamiento en caché de API para mejorar la capacidad de respuesta para la etapa de producción. Ejecute pruebas de carga de 10 minutos. Verifique que la capacidad de caché sea adecuada para la carga de trabajo.
D.
Implementar concurrencia reservada a nivel de función Lambda para proporcionar los recursos que se necesitan durante aumentos repentinos en el tráfico.
AnswerDiscussion
Correct Answer: B
Para administrar el alto volumen de solicitudes PUT provenientes de un solo cliente y que causan errores, la mejor solución es implementar la limitación de API a través de un plan de uso a nivel API Gateway. Este enfoque limitará efectivamente el número de solicitudes que un cliente puede realizar, reduciendo la ocurrencia de errores. Asegurar que la aplicación cliente maneja correctamente las respuestas del código 429 sin errores proporcionará una mejor experiencia para los usuarios y ayudará a mantener la reputación de la API.
Question 23 of 529
Una empresa está ejecutando una aplicación de uso intensivo de datos en AWS. La aplicación se ejecuta en un clúster de cientos de instancias de Amazon EC2. Un sistema de archivos compartidos también se ejecuta en varias instancias EC2 que almacenan 200 TB de datos. La aplicación lee y modifica los datos del sistema de archivos compartidos y genera un informe. El trabajo se ejecuta una vez al mes, lee un subconjunto de los archivos del sistema de archivos compartidos y tarda aproximadamente 72 horas en completarse. Las instancias de cómputos se escalan en un grupo de Auto Scaling, pero las instancias que alojan el sistema de archivos compartido se ejecutan continuamente. Las instancias de cómputos y almacenamiento están todas en la misma región de AWS.
Un arquitecto de soluciones necesita reducir costos reemplazando las instancias de file system compartidas. El sistema de archivos debe proporcionar acceso de alto rendimiento a los datos necesarios durante la ejecución de 72 horas.
Qué solución proporcionará la mayor reducción de costos generales al tiempo que cumple con estos requisitos?
A.
Migre los datos del sistema de archivos compartidos existente a un bucket de Amazon S3 que utilice la clase de almacenamiento S3 Intelligent-Tiering. Antes de que el trabajo se ejecute cada mes, use Amazon FSx for Lustre para crear un nuevo sistema de archivos con los datos de Amazon S3 mediante el uso de carga diferida. Utilice el nuevo sistema de archivos como almacenamiento compartido mientras dure el trabajo. Eliminar el sistema de archivos cuando el trabajo esté completo.
B.
Migre los datos del sistema de archivos compartidos existente a un volumen grande de Amazon Elastic Block Store (Amazon EBS) con conexión múltiple habilitada. Adjunte el volumen de EBS a cada una de las instancias mediante un script de datos de usuario en la plantilla de inicio de grupo de Auto Scaling. Utilice el volumen de EBS como almacenamiento compartido durante la duración del trabajo. Separar el volumen de EBS cuando se complete el trabajo
C.
Migre los datos del sistema de archivos compartidos existente a un bucket de Amazon S3 que utilice la clase de almacenamiento S3 Standard. Antes de que el trabajo se ejecute cada mes, use Amazon FSx for Lustre para crear un nuevo sistema de archivos con los datos de Amazon S3 mediante la carga por lotes. Utilice el nuevo sistema de archivos como almacenamiento compartido mientras dure el trabajo. Eliminar el sistema de archivos cuando el trabajo esté completo.
D.
Migre los datos del sistema de archivos compartidos existente a un bucket de Amazon S3. Antes de que el trabajo se ejecute cada mes, use AWS Storage Gateway para crear una puerta de enlace de archivos con los datos de Amazon S3. Utilice la puerta de enlace de archivos como almacenamiento compartido para el trabajo. Elimine la puerta de enlace de archivos cuando el trabajo esté completo.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de reducir costos y mantener el acceso de alto rendimiento durante 72 horas de ejecución, migrar los datos a un bucket de Amazon S3 utilizando la clase de almacenamiento S3 Intelligent-Tiering es una solución óptima. Esta clase mueve automáticamente los datos a los que se accede con poca frecuencia a niveles de almacenamiento de información de menor costo, lo que reduce significativamente los costos. El uso de Amazon FSx for Lustre para crear un nuevo sistema de archivos con los datos de Amazon S3 con carga diferida permite que los datos se carguen bajo demanda, lo que significa que solo se accederán y cargarán los datos que realmente se necesitan durante el trabajo, optimizando aún más los costos. Eliminar el sistema de archivos después del trabajo asegura que los costos solo se incurren durante la duración del trabajo, no continuamente. Este enfoque aprovecha tanto la rentabilidad como el alto rendimiento, convirtiéndolo en la mejor opción.
Question 24 of 529
Una compañía está desarrollando un nuevo servicio al que se accederá usando TCP en un puerto estático. Un arquitecto de soluciones debe asegurarse de que el servicio esté altamente disponible, tenga redundancia en todas las zonas de disponibilidad y sea accesible usando el nombre DNS my.service.com, que es de acceso público. El servicio debe usar asignaciones de direcciones fijas para que otras empresas puedan agregar las direcciones a sus listas de permisos.
Suponiendo que los recursos se implementen en varias zonas de disponibilidad en una sola región, qué solución cumplirá con estos requisitos?
A.
Cree instancias de Amazon EC2 con una dirección IP elástica para cada instancia. Cree un balanceador de carga de red (NLB) y exponga el puerto TCP estático. Registre instancias EC2 con el NLB. Cree un nuevo conjunto de registros del servidor de nombres llamado my.service.com y asigne las direcciones IP elásticas de las instancias EC2 al conjunto de registros. Proporcione las direcciones IP elásticas de las instancias EC2 a las otras compañías para agregarlas a sus listas de permisos.
B.
Cree un clúster de Amazon ECS y una definición de servicio para la aplicación. Cree y asigne direcciones IP públicas para el clúster ECS. Cree un balanceador de carga de red (NLB) y exponga el puerto TCP. Cree un grupo de destino y asigne el nombre del clúster ECS al NLCree un nuevo conjunto de registros A llamado my.service.com y asigne las direcciones IP públicas del clúster ECS al conjunto de registros. Proporcionar las direcciones IP públicas del clúster ECS a las otras empresas para agregarlas a sus listas de permisos.
C.
Cree instancias de Amazon EC2 para el servicio. Cree una dirección IP elástica para cada zona de disponibilidad. Cree un balanceador de carga de red (NLB) y exponga el puerto TCP asignado. Asigne las direcciones IP elásticas al NLB para cada zona de disponibilidad. Cree un grupo objetivo y registre las instancias EC2 con el NLB. Cree un nuevo conjunto de registros A (alias) llamado my.service.com y asigne el nombre DNS NLB al conjunto de registros.
D.
Cree un clúster de Amazon ECS y una definición de servicio para la aplicación. Crear y asignar una dirección IP pública para cada host del clúster. Cree un balanceador de carga de aplicaciones (ALB) y exponga el puerto TCP estático. Cree un grupo objetivo y asigne el nombre de definición de servicio ECS al ALB. Cree un nuevo conjunto de registros CNAME y asocie las direcciones IP públicas al conjunto de registros. Proporcione las direcciones IP elásticas de las instancias de Amazon EC2 a las otras empresas para agregarlas a sus listas de permisos.
AnswerDiscussion
Correct Answer: C
Para garantizar una alta disponibilidad y redundancia en varias zonas de disponibilidad, el servicio debe distribuirse mediante un balanceador de carga de red (NLB), que admite el tráfico TCP. Al asignar direcciones IP elásticas al NLB para cada Zona de Disponibilidad, el servicio obtiene asignaciones de direcciones fijas que se pueden agregar para permitir listas por otras compañías. Además, al registrar instancias de Amazon EC2 con el NLB y crear un registro A (alias) que apunte al nombre DNS del NLB, el servicio se vuelve accesible a través del dominio my.service.com especificado.
Question 25 of 529
Una empresa utiliza una plataforma de análisis de datos local. El sistema está altamente disponible en una configuración completamente redundante en 12 servidores en el centro de datos de la compañía.
El sistema ejecuta trabajos programados, tanto por hora como diariamente, además de solicitudes únicas de los usuarios. Los trabajos programados pueden tardar entre 20 minutos y 2 horas en terminar de funcionar y tener SLA ajustados. Los trabajos programados representan el 65% del uso del sistema. Los trabajos de usuario generalmente terminan de ejecutarse en menos de 5 minutos y no tienen SLA. Los trabajos de usuario representan el 35% del uso del sistema. Durante fallas del sistema, los trabajos programados deben continuar cumpliendo con los SLA. Sin embargo, los trabajos de usuario pueden retrasarse.
Un arquitecto de soluciones necesita trasladar el sistema a instancias de Amazon EC2 y adoptar un modelo basado en el consumo para reducir costos sin compromisos a largo plazo. La solución debe mantener alta disponibilidad y no debe afectar a los SLA.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Divida las 12 instancias en dos zonas de disponibilidad en la región de AWS elegida. Ejecute dos instancias en cada zona de disponibilidad como instancias bajo demanda con reservas de capacidad. Ejecute cuatro instancias en cada zona de disponibilidad como instancias puntuales.
B.
Divida las 12 instancias en tres zonas de disponibilidad en la región de AWS elegida. En una de las zonas de disponibilidad, ejecute las cuatro instancias como instancias bajo demanda con reservas de capacidad. Ejecute las instancias restantes como Instancias puntuales.
C.
Divida las 12 instancias en tres zonas de disponibilidad en la región de AWS elegida. Ejecute dos instancias en cada zona de disponibilidad como instancias bajo demanda con un plan de ahorro. Ejecute dos instancias en cada zona de disponibilidad como instancias puntuales.
D.
Divida las 12 instancias en tres zonas de disponibilidad en la región de AWS elegida. Ejecute tres instancias en cada zona de disponibilidad como instancias bajo demanda con reservas de capacidad. Ejecute una instancia en cada zona de disponibilidad como instancia de spot.
AnswerDiscussion
Correct Answer: D
La solución correcta debe garantizar una alta disponibilidad, cumplir con el 65% del SLA para trabajos programados y ser rentable. Dividir las 12 instancias en tres zonas de disponibilidad mejora la redundancia. La ejecución de tres instancias en cada AZ como instancias bajo demanda con reservas de capacidad garantiza que siempre haya suficiente capacidad para cumplir con los SLA incluso durante las interrupciones. La capacidad restante requerida puede ser manejada por una instancia de spot por AZ, lo que ofrece ahorros de costos sin afectar la disponibilidad general. Esta configuración proporciona un equilibrio de disponibilidad garantizada para trabajos programados y ahorros de costos para trabajos de usuario.
Question 26 of 529
Un ingeniero de seguridad determinó que una aplicación existente recupera las credenciales de una base de datos de Amazon RDS para MySQL a partir de un archivo cifrado en Amazon S3. Para la siguiente versión de la aplicación, el ingeniero de seguridad quiere implementar los siguientes cambios en el diseño de la aplicación para mejorar la seguridad:
La base de datos debe utilizar contraseñas seguras generadas aleatoriamente almacenadas en un servicio seguro administrado por AWS.
Los recursos de la aplicación deben implementarse a través de AWS CloudFormation.
La aplicación debe rotar las credenciales para la base de datos cada 90 días.
Un arquitecto de soluciones generará una plantilla de CloudFormation para implementar la aplicación.
Qué recursos especificados en la plantilla de CloudFormation cumplirán con los requisitos del ingeniero de seguridad con la MENOR cantidad de sobrecarga operativa?
A.
Genere la contraseña de la base de datos como recurso secreto utilizando AWS Secrets Manager. Cree un recurso de función de AWS Lambda para rotar la contraseña de la base de datos. Especifique un recurso Secrets Manager RotationSchedule para rotar la contraseña de la base de datos cada 90 días.
B.
Genere la contraseña de la base de datos como un tipo de parámetro SecureString con AWS Systems Manager Parameter Store. Cree un recurso de función de AWS Lambda para rotar la contraseña de la base de datos. Especifique un recurso Parameter Store RotationSchedule para rotar la contraseña de la base de datos cada 90 días.
C.
Genere la contraseña de la base de datos como recurso secreto utilizando AWS Secrets Manager. Cree un recurso de función de AWS Lambda para rotar la contraseña de la base de datos. Cree un recurso de regla programado de Amazon EventBridge para activar la rotación de contraseñas de la función Lambda cada 90 días.
D.
Genere la contraseña de la base de datos como un tipo de parámetro SecureString con AWS Systems Manager Parameter Store. Especifique un recurso de AWS AppSync DataSource para rotar automáticamente la contraseña de la base de datos cada 90 días.
AnswerDiscussion
Correct Answer: A
AWS Secrets Manager está diseñado para almacenar y administrar secretos, como credenciales de bases de datos, e incluye soporte integrado para la rotación automatizada de secretos. Al generar la contraseña de la base de datos como secreto en AWS Secrets Manager y especificar un recurso Secrets Manager RotationSchedule, el requisito de rotación automática de contraseñas cada 90 días se puede cumplir fácilmente. Este enfoque aprovecha las capacidades nativas de AWS para minimizar la sobrecarga operativa, lo que garantiza una administración de credenciales segura y eficiente. Otras opciones, como el uso de AWS Systems Manager Parameter Store, no tienen características de rotación secreta integradas y requerirían lógica personalizada adicional, aumentando la complejidad.
Question 27 of 529
Una empresa está almacenando datos en varias tablas de Amazon DynamoDB. Un arquitecto de soluciones debe usar una arquitectura sin servidor para hacer que los datos sean accesibles públicamente a través de una API simple a través de HTTPS. La solución debe escalar automáticamente en respuesta a la demanda.
Qué soluciones cumplen con estos requisitos? (Elija dos.)
A.
Cree una API REST de Amazon API Gateway. Configure esta API con integraciones directas a DynamoDB mediante el tipo de integración de AWS de API Gateway.
B.
Cree una API HTTP de Amazon API Gateway. Configure esta API con integraciones directas a Dynamo DB mediante el tipo de integración de AWS de API Gateway.
C.
Cree una API HTTP de Amazon API Gateway. Configure esta API con integraciones a funciones de AWS Lambda que devuelven datos de las tablas de DynamoDB.
D.
Cree un acelerador en AWS Global Accelerator. Configure este acelerador con integraciones de funciones AWS Lambda @Edge que devuelven datos de las tablas de DynamoDB.
E.
Cree un balanceador de carga de red. Configure reglas de escucha para reenviar solicitudes a las funciones de AWS Lambda adecuadas.
AnswerDiscussion
Correct Answer: A, C
Para crear una API simple a través de HTTPS accesible públicamente y capaz de escalar automáticamente, puede usar Amazon API Gateway. La opción A implica crear una API REST con integraciones directas a DynamoDB mediante el tipo de integración de AWS de API Gateway, que permite un acceso eficiente y directo a los datos de DynamoDB. La opción C implica el uso de una API HTTP integrada con funciones de AWS Lambda que acceden a las tablas de DynamoDB, aprovechando la flexibilidad y las capacidades de escalado automático de Lambda. El uso conjunto de estas dos opciones garantiza una arquitectura robusta y escalable sin servidor.
Question 28 of 529
Una empresa ha registrado 10 nuevos nombres de dominio. La compañía utiliza los dominios para el marketing en línea. La empresa necesita una solución que redirija a los visitantes en línea a una URL específica para cada dominio. Todos los dominios y direcciones URL de destino se definen en un documento JSON. Todos los registros DNS son administrados por Amazon Route 53.
Un arquitecto de soluciones debe implementar un servicio de redireccionamiento que acepte solicitudes HTTP y HTTPS.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos con la MENOR cantidad de esfuerzo operativo? (Elija tres.)
A.
Cree una página web dinámica que se ejecute en una instancia de Amazon EC2. Configure la página web para usar el documento JSON en combinación con el mensaje del evento para buscar y responder con una URL de redirección.
B.
Cree un balanceador de carga de aplicaciones que incluya oyentes HTTP y HTTPS.
C.
Cree una función de AWS Lambda que utilice el documento JSON en combinación con el mensaje de evento para buscar y responder con una URL de redirección.
D.
Utilice una API de Amazon API Gateway con un dominio personalizado para publicar una función de AWS Lambda.
E.
Cree una distribución de Amazon CloudFront. Desplegar una función Lambda @Edge.
F.
Cree un certificado SSL mediante AWS Certificate Manager (ACM). Incluir los dominios como Nombres Alternativos de Sujeto.
AnswerDiscussion
Correct Answer: C, D, F
Para cumplir con los requisitos con la menor cantidad de esfuerzo operativo, el arquitecto de soluciones debe implementar los siguientes pasos: Crear una función de AWS Lambda que utilice el documento JSON en combinación con el mensaje del evento para buscar y responder con una URL de redirección. Esto reduce la dependencia de los servidores web tradicionales. Utilice una API de Amazon API Gateway con un dominio personalizado para publicar la función AWS Lambda, lo que facilitará la redirección de solicitudes HTTP y HTTPS. API Gateway administra el oyente HTTPS por usted, reduciendo aún más la complejidad operativa. Cree un certificado SSL mediante AWS Certificate Manager (ACM) e incluya los dominios como nombres alternativos del sujeto para garantizar que las solicitudes HTTPS seguras se puedan manejar correctamente.
Question 29 of 529
Una empresa que tiene varias cuentas de AWS está utilizando AWS Organizations. Las cuentas de AWS de la compañía alojan VPC, instancias de Amazon EC2 y contenedores.
El equipo de cumplimiento de la compañía ha implementado una herramienta de seguridad en cada VPC donde la compañía tiene implementaciones. Las herramientas de seguridad se ejecutan en instancias EC2 y envían información a la cuenta de AWS dedicada al equipo de cumplimiento. La compañía ha etiquetado todos los recursos relacionados con el cumplimiento con una clave de “CostCenter” y un valor o “cumplimiento”.
La compañía quiere identificar el costo de las herramientas de seguridad que se ejecutan en las instancias EC2 para que la compañía pueda cobrar la cuenta de AWS del equipo de cumplimiento. El cálculo de costos debe ser lo más preciso posible.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
En la cuenta de administración de la organización, active la etiqueta definida por el usuario de CostCenter. Configure informes mensuales de costos y uso de AWS para guardarlos en un bucket de Amazon S3 en la cuenta de administración. Utilice el desglose de etiquetas en el informe para obtener el costo total de los recursos etiquetados de CostCenter.
B.
En las cuentas de miembro de la organización, active la etiqueta definida por el usuario de CostCenter. Configure informes mensuales de costos y uso de AWS para guardarlos en un bucket de Amazon S3 en la cuenta de administración. Programe una función mensual de AWS Lambda para recuperar los informes y calcular el costo total de los recursos etiquetados de CostCenter.
C.
En las cuentas de miembro de la organización, active la etiqueta definida por el usuario de CostCenter. Desde la cuenta de administración, programe un informe mensual de costos y uso de AWS. Utilice el desglose de etiquetas en el informe para calcular el costo total de los recursos etiquetados de CostCenter.
D.
Cree un informe personalizado en la vista de organización en AWS Trusted Advisor. Configure el informe para generar un resumen de facturación mensual para los recursos etiquetados de CostCenter en la cuenta de AWS del equipo de cumplimiento.
AnswerDiscussion
Correct Answer: A
Para identificar y rastrear con precisión los costos asociados con las herramientas de seguridad que se ejecutan en instancias EC2 en varias cuentas de AWS, la cuenta de administración en AWS Organizations debe activar la etiqueta definida por el usuario de CostCenter. Al configurar los informes mensuales de costos y uso de AWS para ahorrar en un bucket de Amazon S3 en la cuenta de administración, la compañía puede aprovechar la función de desglose de etiquetas en estos informes para obtener el costo total de los recursos etiquetados con CostCenter. Este enfoque garantiza que la cuenta de AWS del equipo de cumplimiento se cargue con precisión por el uso de las herramientas de seguridad, lo que proporciona una visión integral y precisa de la asignación de costos en toda la organización.
Question 30 of 529
Una empresa tiene 50 cuentas de AWS que son miembros de una organización en AWS Organizations. Cada cuenta contiene varias VPC. La compañía quiere utilizar AWS Transit Gateway para establecer conectividad entre las VPC en cada cuenta de miembro. Cada vez que se crea una nueva cuenta de miembro, la compañía quiere automatizar el proceso de creación de una nueva VPC y un adjunto de puerta de enlace de tránsito.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Desde la cuenta de administración, comparta la puerta de enlace de tránsito con cuentas de miembros mediante AWS Resource Access Manager.
B.
Desde la cuenta de administración, comparta la puerta de enlace de tránsito con cuentas de miembros mediante un SCP de AWS Organizations.
C.
Inicie un conjunto de pila de AWS CloudFormation desde la cuenta de administración que crea automáticamente una nueva VPC y un adjunto de puerta de enlace de tránsito de VPC en una cuenta de miembro. Asocie el archivo adjunto con la puerta de enlace de tránsito en la cuenta de administración mediante el ID de puerta de enlace de tránsito.
D.
Inicie un conjunto de pila de AWS CloudFormation desde la cuenta de administración que crea automáticamente una nueva VPC y un adjunto de puerta de enlace de tránsito entre pares en una cuenta de miembro. Comparta el archivo adjunto con la puerta de enlace de tránsito en la cuenta de administración mediante un rol vinculado al servicio de puerta de enlace de tránsito.
E.
Desde la cuenta de administración, comparta la puerta de enlace de tránsito con cuentas de miembros mediante AWS Service Catalog.
AnswerDiscussion
Correct Answer: A, C
Para cumplir con los requisitos, primero, desde la cuenta de administración, la puerta de enlace de tránsito debe compartirse con cuentas de miembros mediante AWS Resource Access Manager para permitir el uso compartido de recursos entre diferentes cuentas. Luego, se debe lanzar un conjunto de pila de AWS CloudFormation desde la cuenta de administración para automatizar la creación de una nueva VPC y un adjunto de puerta de enlace de tránsito de VPC en cada cuenta de miembro. Este conjunto de pila debe asociar el archivo adjunto con la puerta de enlace de tránsito en la cuenta de administración utilizando el ID de puerta de enlace de tránsito para garantizar la conectividad.
Question 31 of 529
Una empresa quiere permitir que sus desarrolladores compren software de terceros a través de AWS Marketplace. La compañía utiliza una estructura de cuentas de AWS Organizations con todas las funciones habilitadas, y tiene una cuenta de servicios compartidos en cada unidad organizativa (OU) que será utilizada por los gerentes de compras. La política del equipo de adquisiciones indica que los desarrolladores deben poder obtener software de terceros solo de una lista aprobada y usar Private Marketplace en AWS Marketplace para lograr este requisito. El equipo de adquisiciones quiere que la administración de Private Marketplace se restrinja a un rol llamado procurement-manager-role, que podría ser asumido por los gerentes de compras. A otros usuarios de IAM, grupos, roles y administradores de cuentas en la empresa se les debe denegar el acceso administrativo del Mercado Privado.
Cuál es la manera MÁS eficiente de diseñar una arquitectura para cumplir con estos requisitos?
A.
Cree un rol de IAM denominado rol de administrador de compras en todas las cuentas de AWS de la organización. Agregue la política administrada de PowerUserAccess al rol. Aplique una política en línea a todos los usuarios y roles de IAM en cada cuenta de AWS para denegar permisos en la política administrada AWSPrivateMarketplaceAdminFullAccess.
B.
Cree un rol de IAM denominado rol de administrador de compras en todas las cuentas de AWS de la organización. Agregar la política administrada AdministratorAccess al rol. Defina un límite de permisos con la política administrada AWSPrivateMarketplaceAdminFullAccess y adjúntela a todos los roles de desarrollador.
C.
Cree un rol de IAM denominado rol de administrador de adquisiciones en todas las cuentas de servicios compartidos de la organización. Agregue la política administrada AWSPrivateMarketPlaceAdminFullAccess al rol. Cree un SCP de nivel raíz de la organización para denegar permisos para administrar Private Marketplace a todos, excepto el rol llamado procurement-manager-role. Cree otro SCP de nivel raíz de la organización para denegar permisos para crear un rol de IAM denominado rol de administrador de compras para todos los miembros de la organización.
D.
Cree un rol de IAM denominado rol de administrador de adquisiciones en todas las cuentas de AWS que utilizarán los desarrolladores. Agregue la política administrada AWSPrivateMarketPlaceAdminFullAccess al rol. Cree un SCP en Organizaciones para denegar permisos para administrar Mercado Privado a todos, excepto el rol llamado procurement-manager-role. Aplicar el SCP a todas las cuentas de servicios compartidos de la organización.
AnswerDiscussion
Correct Answer: C
Para cumplir con los requisitos de manera eficiente, cree un rol de IAM denominado procurement-manager-role en todas las cuentas de servicios compartidos y asígnele la política AWSPrivateMarketplaceAdminFullAccess. Luego, implemente políticas de control de servicios (SCP) de nivel raíz de la organización para restringir el acceso administrativo al Mercado Privado. El primer SCP debería denegar a todos, excepto el permiso de rol de administrador de compras para administrar Mercado Privado. El segundo SCP debería evitar la creación de un rol de IAM denominado rol de administrador de compras en toda la organización. Esto garantiza que solo los gerentes de compras tengan los permisos administrativos requeridos al tiempo que bloquean efectivamente a otros usuarios.
Question 32 of 529
Una empresa está en proceso de implementar AWS Organizations para limitar a sus desarrolladores a usar solo Amazon EC2, Amazon S3 y Amazon DynamoDB. La cuenta de desarrolladores reside en una unidad organizativa (OU) dedicada. El arquitecto de soluciones ha implementado el siguiente SCP en la cuenta de los desarrolladores:
Cuando se implementa esta política, los usuarios de IAM en la cuenta de desarrolladores aún pueden usar los servicios de AWS que no aparecen en la política.
Qué debe hacer el arquitecto de soluciones para eliminar la capacidad de los desarrolladores de utilizar servicios fuera del alcance de esta política?
A.
Cree una declaración de denegar explícita para cada servicio de AWS que deba restringirse.
B.
Eliminar el SCP FullawsAccess de la OU de la cuenta de desarrolladores.
C.
Modificar el SCP FullawsAccess para denegar explícitamente todos los servicios.
D.
Agregue una instrucción de denegar explícita usando un comodín al final del SCP.
AnswerDiscussion
Correct Answer: B
La forma correcta de garantizar que los desarrolladores no puedan utilizar servicios fuera de Amazon EC2, Amazon S3 y Amazon DynamoDB es eliminar la Política de control de servicios (SCP) FullawsAccess de la Unidad Organizacional (OU) de la cuenta de los desarrolladores. El SCP FullawsAccess, si está conectado, permite todos los servicios por defecto. Eliminar esta política bloqueará efectivamente el acceso a cualquier servicio que no esté explícitamente permitido por otros SCP aplicados a la cuenta de los desarrolladores o a la unidad organizativa en la que reside.
Question 33 of 529
Una empresa aloja una API monolítica basada en REST para una aplicación móvil en cinco instancias de Amazon EC2 en subredes públicas de una VPC. Los clientes móviles se conectan a la API mediante un nombre de dominio alojado en Amazon Route 53. La compañía ha creado una política de enrutamiento de respuesta multivalue Route 53 con las direcciones IP de todas las instancias EC2. Recientemente, la aplicación se ha visto abrumada por grandes y repentinos aumentos en el tráfico. La app no ha podido mantenerse al día con el tráfico.
Un arquitecto de soluciones necesita implementar una solución para que la aplicación pueda manejar la carga nueva y variable.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Separe la API en funciones individuales de AWS Lambda. Configure una API REST de Amazon API Gateway con integración Lambda para el backend. Actualice el registro Route 53 para que apunte a la API API Gateway.
B.
Containerizar la lógica API. Cree un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Ejecute los contenedores en el clúster mediante Amazon EC2. Crea una entrada de Kubernetes. Actualiza el registro de la Ruta 53 para que apunte a la entrada de Kubernetes.
C.
Cree un grupo de Auto Scaling. Coloque todas las instancias EC2 en el grupo Auto Scaling. Configure el grupo Auto Scaling para realizar acciones de escalado basadas en la utilización de la CPU. Cree una función de AWS Lambda que reaccione a los cambios de grupo de Auto Scaling y actualice el registro Route 53.
D.
Cree un balanceador de carga de aplicaciones (ALB) frente a la API. Mueva las instancias EC2 a subredes privadas en la VPC. Agregue las instancias EC2 como objetivos para el ALB. Actualizar el registro de la Ruta 53 para apuntar a la ALB.
AnswerDiscussion
Correct Answer: D
Para manejar la carga nueva y variable en la API basada en REST con la menor sobrecarga operativa, es más efectivo crear un balanceador de carga de aplicaciones (ALB) frente a las instancias EC2. Este enfoque permite una distribución efectiva del tráfico entrante a través de múltiples instancias, lo que garantiza que ninguna instancia se vea abrumada. Además, mover las instancias EC2 a subredes privadas mejora la seguridad mientras que el ALB se encarga de administrar el tráfico. Esta solución requiere cambios mínimos en la configuración actual y no implica una refactorización significativa del desarrollo ni la necesidad de administrar los marcos de orquestación de contenedores, lo que la convierte en la opción con la menor sobrecarga operativa.
Question 34 of 529
Una compañía ha creado una unidad organizativa en AWS Organizations para cada uno de sus equipos de ingeniería. Cada unidad organizativa posee varias cuentas de AWS. La organización cuenta con cientos de cuentas de AWS.
Un arquitecto de soluciones debe diseñar una solución para que cada unidad organizativa pueda ver un desglose de los costos de uso en sus cuentas de AWS.
Qué solución cumple con estos requisitos?
A.
Cree un informe de costos y uso (CUR) de AWS para cada unidad organizativa mediante AWS Resource Access Manager. Permita que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.
B.
Cree un informe de costos y uso (CUR) de AWS desde la cuenta de administración de AWS Organizations. Permita que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.
C.
Cree un informe de costos y uso (CUR) de AWS en cada cuenta de miembro de AWS Organizations. Permita que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.
D.
Cree un informe de costos y uso (CUR) de AWS mediante AWS Systems Manager. Permita que cada equipo visualice el CUR a través de los paneles de control de Systems Manager OPSCenter.
AnswerDiscussion
Correct Answer: B
La solución más efectiva para permitir que cada unidad organizativa vea un desglose de los costos de uso en sus cuentas de AWS es crear un informe de costos y uso (CUR) de AWS a partir de la cuenta de administración de AWS Organizations. Este enfoque asegura que todos los datos de costos se consoliden en un solo lugar, facilitando su administración y visualización. El CUR se puede visualizar a través de un panel de Amazon QuickSight, que proporciona una interfaz fácil de usar para que los equipos accedan y analicen sus datos de costos.
Question 35 of 529
Una empresa está almacenando datos en las instalaciones en un servidor de archivos Windows. La compañía produce 5 GB de nuevos datos diarios.
La compañía migró parte de su carga de trabajo basada en Windows a AWS y necesita que los datos estén disponibles en un sistema de archivos en la nube. La compañía ya ha establecido una conexión AWS Direct Connect entre la red local y AWS.
Qué estrategia de migración de datos debe utilizar la empresa?
A.
Utilice la opción de puerta de enlace de archivos en AWS Storage Gateway para reemplazar el servidor de archivos de Windows existente y apuntar el recurso compartido de archivos existente a la nueva puerta de enlace de archivos.
B.
Utilice AWS DataSync para programar una tarea diaria para replicar datos entre el servidor de archivos de Windows local y Amazon FSx.
C.
Utilice AWS Data Pipeline para programar una tarea diaria para replicar datos entre el servidor de archivos de Windows local y Amazon Elastic File System (Amazon EFS).
D.
Utilice AWS DataSync para programar una tarea diaria para replicar datos entre el servidor de archivos de Windows local y Amazon Elastic File System (Amazon EFS).
AnswerDiscussion
Correct Answer: B
La empresa necesita una estrategia de migración de datos para tener los datos disponibles en un sistema de archivos en la nube. AWS DataSync está diseñado para transferir de manera eficiente grandes cantidades de datos entre el almacenamiento local y los servicios de almacenamiento de AWS. Amazon FSx para Windows File Server proporciona servidores de archivos Windows completamente administrados en la nube, lo que es adecuado para la carga de trabajo basada en Windows de la compañía. Por lo tanto, usar AWS DataSync para programar tareas diarias para replicar datos entre el servidor de archivos de Windows local y Amazon FSx es la mejor solución. Este enfoque garantiza una integración perfecta y disponibilidad de los datos en la nube.
Question 36 of 529
El arquitecto de soluciones de una empresa está revisando una aplicación web que se ejecuta en AWS. La aplicación hace referencia a activos estáticos en un bucket de Amazon S3 en la región us-east-1. La empresa necesita resiliencia en varias regiones de AWS. La compañía ya ha creado un bucket S3 en una segunda Región.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Configure la aplicación para escribir cada objeto en ambos buckets S3. Configure una zona alojada pública de Amazon Route 53 con un conjunto de registros mediante una política de enrutamiento ponderada para cada bucket de S3. Configure la aplicación para hacer referencia a los objetos mediante el nombre DNS Route 53.
B.
Cree una función de AWS Lambda para copiar objetos del bucket S3 en us-east-1 al bucket S3 en la segunda región. Invocar la función Lambda cada vez que se escribe un objeto en el bucket S3 en us-east-1. Configure una distribución de Amazon CloudFront con un grupo de origen que contenga los dos buckets S3 como orígenes.
C.
Configure la replicación en el bucket S3 en us-east-1 para replicar objetos en el bucket S3 en la segunda región. Configure una distribución de Amazon CloudFront con un grupo de origen que contenga los dos buckets S3 como orígenes.
D.
Configure la replicación en el bucket S3 en us-east-1 para replicar objetos en el bucket S3 en la segunda región. Si se requiere conmutación por error, actualice el código de la aplicación para cargar objetos S3 desde el bucket S3 en la segunda región.
AnswerDiscussion
Correct Answer: C
La mejor solución para lograr resiliencia en varias regiones de AWS con la menor sobrecarga operativa es configurar S3 Cross-Region Replication (CRR) para replicar objetos desde el bucket S3 en us-east-1 al bucket S3 en la segunda región. Esto asegura la replicación automática y continua de objetos entre los dos depósitos. Además, la configuración de una distribución de Amazon CloudFront con un grupo de origen que incluya ambos buckets S3 permite a CloudFront gestionar la conmutación por error automáticamente, sin requerir actualizaciones manuales o configuraciones complejas en el código de la aplicación. Esta configuración minimiza la sobrecarga operativa al tiempo que logra la resiliencia deseada.
Question 37 of 529
Una empresa está alojando una aplicación web de tres niveles en un entorno local. Debido a un aumento reciente en el tráfico que resultó en tiempo de inactividad y un impacto financiero significativo, la administración de la compañía ha ordenado que la aplicación se mueva a AWS. La aplicación está escrita en .NET y tiene una dependencia de una base de datos MySQL. Un arquitecto de soluciones debe diseñar una solución escalable y de alta disponibilidad para satisfacer la demanda de 200,000 usuarios diarios.
Qué pasos debe tomar el arquitecto de soluciones para diseñar una solución adecuada?
A.
Utilice AWS Elastic Beanstalk para crear una nueva aplicación con un entorno de servidor web y una instancia de base de datos Multi-AZ de Amazon RDS MySQL. El entorno debe lanzar un balanceador de carga de red (NLB) frente a un grupo de Auto Scaling de Amazon EC2 en varias zonas de disponibilidad. Utilice un registro de alias de Amazon Route 53 para enrutar el tráfico del dominio de la compañía al NLB.
B.
Utilice AWS CloudFormation para lanzar una pila que contenga un balanceador de carga de aplicaciones (ALB) frente a un grupo de Amazon EC2 Auto Scaling que abarca tres zonas de disponibilidad. La pila debe lanzar una implementación Multi-AZ de un clúster de base de datos MySQL de Amazon Aurora con una política de eliminación de Retain. Utilice un registro de alias Amazon Route 53 para enrutar el tráfico del dominio de la compañía al ALB.
C.
Utilice AWS Elastic Beanstalk para crear un entorno de servidor web de escalado automático que abarque dos regiones independientes con un balanceador de carga de aplicaciones (ALB) en cada región. Cree una implementación Multi-AZ de un clúster de base de datos Amazon Aurora MySQL con una réplica de lectura entre regiones. Utilice Amazon Route 53 con una política de enrutamiento de geoproximidad para enrutar el tráfico entre las dos regiones.
D.
Utilice AWS CloudFormation para lanzar una pila que contenga un balanceador de carga de aplicaciones (ALB) frente a un clúster de instancias puntuales de Amazon ECS que abarquen tres zonas de disponibilidad. La pila debe lanzar una instancia de base de datos MySQL de Amazon RDS con una política de eliminación de instantáneas. Utilice un registro de alias Amazon Route 53 para enrutar el tráfico del dominio de la compañía al ALB.
AnswerDiscussion
Correct Answer: B
Para diseñar una solución escalable y de alta disponibilidad para migrar una aplicación.NET con una base de datos MySQL a AWS, la solución debe utilizar AWS CloudFormation para lanzar una pila. Esta pila contaría con un balanceador de carga de aplicaciones (ALB) frente a un grupo de Auto Scaling de Amazon EC2 que abarca tres zonas de disponibilidad, lo que garantiza la escalabilidad y la tolerancia a fallas. Para la base de datos, una implementación Multi-AZ de un clúster de base de datos Amazon Aurora MySQL proporcionará alta disponibilidad y conmutación por error automática. El uso de un registro de alias de Amazon Route 53 enrutará de manera eficiente el tráfico del dominio de la compañía al ALB, asegurando una resolución DNS adecuada y una distribución de carga. Este enfoque satisface las demandas de escalabilidad, alta disponibilidad y enrutamiento adecuado al tiempo que aprovecha los servicios de AWS diseñados para estos fines.
Question 38 of 529
Una empresa utiliza AWS Organizations para administrar varias cuentas de AWS. Por razones de seguridad, la empresa requiere la creación de un tema de Amazon Simple Notification Service (Amazon SNS) que permita la integración con un sistema de alertas de terceros en todas las cuentas de miembros de las Organizaciones.
Un arquitecto de soluciones utilizó una plantilla de AWS CloudFormation para crear los conjuntos de temas y pilas de SNS para automatizar la implementación de las pilas de CloudFormation. Se ha habilitado el acceso de confianza en las Organizaciones.
Qué debería hacer el arquitecto de soluciones para implementar los StackSets de CloudFormation en todas las cuentas de AWS?
A.
Crear un conjunto de pila en las cuentas de miembros de Organizaciones. Utilice permisos administrados por el servicio. Establezca las opciones de implementación para implementar en una organización. Utilice la detección de deriva de CloudFormation StackSets.
B.
Crear pilas en las cuentas de miembros de las Organizaciones. Utilizar permisos de autoservicio. Establezca las opciones de implementación para implementar en una organización. Habilite la implementación automática de CloudFormation StackSets.
C.
Crea un conjunto de stack en la cuenta de administración de Organizaciones. Utilice permisos administrados por el servicio. Establezca las opciones de implementación para implementar en la organización. Habilite la implementación automática de CloudFormation StackSets.
D.
Crear pilas en la cuenta de administración de organizaciones. Utilice permisos administrados por el servicio. Establezca las opciones de implementación para implementar en la organización. Habilite la detección de deriva de CloudFormation StackSets.
AnswerDiscussion
Correct Answer: C
Para implementar un tema de Amazon SNS a través de AWS CloudFormation StackSets en todas las cuentas miembros de AWS Organizations, el conjunto de pila debe crearse en la cuenta de administración. Esta administración central simplifica las operaciones y garantiza una implementación consistente en todas las cuentas de los miembros. Los permisos administrados por servicios aprovechan AWS CloudFormation para administrar los roles necesarios, optimizando los permisos. La configuración de las opciones de implementación para implementar en la organización garantiza la implementación en todas las cuentas de los miembros. Habilitar la implementación automática garantiza que todas las cuentas nuevas agregadas a la organización reciban automáticamente el conjunto de pila, manteniendo la consistencia en toda la organización.
Question 39 of 529
Una empresa quiere migrar sus cargas de trabajo desde las instalaciones a AWS. Las cargas de trabajo se ejecutan en Linux y Windows. La compañía cuenta con una gran infraestructura local que consiste en máquinas físicas y VMs que alojan numerosas aplicaciones.
La compañía debe capturar detalles sobre la configuración del sistema, el rendimiento del sistema, los procesos en ejecución y las conexiones de red de sus cargas de trabajo locales. La compañía también debe dividir las aplicaciones locales en grupos para las migraciones de AWS. La compañía necesita recomendaciones para los tipos de instancias de Amazon EC2 para que la compañía pueda ejecutar sus cargas de trabajo en AWS de la manera más rentable.
Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Evalúe las aplicaciones existentes instalando AWS Application Discovery Agent en las máquinas físicas y las máquinas virtuales.
B.
Evalúe las aplicaciones existentes instalando AWS Systems Manager Agent en las máquinas físicas y las máquinas virtuales.
C.
Agrupe servidores en aplicaciones para migrarlos mediante AWS Systems Manager Application Manager.
D.
Agrupe los servidores en aplicaciones para la migración mediante AWS Migration Hub.
E.
Genere tipos de instancia recomendados y costos asociados mediante AWS Migration Hub.
F.
Importe datos sobre los tamaños de los servidores a AWS Trusted Advisor. Siga las recomendaciones para la optimización de costos.
AnswerDiscussion
Correct Answer: A, D, E
Los requisitos requieren capturar detalles sobre las configuraciones del sistema, el rendimiento, los procesos en ejecución y las conexiones de red de las cargas de trabajo locales. Para ello, es apropiado usar AWS Application Discovery Agent, ya que recopila datos completos de máquinas físicas y máquinas virtuales. La agrupación de servidores en aplicaciones para la migración puede ser manejada de manera eficiente por AWS Migration Hub, que proporciona una ubicación centralizada y herramientas para organizar y rastrear migraciones. Por último, la generación de tipos de instancias recomendados y costos asociados también se debe realizar a través de AWS Migration Hub, que tiene la capacidad de analizar los datos recopilados y recomendar instancias EC2 adecuadas para una migración rentable.
Question 40 of 529
Una empresa está alojando un servicio de procesamiento de imágenes en AWS en una VPC. La VPC se extiende a través de dos zonas de disponibilidad. Cada zona de disponibilidad contiene una subred pública y una subred privada.
El servicio se ejecuta en instancias de Amazon EC2 en las subredes privadas. Un balanceador de carga de aplicaciones en las subredes públicas está frente al servicio. El servicio necesita comunicarse con Internet y lo hace a través de dos pasarelas NAT. El servicio utiliza Amazon S3 para el almacenamiento de imágenes. Las instancias EC2 recuperan aproximadamente 1 ТВ de datos de un bucket S3 cada día.
La compañía ha promovido el servicio como altamente seguro. Un arquitecto de soluciones debe reducir los gastos en la nube tanto como sea posible sin comprometer la postura de seguridad del servicio o aumentar el tiempo dedicado a las operaciones en curso.
Qué solución cumplirá con estos requisitos?
A.
Reemplace las puertas de enlace NAT con instancias NAT. En la tabla de rutas de VPC, cree una ruta desde las subredes privadas a las instancias NAT.
B.
Mueva las instancias EC2 a las subredes públicas. Quite las puertas de enlace NAT.
C.
Configure un punto final de VPC de puerta de enlace S3 en el vPATTach una directiva de punto final para el punto final para permitir las acciones necesarias en el bucket S3.
D.
Adjunte un volumen de Amazon Elastic File System (Amazon EFS) a las instancias EC2. Alojar las imágenes en el volumen EFS.
AnswerDiscussion
Correct Answer: C
Un punto final de VPC de puerta de enlace S3 permite que las instancias EC2 en las subredes privadas se comuniquen directamente con Amazon S3 sin necesidad de pasar por las puertas de enlace NAT o Internet. Esto reduce el costo asociado a las puertas de enlace NAT a la vez que mantiene un alto nivel de seguridad ya que los datos no salen de la red de AWS. Además, la configuración de una política de punto final garantiza que solo se permiten las acciones requeridas en el bucket S3, manteniendo la postura de seguridad y no aumentando la sobrecarga operativa. Esta configuración también es beneficiosa para transferencias de big data como la 1 TB de datos recuperados diariamente de S3.
Question 41 of 529
Una empresa implementó recientemente una aplicación en AWS. La aplicación utiliza Amazon DynamoDB. La compañía midió la carga de la aplicación y configuró las RCUs y WCUs en la tabla DynamoDB para que coincidieran con la carga máxima esperada. La carga máxima ocurre una vez a la semana durante un periodo de 4 horas y es el doble de la carga promedio. La carga de la aplicación es cercana a la carga promedio para el resto de la semana. El patrón de acceso incluye muchas más escrituras en la tabla que lecturas de la tabla.
Un arquitecto de soluciones necesita implementar una solución para minimizar el costo de la mesa.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS Application Auto Scaling para aumentar la capacidad durante el período pico. Compra RCUs reservadas y WCUs para que coincidan con la carga promedio.
B.
Configurar el modo de capacidad bajo demanda para la mesa.
C.
Configure el Acelerador DynamoDB (DAX) frente a la mesa. Reduzca la capacidad de lectura aprovisionada para que coincida con la nueva carga máxima en la mesa.
D.
Configure el Acelerador DynamoDB (DAX) frente a la mesa. Configurar el modo de capacidad bajo demanda para la mesa.
AnswerDiscussion
Correct Answer: A
La solución más adecuada para minimizar el costo de la tabla DynamoDB es usar AWS Application Auto Scaling para aumentar la capacidad durante el período pico y comprar RCU y WCUs reservadas para que coincidan con la carga promedio. Este enfoque utiliza la capacidad reservada para la carga promedio consistente, que es más rentable, y aprovecha el escalado automático para manejar los períodos pico conocidos, asegurando que la tabla pueda acomodar un mayor tráfico sin incurrir en los costos más altos asociados con la capacidad bajo demanda.
Question 42 of 529
Un arquitecto de soluciones necesita asesorar a una empresa sobre cómo migrar su aplicación de procesamiento de datos local a la nube de AWS. Actualmente, los usuarios cargan archivos de entrada a través de un portal web. Luego, el servidor web almacena los archivos cargados en NAS y envía mensajes al servidor de procesamiento a través de una cola de mensajes. Cada archivo multimedia puede tardar hasta 1 hora en procesarse. La compañía ha determinado que el número de archivos multimedia en espera de procesamiento es significativamente mayor durante el horario comercial, con el número de archivos disminuyendo rápidamente después del horario comercial.
Cuál es la recomendación de migración MÁS rentable?
A.
Cree una cola con Amazon SQS. Configure el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, invoque una función de AWS Lambda para extraer solicitudes de la cola y procesar los archivos. Almacene los archivos procesados en un bucket de Amazon S3.
B.
Cree una cola con Amazon MQ. Configure el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, cree una nueva instancia de Amazon EC2 para sacar solicitudes de la cola y procesar los archivos. Almacene los archivos procesados en Amazon EFS. Apague la instancia EC2 una vez completada la tarea.
C.
Cree una cola con Amazon MQ. Configure el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, invoque una función de AWS Lambda para extraer solicitudes de la cola y procesar los archivos. Almacene los archivos procesados en Amazon EFS.
D.
Cree una cola con Amazon SQS. Configure el servidor web existente para publicar en la nueva cola. Utilice instancias de Amazon EC2 en un grupo EC2 Auto Scaling para extraer solicitudes de la cola y procesar los archivos. Escale las instancias EC2 según la longitud de la cola de SQS. Almacene los archivos procesados en un bucket de Amazon S3.
AnswerDiscussion
Correct Answer: D
La creación de una cola con Amazon SQS y la configuración del servidor web existente para que se publique en la nueva cola garantiza una cola de mensajes confiable con alta disponibilidad y bajo costo. La utilización de instancias de Amazon EC2 en un grupo EC2 Auto Scaling permite el procesamiento escalable de las solicitudes de la cola. Las instancias EC2 se pueden escalar automáticamente en función de la longitud de la cola SQS, lo que proporciona flexibilidad para manejar cargas más altas durante las horas pico y reducir los costos durante las horas de menor actividad. El almacenamiento de los archivos procesados en un bucket de Amazon S3 minimiza aún más los costos de almacenamiento al tiempo que garantiza la durabilidad y la disponibilidad.
Question 43 of 529
Una empresa está utilizando Amazon OpenSearch Service para analizar datos. La empresa carga datos en un clúster de OpenSearch Service con 10 nodos de datos desde un bucket de Amazon S3 que utiliza almacenamiento S3 Standard. Los datos residen en el clúster durante 1 mes para análisis de solo lectura. Después de 1 mes, la compañía elimina el índice que contiene los datos del clúster. Para fines de cumplimiento, la empresa debe conservar una copia de todos los datos de entrada.
La compañía está preocupada por los costos continuos y pide a un arquitecto de soluciones que recomiende una nueva solución.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Reemplace todos los nodos de datos por nodos UltraWarm para manejar la capacidad esperada. Realice la transición de los datos de entrada de S3 Standard a S3 Glacier Deep Archive cuando la compañía carga los datos en el clúster.
B.
Reducir el número de nodos de datos en el clúster a 2 Agregar nodos UltraWarm para manejar la capacidad esperada. Configure los índices para hacer la transición a UltraWarm cuando OpenSearch Service ingiera los datos. Haga la transición de los datos de entrada a S3 Glacier Deep Archive después de 1 mes mediante una política de ciclo de vida de S3.
C.
Reducir el número de nodos de datos en el clúster a 2. Agregue nodos UltraWarm para manejar la capacidad esperada. Configure los índices para hacer la transición a UltraWarm cuando OpenSearch Service ingiera los datos. Agregar nodos de almacenamiento en frío al clúster Transición de los índices de UltraWarm a almacenamiento en frío. Elimine los datos de entrada del bucket S3 después de 1 mes mediante una política de ciclo de vida de S3.
D.
Reducir el número de nodos de datos en el clúster a 2. Agregue nodos de datos respaldados por instancias para manejar la capacidad esperada. Realice la transición de los datos de entrada de S3 Standard a S3 Glacier Deep Archive cuando la compañía carga los datos en el clúster.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos de manera más rentable, el clúster de OpenSearch Service debe reducir el número de nodos de datos a 2 y utilizar nodos UltraWarm para manejar la capacidad esperada. Los nodos UltraWarm están diseñados para grandes volúmenes de datos de solo lectura y son rentables para este caso de uso. La configuración de índices para la transición a UltraWarm inmediatamente después de la ingestión optimiza los costos de almacenamiento. Después de 1 mes, los datos de entrada deben pasar de S3 Standard a S3 Glacier Deep Archive usando una política de ciclo de vida de S3 porque S3 Glacier Deep Archive es la solución de almacenamiento a largo plazo más rentable para fines de cumplimiento.
Question 44 of 529
Una empresa tiene 10 cuentas que forman parte de una organización en AWS Organizations. AWS Config se configura en cada cuenta. Todas las cuentas pertenecen a la OU Prod o a la OU NProd.
La compañía ha configurado una regla de Amazon EventBridge en cada cuenta de AWS para notificar a un tema de Amazon Simple Notification Service (Amazon SNS) cuando se crea una regla entrante de grupo de seguridad de Amazon EC2 con 0.0.0.0/0 como origen. El equipo de seguridad de la compañía está suscrito al tema SNS.
Para todas las cuentas en la unidad organizativa NonProd, el equipo de seguridad necesita eliminar la capacidad de crear una regla entrante de grupo de seguridad que incluya 0.0.0.0/0 como origen.
Qué solución cumplirá con este requisito con la menor sobrecarga operativa?
A.
Modifique la regla EventBridge para invocar una función de AWS Lambda para eliminar la regla entrante del grupo de seguridad y publicarla en el tema SNS. Desplegar la regla actualizada en la OU NonProd.
B.
Agregue la regla administrada de AWS Config vpc-sg-open-onl-to-authorized-ports a la unidad organizativa NonProd.
C.
Configure un SCP para permitir la acción EC2:AuthorizeSegurityGroupingress cuando el valor de la clave de condición aws:sourceIP no es 0.0.0.0/0. Aplicar el SCP a la unidad organizativa NonProd.
D.
Configure un SCP para denegar la acción EC2:AuthorizeSegurityGroupingress cuando el valor de la clave de condición aws:sourceIP es 0.0.0.0/0. Aplicar el SCP a la unidad organizativa NonProd.
AnswerDiscussion
Correct Answer: D
La solución correcta es configurar un SCP (Service Control Policy) para denegar la acción EC2:AuthorizeSegurityGroupingress cuando el valor de la clave de condición aws:sourceIP es 0.0.0.0/0. La aplicación de este SCP a la unidad organizativa NonProd evitará la creación de cualquier regla entrante de grupo de seguridad que incluya 0.0.0.0/0 como IP de origen. Este enfoque cumple con el requisito con la menor sobrecarga operativa, ya que bloquea proactivamente la acción indeseable a nivel de aplicación de políticas, evitando la necesidad de medidas reactivas o pasos adicionales para eliminar dichas reglas después de su creación.
Question 45 of 529
Una empresa aloja un repositorio Git en un centro de datos local. La compañía utiliza webhooks para invocar la funcionalidad que se ejecuta en la nube de AWS. La compañía aloja la lógica de webhook en un conjunto de instancias de Amazon EC2 en un grupo de Auto Scaling que la compañía estableció como objetivo para un balanceador de carga de aplicaciones (ALB). El servidor Git llama al ALB para los webhooks configurados. La compañía quiere trasladar la solución a una arquitectura sin servidor.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Para cada webhook, cree y configure una URL de función de AWS Lambda. Actualice los servidores Git para llamar a las URL individuales de la función Lambda.
B.
Cree una API HTTP de Amazon API Gateway. Implemente cada lógica de webhook en una función de AWS Lambda separada. Actualice los servidores Git para llamar al punto final de API Gateway.
C.
Implementar la lógica de webhook en AWS App Runner. Crea un ALB y establece App Runner como objetivo. Actualice los servidores Git para llamar al punto final ALB.
D.
Containerizar la lógica de webhook. Cree un clúster de Amazon Elastic Container Service (Amazon ECS) y ejecute la lógica de webhook en AWS Fargate. Cree una API REST de Amazon API Gateway y establezca Fargate como destino. Actualice los servidores Git para llamar al punto final de API Gateway.
AnswerDiscussion
Correct Answer: B
La solución con la menor sobrecarga operativa es crear una API HTTP de Amazon API Gateway e implementar cada lógica de webhook en una función de AWS Lambda separada. Este enfoque aprovecha las capacidades sin servidor de API Gateway y Lambda, que administran automáticamente la infraestructura subyacente, el escalado y el mantenimiento. Al usar API Gateway como único punto de entrada, elimina la necesidad de administrar múltiples URL de funciones Lambda individuales y se asegura de que las actualizaciones se puedan centralizar a través de la configuración de API Gateway. Esto reduce en gran medida la complejidad y el esfuerzo operativo en comparación con otras opciones, como contenerizar la lógica o usar App Runner, lo que requeriría configuraciones más complejas y servicios adicionales.
Question 46 of 529
Una empresa planea migrar 1.000 servidores locales a AWS. Los servidores se ejecutan en varios clústeres de VMware en el centro de datos de la compañía. Como parte del plan de migración, la compañía quiere recopilar métricas de servidor como detalles de CPU, uso de RAM, información del sistema operativo y procesos en ejecución. A continuación, la empresa quiere consultar y analizar los datos.
Qué solución cumplirá con estos requisitos?
A.
Implemente y configure el dispositivo virtual AWS Agentless Discovery Connector en los hosts locales. Configure la exploración de datos en AWS Migration Hub. Utilice AWS Glue para realizar un trabajo ETL contra los datos. Consulta los datos mediante Amazon S3 Select.
B.
Exporte solo la información de rendimiento de la máquina virtual desde los hosts locales. Importe directamente los datos requeridos en AWS Migration Hub. Actualiza cualquier información que falte en Migration Hub. Consulta los datos mediante Amazon QuickSight.
C.
Cree un script para recopilar automáticamente la información del servidor de los hosts locales. Utilice la CLI de AWS para ejecutar el comando put-resource-atributos para almacenar los datos detallados del servidor en AWS Migration Hub. Consulta los datos directamente en la consola de Migration Hub.
D.
Implemente AWS Application Discovery Agent en cada servidor local. Configure la exploración de datos en AWS Migration Hub. Utilice Amazon Athena para ejecutar consultas predefinidas contra los datos en Amazon S3.
AnswerDiscussion
Correct Answer: D
La solución más adecuada implica implementar AWS Application Discovery Agent en cada servidor local. Este agente está diseñado específicamente para recopilar métricas detalladas del servidor, incluidos los detalles de la CPU, el uso de RAM, la información del sistema operativo y los procesos en ejecución. Una vez que se completa la recopilación de datos, la configuración de la exploración de datos en AWS Migration Hub permite realizar análisis y consultas eficientes. Amazon Athena se puede utilizar para ejecutar consultas predefinidas contra los datos almacenados en Amazon S3, lo que proporciona una forma potente y flexible de analizar las métricas del servidor. Este enfoque garantiza una recopilación integral de datos y capacidades de consulta sólidas, cumpliendo con los requisitos de la compañía de manera efectiva.
Question 47 of 529
Una empresa está construyendo una aplicación sin servidor que se ejecuta en una función de AWS Lambda que está conectada a una VPC. La empresa necesita integrar la aplicación con un nuevo servicio de un proveedor externo. El proveedor externo solo admite solicitudes que provienen de direcciones IPv4 públicas que están en una lista de permitidos.
La compañía debe proporcionar una única dirección IP pública al proveedor externo antes de que la aplicación pueda comenzar a usar el nuevo servicio.
Qué solución le dará a la aplicación la posibilidad de acceder al nuevo servicio?
A.
Desplegar una puerta de enlace NAT. Asocie una dirección IP elástica con la puerta de enlace NAT. Configure la VPC para usar la puerta de enlace NAT.
B.
Implementar una puerta de enlace de Internet solo para egresos. Asocie una dirección IP elástica con la puerta de enlace de Internet solo para egresos. Configure la interfaz de red elástica en la función Lambda para usar la puerta de enlace de Internet solo para egresos.
C.
Desplegar una puerta de enlace a Internet. Asociar una dirección IP elástica con la puerta de enlace de Internet. Configure la función Lambda para usar la puerta de enlace de Internet.
D.
Desplegar una puerta de enlace a Internet. Asociar una dirección IP elástica con la puerta de enlace de Internet. Configure la ruta predeterminada en la tabla de rutas de VPC pública para usar la puerta de enlace de Internet.
AnswerDiscussion
Correct Answer: A
Para habilitar una función de AWS Lambda en una VPC para acceder a un servicio externo que requiere que las solicitudes provengan de una única dirección IPv4 pública, debe implementar una puerta de enlace NAT. Al asociar una dirección IP elástica con la puerta de enlace NAT, el tráfico saliente de la función Lambda enrutada a través de la puerta de enlace NAT parecerá provenir de esta única dirección IP pública. Esta configuración permite al proveedor externo incluir en la lista blanca la dirección IP pública específica, permitiendo que la función Lambda acceda al nuevo servicio. La puerta de enlace NAT traducirá la dirección IP privada de la función Lambda a la dirección IP elástica, asegurando que todo el tráfico parece provenir de una sola dirección IP pública.
Question 48 of 529
Un arquitecto de soluciones ha desarrollado una aplicación web que utiliza un endpoint regional de Amazon API Gateway y una función AWS Lambda. Los consumidores de la aplicación web están todos cerca de la región de AWS donde se implementará la aplicación. La función Lambda solo consulta una base de datos MySQL de Amazon Aurora. El arquitecto de soluciones ha configurado la base de datos para tener tres réplicas de lectura.
Durante las pruebas, la aplicación no cumple con los requisitos de rendimiento. Bajo carga alta, la aplicación abre una gran cantidad de conexiones de base de datos. El arquitecto de soluciones debe mejorar el rendimiento de la aplicación.
Qué acciones debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Utilice el punto final del clúster de la base de datos Aurora.
B.
Utilice RDS Proxy para configurar un grupo de conexiones al punto final del lector de la base de datos Aurora.
C.
Utilice la función de concurrencia aprovisionada de Lambda.
D.
Mueva el código para abrir la conexión de base de datos en la función Lambda fuera del controlador de eventos.
E.
Cambie el punto final de API Gateway a un punto final optimizado para bordes.
AnswerDiscussion
Correct Answer: B, D
Para mejorar el rendimiento de la aplicación bajo alta carga cuando abre una gran cantidad de conexiones de base de datos, el arquitecto de soluciones debe usar RDS Proxy para configurar un grupo de conexiones al punto final del lector de la base de datos Aurora. RDS Proxy ayuda a administrar y agrupar de manera eficiente las conexiones de bases de datos, reduciendo la sobrecarga de apertura y cierre de conexiones, mejorando así el rendimiento. Además, mover el código para abrir la conexión de base de datos en la función Lambda fuera del controlador de eventos puede ayudar reutilizando la conexión de la base de datos a través de múltiples solicitudes. Esto evita el lento proceso de establecer una nueva conexión para cada solicitud y reduce el uso de recursos.
Question 49 of 529
Una empresa planea alojar una aplicación web en AWS y quiere equilibrar la carga del tráfico en un grupo de instancias de Amazon EC2. Uno de los requisitos de seguridad es habilitar el cifrado de extremo a extremo en tránsito entre el cliente y el servidor web.
Qué solución cumplirá con este requisito?
A.
Coloque las instancias EC2 detrás de un balanceador de carga de aplicaciones (ALB). Aprovisione un certificado SSL mediante AWS Certificate Manager (ACM) y asocie el certificado SSL con el ALB. Exporte el certificado SSL e instálelo en cada instancia EC2. Configure el ALB para que escuche en el puerto 443 y reenvíe el tráfico al puerto 443 en las instancias.
B.
Asocie las instancias EC2 con un grupo objetivo. Aprovisione un certificado SSL mediante AWS Certificate Manager (ACM). Cree una distribución de Amazon CloudFront y configúrela para usar el certificado SSL. Establezca CloudFront para que use el grupo de destino como servidor de origen.
C.
Coloque las instancias EC2 detrás de un balanceador de carga de aplicaciones (ALB) Aprovisione un certificado SSL mediante AWS Certificate Manager (ACM) y asocie el certificado SSL con el ALB. Aprovisione un certificado SSL de terceros e instálelo en cada instancia EC2. Configure el ALB para que escuche en el puerto 443 y reenvíe el tráfico al puerto 443 en las instancias.
D.
Coloque las instancias EC2 detrás de un balanceador de carga de red (NLB). Aprovisione un certificado SSL de terceros e instálelo en el NLB y en cada instancia EC2. Configure el NLB para escuchar en el puerto 443 y reenviar el tráfico al puerto 443 en las instancias.
AnswerDiscussion
Correct Answer: D
Para lograr el cifrado de extremo a extremo en tránsito entre el cliente y el servidor web, el uso de un balanceador de carga de red (NLB) con escucha TCP en el puerto 443 es la solución adecuada. Este enfoque garantiza que el tráfico cifrado se reenvíe a las instancias EC2 sin descifrarlo en el NLB, manteniendo el cifrado desde el cliente hasta el servidor web. Por lo tanto, la opción NLB cumple con el requisito de cifrado de extremo a extremo de manera efectiva.
Question 50 of 529
Una empresa quiere migrar su entorno de análisis de datos desde las instalaciones a AWS. El entorno consta de dos simples aplicaciones Node.js. Una de las aplicaciones recopila datos de sensores y los carga en una base de datos MySQL. La otra aplicación agrega los datos en informes. Cuando se ejecutan los trabajos de agregación, algunos de los trabajos de carga no se ejecutan correctamente.
La empresa debe resolver el problema de carga de datos. La compañía también necesita que la migración se produzca sin interrupciones ni cambios para los clientes de la compañía.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Configure una base de datos MySQL de Amazon Aurora como destino de replicación para la base de datos local. Cree una réplica Aurora para la base de datos Aurora MySQL y mueva los trabajos de agregación para que se ejecuten contra la réplica Aurora. Configure puntos finales de recopilación como funciones de AWS Lambda detrás de un balanceador de carga de red (NLB) y use Amazon RDS Proxy para escribir en la base de datos Aurora MySQL. Cuando se sincronicen las bases de datos, deshabilite el trabajo de replicación y reinicie Aurora Replica como instancia principal. Apunte el registro DNS del recopilador a la NLB.
B.
Configure una base de datos MySQL de Amazon Aurora. Utilice AWS Database Migration Service (AWS DMS) para realizar la replicación continua de datos desde la base de datos local a Aurora. Mueva los trabajos de agregación para que se ejecuten contra la base de datos Aurora MySQL. Configure puntos finales de recopilación detrás de un balanceador de carga de aplicaciones (ALB) como instancias de Amazon EC2 en un grupo de Auto Scaling. Cuando se sincronicen las bases de datos, apunte el registro DNS del recopilador a la tarea ALDesactivar la sincronización de AWS DMS después del cambio de local a AWS.
C.
Configure una base de datos MySQL de Amazon Aurora. Utilice AWS Database Migration Service (AWS DMS) para realizar la replicación continua de datos desde la base de datos local a Aurora. Cree una réplica Aurora para la base de datos Aurora MySQL y mueva los trabajos de agregación para que se ejecuten contra la réplica Aurora. Configure puntos finales de recopilación como funciones de AWS Lambda detrás de un balanceador de carga de aplicaciones (ALB) y use Amazon RDS Proxy para escribir en la base de datos Aurora MySQL. Cuando las bases de datos están sincronizadas, apunte el registro DNS del recopilador al ALB. Deshabilite la tarea de sincronización de AWS DMS después de pasar de local a AWS.
D.
Configure una base de datos MySQL de Amazon Aurora. Cree una réplica Aurora para la base de datos Aurora MySQL y mueva los trabajos de agregación para que se ejecuten contra la réplica Aurora. Configure puntos finales de recopilación como una transmisión de datos de Amazon Kinesis. Utilice Amazon Kinesis Data Firehose para replicar los datos en la base de datos Aurora MySQL. Cuando se sincronicen las bases de datos, deshabilite el trabajo de replicación y reinicie Aurora Replica como instancia principal. Apunte el registro DNS del recopilador al flujo de datos de Kinesis.
AnswerDiscussion
Correct Answer: C
Para migrar el entorno de análisis de datos desde las instalaciones a AWS mientras se abordan los problemas de carga y se garantiza que no haya interrupciones ni cambios para los clientes, es crucial configurar una base de datos Amazon Aurora MySQL y usar AWS Database Migration Service (AWS DMS) para la replicación continua de datos desde la base de datos local. La creación de una réplica Aurora permite que los trabajos de agregación se ejecuten contra ella, descargando así las operaciones de lectura de la base de datos primaria y mitigando los problemas de carga. El uso de las funciones de AWS Lambda detrás de un balanceador de carga de aplicaciones (ALB) para puntos finales de recopilación, combinado con Amazon RDS Proxy para manejar conexiones de base de datos, proporciona escalabilidad y confiabilidad. Una vez sincronizadas las bases de datos, apuntar el registro DNS del recopilador al ALB y deshabilitar la tarea de sincronización de AWS DMS garantiza una transición fluida sin afectar a los usuarios finales.
Question 51 of 529
Una compañía de seguros de salud almacena información de identificación personal (PII) en un cubo de Amazon S3. La compañía utiliza el cifrado del lado del servidor con claves de cifrado administradas S3 (SSE-S3) para cifrar los objetos. De acuerdo con un nuevo requisito, todos los objetos actuales y futuros en el bucket S3 deben estar encriptados por claves que el equipo de seguridad de la compañía administra. El bucket S3 no tiene habilitado el control de versiones.
Qué solución cumplirá con estos requisitos?
A.
En las propiedades del bucket S3, cambie el cifrado predeterminado a SSE-S3 con una clave administrada por el cliente. Utilice la CLI de AWS para volver a cargar todos los objetos en el bucket S3. Establezca una política de bucket S3 para denegar solicitudes de PutObject no cifradas.
B.
En las propiedades del bucket S3, cambie el cifrado predeterminado a cifrado del lado del servidor con claves de cifrado administradas de AWS KMS (SSE-KMS). Establezca una política de bucket S3 para denegar solicitudes de PutObject no cifradas. Utilice la CLI de AWS para volver a cargar todos los objetos en el bucket S3.
C.
En las propiedades del bucket S3, cambie el cifrado predeterminado a cifrado del lado del servidor con claves de cifrado administradas de AWS KMS (SSE-KMS). Establezca una política de bucket de S3 para cifrar automáticamente los objetos en las solicitudes GetObject y PutObject.
D.
En las propiedades del bucket S3, cambie el cifrado predeterminado a AES-256 con una clave administrada por el cliente. Adjunte una política para denegar solicitudes de PutObject no cifradas a cualquier entidad que acceda al bucket S3. Utilice la CLI de AWS para volver a cargar todos los objetos en el bucket S3.
AnswerDiscussion
Correct Answer: B
Para cumplir con el requisito de cifrar todos los objetos actuales y futuros en el bucket S3 con claves que administra el equipo de seguridad de la compañía, la solución adecuada es utilizar el cifrado del lado del servidor con claves de cifrado administradas de AWS KMS (SSE-KMS). Esto permite a la compañía especificar una clave administrada por el cliente que controla a través de AWS KMS. El proceso implica cambiar el cifrado predeterminado en las propiedades del bucket de S3 a SSE-KMS, establecer una política de bucket de S3 para denegar solicitudes de PutObject no cifradas y usar la CLI de AWS para volver a cargar todos los objetos existentes para garantizar que cumplen con el nuevo estándar de cifrado. Este enfoque asegura que tanto los objetos nuevos como los existentes estén encriptados con las claves administradas por el equipo de seguridad de la compañía.
Question 52 of 529
Una empresa está ejecutando una aplicación web en la nube de AWS. La aplicación consiste en contenido dinámico que se crea en un conjunto de instancias de Amazon EC2. Las instancias EC2 se ejecutan en un grupo de Auto Scaling que está configurado como grupo de destino para un balanceador de carga de aplicaciones (ALB).
La compañía está utilizando una distribución de Amazon CloudFront para distribuir la aplicación globalmente. La distribución CloudFront utiliza el ALB como origen. La compañía utiliza Amazon Route 53 para DNS y ha creado un registro A de www.example.com para la distribución de CloudFront.
Un arquitecto de soluciones debe configurar la aplicación para que sea altamente disponible y tolerante a fallas.
Qué solución cumple con estos requisitos?
A.
Aprovisione una implementación completa de aplicaciones secundarias en una región de AWS diferente. Actualice el registro Route 53 A para que sea un registro de conmutación por error. Agregue ambas distribuciones de CloudFront como valores. Crear comprobaciones de estado de la Ruta 53.
B.
Aprovisione un ALB, un grupo de Auto Scaling e instancias EC2 en una región de AWS diferente. Actualice la distribución de CloudFront y cree un segundo origen para el nuevo ALCrear un grupo de origen para los dos orígenes. Configure un origen como primario y un origen como secundario.
C.
Aprovisione un grupo de Auto Scaling e instancias EC2 en una región de AWS diferente. Cree un segundo objetivo para el nuevo grupo Auto Scaling en el ALB. Configure el algoritmo de enrutamiento de conmutación por error en el ALB.
D.
Aprovisione una implementación completa de aplicaciones secundarias en una región de AWS diferente. Cree una segunda distribución de CloudFront y agregue la nueva configuración de la aplicación como origen. Cree un acelerador de AWS Global Accelerator. Agregue ambas distribuciones de CloudFront como endpoints.
AnswerDiscussion
Correct Answer: B
Para garantizar que la aplicación esté altamente disponible y sea tolerante a fallas, la solución implica el aprovisionamiento de un ALB adicional, un grupo de Auto Scaling e instancias EC2 en una región de AWS diferente. Esta configuración garantiza la redundancia y la capacidad de conmutación por error. Al actualizar la distribución de CloudFront para incluir un segundo origen para el nuevo ALB y crear un grupo de origen con ambos orígenes, CloudFront puede enrutar automáticamente el tráfico al origen en buen estado si falla el principal. Este enfoque aprovecha el alcance global de CloudFront para mejorar la disponibilidad y la tolerancia a fallas sin depender de los cambios a nivel de DNS, lo que podría introducir latencia.
Question 53 of 529
Una empresa tiene una organización en AWS Organizations que cuenta con un gran número de cuentas de AWS. Una de las cuentas de AWS está designada como cuenta de tránsito y tiene una puerta de enlace de tránsito que se comparte con todas las demás cuentas de AWS. Las conexiones VPN de sitio a sitio de AWS se configuran entre todas las oficinas globales de la compañía y la cuenta de tránsito. La compañía tiene AWS Config habilitada en todas sus cuentas.
El equipo de redes de la compañía necesita administrar de manera centralizada una lista de rangos de direcciones IP internas que pertenecen a las oficinas globales. Los desarrolladores harán referencia a esta lista para obtener acceso a sus aplicaciones de forma segura.
Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Cree un archivo JSON alojado en Amazon S3 y que enumere todos los rangos de direcciones IP internas. Configure un tema de Amazon Simple Notification Service (Amazon SNS) en cada una de las cuentas que se puedan invocar cuando se actualice el archivo JSON. Suscríbase una función de AWS Lambda al tema SNS para actualizar todas las reglas de grupos de seguridad relevantes con los rangos de direcciones IP actualizados.
B.
Cree una nueva regla administrada de AWS Config que contenga todos los rangos de direcciones IP internas. Utilice la regla para verificar los grupos de seguridad en cada una de las cuentas para asegurar el cumplimiento de la lista de rangos de direcciones IP. Configure la regla para corregir automáticamente cualquier grupo de seguridad no conforme que se detecte.
C.
En la cuenta de tránsito, cree una lista de prefijos de VPC con todos los rangos de direcciones IP internas. Utilice AWS Resource Access Manager para compartir la lista de prefijos con todas las demás cuentas. Utilice la lista de prefijos compartidos para configurar reglas de grupos de seguridad en las otras cuentas.
D.
En la cuenta de tránsito, cree un grupo de seguridad con todos los rangos de direcciones IP internas. Configure los grupos de seguridad en las otras cuentas para hacer referencia al grupo de seguridad de la cuenta de tránsito usando una referencia de grupo de seguridad anidada de “/sg-1a2b3c4d”.
AnswerDiscussion
Correct Answer: C
La mejor solución es crear una lista de prefijos de VPC con todos los rangos de direcciones IP internas en la cuenta de tránsito y compartir esta lista de prefijos con todas las demás cuentas usando AWS Resource Access Manager. Este método permite la administración central de los rangos de direcciones IP y reduce la sobrecarga operativa. Al usar la lista de prefijos para configurar reglas de grupos de seguridad en otras cuentas, esta solución simplifica el proceso de actualización y garantiza configuraciones de seguridad consistentes en toda la organización.
Question 54 of 529
Una empresa ejecuta una nueva aplicación como sitio web estático en Amazon S3. La compañía ha implementado la aplicación en una cuenta de AWS de producción y utiliza Amazon CloudFront para entregar el sitio web. El sitio web llama una API REST de Amazon API Gateway. Una función de AWS Lambda respalda cada método API.
La compañía quiere crear un informe CSV cada 2 semanas para mostrar la memoria configurada recomendada de cada función API Lambda, el costo recomendado y la diferencia de precio entre las configuraciones actuales y las recomendaciones. La compañía almacenará los informes en un bucket S3.
Qué solución cumplirá estos requisitos con el menor tiempo de desarrollo?
A.
Cree una función Lambda que extraiga datos de métricas para cada función API Lambda de Amazon CloudWatch Logs durante el período de 2 semanas. Colocar los datos en formato tabular. Almacene los datos como un archivo.csv en un bucket S3. Cree una regla de Amazon EventBridge para programar la función Lambda para que se ejecute cada 2 semanas.
B.
Opte por AWS Compute Optimizer. Cree una función Lambda que llame a la operación ExportLambdaFunctionRecommendations. Exporte el archivo.csv a un bucket S3. Cree una regla de Amazon EventBridge para programar la función Lambda para que se ejecute cada 2 semanas.
C.
Opte por AWS Compute Optimizer. Configure métricas de infraestructura mejoradas. Dentro de la consola Compute Optimizer, programe un trabajo para exportar las recomendaciones de Lambda a un archivo.csv. Almacene el archivo en un bucket S3 cada 2 semanas.
D.
Adquiera el plan de AWS Business Support para la cuenta de producción. Opte por AWS Compute Optimizer para las comprobaciones de AWS Trusted Advisor. En la consola de Trusted Advisor, programe un trabajo para exportar las comprobaciones de optimización de costos a un archivo.csv. Almacene el archivo en un bucket S3 cada 2 semanas.
AnswerDiscussion
Correct Answer: B
Optar por AWS Compute Optimizer y crear una función Lambda que llame a la operación ExportLambdaFunctionRecommendations es la solución más eficiente para minimizar el tiempo de desarrollo. AWS Compute Optimizer ya realiza los análisis y recomendaciones necesarios para las funciones de AWS Lambda, incluida la optimización de costos y memoria. Al aprovechar la API ExportLambdaFunctionRecommendations, la compañía puede automatizar la extracción de estas recomendaciones directamente en un archivo CSV que luego se almacena en un bucket S3. La programación de esta función Lambda para que se ejecute cada dos semanas con Amazon EventBridge garantiza la automatización con un mínimo de código y esfuerzo de desarrollo.
Question 55 of 529
Las aplicaciones de fábrica y automatización de una empresa se ejecutan en una sola VPC. Más de 20 aplicaciones se ejecutan en una combinación de Amazon EC2, Amazon Elastic Container Service (Amazon ECS) y Amazon RDS.
La compañía cuenta con ingenieros de software repartidos en tres equipos. Uno de los tres equipos posee cada aplicación, y cada vez es responsable del costo y rendimiento de todas sus aplicaciones. Los recursos del equipo tienen etiquetas que representan su aplicación y equipo. Los equipos utilizan el acceso IAM para las actividades diarias.
La compañía necesita determinar qué costos en la factura mensual de AWS son atribuibles a cada aplicación o equipo. La compañía también debe poder crear reportes para comparar costos de los últimos 12 meses y ayudar a pronosticar costos para los próximos 12 meses. Un arquitecto de soluciones debe recomendar una solución de facturación y gestión de costos de AWS que proporcione estos informes de costos.
Qué combinación de acciones cumplirá con estos requisitos? (Elija tres.)
A.
Activar las etiquetas de asignación de costos definidas por el usuario que representan la aplicación y el equipo.
B.
Activar las etiquetas de asignación de costos generadas por AWS que representan la aplicación y el equipo.
C.
Cree una categoría de costos para cada aplicación en Facturación y Administración de Costos.
D.
Activa el acceso de IAM a Facturación y Administración de Costos.
E.
Crear un presupuesto de costos.
F.
Habilite el Explorador de Costos.
AnswerDiscussion
Correct Answer: A, D, F
Para determinar con precisión qué costos en la factura mensual de AWS son atribuibles a cada aplicación o equipo y para crear informes detallados que comparen los costos de los últimos 12 meses y pronosticar costos para los próximos 12 meses, son necesarias las siguientes acciones: Primero, activar las etiquetas de asignación de costos definidas por el usuario que representan la aplicación y el equipo, asegurando que los costos se puedan atribuir adecuadamente. En segundo lugar, habilite Cost Explorer, que permite analizar gastos pasados y pronosticar costos futuros. Por último, es crucial activar el acceso de IAM a Facturación y Administración de Costos, para que los miembros del equipo que sean responsables de los costos y el desempeño de su aplicación puedan acceder a la información y reportes de facturación necesarios.
Question 56 of 529
Un cliente de AWS tiene una aplicación web que se ejecuta en las instalaciones. La aplicación web obtiene datos de una API de terceros que está detrás de un firewall. El tercero acepta solo un bloque CIDR público en la lista de permisos de cada cliente.
El cliente quiere migrar su aplicación web a la nube de AWS. La aplicación se alojará en un conjunto de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB) en una VPC. El ALB se encuentra en subredes públicas. Las instancias EC2 se encuentran en subredes privadas. Las puertas de enlace NAT proporcionan acceso a Internet a las subredes privadas.
Cómo debe un arquitecto de soluciones garantizar que la aplicación web pueda seguir llamando a la API de terceros después de la migración?
A.
Asocie un bloque de direcciones IP públicas propiedad del cliente a la VPC. Habilite la dirección IP pública para las subredes públicas en la VPC.
B.
Registre un bloque de direcciones IP públicas propiedad del cliente en la cuenta de AWS. Cree direcciones IP elásticas a partir del bloque de direcciones y asígnelas a las puertas de enlace NAT en la VPC.
C.
Cree direcciones IP elásticas a partir del bloque de direcciones IP propiedad del cliente. Asigne las direcciones IP elásticas estáticas al ALB.
D.
Registre un bloque de direcciones IP públicas propiedad del cliente en la cuenta de AWS. Configure AWS Global Accelerator para usar direcciones IP elásticas del bloque de direcciones. Establezca el ALB como punto final del acelerador.
AnswerDiscussion
Correct Answer: B
Para garantizar que la aplicación web migrada pueda seguir llamando a la API de terceros, la solución debe permitir que el tercero incluya en la lista blanca un único bloque CIDR público a través del cual parecerán provenir las solicitudes. Al registrar un bloque de direcciones IP públicas propiedad del cliente en la cuenta de AWS y crear direcciones IP elásticas a partir de ese bloque para asignarlas a las puertas de enlace NAT en la VPC, todo el tráfico saliente de las instancias EC2 a la API de terceros se enrutará a través de las puertas de enlace NAT. Esta configuración asegura que la IP de origen vista por la API de terceros siga siendo consistente y permite usar el bloque CIDR propiedad del cliente para la lista de permisos.
Question 57 of 529
Una empresa con varias cuentas de AWS está utilizando organizaciones de AWS y políticas de control de servicios (SCP). Un administrador creó el siguiente SCP y lo ha adjuntado a una unidad organizativa (OU) que contiene la cuenta de AWS 1111-1111-1111:
Los desarrolladores que trabajan en la cuenta 1111-1111-1111 se quejan de que no pueden crear buckets de Amazon S3. Cómo debe abordar el administrador este problema?
A.
Agrega s3:CreateBucket con el efecto “Permitir” al SCP.
B.
Retire la cuenta de la unidad organizativa y adjunte el SCP directamente a la cuenta 1111-1111-1111.
C.
Instruya a los desarrolladores para que agreguen permisos de Amazon S3 a sus entidades de IAM.
D.
Quitar el SCP de la cuenta 1111-1111-1111.
AnswerDiscussion
Correct Answer: C
El problema descrito no se origina a partir de la propia Política de Control de Servicio (SCP) basada en el contenido de SCP proporcionado. El SCP está configurado para permitir todas las acciones excepto las relacionadas con AWS CloudTrail, que se deniegan explícitamente. Por lo tanto, la incapacidad de los desarrolladores para crear buckets de Amazon S3 no se debe a este SCP, ya que no restringe las acciones de S3. Los SCP definen barandales y establecen límites a las acciones y no otorgan permisos directamente. El problema probable es que las entidades IAM de los desarrolladores carecen de los permisos necesarios para crear buckets S3. Por lo tanto, la forma correcta de abordar este problema es instruir a los desarrolladores para que agreguen permisos de Amazon S3 a sus entidades de IAM, ya que se requieren permisos de IAM para realizar acciones dentro de las cuentas de AWS.
Question 58 of 529
Una empresa tiene una aplicación monolítica que es crítica para el negocio de la compañía. La compañía aloja la aplicación en una instancia de Amazon EC2 que ejecuta Amazon Linux 2. El equipo de aplicaciones de la compañía recibe una directiva del departamento legal para hacer copias de seguridad de los datos del volumen cifrado de Amazon Elastic Block Store (Amazon EBS) de la instancia en un bucket de Amazon S3. El equipo de aplicación no tiene el par de claves SSH administrativas para la instancia. La aplicación debe seguir atendiendo a los usuarios.
Qué solución cumplirá con estos requisitos?
A.
Adjunte un rol a la instancia con permiso para escribir en Amazon S3. Utilice la opción de AWS Systems Manager Session Manager para obtener acceso a la instancia y ejecutar comandos para copiar datos en Amazon S3.
B.
Crea una imagen de la instancia con la opción de reinicio activada. Lanzar una nueva instancia EC2 desde la imagen. Adjunte un rol a la nueva instancia con permiso para escribir en Amazon S3. Ejecute un comando para copiar datos en Amazon S3.
C.
Tome una instantánea del volumen de EBS mediante Amazon Data Lifecycle Manager (Amazon DLM). Copie los datos en Amazon S3.
D.
Crear una imagen de la instancia. Lanzar una nueva instancia EC2 desde la imagen. Adjunte un rol a la nueva instancia con permiso para escribir en Amazon S3. Ejecute un comando para copiar datos en Amazon S3.
AnswerDiscussion
Correct Answer: A
Para realizar una copia de seguridad de los datos del volumen EBS de una instancia de EC2 en un bucket S3 sin interrumpir la aplicación en ejecución y sin requerir acceso SSH, adjunte un rol de IAM a la instancia con permisos para escribir en S3. A continuación, utilice AWS Systems Manager Session Manager para acceder a la instancia y ejecutar comandos para copiar los datos en S3. Este método permite el acceso remoto sin necesidad de claves SSH administrativas y mantiene el funcionamiento continuo de la aplicación.
Question 59 of 529
Un arquitecto de soluciones necesita copiar datos de un bucket de Amazon S3 en una cuenta de AWS a un nuevo bucket S3 en una nueva cuenta de AWS. El arquitecto de soluciones debe implementar una solución que utilice la CLI de AWS.
Qué combinación de pasos copiará con éxito los datos? (Elija tres.)
A.
Cree una política de bucket para permitir que el bucket de origen enumere su contenido y ponga objetos y establezca ACL de objetos en el bucket de destino. Adjunte la política de bucket al bucket de destino.
B.
Cree una política de bucket para permitir que un usuario en la cuenta de destino enumere el contenido del bucket de origen y lea los objetos del bucket de origen. Adjunte la política de bucket al bucket de origen.
C.
Crear una política de IAM en la cuenta de origen. Configure la política para permitir que un usuario de la cuenta de origen enumere el contenido y obtenga objetos en el bucket de origen, y que enumere el contenido, coloque objetos y establezca ACL de objetos en el bucket de destino. Adjuntar la política al usuario.
D.
Crear una política de IAM en la cuenta de destino. Configure la política para permitir que un usuario de la cuenta de destino enumere el contenido y obtenga objetos en el bucket de origen, y que enumere el contenido, coloque objetos y establezca ObjectACL en el bucket de destino. Adjuntar la política al usuario.
E.
Ejecute el comando aws s3 sync como usuario en la cuenta de origen. Especifique los buckets de origen y destino para copiar los datos.
F.
Ejecute el comando aws s3 sync como usuario en la cuenta de destino. Especifique los buckets de origen y destino para copiar los datos.
AnswerDiscussion
Correct Answer: B, D, F
Para copiar datos de un bucket S3 de origen en una cuenta de AWS a un bucket S3 de destino en una nueva cuenta de AWS mediante la CLI de AWS, debe seguir estos pasos: Crear una política de bucket para permitir que un usuario de la cuenta de destino enumere el contenido del bucket de origen y lea sus objetos. Adjunte esta política al bucket de origen para otorgar los permisos necesarios. Luego, cree una política de IAM en la cuenta de destino que permita a un usuario enumerar contenidos y obtener objetos del bucket de origen, así como enumerar contenidos, poner objetos y establecer ACL de objetos en el bucket de destino. Adjuntar esta política al usuario. Finalmente, ejecute el comando 'aws s3 sync' como usuario en la cuenta de destino. Al ejecutar el comando sync como usuario en la cuenta de destino, se asegura de que los objetos copiados tendrán los permisos adecuados para los usuarios en la cuenta de destino. Por lo tanto, los pasos correctos son B, D y F.
Question 60 of 529
Una compañía creó una aplicación basada en AWS Lambda implementada en una pila de AWS CloudFormation. El último lanzamiento de producción de la aplicación web introdujo un problema que resultó en una interrupción que duró varios minutos. Un arquitecto de soluciones debe ajustar el proceso de implementación para admitir una versión canaria.
Qué solución cumplirá con estos requisitos?
A.
Cree un alias para cada nueva versión implementada de la función Lambda. Utilice el comando update-alias de la CLI de AWS con el parámetro routing-config para distribuir la carga.
B.
Despliegue la aplicación en una nueva pila de CloudFormation. Utilice una política de enrutamiento ponderado de Amazon Route 53 para distribuir la carga.
C.
Cree una versión para cada nueva función Lambda implementada. Utilice el comando update-function-configuration de la CLI de AWS con el parámetro routing-config para distribuir la carga.
D.
Configure AWS CodeDeploy y use CodeDeployDefault.OneAtatime en la configuración de implementación para distribuir la carga.
AnswerDiscussion
Correct Answer: A
Para admitir una versión canaria para una función de AWS Lambda, es efectivo crear un alias para cada nueva versión implementada de la función Lambda. El uso del comando update-alias de la CLI de AWS con el parámetro routing-config le permite distribuir el tráfico entre diferentes versiones de la función. Este enfoque le permite cambiar gradualmente el tráfico a la nueva versión, monitorear su rendimiento y retroceder rápidamente si surge algún problema. Proporciona una solución más simple y efectiva en comparación con la implementación en una nueva pila de CloudFormation o el uso de CodeDeploy, especialmente dado que las configuraciones específicas de CodeDeploy no se mencionaron como opciones.
Question 61 of 529
Una empresa financiera aloja un lago de datos en Amazon S3. La compañía recibe registros de datos financieros a través de SFTP cada noche de varios terceros. La compañía ejecuta su propio servidor SFTP en una instancia de Amazon EC2 en una subred pública de una VPC. Después de cargar los archivos, se mueven al lago de datos mediante un trabajo cron que se ejecuta en la misma instancia. Se puede acceder al servidor SFTP en DNS sftp.example.com mediante el uso de Amazon Route 53.
Qué debe hacer un arquitecto de soluciones para mejorar la confiabilidad y escalabilidad de la solución SFTP?
A.
Mueva la instancia EC2 a un grupo de Auto Scaling. Coloque la instancia EC2 detrás de un balanceador de carga de aplicaciones (ALB). Actualiza el registro DNS sftp.example.com en la Ruta 53 para apuntar al ALB.
B.
Migre el servidor SFTP a AWS Transfer para SFTP. Actualice el registro DNS sftp.example.com en Route 53 para que apunte al nombre de host del endpoint del servidor.
C.
Migre el servidor SFTP a una puerta de enlace de archivos en AWS Storage Gateway. Actualice el registro DNS sftp.example.com en Route 53 para que apunte al punto final de puerta de enlace de archivos.
D.
Coloque la instancia EC2 detrás de un balanceador de carga de red (NLB). Actualiza el registro DNS sftp.example.com en la Ruta 53 para que apunte a la NLB.
AnswerDiscussion
Correct Answer: B
La migración del servidor SFTP a AWS Transfer para SFTP mejoraría significativamente la confiabilidad y escalabilidad de la solución SFTP. AWS Transfer para SFTP es un servicio completamente administrado proporcionado por AWS, lo que significa que AWS se encarga de la administración de la infraestructura, incluida la alta disponibilidad y el escalado automático. Esta solución permite a la empresa transferir archivos directamente dentro y fuera de Amazon S3 mediante el protocolo SFTP, integrándose así a la perfección con la configuración del lago de datos existente en S3. La actualización del registro DNS en Route 53 para que apunte al nombre de host del punto final del servidor garantiza que el servicio siga siendo accesible usando el nombre DNS existente.
Question 62 of 529
Una empresa quiere migrar una aplicación a Amazon EC2 desde VMware Infrastructure que se ejecute en un centro de datos local. Un arquitecto de soluciones debe conservar el software y los ajustes de configuración durante la migración.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Configure el agente AWS DataSync para comenzar a replicar el data store en Amazon FSx para Windows File Server. Utilice el recurso compartido SMB para alojar el data store de VMware. Utilice VM Import/Export para mover las máquinas virtuales a Amazon EC2.
B.
Utilice el cliente VMware vSphere para exportar la aplicación como una imagen en formato Open Virtualization Format (OVF). Cree un bucket de Amazon S3 para almacenar la imagen en la región de AWS de destino. Cree y aplique un rol de IAM para la importación de VM. Utilice la CLI de AWS para ejecutar el comando EC2 import.
C.
Configure AWS Storage Gateway para el servicio de archivos para exportar un recurso compartido de Common Internet File System (CIFS). Cree una copia de seguridad en la carpeta compartida. Inicie sesión en la consola de administración de AWS y cree una AMI a partir de la copia de seguridad. Lanzar una instancia EC2 basada en la AMI.
D.
Cree una activación de instancia administrada para un entorno híbrido en AWS Systems Manager. Descargue e instale Systems Manager Agent en la máquina virtual local. Registre la VM con Systems Manager para que sea una instancia administrada. Utilice AWS Backup para crear una instantánea de la VM y crear una AMI. Lanzar una instancia EC2 basada en la AMI.
AnswerDiscussion
Correct Answer: B
Para migrar una aplicación de VMware Infrastructure en un centro de datos local a Amazon EC2 mientras se conservan los ajustes de configuración y software, utilice el cliente VMware vSphere para exportar la aplicación como una imagen en formato Open Virtualization Format (OVF). Almacene la imagen en un bucket de Amazon S3 en la región de AWS de destino. Cree y aplique una función de IAM para VM Import y utilice la AWS CLI para ejecutar el comando EC2 import. Este método garantiza que el software y los ajustes de configuración se mantengan durante el proceso de migración.
Question 63 of 529
Una empresa de procesamiento de video tiene una aplicación que descarga imágenes de un bucket de Amazon S3, procesa las imágenes, almacena una imagen transformada en un segundo bucket S3 y actualiza metadatos sobre la imagen en una tabla de Amazon DynamoDB. La aplicación está escrita en Node.js y se ejecuta mediante una función de AWS Lambda. La función Lambda se invoca cuando se carga una nueva imagen en Amazon S3.
La aplicación se ejecutó sin incidentes por un tiempo. Sin embargo, el tamaño de las imágenes ha crecido significativamente. La función Lambda ahora está fallando frecuentemente con errores de tiempo de espera. El tiempo de espera de la función se establece en su valor máximo. Un arquitecto de soluciones necesita refactorizar la arquitectura de la aplicación para evitar fallas de invocación. La compañía no quiere administrar la infraestructura subyacente.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Modifique la implementación de la aplicación creando una imagen Docker que contenga el código de la aplicación. Publique la imagen en Amazon Elastic Container Registry (Amazon ECR).
B.
Cree una nueva definición de tarea de Amazon Elastic Container Service (Amazon ECS) con un tipo de compatibilidad de AWS Fargate. Configure la definición de tarea para usar la nueva imagen en Amazon Elastic Container Registry (Amazon ECR). Ajuste la función Lambda para invocar una tarea ECS mediante la definición de tarea ECS cuando llegue un nuevo archivo a Amazon S3.
C.
Cree una máquina de estado AWS Step Functions con un estado Parallel para invocar la función Lambda. Aumentar la concurrencia aprovisionada de la función Lambda.
D.
Cree una nueva definición de tarea de Amazon Elastic Container Service (Amazon ECS) con un tipo de compatibilidad de Amazon EC2. Configure la definición de tarea para usar la nueva imagen en Amazon Elastic Container Registry (Amazon ECR). Ajuste la función Lambda para invocar una tarea ECS mediante la definición de tarea ECS cuando llegue un nuevo archivo a Amazon S3.
E.
Modifique la aplicación para almacenar imágenes en Amazon Elastic File System (Amazon EFS) y para almacenar metadatos en una instancia de base de datos de Amazon RDS. Ajuste la función Lambda para montar el recurso compartido de archivos EFS.
AnswerDiscussion
Correct Answer: A, B
La aplicación actual está experimentando errores de tiempo de espera debido al mayor tamaño de las imágenes que se procesan. Para abordar este problema, es recomendable contenerizar el código de la aplicación y ejecutarlo en un servicio que pueda manejar los mayores requerimientos de recursos. Primero, al modificar la implementación de la aplicación para construir una imagen Docker y publicarla en Amazon Elastic Container Registry (ECR), se asegura que la aplicación se empaqueta de manera eficiente. Luego, la creación de una nueva definición de tarea de Amazon Elastic Container Service (ECS) con un tipo de compatibilidad de AWS Fargate permite que la aplicación contenerizada se ejecute sin administrar la infraestructura subyacente. Fargate asigna automáticamente los recursos necesarios, mitiga los errores de tiempo de espera y cumple con los requisitos de la compañía de no administrar la infraestructura subyacente.
Question 64 of 529
Una empresa tiene una organización en AWS Organizations. La compañía está utilizando AWS Control Tower para implementar una zona de aterrizaje para la organización. La compañía quiere implementar la gobernanza y la aplicación de políticas. La compañía debe implementar una política que detecte instancias de base de datos de Amazon RDS que no estén cifradas en reposo en la unidad organizativa de producción de la compañía.
Qué solución cumplirá con este requisito?
A.
Encienda las barandillas obligatorias en la Torre de Control de AWS. Aplicar los barandales obligatorios a la OU de producción.
B.
Habilite la barandilla apropiada de la lista de barandillas altamente recomendadas en AWS Control Tower. Aplicar la barandilla a la OU de producción.
C.
Utilice AWS Config para crear una nueva barandilla obligatoria. Aplicar la regla a todas las cuentas de la OU de producción.
D.
Cree un SCP personalizado en AWS Control Tower. Aplicar el SCP a la OU de producción.
AnswerDiscussion
Correct Answer: B
Para cumplir con el requisito de detectar instancias de base de datos de Amazon RDS que no están cifradas en reposo en la unidad organizativa de producción de la compañía, habilitar la barandilla adecuada de la lista de barandas altamente recomendadas en AWS Control Tower es la solución adecuada. Estas barandillas altamente recomendadas ofrecen comprobaciones de las mejores prácticas y medidas de seguridad adicionales que no se aplican automáticamente, pero que se pueden usar para aplicar políticas como el cifrado en reposo para instancias RDS. Esto asegurará que todas las instancias RDS en la unidad organizativa de producción sean verificadas para verificar el cumplimiento del cifrado, cumpliendo así con los requisitos de la compañía.
Question 65 of 529
Una empresa startup aloja una flota de instancias de Amazon EC2 en subredes privadas utilizando la última AMI de Amazon Linux 2. Los ingenieros de la compañía confían en gran medida en el acceso SSH a las instancias para la resolución de problemas.
La arquitectura existente de la compañía incluye lo siguiente:
• Una VPC con subredes privadas y públicas, y una puerta de enlace NAT.
• VPN de sitio a sitio para conectividad con el entorno local.
• Grupos de seguridad EC2 con acceso directo SSH desde el entorno local.
La compañía necesita aumentar los controles de seguridad en torno al acceso SSH y proporcionar auditoría de comandos ejecutados por los ingenieros.
Qué estrategia debe utilizar un arquitecto de soluciones?
A.
Instale y configure EC2 Instance Connect en la flota de instancias EC2. Elimine todas las reglas de grupo de seguridad asociadas a instancias EC2 que permitan TCP entrante en el puerto 22. Aconseje a los ingenieros para que accedan de forma remota a las instancias mediante la CLI de EC2 Instance Connect.
B.
Actualice los grupos de seguridad EC2 para permitir únicamente TCP entrante en el puerto 22 a las direcciones IP de los dispositivos del ingeniero. Instale el agente de Amazon CloudWatch en todas las instancias EC2 y envíe los registros de auditoría del sistema operativo a CloudWatch Logs.
C.
Actualice los grupos de seguridad EC2 para permitir únicamente TCP entrante en el puerto 22 a las direcciones IP de los dispositivos del ingeniero. Habilite AWS Config para cambios en los recursos del grupo de seguridad EC2. Habilite AWS Firewall Manager y aplique una política de grupo de seguridad que corrija automáticamente los cambios en las reglas.
D.
Cree un rol de IAM con la política administrada AmazonsSMManagedInanceCore adjunta. Adjunte el rol de IAM a todas las instancias EC2. Elimine todas las reglas de grupo de seguridad asociadas a las instancias EC2 que permiten TCP entrante en el puerto 22. Haga que los ingenieros instalen el complemento AWS Systems Manager Session Manager para sus dispositivos y accedan de forma remota a las instancias mediante la llamada a la API de inicio de sesión de Systems Manager.
AnswerDiscussion
Correct Answer: D
La creación de un rol de IAM con la política administrada AmazonsSMManagedInanceCore y el uso de AWS Systems Manager Session Manager proporciona capacidades mejoradas de seguridad y auditoría sin necesidad de SSH. Al adjuntar el rol de IAM a las instancias EC2, el acceso SSH puede restringirse eliminando TCP entrante en el puerto 22. Luego, los ingenieros pueden usar el Administrador de sesiones de Systems Manager para iniciar sesiones, que se registran con fines de auditoría. Este enfoque aumenta la seguridad al eliminar la dependencia de las reglas de grupo de seguridad basadas en IP y garantiza que todas las actividades sean rastreadas y auditables.
Question 66 of 529
Una empresa que utiliza AWS Organizations permite a los desarrolladores experimentar en AWS. Como parte de la zona de aterrizaje que la compañía ha desplegado, los desarrolladores utilizan la dirección de correo electrónico de su empresa para solicitar una cuenta. La compañía quiere asegurarse de que los desarrolladores no estén lanzando servicios costosos o ejecutando servicios innecesariamente. La compañía debe dar a los desarrolladores un presupuesto mensual fijo para limitar sus costos de AWS.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Cree un SCP para establecer un límite fijo de uso mensual de la cuenta. Aplicar el SCP a las cuentas de desarrollador.
B.
Utilice los presupuestos de AWS para crear un presupuesto mensual fijo para cada cuenta de desarrollador como parte del proceso de creación de la cuenta.
C.
Cree un SCP para denegar el acceso a servicios y componentes costosos. Aplicar el SCP a las cuentas de desarrollador.
D.
Cree una política de IAM para denegar el acceso a servicios y componentes costosos. Aplicar la política de IAM a las cuentas de desarrollador.
E.
Cree una acción de alerta de presupuestos de AWS para terminar los servicios cuando se alcance el monto presupuestado. Configure la acción para terminar todos los servicios.
F.
Cree una acción de alerta de presupuestos de AWS para enviar una notificación de Amazon Simple Notification Service (Amazon SNS) cuando se alcance el monto presupuestado. Invocar una función de AWS Lambda para terminar todos los servicios.
AnswerDiscussion
Correct Answer: B, C, F
Para cumplir con los requisitos, primero, cree un presupuesto mensual fijo para cada cuenta de desarrollador utilizando AWS Budget. Segundo, crear una Política de Control de Servicios (SCP) para denegar el acceso a servicios y componentes costosos, que se pueden aplicar a las cuentas de desarrollador para garantizar que no lancen recursos costosos. Por último, configure una acción de alerta de presupuestos de AWS para enviar una notificación SNS cuando se alcance el monto presupuestado. Esta notificación puede invocar una función Lambda para terminar todos los servicios, administrando efectivamente los costos y asegurando que los desarrolladores se mantengan dentro de sus presupuestos mensuales.
Question 67 of 529
Una empresa tiene aplicaciones en una cuenta de AWS que se llama Source. La cuenta está en una organización de AWS Organizations. Una de las aplicaciones utiliza las funciones de AWS Lambda y almacena datos de inventario en una base de datos de Amazon Aurora. La aplicación implementa las funciones de Lambda mediante el uso de un paquete de implementación. La compañía ha configurado copias de seguridad automatizadas para Aurora.
La compañía quiere migrar las funciones Lambda y la base de datos Aurora a una nueva cuenta de AWS que se llama Target. La aplicación procesa datos críticos, por lo que la empresa debe minimizar el tiempo de inactividad.
Qué solución cumplirá con estos requisitos?
A.
Descargue el paquete de implementación de la función Lambda desde la cuenta Source. Utilice el paquete de implementación y cree nuevas funciones Lambda en la cuenta Target. Comparta la instantánea automatizada del clúster de base de datos Aurora con la cuenta Target.
B.
Descargue el paquete de implementación de la función Lambda desde la cuenta Source. Utilice el paquete de implementación y cree nuevas funciones Lambda en la cuenta Target. Comparta el clúster de base de datos Aurora con la cuenta Target mediante AWS Resource Access Manager {AWS RAM). Otorgue permiso a la cuenta Target para clonar el clúster de base de datos Aurora.
C.
Utilice AWS Resource Access Manager (AWS RAM) para compartir las funciones de Lambda y el clúster de base de datos Aurora con la cuenta Target. Otorgue permiso a la cuenta Target para clonar el clúster de base de datos Aurora.
D.
Utilice AWS Resource Access Manager (AWS RAM) para compartir las funciones de Lambda con la cuenta de Target. Comparta la instantánea automatizada del clúster de base de datos Aurora con la cuenta Target.
AnswerDiscussion
Correct Answer: A
Para migrar las funciones Lambda y la base de datos Aurora a una nueva cuenta de AWS mientras se minimiza el tiempo de inactividad, la solución más práctica consiste en crear nuevas funciones Lambda en la cuenta de Target utilizando el paquete de implementación y compartir la instantánea automatizada del clúster de base de datos Aurora con la cuenta de Target. Este método aprovecha las funcionalidades existentes para garantizar una interrupción mínima. La creación de nuevas funciones Lambda en la cuenta Target garantiza que las funciones de Lambda estén configuradas correctamente sin depender de métodos de uso compartido potencialmente no compatibles. Compartir la instantánea automatizada del clúster de base de datos Aurora permite que la cuenta Target restaure la base de datos y continúe las operaciones con los datos críticos intactos.
Question 68 of 529
Una empresa ejecuta un script de Python en una instancia de Amazon EC2 para procesar datos. El guión se ejecuta cada 10 minutos. El script ingiere archivos de un bucket de Amazon S3 y los procesa. En promedio, el script tarda aproximadamente 5 minutos en procesar cada archivo El script no volverá a procesar un archivo que el script ya haya procesado.
La compañía revisó las métricas de Amazon CloudWatch y notó que la instancia EC2 está inactiva durante aproximadamente el 40% del tiempo debido a la velocidad de procesamiento de archivos. La compañía quiere que la carga de trabajo sea altamente disponible y escalable. La compañía también quiere reducir los gastos generales de gestión a largo plazo.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Migre el script de procesamiento de datos a una función de AWS Lambda. Utilice una notificación de eventos S3 para invocar la función Lambda para procesar los objetos cuando la empresa carga los objetos.
B.
Cree una cola de Amazon Simple Queue Service (Amazon SQS). Configure Amazon S3 para enviar notificaciones de eventos a la cola SQS. Cree un grupo EC2 Auto Scaling con un tamaño mínimo de una instancia. Actualice el script de procesamiento de datos para sondear la cola SQS. Procese los objetos S3 que identifica el mensaje SQS.
C.
Migrar el script de procesamiento de datos a una imagen de contenedor. Ejecute el contenedor de procesamiento de datos en una instancia EC2. Configure el contenedor para sondear el bucket S3 en busca de nuevos objetos y para procesar los objetos resultantes.
D.
Migre el script de procesamiento de datos a una imagen de contenedor que se ejecute en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Cree una función de AWS Lambda que llame a la operación Fargate RunTaskAPI cuando el contenedor procesa el archivo. Utilice una notificación de evento S3 para invocar la función Lambda.
AnswerDiscussion
Correct Answer: A
La migración del script de procesamiento de datos a una función de AWS Lambda y el uso de una notificación de eventos S3 para invocar la función Lambda para procesar los objetos cuando la empresa carga los objetos es la solución más rentable. Lambda no tiene servidor, lo que significa que no hay necesidad de administrar ninguna infraestructura. Se escala automáticamente en función del número de solicitudes, lo que garantiza una alta disponibilidad y capacidades de escalado. El modelo de precios de pago por uso de Lambda probablemente será más rentable para esta carga de trabajo en comparación con ejecutar una instancia EC2 o administrar contenedores ECS, especialmente considerando que el script se ejecuta solo 5 minutos cada 10 minutos. Este enfoque también minimiza los gastos generales de gestión a largo plazo.
Question 69 of 529
Una compañía de servicios financieros en Norteamérica planea lanzar una nueva aplicación web en línea a sus clientes en AWS. La compañía lanzará la aplicación en la región us-east-1 en instancias de Amazon EC2. La aplicación debe estar altamente disponible y debe escalar dinámicamente para satisfacer el tráfico de usuarios. La compañía también quiere implementar un entorno de recuperación ante desastres para la aplicación en la región us-west-1 mediante el uso de failover activo-pasivo.
Qué solución cumplirá con estos requisitos?
A.
Cree una VPC en us-east-1 y una VPC en us-west-1. Configurar el peering de VPC. En la VPC us-east-1, cree un balanceador de carga de aplicaciones (ALB) que se extienda a través de varias zonas de disponibilidad en ambas VPC. Cree un grupo de Auto Scaling que implemente las instancias EC2 en las múltiples zonas de disponibilidad en ambas VPC. Coloque el grupo Auto Scaling detrás del ALB.
B.
Cree una VPC en us-east-1 y una VPC en us-west-1. En la VPC us-east-1, cree un balanceador de carga de aplicaciones (ALB) que se extienda a través de varias zonas de disponibilidad en esa VPC. Cree un grupo de Auto Scaling que implemente las instancias EC2 en las múltiples zonas de disponibilidad en la VPC us-east-1. Coloque el grupo Auto Scaling detrás del ALConfigure la misma configuración en la VPC us-west-1. Crea una zona alojada de Amazon Route 53. Cree registros separados para cada unHabilite las comprobaciones de estado para garantizar una alta disponibilidad entre regiones.
C.
Cree una VPC en us-east-1 y una VPC en us-west-1. En la VPC us-east-1, cree un balanceador de carga de aplicaciones (ALB) que se extienda a través de varias zonas de disponibilidad en esa VPCrear un grupo de Auto Scaling que implemente las instancias EC2 en las múltiples zonas de disponibilidad en la VPN us-east-1 Coloque el grupo Auto Scaling detrás del ALB. Configure la misma configuración en la VPN us-west-1 Crear una zona alojada de Amazon Route 53. Crear registros separados para cada ALB. Habilite las comprobaciones de estado y configure una política de enrutamiento de conmutación por error para cada registro.
D.
Cree una VPC en us-east-1 y una VPC en us-west-1. Configurar el peering de VPC. En la VPC us-east-1, cree un balanceador de carga de aplicaciones (ALB) que se extienda a través de varias zonas de disponibilidad en ambas VPC. Cree un grupo de Auto Scaling que implemente las instancias EC2 en las múltiples zonas de disponibilidad en ambas VPC. Coloque el grupo Auto Scaling detrás del ALB. Crea una zona alojada de Amazon Route 53. Crear un registro para el ALB.
AnswerDiscussion
Correct Answer: C
Para lograr una alta disponibilidad y un escalado dinámico en AWS, la aplicación debe incluir varias zonas de disponibilidad dentro de us-east-1. Además, se debe configurar un sitio de recuperación ante desastres con failover activo-pasivo en us-west-1. El enfoque correcto implica configurar una VPC y colocar un balanceador de carga de aplicaciones (ALB) y un grupo de Auto Scaling dentro de cada región. El ALB garantiza la distribución del tráfico en varias zonas de disponibilidad, mientras que el grupo Auto Scaling administra el escalado de instancias. En ambas regiones, los recursos se configuran de forma independiente para garantizar la resiliencia. La implementación de Amazon Route 53 con comprobaciones de estado y una política de enrutamiento de conmutación por error entre los ALB en us-east-1 y us-west-1 garantiza que el tráfico se dirigirá a la región secundaria en caso de falla de la región primaria, cumpliendo con los requisitos de alta disponibilidad y recuperación ante desastres.
Question 70 of 529
Una empresa tiene un entorno que tiene una sola cuenta de AWS. Un arquitecto de soluciones está revisando el entorno para recomendar lo que la compañía podría mejorar específicamente en términos de acceso a la consola de administración de AWS. Los trabajadores de soporte de TI de la compañía actualmente acceden a la consola para tareas administrativas, autenticándose con usuarios de IAM nombrados que han sido asignados a su rol laboral.
Los trabajadores de soporte de TI ya no quieren mantener sus cuentas de usuario de Active Directory e IAM. Quieren poder acceder a la consola usando sus credenciales existentes de Active Directory. El arquitecto de soluciones está utilizando AWS IAM Identity Center (AWS Single Signa-On) para implementar esta funcionalidad.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Crear una organización en AWS Organizations. Active la función IAM Identity Center en Organizaciones. Cree y configure un directorio en AWS Directory Service para Microsoft Active Directory (AWS Managed Microsoft AD) con una confianza bidireccional al Active Directory local de la compañía. Configure IAM Identity Center y establezca el directorio AWS Managed Microsoft AD como origen de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del directorio AWS Managed Microsoft AD.
B.
Crear una organización en AWS Organizations. Active la función IAM Identity Center en Organizaciones. Cree y configure un conector AD para conectarse al Active Directory local de la compañía. Configure IAM Identity Center y seleccione AD Connector como origen de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del Directorio Activo de la compañía.
C.
Crear una organización en AWS Organizations. Activa todas las funciones para la organización. Cree y configure un directorio en AWS Directory Service para Microsoft Active Directory (AWS Managed Microsoft AD) con una confianza bidireccional al Active Directory local de la compañía. Configure IAM Identity Center y seleccione el directorio AWS Managed Microsoft AD como origen de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del directorio AWS Managed Microsoft AD.
D.
Crear una organización en AWS Organizations. Activa todas las funciones para la organización. Cree y configure un conector AD para conectarse al Active Directory local de la compañía. Configure IAM Identity Center y establezca AD Connector como origen de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del Directorio Activo de la compañía.
ResponderDiscusión
Correct Answer: D
Para permitir que los trabajadores de soporte de TI accedan a la consola de administración de AWS utilizando sus credenciales existentes de Active Directory sin mantener cuentas de usuario de IAM separadas, la solución implica aprovechar la infraestructura de Active Directory existente en las instalaciones de la compañía. Crear una organización en AWS Organizations y habilitar todas las funciones es necesario para administrar cuentas con IAM Identity Center (AWS SSO). Usar un conector AD para conectarse al Active Directory local y configurar IAM Identity Center para establecer AD Connector como origen de identidad es la solución más rentable. Este enfoque evita la necesidad de un nuevo directorio AWS Managed Microsoft AD, lo que reduce los costos y simplifica la configuración a la vez que cumple con todos los requisitos especificados.
Question 71 of 529
Una compañía de transmisión de video lanzó recientemente una aplicación móvil para compartir videos. La aplicación carga varios archivos a un bucket de Amazon S3 en la región us-east-1. Los archivos varían en tamaño de 1 GB a 10 GB.
Los usuarios que acceden a la aplicación desde Australia han experimentado subidas que tardan largos períodos de tiempo. En ocasiones los archivos no se suben completamente para estos usuarios. Un arquitecto de soluciones debe mejorar el rendimiento de la aplicación para estas cargas.
Qué soluciones cumplirán con estos requisitos? (Elija dos.)
A.
Habilite S3 Transfer Acceleration en el bucket S3. Configure la aplicación para usar el punto final Aceleración de transferencia para las cargas.
B.
Configure un bucket S3 en cada región para recibir las cargas. Utilice S3 Cross-Region Replication para copiar los archivos en el bucket S3 de distribución.
C.
Configure Amazon Route 53 con enrutamiento basado en latencia para enrutar las cargas a la región de bucket S3 más cercana.
D.
Configure la aplicación para dividir los archivos de video en trozos. Utilice una carga multiparte para transferir archivos a Amazon S3.
E.
Modifique la aplicación para agregar prefijos aleatorios a los archivos antes de subirlos.
ResponderDiscusión
Correct Answer: A, D
Para mejorar el rendimiento de carga para los usuarios en Australia, habilitar S3 Transfer Acceleration en el bucket S3 proporcionará una forma rápida y segura de transferir archivos grandes a través de Internet utilizando las ubicaciones de borde distribuidas globalmente de Amazon CloudFront. Esto puede reducir significativamente la latencia y mejorar las velocidades de transferencia. Adicionalmente, configurar la aplicación para dividir los videos en trozos y usar cargas multiparte permitirá que los archivos grandes se carguen en paralelo, lo que aumenta la velocidad de carga y mitiga el riesgo de fallas para archivos grandes debido al tamaño reducido de las partes individuales que se están cargando.
Question 72 of 529
Una aplicación utiliza una instancia de base de datos Multi-AZ de Amazon RDS para MySQL en la región us-east-1. Después de una prueba de failover, la aplicación perdió las conexiones a la base de datos y no pudo restablecer las conexiones. Después de reiniciar la aplicación, la aplicación restableció las conexiones.
Un arquitecto de soluciones debe implementar una solución para que la aplicación pueda restablecer las conexiones a la base de datos sin necesidad de reiniciar.
Qué solución cumplirá con estos requisitos?
A.
Cree una instancia de base de datos de Amazon Aurora MySQL Serverless v1. Migre la instancia de base de datos RDS a la instancia de base de datos Aurora Serverless v1. Actualice la configuración de conexión en la aplicación para que apunte al punto final del lector Aurora.
B.
Cree un proxy RDS. Configure el punto final de RDS existente como destino. Actualice la configuración de conexión en la aplicación para que apunte al punto final del proxy RDS.
C.
Cree un clúster de base de datos Amazon Aurora MySQL de dos nodos. Migre la instancia de base de datos RDS al clúster de base de datos Aurora. Cree un proxy RDS. Configure el punto final de RDS existente como destino. Actualice la configuración de conexión en la aplicación para que apunte al punto final del proxy RDS.
D.
Cree un bucket de Amazon S3. Exporte la base de datos a Amazon S3 mediante AWS Database Migration Service (AWS DMS). Configure Amazon Athena para usar el bucket S3 como data store. Instale el último controlador de conectividad de base de datos abierta (ODBC) para la aplicación. Actualizar la configuración de conexión en la aplicación para que apunte al punto final de Athena
ResponderDiscusión
Correct Answer: B
La aplicación requiere una solución que le permita restablecer las conexiones de base de datos automáticamente después de una conmutación por error sin necesidad de reiniciar. RDS Proxy está diseñado para ayudar con esto agrupando y compartiendo conexiones de bases de datos, lo que hace que las aplicaciones sean más resistentes a fallas de bases de datos. Puede detectar automáticamente failovers y redirigir las conexiones a instancias en espera, manteniendo el tiempo de actividad y el rendimiento de las aplicaciones. La creación de un proxy RDS, la configuración del punto final de RDS existente como destino y la actualización de la configuración de conexión de la aplicación para que apunte al punto final del proxy RDS aborda el problema de manera efectiva sin requerir una migración completa o soluciones más complejas.
Question 73 of 529
Una empresa está construyendo una solución en la nube de AWS. Miles o dispositivos se conectarán a la solución y enviarán datos. Cada dispositivo necesita poder enviar y recibir datos en tiempo real a través del protocolo MQTT. Cada dispositivo debe autenticarse utilizando un certificado X.509 único.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Configure AWS IoT Core. Para cada dispositivo, cree una cola de Amazon MQ correspondiente y aprovisione un certificado. Conecte cada dispositivo a Amazon MQ.
B.
Crear un balanceador de carga de red (NLB) y configurarlo con un autorizador de AWS Lambda. Ejecute un broker MQTT en instancias de Amazon EC2 en un grupo de Auto Scaling. Establezca el grupo Auto Scaling como el destino para el NLConnect cada dispositivo al NLB.
C.
Configure AWS IoT Core. Para cada dispositivo, cree una cosa AWS IoT correspondiente y aprovisione un certificado. Conecte cada dispositivo a AWS IoT Core.
D.
Configure una API HTTP de Amazon API Gateway y un balanceador de carga de red (NLB). Crear integración entre API Gateway y el NLB. Configure un autorizador de certificados TLS mutuo en la API HTTP. Ejecute un broker MQTT en una instancia de Amazon EC2 a la que se dirija el NLB. Conecte cada dispositivo al NLB.
ResponderDiscusión
Correct Answer: C
La mejor solución para cumplir con los requisitos con la menor sobrecarga operativa es configurar AWS IoT Core, crear una cosa de AWS IoT correspondiente para cada dispositivo y aprovisionar un certificado. AWS IoT Core proporciona un servicio completamente administrado que permite una comunicación bidireccional segura entre dispositivos conectados a Internet y la nube de AWS. Es compatible con el protocolo MQTT e incluye autenticación de dispositivos y control de acceso integrados. Esto minimiza efectivamente la complejidad operativa en comparación con otras opciones, convirtiéndola en la opción más adecuada para el escenario descrito.
Question 74 of 529
Una empresa está ejecutando varias cargas de trabajo en una sola cuenta de AWS. Una nueva política de la compañía establece que los ingenieros solo pueden aprovisionar recursos aprobados y que los ingenieros deben usar AWS CloudFormation para aprovisionar estos recursos. Un arquitecto de soluciones necesita crear una solución para hacer cumplir la nueva restricción en el rol de IAM que los ingenieros utilizan para acceder.
Qué debe hacer el arquitecto de soluciones para crear la solución?
A.
Cargue plantillas de AWS CloudFormation que contengan recursos aprobados en un bucket de Amazon S3. Actualice la política de IAM para el rol de IAM de los ingenieros para permitir únicamente el acceso a Amazon S3 y AWS CloudFormation. Utilice las plantillas de AWS CloudFormation para aprovisionar recursos.
B.
Actualice la política de IAM para el rol de IAM de los ingenieros con permisos para permitir únicamente el aprovisionamiento de recursos aprobados y AWS CloudFormation. Utilice las plantillas de AWS CloudFormation para crear pilas con recursos aprobados.
C.
Actualice la política de IAM para el rol de IAM de los ingenieros con permisos para permitir únicamente acciones de AWS CloudFormation. Cree una nueva política de IAM con permiso para aprovisionar recursos aprobados y asigne la política a una nueva función de servicio de IAM. Asigne la función de servicio de IAM a AWS CloudFormation durante la creación de la pila.
D.
Aprovisione recursos en pilas de AWS CloudFormation. Actualice la política de IAM para el rol de IAM de los ingenieros para permitir solo el acceso a su propia pila de AWS CloudFormation.
ResponderDiscusión
Correct Answer: C
La solución correcta implica actualizar la política de IAM para el rol de IAM de los ingenieros para permitir únicamente acciones de AWS CloudFormation y crear una nueva política de IAM con permiso para aprovisionar recursos aprobados. Esta nueva política debe asignarse a un nuevo rol de servicio de IAM que CloudFormation asumirá durante la creación de la pila. Este enfoque garantiza que los ingenieros solo puedan administrar los recursos a través de CloudFormation y que solo se puedan aprovisionar los recursos aprobados, haciendo cumplir efectivamente la política de la compañía.
Question 75 of 529
Un arquitecto de soluciones está diseñando la arquitectura de almacenamiento y recuperación de datos para una nueva aplicación que una compañía lanzará pronto. La aplicación está diseñada para ingerir millones de pequeños registros por minuto de dispositivos de todo el mundo. Cada registro tiene menos de 4 KB de tamaño y debe almacenarse en una ubicación duradera donde pueda recuperarse con baja latencia. Los datos son efímeros y se requiere que la empresa almacene los datos solo durante 120 días, después de lo cual los datos pueden ser eliminados.
El arquitecto de soluciones calcula que, en el transcurso de un año, los requisitos de almacenamiento serían de unos 10-15 TB.
Qué estrategia de almacenamiento es la MÁS rentable y cumple con los requisitos de diseño?
A.
Diseñe la aplicación para almacenar cada registro entrante como un único archivo.csv en un bucket de Amazon S3 para permitir la recuperación indexada. Configure una política de ciclo de vida para eliminar datos de más de 120 días.
B.
Diseñe la aplicación para almacenar cada registro entrante en una tabla de Amazon DynamoDB correctamente configurada para la báscula. Configure la función Tiempo de vida (TTL) de DynamoDB para eliminar registros de más de 120 días.
C.
Diseñe la aplicación para almacenar cada registro entrante en una sola tabla en una base de datos MySQL de Amazon RDS. Ejecute un trabajo de cron nocturno que ejecute una consulta para eliminar cualquier registro anterior a 120 días.
D.
Diseñe la aplicación para lotes de registros entrantes antes de escribirlos en un bucket de Amazon S3. Actualice los metadatos del objeto para que contenga la lista de registros en el lote y utilice la función de búsqueda de metadatos de Amazon S3 para recuperar los datos. Configure una política de ciclo de vida para eliminar los datos después de 120 días.
ResponderDiscusión
Correct Answer: B
La mejor estrategia de almacenamiento consiste en almacenar cada registro entrante en una tabla de Amazon DynamoDB, configurada para la escala requerida y usar la función Time to Live (TTL) para eliminar automáticamente registros de más de 120 días. DynamoDB está diseñado para una alta escala y rendimiento, capaz de manejar millones de registros pequeños de manera eficiente con baja latencia. Esto lo hace adecuado para los requisitos de recuperación y durabilidad de baja latencia. Adicionalmente, la función TTL sistematiza el proceso de eliminación, alineándose con el período de retención de datos de 120 días, haciendo que esta solución sea efectiva y rentable dado el volumen y la frecuencia de los datos.
Question 76 of 529
Una empresa minorista aloja un sitio web de comercio electrónico en AWS en varias regiones de AWS. La compañía quiere que el sitio web esté operativo en todo momento para compras en línea. El sitio web almacena datos en una instancia de base de datos de Amazon RDS para MySQL.
Qué solución proporcionará la mayor disponibilidad para la base de datos?
A.
Configure copias de seguridad automatizadas en Amazon RDS. En caso de interrupción, promueva una copia de seguridad automatizada para que sea una instancia de base de datos independiente. Dirija el tráfico de la base de datos a la instancia de base de datos promovida. Cree una réplica de lectura de reemplazo que tenga como origen la instancia de base de datos promovida.
B.
Configure tablas globales y réplicas de lectura en Amazon RDS. Activa el ámbito entre regiones. En caso de interrupción, utilice AWS Lambda para copiar las réplicas de lectura de una región a otra región.
C.
Configure tablas globales y copias de seguridad automatizadas en Amazon RDS. En caso de interrupción, utilice AWS Lambda para copiar las réplicas de lectura de una región a otra región.
D.
Configure réplicas de lectura en Amazon RDS. En caso de interrupción, promueva una réplica de lectura y región cruzada para que sea una instancia de base de datos independiente. Dirija el tráfico de la base de datos a la instancia de base de datos promovida. Cree una réplica de lectura de reemplazo que tenga como origen la instancia de base de datos promovida.
ResponderDiscusión
Correct Answer: D
Para lograr la mayor disponibilidad para la base de datos, configurar réplicas de lectura en Amazon RDS y promover una réplica de lectura entre regiones a una instancia de base de datos independiente en caso de interrupción es la solución más eficaz. Esta configuración garantiza que haya un backup listo para hacerse cargo inmediatamente si falla la base de datos primaria, minimizando el tiempo de inactividad y la pérdida de datos. El uso de réplicas entre regiones también mejora la disponibilidad al distribuir las copias en diferentes ubicaciones geográficas, lo que protege contra interrupciones regionales y proporciona una configuración de recuperación ante desastres resiliente.
Question 77 of 529
Example Corp. tiene un centro de datos local y una VPC llamada VPC A en la cuenta de AWS de Example Corp. La red local se conecta a la VPC A a través de una VPN de sitio a sitio de AWS. Los servidores locales pueden acceder correctamente a VPC A. Example Corp. acaba de adquirir AnyCompany, que tiene una VPC llamada VPC B. No hay superposición de direcciones IP entre estas redes. Ejemplo Corp. ha analizado VPC A y VPC B.
Example Corp. quiere conectarse desde sus servidores on-premise a VPC B. Example Corp. ha configurado correctamente la ACL de red y los grupos de seguridad.
Qué solución cumplirá con este requisito con el MENOR esfuerzo operativo?
A.
Crear una puerta de enlace de tránsito. Conecte la VPN de sitio a sitio, la VPC A y la VPC B a la puerta de enlace de tránsito. Actualice las tablas de rutas de puerta de enlace de tránsito para todas las redes para agregar rutas de rango IP para todas las demás redes.
B.
Crear una puerta de enlace de tránsito. Cree una conexión VPN de sitio a sitio entre la red local y la VPC B, y conecte la conexión VPN a la puerta de enlace de tránsito. Agregue una ruta para dirigir el tráfico a las VPC interconectadas y agregue una regla de autorización para dar a los clientes acceso a las VPC A y B.
C.
Actualice las tablas de rutas para la VPN de sitio a sitio y ambas VPC para las tres redes. Configure la propagación BGP para las tres redes. Espere hasta 5 minutos para que termine la propagación de BGP.
D.
Modifique la definición de puerta de enlace privada virtual de la VPN de sitio a sitio para incluir la VPC A y la VPC B. Dividir los dos enrutadores de la escapada privada virtual entre las dos VPC.
ResponderDiscusión
Correct Answer: A
Para permitir una comunicación fluida entre la red local y la VPC B con un mínimo esfuerzo operativo, la mejor solución es crear una puerta de enlace de tránsito. Conecte la VPN de sitio a sitio, la VPC A y la VPC B a la puerta de enlace de tránsito y actualice las tablas de rutas de puerta de enlace de tránsito para todas las redes para incluir rutas de rango IP para todas las demás redes. Este enfoque simplifica la administración de la red y proporciona un punto centralizado para administrar la conectividad entre la red local y ambas VPC.
Question 78 of 529
Una empresa completó recientemente la migración de un centro de datos local a la nube de AWS utilizando una estrategia de replatforming. Uno de los servidores migrados está ejecutando un servicio heredado de Protocolo Simple de Transferencia de Correo (SMTP) en el que se basa una aplicación crítica. La aplicación envía mensajes de correo electrónico salientes a los clientes de la compañía. El servidor SMTP heredado no admite el cifrado TLS y usa el puerto TCP 25. La aplicación solo puede usar SMTP.
La compañía decide utilizar Amazon Simple Email Service (Amazon SES) y retirar el servidor SMTP heredado. La compañía ha creado y validado el dominio SES. La compañía ha levantado los límites del SES.
Qué debe hacer la empresa para modificar la aplicación para enviar mensajes de correo electrónico desde Amazon SES?
A.
Configure la aplicación para conectarse a Amazon SES mediante TLS Wrapper. Cree un rol de IAM que tenga permisos ses:sendeMail y ses:sendrawemail. Adjunte el rol de IAM a una instancia de Amazon EC2.
B.
Configure la aplicación para conectarse a Amazon SES mediante STARTTLS. Obtenga las credenciales SMTP de Amazon SES. Utilice las credenciales para autenticarse con Amazon SES.
C.
Configure la aplicación para usar la API de SES para enviar mensajes de correo electrónico. Cree un rol de IAM que tenga permisos ses:sendeMail y ses:sendrawemail. Utilice la función de IAM como función de servicio para Amazon SES.
D.
Configure la aplicación para que utilice los SDK de AWS para enviar mensajes de correo electrónico. Cree un usuario de IAM para Amazon SES. Generar claves de acceso API. Utilice las claves de acceso para autenticarse con Amazon SES.
ResponderDiscusión
Correct Answer: B
Para enviar mensajes de correo electrónico desde Amazon SES mediante una aplicación que solo pueda usar SMTP, configure la aplicación para que se conecte a Amazon SES mediante STARTTLS. Obtenga credenciales SMTP de Amazon SES y utilícelas para autenticarse con Amazon SES. STARTTLS se utiliza para asegurar las conexiones, y este enfoque requiere cambios mínimos en la aplicación mientras se adhiere a las mejores prácticas de seguridad.
Question 79 of 529
Una empresa adquirió recientemente varias otras empresas. Cada compañía tiene una cuenta de AWS separada con un método diferente de facturación e informes. La compañía adquirente ha consolidado todas las cuentas en una sola organización en AWS Organizations. Sin embargo, a la empresa adquirente le ha resultado difícil generar un reporte de costos que contenga grupos significativos para todos los equipos.
El equipo financiero de la compañía adquirente necesita una solución para informar sobre los costos de todas las empresas a través de una aplicación autogestionada.
Qué solución cumplirá con estos requisitos?
A.
Cree un informe de costos y uso de AWS para la organización. Defina etiquetas y categorías de costos en el reporte. Crea una mesa en Amazon Atenea. Cree un conjunto de datos de Amazon QuickSight basado en la tabla Athena. Compartir el conjunto de datos con el equipo de finanzas.
B.
Cree un informe de costos y uso de AWS para la organización. Defina etiquetas y categorías de costos en el reporte. Cree una plantilla especializada en AWS Cost Explorer que el departamento de finanzas utilizará para crear informes.
C.
Cree un conjunto de datos de Amazon QuickSight que reciba información de gastos de la API de consulta de lista de precios de AWS. Compartir el conjunto de datos con el equipo de finanzas.
D.
Utilice la API de consulta de lista de precios de AWS para recopilar información sobre los gastos de la cuenta. Cree una plantilla especializada en AWS Cost Explorer que el departamento de finanzas utilizará para crear informes.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de generar informes de costos detallados y significativos para todas las empresas dentro de la organización consolidada de AWS, la mejor solución es crear un informe de costos y uso de AWS para la organización y definir etiquetas y categorías de costos en el informe. Este enfoque garantiza un nivel granular de detalle para el reporte de costos. Al crear una tabla en Amazon Athena y luego un conjunto de datos de Amazon QuickSight basado en esa tabla de Athena, el equipo de finanzas podrá realizar consultas detalladas y generar informes sobre los costos. El conjunto de datos se puede compartir fácilmente con el equipo de finanzas, lo que les permite crear y ver los informes según sea necesario.
Question 80 of 529
Una empresa maneja una plataforma IoT en AWS. Los sensores de IoT en varias ubicaciones envían datos a los servidores API Node.js de la compañía en instancias de Amazon EC2 que se ejecutan detrás de un balanceador de carga de aplicaciones. Los datos se almacenan en una instancia de base de datos MySQL de Amazon RDS que utiliza un volumen SSD de propósito general de 4 TB.
El número de sensores que la compañía ha desplegado en campo ha aumentado con el tiempo, y se espera que crezca significativamente. Los servidores API están constantemente sobrecargados y las métricas de RDS muestran una alta latencia de escritura.
Cuál de los siguientes pasos juntos resolverá los problemas de forma permanente y permitirá el crecimiento a medida que se aprovisionen nuevos sensores, manteniendo esta plataforma rentable? (Elija dos.)
A.
Cambiar el tamaño del almacenamiento SSD de propósito general MySQL a 6 TB para mejorar las IOPS del volumen.
B.
Rediseñe el nivel de base de datos para usar Amazon Aurora en lugar de una instancia de base de datos MySQL de RDS y agregue réplicas de lectura.
C.
Aproveche Amazon Kinesis Data Stream y AWS Lambda para ingerir y procesar los datos sin procesar.
D.
Utilice AWS X-Ray para analizar y depurar problemas de aplicaciones y agregar más servidores API para que coincidan con la carga.
E.
Rediseñe el nivel de base de datos para usar Amazon DynamoDB en lugar de una instancia de base de datos MySQL de RDS.
ResponderDiscusión
Correct Answer: B, C
Para hacer frente a la sobrecarga constante de los servidores API y la alta latencia de escritura en RDS, aprovechar Amazon Kinesis Data Streams y AWS Lambda para ingerir y procesar los datos sin procesar es una solución eficaz. Esta configuración permite el procesamiento de datos en tiempo real y puede reducir la carga en los servidores API. Además, rediseñar el nivel de base de datos para usar Amazon Aurora en lugar de una instancia de base de datos MySQL de RDS y agregar réplicas de lectura puede mejorar significativamente el rendimiento y la escalabilidad. Aurora ofrece un rendimiento de escritura mejorado, escalado automático de almacenamiento y réplicas de lectura que ayudan a distribuir la carga de lectura, lo que permite que el sistema maneje el aumento esperado en los datos de los nuevos sensores.
Question 81 of 529
Una empresa está construyendo un sistema de gestión electrónica de documentos en el que los usuarios suben sus documentos. La pila de aplicaciones es completamente sin servidor y se ejecuta en AWS en la región eu-central-1. El sistema incluye una aplicación web que utiliza una distribución de Amazon CloudFront para su entrega con Amazon S3 como origen. La aplicación web se comunica con los endpoints regionales de Amazon API Gateway. Las API de API Gateway llaman a las funciones de AWS Lambda que almacenan metadatos en una base de datos Amazon Aurora Serverless y colocan los documentos en un bucket S3.
La compañía está creciendo de manera constante y ha completado una prueba de concepto con su mayor cliente. La compañía debe mejorar la latencia fuera de Europa.
Qué combinación de acciones cumplirá con estos requisitos? (Elija dos.)
A.
Habilite S3 Transfer Acceleration en el bucket S3. Asegúrese de que la aplicación web utilice las URL firmadas de Aceleración de Transferencia.
B.
Cree un acelerador en AWS Global Accelerator. Conecte el acelerador a la distribución de CloudFront.
C.
Cambie los endpoints regionales de API Gateway a endpoints optimizados para bordes.
D.
Aprovisione toda la pila en otras dos ubicaciones que están repartidas por todo el mundo. Utilice bases de datos globales en el clúster Aurora Serverless.
E.
Agregue un proxy de Amazon RDS entre las funciones Lambda y la base de datos Aurora Serverless.
ResponderDiscusión
Correct Answer: A, C
Para mejorar la latencia de usuarios fuera de Europa, se pueden tomar dos acciones principales. Primero, habilitar S3 Transfer Acceleration en el bucket S3 y usar las URL firmadas de Transfer Acceleration acelerará la carga de documentos utilizando las ubicaciones de borde distribuidas globalmente de Amazon CloudFront. Esto ayuda a reducir la latencia al enrutar los datos a través de la red perimetral de AWS, más cerca de los usuarios, antes de llegar al bucket S3. En segundo lugar, cambiar los endpoints regionales de API Gateway a endpoints optimizados en el borde mejorará la latencia al enrutar las solicitudes de API al punto de presencia de CloudFront más cercano, reduciendo así el tiempo que tardan las solicitudes de los usuarios en llegar al servidor y recibir una respuesta. Estas dos medidas abordan directamente los problemas de latencia al aprovechar la infraestructura global de AWS para acercar la transferencia de datos y el procesamiento de API a los usuarios, lo que lleva a mejoras notables en el rendimiento.
Question 82 of 529
Una compañía de aventuras ha lanzado una nueva función en su aplicación móvil. Los usuarios pueden usar la función para subir sus fotos y videos de senderismo y rafting en cualquier momento. Las fotos y videos se almacenan en el almacenamiento estándar de Amazon S3 en un bucket S3 y se sirven a través de Amazon CloudFront.
La empresa necesita optimizar el costo del almacenamiento. Un arquitecto de soluciones descubre que la mayoría de las fotos y videos subidos se accede con poca frecuencia después de 30 días. Sin embargo, algunas de las fotos y videos subidos son accedidos frecuentemente después de 30 días. El arquitecto de soluciones necesita implementar una solución que mantenga la disponibilidad de recuperación de milisegundos de las fotos y videos al menor costo posible.
Qué solución cumplirá con estos requisitos?
A.
Configure S3 Intelligent-Tiering en el bucket S3.
B.
Configure una política de ciclo de vida de S3 para hacer la transición de objetos de imagen y de vídeo de S3 Standard a S3 Glacier Deep Archive después de 30 días.
C.
Reemplace Amazon S3 por un sistema de archivos de Amazon Elastic File System (Amazon EFS) montado en instancias de Amazon EC2.
D.
Agregue un encabezado Cache-Control: max-age a los objetos de imagen S3 y a los objetos de video S3. Establezca el encabezado en 30 días.
ResponderDiscusión
Correct Answer: A
La compañía necesita una solución de almacenamiento rentable que aún proporcione disponibilidad de recuperación de milisegundos. Amazon S3 Intelligent-Tiering mueve automáticamente objetos entre dos niveles de acceso (frecuente e infrecuente) en función de los patrones de acceso, lo que lo hace adecuado para situaciones en las que la frecuencia de acceso a los datos cambia con el tiempo. Esta organización en niveles garantiza la optimización de costos sin intervenciones manuales y mantiene la disponibilidad de recuperación de milisegundos, lo cual es crucial para los datos a los que se accede con frecuencia después de 30 días. Otras opciones implican un archivado más profundo que aumenta los tiempos de recuperación, introduce complejidades y costos adicionales con otros servicios, o centrarse en el almacenamiento en caché que no optimiza los costos de almacenamiento de información de manera efectiva.
Question 83 of 529
Una empresa utiliza Amazon S3 para almacenar archivos e imágenes en una variedad de clases de almacenamiento. Los costos de S3 de la compañía han aumentado sustancialmente durante el último año.
Un arquitecto de soluciones necesita revisar las tendencias de datos de los últimos 12 meses e identificar la clase de almacenamiento adecuada para los objetos.
Qué solución cumplirá con estos requisitos?
A.
Descargue los informes de costos y uso de AWS de los últimos 12 meses de uso de S3. Revise las recomendaciones de AWS Trusted Advisor para obtener ahorros en costos.
B.
Utilice el análisis de clase de almacenamiento S3. Importe tendencias de datos a un panel de Amazon QuickSight para analizar las tendencias de almacenamiento.
C.
Usa Lente de Almacenamiento Amazon S3. Actualice el panel predeterminado para incluir métricas avanzadas para las tendencias de almacenamiento.
D.
Utilice Access Analyzer para S3. Descargue el informe de Access Analyzer para S3 de los últimos 12 meses. Importe el archivo.csv a un panel de Amazon QuickSight.
ResponderDiscusión
Correct Answer: C
Para revisar las tendencias de datos de los últimos 12 meses e identificar la clase de almacenamiento adecuada para los objetos en Amazon S3, Amazon S3 Storage Lens es la solución adecuada. La lente de almacenamiento S3 proporciona métricas e información completas sobre el uso del almacenamiento y las tendencias de actividad de hasta 15 meses. Permite un análisis en profundidad de los datos históricos, lo que los hace ideales para la optimización de costos y determinar la mejor clase de almacenamiento en función de los patrones de uso reales.
Question 84 of 529
Una empresa tiene su infraestructura en la nube en AWS. Un arquitecto de soluciones necesita definir la infraestructura como código. La infraestructura está actualmente implementada en una región de AWS. El plan de expansión empresarial de la compañía incluye implementaciones en varias regiones en varias cuentas de AWS.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice las plantillas de AWS CloudFormation. Agregue políticas de IAM para controlar las diversas cuentas, Implemente las plantillas en las múltiples regiones.
B.
Utilice las organizaciones de AWS. Implemente plantillas de AWS CloudFormation desde la cuenta de administración Utilice AWS Control Tower para administrar implementaciones en todas las cuentas.
C.
Utilice AWS Organizations y AWS CloudFormation StackSets. Implementar una plantilla de Cloud Formation desde una cuenta que tenga los permisos de IAM necesarios.
D.
Utilice pilas anidadas con plantillas de AWS CloudFormation. Cambia la región usando pilas anidadas.
ResponderDiscusión
Correct Answer: C
Para administrar implementaciones en varias cuentas y regiones de AWS, la mejor solución implica el uso de AWS Organizations junto con AWS CloudFormation StackSets. AWS Organizations permite la administración centralizada de múltiples cuentas, lo que facilita la gobernanza y la escalabilidad. AWS CloudFormation StackSets amplía la capacidad de CloudFormation al permitir la implementación de una sola plantilla en varias cuentas y regiones, lo que garantiza el aprovisionamiento y la administración consistentes de los recursos. Esta combinación garantiza una gestión eficiente y escalable de la infraestructura en una configuración multicuenta y multi-región.
Question 85 of 529
Una empresa tiene su infraestructura en la nube en AWS. Un arquitecto de soluciones necesita definir la infraestructura como código. La infraestructura está actualmente implementada en una región de AWS. El plan de expansión empresarial de la compañía incluye implementaciones en varias regiones en varias cuentas de AWS.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice las plantillas de AWS CloudFormation. Agregue políticas de IAM para controlar las diversas cuentas, Implemente las plantillas en las múltiples regiones.
B.
Utilice las organizaciones de AWS. Implemente plantillas de AWS CloudFormation desde la cuenta de administración Utilice AWS Control Tower para administrar implementaciones en todas las cuentas.
C.
Utilice AWS Organizations y AWS CloudFormation StackSets. Implementar una plantilla de Cloud Formation desde una cuenta que tenga los permisos de IAM necesarios.
D.
Utilice pilas anidadas con plantillas de AWS CloudFormation. Cambia la región usando pilas anidadas.
ResponderDiscusión
Correct Answer: C
Para cumplir con el requisito de definir la infraestructura como código e implementarla en varias regiones y cuentas de AWS, el mejor enfoque es usar AWS Organizations y AWS CloudFormation StackSets. AWS Organizations permite la administración centralizada de múltiples cuentas, proporcionando la estructura organizativa necesaria. Los StackSets de AWS CloudFormation permiten la implementación de pilas de CloudFormation en varias cuentas de AWS y regiones desde una cuenta de administrador central. Esta combinación garantiza una gestión e implementación optimizadas de los recursos en toda la infraestructura requerida.
Question 86 of 529
Una empresa planea refactorizar una aplicación monolítica en un diseño de aplicación moderno implementado en AWS. Es necesario actualizar la tubería CI/CD para admitir el diseño moderno de la aplicación con los siguientes requisitos:
• Debe permitir que los cambios se liberen varias veces cada hora.
• Debe ser capaz de hacer retroceder los cambios lo más rápido posible.
Qué diseño cumplirá con estos requisitos?
A.
Implemente una canalización de CI/CD que incorpore AMIs para contener la aplicación y sus configuraciones. Implemente la aplicación reemplazando las instancias de Amazon EC2.
B.
Especifique AWS Elastic Beanstalk para que se organice en un entorno secundario como destino de implementación para la canalización de CI/CD de la aplicación. Para implementar, intercambie las URL del entorno de producción y puesta en escena.
C.
Utilice AWS Systems Manager para volver a aprovisionar la infraestructura para cada implementación. Actualice los datos de usuario de Amazon EC2 para extraer el último artefacto de código de Amazon S3 y utilice el enrutamiento ponderado de Amazon Route 53 para apuntar al nuevo entorno.
D.
Implemente las actualizaciones de la aplicación como parte de un evento de Auto Scaling utilizando las AMIs prediseñadas. Utilice nuevas versiones de las AMI para agregar instancias. y eliminar gradualmente todas las instancias que utilizan la versión anterior de AMI con la política de terminación configurada durante un evento de implementación.
ResponderDiscusión
Correct Answer: B
Especificar AWS Elastic Beanstalk para que se ponga en escena en un entorno secundario como destino de implementación para la canalización de CI/CD de la aplicación y el intercambio de las URL del entorno de producción y almacenamiento permitirá que los cambios se publiquen varias veces cada hora y se habiliten reversiones rápidas. Elastic Beanstalk admite de forma nativa el intercambio de entornos, lo que minimiza el tiempo de inactividad y proporciona una manera simple y eficiente de administrar los procesos de implementación y rollback.
Question 87 of 529
Una empresa tiene una aplicación que se ejecuta en instancias de Amazon EC2. Un arquitecto de soluciones está diseñando infraestructura de VPC en una región de AWS donde la aplicación necesita acceder a un clúster de base de datos de Amazon Aurora. Las instancias EC2 están asociadas con el mismo grupo de seguridad. El clúster de base de datos está asociado con su propio grupo de seguridad.
El arquitecto de soluciones necesita agregar reglas a los grupos de seguridad para proporcionar a la aplicación el menor acceso de privilegios al clúster de base de datos.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Agregue una regla de entrada al grupo de seguridad de las instancias EC2. Especifique el grupo de seguridad del clúster de base de datos como origen sobre el puerto Aurora predeterminado.
B.
Agregue una regla de salida al grupo de seguridad de las instancias EC2. Especifique el grupo de seguridad del clúster de base de datos como destino sobre el puerto Aurora predeterminado.
C.
Agregue una regla entrante al grupo de seguridad del clúster de base de datos. Especifique el grupo de seguridad de las instancias EC2 como origen sobre el puerto Aurora predeterminado.
D.
Agregue una regla de salida al grupo de seguridad del clúster de base de datos. Especifique el grupo de seguridad de las instancias EC2 como destino sobre el puerto Aurora predeterminado.
E.
Agregue una regla de salida al grupo de seguridad del clúster de base de datos. Especifique el grupo de seguridad de las instancias EC2 como destino sobre los puertos efímeros.
ResponderDiscusión
Correct Answer: B, C
Para garantizar que la aplicación en las instancias EC2 tenga el menor acceso de privilegios al clúster de base de datos de Amazon Aurora, las reglas de grupo de seguridad necesarias deben permitir el tráfico adecuado. Primero, agregue una regla de salida al grupo de seguridad de las instancias EC2 especificando el grupo de seguridad del clúster de base de datos como destino sobre el puerto Aurora predeterminado. Esto permite que las instancias EC2 inicien conexiones con el clúster de base de datos. En segundo lugar, agregue una regla de entrada al grupo de seguridad del clúster de base de datos que especifique el grupo de seguridad de las instancias EC2 como origen sobre el puerto Aurora predeterminado. Esto permite que el clúster de base de datos acepte conexiones de las instancias EC2. Esta combinación asegura que solo se permita el tránsito necesario, apegándose al principio de menor privilegio.
Question 88 of 529
Una empresa quiere cambiar su estrategia interna de facturación en la nube para cada una de sus unidades de negocio. Actualmente, el equipo de gobierno de la nube comparte informes sobre el gasto general en la nube con el jefe de cada unidad de negocio. La compañía utiliza AWS Organizations para administrar las cuentas de AWS separadas para cada unidad de negocio. El estándar de etiquetado existente en las Organizaciones incluye la aplicación, el entorno y el propietario. El equipo de gobierno de la nube quiere una solución centralizada para que cada unidad de negocio reciba informes mensuales sobre su gasto en la nube. La solución también debe enviar notificaciones de cualquier gasto en la nube que supere un umbral establecido.
Cuál es la solución MÁS rentable para cumplir con estos requisitos?
A.
Configure los presupuestos de AWS en cada cuenta y configure alertas de presupuesto agrupadas por aplicación, entorno y propietario. Agregue cada unidad de negocio a un tema de Amazon SNS para cada alerta. Utilice el Explorador de Costos en cada cuenta para crear informes mensuales para cada unidad de negocio.
B.
Configure los presupuestos de AWS en la cuenta de administración de la organización y configure alertas de presupuesto agrupadas por aplicación, entorno y propietario. Agregue cada unidad de negocio a un tema de Amazon SNS para cada alerta. Utilice el Explorador de costos en la cuenta de administración de la organización para crear informes mensuales para cada unidad de negocio.
C.
Configure los presupuestos de AWS en cada cuenta y configure alertas de presupuesto agrupadas por aplicación, entorno y propietario. Agregue cada unidad de negocio a un tema de Amazon SNS para cada alerta. Utilice el panel de control de facturación y administración de costos de AWS en cada cuenta para crear informes mensuales para cada unidad de negocio.
D.
Habilite los informes de costos y uso de AWS en la cuenta de administración de la organización y configure los informes agrupados por aplicación, entorno y propietario. Cree una función de AWS Lambda que procese los informes de costos y uso de AWS, envíe alertas de presupuesto y envíe informes mensuales a la lista de correo electrónico de cada unidad de negocio.
ResponderDiscusión
Correct Answer: B
La solución más rentable es configurar los presupuestos de AWS en la cuenta de administración de la organización y configurar alertas de presupuesto agrupadas por aplicación, entorno y propietario. Esta configuración permite una gestión centralizada de presupuestos y alertas, eliminando la necesidad de configurar y administrar estos ajustes individualmente en cada cuenta. El uso de Cost Explorer en la cuenta de administración permite vistas de gasto consolidadas y creación de informes, lo que simplifica y reduce el costo de administrar el gasto en la nube para cada unidad de negocio.
Question 89 of 529
Una empresa está utilizando AWS CloudFormation para implementar su infraestructura. A la compañía le preocupa que, si se elimina una pila de CloudFormation de producción, también se puedan eliminar datos importantes almacenados en bases de datos de Amazon RDS o volúmenes de Amazon EBS.
Cómo puede la empresa evitar que los usuarios eliminen accidentalmente datos de esta manera?
A.
Modifique las plantillas de CloudFormation para agregar un atributo DeletionPolicy a los recursos de RDS y EBS.
B.
Configure una política de pila que no permita la eliminación de recursos RDS y EBS.
C.
Modificar políticas de IAM para denegar la eliminación de recursos RDS y EBS etiquetados con una etiqueta “aws:cloudformation:stack-name”.
D.
Utilice las reglas de AWS Config para evitar eliminar recursos RDS y EBS.
ResponderDiscusión
Correct Answer: A
Para evitar que se eliminen datos importantes almacenados en bases de datos de Amazon RDS o volúmenes de Amazon EBS cuando se elimina una pila de CloudFormation, la empresa puede agregar un atributo DeletionPolicy a sus plantillas de CloudFormation. Este atributo se puede establecer en 'Retener' o 'Instantánea' para los recursos específicos, asegurando que los datos se conservan o se crea una instantánea en lugar de eliminar los recursos. Este enfoque se alinea directamente con la preocupación de retener datos incluso cuando se elimina la pila misma.
Question 90 of 529
Una compañía tiene habilitados los registros de flujo de VPC para su puerta de enlace NAT. La compañía está viendo Acción = ACEPTAR para el tráfico entrante que proviene de la dirección IP pública 198.51.100.2 destinada a una instancia privada de Amazon EC2.
Un arquitecto de soluciones debe determinar si el tráfico representa conexiones entrantes no solicitadas desde Internet. Los dos primeros octetos del bloque CIDR de VPC son 203.0.
Qué conjunto de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Abra la consola de AWS CloudTrail. Seleccione el grupo de registros que contiene la interfaz de red elástica de la puerta de enlace NAT y el entrelazado de red elástica de la instancia privada. Ejecute una consulta para filtrar con la dirección de destino establecida como “like 203.0" y la dirección de origen establecida como “like 198.51.100.2". Ejecute el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y la dirección de destino.
B.
Abra la consola de Amazon CloudWatch. Seleccione el grupo de registros que contiene la interfaz de red elástica de la puerta de enlace NAT y la interfaz de red elástica de la instancia privada. Ejecute una consulta para filtrar con la dirección de destino establecida como “like 203.0" y la dirección de origen establecida como “like 198.51.100.2". Ejecute el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y la dirección de destino.
C.
Abra la consola de AWS CloudTrail. Seleccione el grupo de registros que contiene la interfaz de red elástica de la puerta de enlace NAT y la interfaz de red elástica de la instancia privada. Ejecuta una consulta para filtrar con la dirección de destino establecida como “like 198.51.100.2" y la dirección de origen establecida como “like 203.0". Ejecute el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y la dirección de destino.
D.
Abra la consola de Amazon CloudWatch. Seleccione el grupo de registros que contiene la interfaz de red elástica de la puerta de enlace NAT y la interfaz de red elástica de la instancia privada. Ejecuta una consulta para filtrar con la dirección de destino establecida como “like 198.51.100.2" y la dirección de origen establecida como “like 203.0". Ejecute el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y la dirección de destino.
ResponderDiscusión
Correct Answer: D
Para determinar si el tráfico representa conexiones entrantes no solicitadas desde internet, el arquitecto de soluciones debe investigar si el tráfico a la IP pública 198.51.100.2 se solicitó inicialmente desde una IP privada interna (como las que están dentro del rango 203.0.x.x). Esto se puede hacer comprobando los registros de flujo para ver los patrones de tráfico a partir de la IP privada interna y destinados a la IP pública 198.51.100.2 en Amazon CloudWatch. Filtrar los registros con la dirección de destino establecida en '198.51.100.2' y la dirección de origen establecida en '203.0' ayudará a determinar si el tráfico entrante de Internet fue una respuesta a una solicitud iniciada desde dentro de la VPC.
Question 91 of 529
Una empresa consta o dos unidades de negocio separadas. Cada unidad de negocio tiene su propia cuenta de AWS dentro de una sola organización en AWS Organizations. Las unidades de negocio comparten regularmente documentos confidenciales entre sí. Para facilitar el uso compartido, la compañía creó un bucket de Amazon S3 en cada cuenta y configuró la replicación a baja distancia entre los buckets S3. Los cubos S3 tienen millones de objetos.
Recientemente, una auditoría de seguridad identificó que ninguno de los bucket S3 tiene habilitado el cifrado en reposo. La política de la compañía requiere que todos los documentos se almacenen con cifrado en reposo. La compañía quiere implementar el cifrado del lado del servidor con claves de cifrado administradas de Amazon S3 (SSE-S3).
Cuál es la solución más eficiente desde el punto de vista operativo que cumple con estos requisitos?
A.
Encienda SSE-S3 en ambos cubos S3. Utilice S3 Batch Operations para copiar y cifrar los objetos en la misma ubicación.
B.
Cree una clave de AWS Key Management Service (AWS KMS) en cada cuenta. Active el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) en cada bucket S3 utilizando la clave KMS correspondiente en esa cuenta de AWS. Cifrar los objetos existentes mediante un comando de copia de S3 en la CLI de AWS.
C.
Encienda SSE-S3 en ambos cubos S3. Cifrar los objetos existentes mediante un comando de copia de S3 en la CLI de AWS.
D.
Cree una clave de AWS Key Management Service (AWS KMS) en cada cuenta. Active el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) en cada bucket S3 utilizando la clave KMS correspondiente en esa cuenta de AWS. Utilice S3 Batch Operations para copiar los objetos en la misma ubicación.
ResponderDiscusión
Correct Answer: A
Cumplir con el requisito de la política de la compañía de cifrar todos los documentos en reposo y considerar la eficiencia operativa debido a la gran cantidad de objetos, habilitar SSE-S3 directamente en ambos buckets S3 y usar S3 Batch Operations para cifrar los objetos existentes en su lugar es la solución más eficiente. S3 Batch Operations está diseñado para manejar operaciones a gran escala de manera eficiente, y copiar objetos en su lugar permite el cifrado sin mover datos innecesariamente.
Question 92 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. La aplicación recopila y almacena una gran cantidad de datos no estructurados en un bucket de Amazon S3. El bucket S3 contiene varios terabytes de datos y utiliza la clase de almacenamiento S3 Standard. Los datos aumentan de tamaño en varios gigabytes cada día.
La empresa necesita consultar y analizar los datos. La empresa no accede a datos que tengan más de 1 año de antigüedad. No obstante, la empresa debe conservar todos los datos indefinidamente por razones de cumplimiento.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Utilice S3 Select para consultar los datos. Cree una política de ciclo de vida de S3 para hacer la transición de datos que tengan más de 1 año de antigüedad a S3 Glacier Deep Archive.
B.
Utilice Amazon Redshift Spectrum para consultar los datos. Cree una política de ciclo de vida de S3 para hacer la transición de datos que tengan más de 1 año de antigüedad 10 S3 Glacier Deep Archive.
C.
Utilice un catálogo de datos de AWS Glue y Amazon Athena para consultar los datos. Cree una política de ciclo de vida de S3 para hacer la transición de datos que tengan más de 1 año de antigüedad a S3 Glacier Deep Archive.
D.
Utilice Amazon Redshift Spectrum para consultar los datos. Cree una política de ciclo de vida de S3 para hacer la transición de los datos que tienen más de 1 año a S3 Intelligent-Tiering.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de la compañía de manera más rentable, usar un catálogo de datos de AWS Glue y Amazon Athena para consultar los datos es una solución adecuada. AWS Glue Data Catalog es un repositorio de metadatos administrados que ayuda a definir y organizar los datos almacenados en Amazon S3. Amazon Athena es un servicio de consultas interactivas sin servidor, que permite un análisis eficiente de datos directamente en S3 usando SQL. Esta combinación es especialmente rentable para analizar grandes cantidades de datos no estructurados o semiestructurados. Además, la creación de una política de ciclo de vida de S3 para la transición de datos que tienen más de 1 año de antigüedad a S3 Glacier Deep Archive garantiza que los costos de almacenamiento se minimicen mientras se retienen los datos indefinidamente para el cumplimiento de normas. Este enfoque minimiza los costos de manera más efectiva que mantener los datos en la clase de almacenamiento S3 Standard.
Question 93 of 529
Una empresa de procesamiento de video quiere construir un modelo de aprendizaje automático (ML) mediante el uso de 600 TB de datos comprimidos que se almacenan como miles de archivos en el sistema de almacenamiento conectado a la red local de la compañía. La compañía no cuenta con los recursos informáticos necesarios en las instalaciones para los experimentos de ML y quiere usar AWS.
La compañía necesita completar la transferencia de datos a AWS en un plazo de 3 semanas. La transferencia de datos será una transferencia única. Los datos deben estar encriptados en tránsito. La velocidad de carga medida de la conexión a Internet de la compañía es de 100 Mbps. y múltiples departamentos comparten la conexión.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Solicite varios dispositivos optimizados para AWS Snowball Edge Storage mediante la consola de administración de AWS. Configure los dispositivos con un bucket S3 de destino. Copia los datos a los dispositivos. Envíe los dispositivos de nuevo a AWS.
B.
Configure una conexión AWS Direct Connect de 10 Gbps entre la ubicación de la empresa y la región de AWS más cercana. Transfiera los datos a través de una conexión VPN a la región para almacenarlos en Amazon S3.
C.
Cree una conexión VPN entre el almacenamiento conectado a la red local y la región de AWS más cercana. Transfiere los datos a través de la conexión VPN.
D.
Implementar una puerta de enlace de archivos de AWS Storage Gateway en las instalaciones. Configure la puerta de enlace de archivos con un bucket S3 de destino. Copiar los datos a la puerta de enlace de archivos.
ResponderDiscusión
Correct Answer: A
La solución más rentable para transferir 600 TB de datos comprimidos a AWS en un plazo de 3 semanas, a la vez que se garantiza el cifrado de datos en tránsito, es ordenar varios dispositivos optimizados para el almacenamiento de AWS Snowball Edge. Estos dispositivos están diseñados específicamente para transferir grandes cantidades de datos de forma rápida y segura. Los dispositivos manejan la transferencia de datos sin depender de la conexión a Internet de la compañía, eliminando las restricciones de ancho de banda. Una vez copiados los datos, los dispositivos se envían de nuevo a AWS, donde los datos se cargan en el bucket S3 especificado.
Question 94 of 529
Una empresa ha migrado su aplicación de procesamiento de formularios a AWS. Cuando los usuarios interactúan con la aplicación, cargan formularios escaneados como archivos a través de una aplicación web. Una base de datos almacena metadatos de usuario y referencias a archivos almacenados en Amazon S3. La aplicación web se ejecuta en instancias de Amazon EC2 y una base de datos de Amazon RDS para PostgreSQL.
Cuando se cargan formularios, la aplicación envía notificaciones a un equipo a través de Amazon Simple Notification Service (Amazon SNS). Luego, un miembro del equipo inicia sesión y procesa cada formulario. El miembro del equipo realiza la validación de datos en el formulario y extrae datos relevantes antes de ingresar la información en otro sistema que usa una API.
Un arquitecto de soluciones necesita automatizar el procesamiento manual de los formularios. La solución debe proporcionar una extracción precisa de la forma. minimizar el tiempo de comercialización y minimizar la sobrecarga operativa a largo plazo.
Qué solución cumplirá con estos requisitos?
A.
Desarrollar bibliotecas personalizadas para realizar reconocimiento óptico de caracteres (OCR) en los formularios. Implementar las bibliotecas en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) como un nivel de aplicación. Utilice este nivel para procesar los formularios cuando se carguen los formularios. Almacene la salida en Amazon S3. Analice esta salida extrayendo los datos en una tabla de Amazon DynamoDB. Presentar los datos a la APL del sistema objetivo. Aloje el nuevo nivel de aplicación en instancias EC2.
B.
Amplíe el sistema con un nivel de aplicación que utilice AWS Step Functions y AWS Lambda. Configure este nivel para usar modelos de inteligencia artificial y aprendizaje automático (AI/ML) que se entrenan y alojan en una instancia EC2 para realizar reconocimiento óptico de caracteres (OCR) en los formularios cuando se cargan los formularios. Almacene la salida en Amazon S3. Analice esta salida extrayendo los datos que se requieren dentro del nivel de aplicación. Enviar los datos a la API del sistema de destino.
C.
Aloje un nuevo nivel de aplicación en instancias EC2. Utilice este nivel para llamar a endpoints que alojan modelos de inteligencia artificial y equipos de equipo (AI/ML) que están capacitados y alojados en Amazon SageMaker para realizar reconocimiento óptico de caracteres (OCR) en los formularios. Almacene la salida en Amazon ElastiCache. Analice esta salida extrayendo los datos que se requieren dentro del nivel de aplicación. Enviar los datos a la API del sistema de destino.
D.
Amplíe el sistema con un nivel de aplicación que utilice AWS Step Functions y AWS Lambda. Configure este nivel para usar Amazon Textract y Amazon Comprehend para realizar el reconocimiento óptico de caracteres (OCR) en los formularios cuando se cargan los formularios. Almacene la salida en Amazon S3. Analice esta salida extrayendo los datos que se requieren dentro del nivel de aplicación. Enviar los datos a la API del sistema de destino.
ResponderDiscusión
Correct Answer: D
Ampliar el sistema con un nivel de aplicación que utilice AWS Step Functions y AWS Lambda, configurados para usar Amazon Textract y Amazon Comprehend, es la mejor opción. Este enfoque aborda de manera efectiva los requisitos de automatizar el procesamiento manual de formularios con extracción precisa de formularios, al tiempo que minimiza el tiempo de comercialización y la sobrecarga operativa a largo plazo. Amazon Textract puede realizar reconocimiento óptico de caracteres (OCR) para extraer automáticamente texto y datos de documentos escaneados, y Amazon Comprehend puede analizar texto para obtener información clave. Ambos servicios son totalmente administrados y sin servidor, minimizando la necesidad de desarrollo personalizado y mantenimiento continuo. Además, el uso de Step Functions y Lambda permite una fácil orquestación y escalabilidad.
Question 95 of 529
Una empresa está refactorizando su plataforma de procesamiento de pedidos local en la nube de AWS. La plataforma incluye un front-end web alojado en una flota de máquinas virtuales, RabbitMQ para conectar el front-end al backend y un clúster de Kubernetes para ejecutar un sistema backend contenerizado para procesar los pedidos. La empresa no quiere realizar ningún cambio importante en la aplicación.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Crear una AMI de la VM del servidor web. Cree un grupo de Auto Scaling de Amazon EC2 que utilice la AMI y un balanceador de carga de aplicaciones. Configure Amazon MQ para reemplazar la cola de mensajería local. Configure Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos.
B.
Cree un tiempo de ejecución personalizado de AWS Lambda para imitar el entorno del servidor web. Cree una API de Amazon API Gateway para reemplazar los servidores web front-end. Configure Amazon MQ para reemplazar la cola de mensajería local. Configure Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos.
C.
Crear una AMI de la VM del servidor web. Cree un grupo de Auto Scaling de Amazon EC2 que utilice la AMI y un balanceador de carga de aplicaciones. Configure Amazon MQ para reemplazar la cola de mensajería local. Instale Kubernetes en una flota de diferentes instancias EC2 para alojar el backend de procesamiento de pedidos.
D.
Crear una AMI de la VM del servidor web. Cree un grupo de Auto Scaling de Amazon EC2 que utilice la AMI y un balanceador de carga de aplicaciones. Configure una cola de Amazon Simple Queue Service (Amazon SQS) para reemplazar la cola de mensajería local. Configure Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos con la menor sobrecarga operativa, la mejor solución es crear una imagen de máquina de Amazon (AMI) de la máquina virtual del servidor web y usarla para lanzar instancias EC2 dentro de un grupo EC2 Auto Scaling, junto con un balanceador de carga de aplicaciones para el front-end web. Este enfoque permite un escalado fácil y una alta disponibilidad. Reemplazar RabbitMQ por Amazon MQ, un servicio administrado compatible con RabbitMQ, garantiza que no haya cambios importantes en el sistema de mensajería, manteniendo la compatibilidad y confiabilidad. Por último, usar Amazon Elastic Kubernetes Service (EKS) para alojar el backend contenerizado es eficiente porque administra el plano de control de Kubernetes, lo que reduce la sobrecarga operativa y proporciona un entorno administrado para el clúster de Kubernetes existente. Esta solución mantiene la mayor cantidad posible de la infraestructura existente, alineándose con los requerimientos de la compañía para evitar grandes cambios.
Question 96 of 529
Un arquitecto de soluciones necesita implementar un mecanismo de cifrado del lado del cliente para los objetos que se almacenarán en un nuevo bucket de Amazon S3. El arquitecto de soluciones creó un CMK que se almacena en AWS Key Management Service (AWS KMS) para este propósito.
El arquitecto de soluciones creó la siguiente política de IAM y la adjuntó a un rol de IAM:
Durante las pruebas, el arquitecto de soluciones pudo obtener con éxito los objetos de prueba existentes en el bucket S3. Sin embargo, los intentos de subir un nuevo objeto dieron como resultado un mensaje de error. El mensaje de error decía que la acción estaba prohibida.
Qué acción debe agregar el arquitecto de soluciones a la política de IAM para cumplir con todos los requisitos?
A.
KM:GenerateDataKey
B.
KMs:GetKeyPolicy
C.
KM:GetPublicKey
D.
Kms:Signo
ResponderDiscusión
Correct Answer: A
Para implementar el cifrado del lado del cliente para los objetos almacenados en Amazon S3, el arquitecto de soluciones necesita la capacidad de generar una clave de datos para las operaciones de cifrado y descifrado. Esto requiere la adición de la acción 'KMS:GenerateDataKey' a la política de IAM, que permite que el rol solicite a AWS Key Management Service (KMS) generar una clave de datos única para cifrar objetos S3. Sin este permiso, el rol de IAM no tendría el acceso necesario para realizar el cifrado, lo que llevaría al error encontrado durante la carga de nuevos objetos.
Question 97 of 529
Una empresa ha desarrollado una aplicación web. La compañía está alojando la aplicación en un grupo de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. La compañía quiere mejorar la postura de seguridad de la aplicación y planea utilizar las ACL web de AWS WAF. La solución no debe afectar negativamente el tráfico legítimo a la aplicación.
Cómo debe un arquitecto de soluciones configurar las ACL web para cumplir con estos requisitos?
A.
Establezca la acción de las reglas de ACL web en Count. Habilite el registro de AWS WAF. Analizar las solicitudes de falsos positivos. Modificar las reglas para evitar cualquier falso positivo. Con el tiempo, cambie la acción de las reglas de ACL web de Count a Block.
B.
Use solo reglas basadas en tasas en las ACL web y establezca el límite del acelerador lo más alto posible. Bloquear temporalmente todas las solicitudes que rebasen el límite. Defina reglas anidadas para reducir el alcance del seguimiento de tarifas.
C.
Establezca la acción de las reglas de ACL web en Bloquear. Utilice solo los grupos de reglas administrados por AWS en las ACL web. Evalúe los grupos de reglas mediante métricas de Amazon CloudWatch con solicitudes muestreadas de AWS WAF o registros de AWS WAF.
D.
Utilice solo grupos de reglas personalizados en las ACL web y establezca la acción en Permitir. Habilite el registro de AWS WAF. Analizar las solicitudes de falsos positivos. Modificar las reglas para evitar cualquier falso positivo. Con el tiempo, cambie la acción de las reglas de ACL web de Permitir a Bloquear.
ResponderDiscusión
Correct Answer: A
Para implementar las ACL web de AWS WAF de manera efectiva sin afectar el tráfico legítimo, es prudente establecer la acción de las reglas de ACL web en Count inicialmente. Este enfoque permite monitorear y registrar el tráfico para comprender los patrones e identificar falsos positivos. Con el tiempo, el análisis de los datos registrados ayuda a ajustar las reglas para mejorar la precisión. Una vez que se verifican las reglas para minimizar los falsos positivos, la acción se puede cambiar gradualmente de Contar a Bloquear, mejorando así la seguridad sin interrumpir el tráfico legítimo.
Question 98 of 529
Una empresa tiene una organización que tiene muchas cuentas de AWS en AWS Organizations. Un arquitecto de soluciones debe mejorar la forma en que la compañía administra las reglas comunes del grupo de seguridad para las cuentas de AWS en la organización.
La compañía tiene un conjunto común de rangos de IP CIDR en una lista de permisos en cada cuenta de AWS para permitir el acceso a y desde la red local de la compañía. Los desarrolladores dentro de cada cuenta son responsables de agregar nuevos rangos de IP CIDR a sus grupos de seguridad. El equipo de seguridad tiene su propia cuenta de AWS. Actualmente, el equipo de seguridad notifica a los propietarios de las otras cuentas de AWS cuando se realizan cambios en la lista de permisos.
El arquitecto de soluciones debe diseñar una solución que distribuya el conjunto común de rangos CIDR en todas las cuentas.
Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Configure un tema de Amazon Simple Notification Service (Amazon SNS) en la cuenta de AWS del equipo de seguridad. Implemente una función de AWS Lambda en cada cuenta de AWS. Configure la función Lambda para que se ejecute cada vez que un tema SNS reciba un mensaje. Configure la función Lambda para tomar una dirección IP como entrada y agregarla a una lista de grupos de seguridad en la cuenta. Instruir al equipo de seguridad para que distribuya los cambios mediante la publicación de mensajes en su tema SNS.
B.
Cree nuevas listas de prefijos administrados por el cliente en cada cuenta de AWS dentro de la organización. Rellenar las listas de prefijos en cada cuenta con todos los rangos CIDR internos. Notificar al propietario de cada cuenta de AWS para permitir los nuevos ID de lista de prefijos administrados por el cliente en sus cuentas en sus grupos de seguridad. Instruya al equipo de seguridad para que comparta las actualizaciones con cada propietario de cuenta de AWS.
C.
Cree una nueva lista de prefijos administrados por el cliente en la cuenta de AWS del equipo de seguridad. Rellenar la lista de prefijos administrados por el cliente con todos los rangos internos de CIDR. Comparta la lista de prefijos administrados por el cliente con la organización mediante AWS Resource Access Manager. Notificar al propietario de cada cuenta de AWS para permitir el nuevo ID de lista de prefijos administrados por el cliente en sus grupos de seguridad.
D.
Crear un rol de IAM en cada cuenta de la organización. Otorgar permisos para actualizar grupos de seguridad. Implemente una función de AWS Lambda en la cuenta de AWS del equipo de seguridad. Configure la función Lambda para tomar como entrada una lista de direcciones IP internas, asumir un rol en cada cuenta de la organización y agregar la lista de direcciones IP a los grupos de seguridad de cada cuenta.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos con la menor sobrecarga operativa, la solución debe aprovechar un enfoque de administración centralizada. Crear una nueva lista de prefijos administrados por el cliente en la cuenta de AWS del equipo de seguridad y llenarla con todos los rangos CIDR internos permite un control centralizado. Al compartir esta lista de prefijos con la organización mediante AWS Resource Access Manager, cada cuenta de AWS puede hacer referencia a la lista de prefijos compartidos en sus grupos de seguridad. Este enfoque minimiza la necesidad de configurar recursos adicionales en cada cuenta y reduce las tareas de mantenimiento continuo, como la actualización manual o la notificación de cambios a los propietarios de cuentas, lo que disminuye significativamente la sobrecarga operativa general.
Question 99 of 529
Una compañía ha introducido una nueva política que permite a los empleados trabajar de forma remota desde sus hogares si se conectan usando una VPN. La compañía está alojando aplicaciones internas con VPC en múltiples cuentas de AWS. Actualmente, las aplicaciones son accesibles desde la red de oficinas locales de la compañía a través de una conexión VPN de sitio a sitio de AWS. La VPC en la cuenta principal de AWS de la compañía tiene conexiones de peering establecidas con VPC en otras cuentas de AWS.
Un arquitecto de soluciones debe diseñar una solución VPN de cliente de AWS escalable para que los empleados la usen mientras trabajan desde casa.
Cuál es la solución MÁS rentable que cumple con estos requisitos?
A.
Cree un punto final de VPN de cliente en cada cuenta de AWS. Configure el enrutamiento requerido que permita el acceso a aplicaciones internas.
B.
Cree un punto final de VPN de cliente en la cuenta principal de AWS. Configure el enrutamiento requerido que permita el acceso a aplicaciones internas.
C.
Cree un punto final de VPN de cliente en la cuenta principal de AWS. Aprovisione una puerta de enlace de tránsito que esté conectada a cada cuenta de AWS. Configure el enrutamiento requerido que permita el acceso a aplicaciones internas.
D.
Cree un punto final de VPN de cliente en la cuenta principal de AWS. Establezca conectividad entre el punto final de VPN de cliente y la VPN de sitio a sitio de AWS.
ResponderDiscusión
Correct Answer: B
Crear un punto final de VPN cliente en la cuenta principal de AWS es la solución más rentable. Esta configuración aprovecha las conexiones de interconexión de VPC existentes para permitir el acceso a aplicaciones internas a través de varias cuentas de AWS. Al centralizar el punto final de VPN de cliente en la cuenta principal, se evitan endpoints adicionales y los costos asociados con ellos. Si bien las pasarelas de tránsito proporcionan escalabilidad, introducen costos innecesarios en comparación con las conexiones de interconexión más simples que ya están establecidas y suficientes para este escenario.
Question 100 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. Las métricas recientes de la aplicación muestran tiempos de respuesta inconsistentes y un aumento significativo en las tasas de error. Las llamadas a servicios de terceros están causando los retrasos. Actualmente, la aplicación llama a servicios de terceros de forma sincrónica invocando directamente una función de AWS Lambda.
Un arquitecto de soluciones necesita desacoplar las llamadas de servicio de terceros y asegurarse de que todas las llamadas finalmente se completen.
Qué solución cumplirá con estos requisitos?
A.
Utilice una cola de Amazon Simple Queue Service (Amazon SQS) para almacenar eventos e invocar la función Lambda.
B.
Utilice una máquina de estado AWS Step Functions para pasar eventos a la función Lambda.
C.
Utilice una regla de Amazon EventBridge para pasar eventos a la función Lambda.
D.
Utilice un tema Amazon Simple Notification Service (Amazon SNS) para almacenar eventos e invocar la función Lambda.
ResponderDiscusión
Correct Answer: A
Para abordar los tiempos de respuesta inconsistentes y el aumento de las tasas de error causadas por llamadas síncronas de servicios de terceros, implementar Amazon Simple Queue Service (SQS) para almacenar eventos y luego invocar la función Lambda es una solución sólida. SQS desconecta la aplicación de los servicios de terceros al poner en cola las solicitudes, lo que permite que la aplicación continúe procesando sin esperar respuestas. Este enfoque asincrónico mitiga los problemas de tiempo de respuesta y garantiza que todas las llamadas de servicio se completen, abordando el problema al tiempo que mejora la confiabilidad y escalabilidad.
Question 101 of 529
Una empresa está ejecutando aplicaciones en AWS en un entorno multicuenta. El equipo de ventas y el equipo de marketing de la compañía utilizan cuentas de AWS separadas en las organizaciones de AWS.
El equipo de ventas almacena petabytes de datos en un bucket de Amazon S3. El equipo de marketing utiliza Amazon QuickSight para visualizaciones de datos. El equipo de marketing necesita acceso a los datos que el equipo sates almacena en el bucket S3. La compañía ha cifrado el bucket S3 con una clave de AWS Key Management Service (AWS KMS). El equipo de marketing ya ha creado la función de servicio de IAM para QuickSight para proporcionar acceso a QuickSight en la cuenta de marketing de AWS. La compañía necesita una solución que proporcione acceso seguro a los datos del bucket S3 en todas las cuentas de AWS.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Crear un nuevo bucket S3 en la cuenta de marketing. Cree una regla de replicación S3 en la cuenta de ventas para copiar los objetos en el nuevo bucket S3 en la cuenta de marketing. Actualice los permisos de QuickSight en la cuenta de marketing para otorgar acceso al nuevo bucket S3.
B.
Cree un SCP para otorgar acceso al bucket S3 a la cuenta de marketing. Utilice AWS Resource Access Manager (AWS RAM) para compartir la clave KMS de la cuenta sates con la cuenta de marketing. Actualice los permisos de QuickSight en la cuenta de marketing para otorgar acceso al bucket S3.
C.
Actualice la política de bucket de S3 en la cuenta de marketing para otorgar acceso al rol de QuickSight. Cree una concesión de KMS para la clave de cifrado que se utiliza en el bucket S3. Otorgue acceso de descifrado al rol de QuickSight. Actualice los permisos de QuickSight en la cuenta de marketing para otorgar acceso al bucket S3.
D.
Cree un rol de IAM en la cuenta de ventas y otorgue acceso al bucket S3. Desde la cuenta de marketing, asuma el rol de IAM en la cuenta de ventas para acceder al bucket S3. Actualice la memoria QuickSight, para crear una relación de confianza con el nuevo rol de IAM en la cuenta de ventas.
AnswerDiscussion
Correct Answer: D
Para proporcionar acceso seguro a los datos en el bucket S3 en todas las cuentas de AWS con la menor sobrecarga operativa, crear un rol de IAM en la cuenta de ventas y otorgarle acceso al bucket S3 permite que la cuenta de marketing asuma esta función para el acceso. Este enfoque no requiere duplicar datos ni actualizar la política de bucket o claves KMS, simplificar la administración y mantener la seguridad. Establecer una relación de confianza desde la cuenta de marketing hasta el rol de IAM en la cuenta de ventas se alinea con las mejores prácticas para el acceso entre cuentas en AWS.
Question 102 of 529
Una empresa planea migrar sus aplicaciones críticas para el negocio de un centro de datos local a AWS. La compañía tiene una instalación local de un clúster de Microsoft SQL Server Always On. La compañía quiere migrar a un servicio de base de datos administrado por AWS. Un arquitecto de soluciones debe diseñar una migración heterogénea de bases de datos en AWS.
Qué solución cumplirá con estos requisitos?
A.
Migre las bases de datos de SQL Server a Amazon RDS para MySQL mediante utilidades de copia de seguridad y restauración.
B.
Utilice un dispositivo AWS Snowball Edge Storage Optimized para transferir datos a Amazon S3. Configure Amazon RDS para MySQL. Utilice la integración de S3 con funciones de SQL Server, como BULK INSERT.
C.
Utilice la herramienta de conversión de esquemas de AWS para traducir el esquema de la base de datos a Amazon RDS para MySQL. A continuación, utilice AWS Database Migration Service (AWS DMS) para migrar los datos de bases de datos locales a Amazon RDS.
D.
Utilice AWS DataSync para migrar datos a través de la red entre el almacenamiento local y Amazon S3. Configure Amazon RDS para MySQL. Utilice la integración de S3 con funciones de SQL Server, como BULK INSERT.
AnswerDiscussion
Correct Answer: C
Para una migración exitosa de bases de datos heterogéneas de un servidor Microsoft SQL Server local a un servicio administrado de AWS como Amazon RDS para MySQL, se requiere la herramienta de conversión de esquemas de AWS (SCT) para convertir el esquema de la base de datos. SCT puede traducir el esquema y el código de la base de datos de Microsoft SQL Server a MySQL sin problemas. Después de la conversión del esquema, AWS Database Migration Service (DMS) puede manejar la migración de datos real, asegurando que los datos se transfieran correcta y eficientemente a la instancia de RDS para MySQL de destino. Esta combinación de SCT y DMS proporciona un proceso simplificado para migrar entre diferentes motores de bases de datos.
Question 103 of 529
El equipo de diseño de una empresa editorial actualiza los iconos y otros activos estáticos que utiliza una aplicación web de comercio electrónico. La compañía sirve los iconos y activos desde un bucket de Amazon S3 que está alojado en la cuenta de producción de la compañía. La compañía también utiliza una cuenta de desarrollo a la que pueden acceder los miembros del equipo de diseño.
Después de que el equipo de diseño prueba los activos estáticos en la cuenta de desarrollo, el equipo de diseño necesita cargar los activos en el bucket S3 en la cuenta de producción. Un arquitecto de soluciones debe proporcionar al equipo de diseño acceso a la cuenta de producción sin exponer otras partes de la aplicación web al riesgo de cambios no deseados.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
En la cuenta de producción, cree una nueva política de IAM que permita el acceso de lectura y escritura al bucket S3.
B.
En la cuenta de desarrollo, cree una nueva política de IAM que permita el acceso de lectura y escritura al bucket S3.
C.
En la cuenta de producción, crear un rol Adjuntar la nueva política al rol. Definir la cuenta de desarrollo como una entidad de confianza.
D.
En la cuenta de desarrollo, crear un rol. Adjuntar la nueva política al rol Definir la cuenta de producción como una entidad de confianza.
E.
En la cuenta de desarrollo, cree un grupo que contenga a todos los usuarios de IAM del equipo de diseño Adjunte una política de IAM diferente al grupo para permitir la acción STS:Assumerole sobre el rol En la cuenta de producción.
F.
En la cuenta de desarrollo, cree un grupo que contenga a todos los usuarios de IAM del equipo de diseño Adjunte una política de IAM diferente al grupo para permitir la acción STS:Assumerole sobre el rol en la cuenta de desarrollo.
AnswerDiscussion
Correct Answer: A, C, E
Para permitir que el equipo de diseño actualice los activos estáticos en el bucket S3 de producción mientras mantiene la seguridad, siga estos pasos: Primero, en la cuenta de producción, cree una nueva política de IAM que otorgue acceso de lectura y escritura al bucket S3. Esto asegura que existan los permisos necesarios para administrar los activos. A continuación, en la cuenta de producción, crear un rol y adjuntar la nueva política a este rol, definiendo la cuenta de desarrollo como una entidad de confianza. Esta configuración permite que el equipo de diseño de la cuenta de desarrollo asuma este rol y obtenga acceso al bucket S3. Por último, en la cuenta de desarrollo, crear un grupo que contenga a todos los usuarios de IAM del equipo de diseño y adjunte una política a este grupo que permita la acción STS:Assumerole sobre el rol en la cuenta de producción. Esto permite que el equipo de diseño asuma el rol creado en la cuenta de producción, accediendo y administrando así los activos del bucket S3 de forma segura.
Question 104 of 529
Una compañía desarrolló una aplicación piloto mediante el uso de AWS Elastic Beanstalk y Java. Para ahorrar costos durante el desarrollo, el equipo de desarrollo de la compañía implementó la aplicación en un entorno de instancia única. Pruebas recientes indican que la aplicación consume más CPU de lo esperado. La utilización de la CPU es regularmente superior al 85%, lo que provoca algunos cuellos de botella en el rendimiento.
Un arquitecto de soluciones debe mitigar los problemas de rendimiento antes de que la compañía lance la aplicación a producción.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una nueva aplicación de Elastic Beanstalk. Seleccione un tipo de entorno con equilibrio de carga. Seleccione todas las Zonas de Disponibilidad. Agregue una regla de escalamiento vertical que se ejecutará si la utilización máxima de la CPU supera el 85% durante 5 minutos.
B.
Cree un segundo entorno de Elastic Beanstalk. Aplicar la política de despliegue de división de tráfico. Especificar un porcentaje de tráfico entrante para dirigir al nuevo entorno en la utilización promedio de la CPU es superior al 85% durante 5 minutos.
C.
Modifique la configuración de capacidad del entorno existente para utilizar un tipo de entorno con equilibrio de carga. Seleccione todas las Zonas de Disponibilidad. Agregue una regla de escalado vertical que se ejecutará si el uso promedio de la CPU supera el 85% durante 5 minutos.
D.
Seleccione la acción Reconstruir entorno con la opción de equilibrio de carga. Seleccione una zona de disponibilidad. Agregue una regla de escalado vertical que se ejecutará si la suma de utilización de la CPU supera el 85% durante 5 minutos.
AnswerDiscussion
Correct Answer: C
Para mitigar los problemas de rendimiento con la menor sobrecarga operativa, se debe modificar la configuración de capacidad del entorno existente para utilizar un tipo de entorno de carga equilibrada. Este enfoque permite adaptar la configuración actual sin necesidad de crear una nueva aplicación o entorno, utilizando las capacidades integradas de AWS Elastic Beanstalk para escalar fácilmente en función del uso de la CPU. Esto garantiza una interrupción mínima y hace un uso eficiente de los recursos existentes mientras se cumplen los requisitos de rendimiento de la aplicación.
Question 105 of 529
Una compañía financiera está ejecutando su aplicación crítica para el negocio en instancias Linux EC2 de la generación actual. La aplicación incluye una base de datos MySQL autogestionada que realiza operaciones pesadas de E/S. La aplicación está funcionando bien para manejar una cantidad moderada de tráfico durante el mes. Sin embargo, se ralentiza durante los últimos tres días de cada mes debido a los informes de fin de mes, a pesar de que la compañía está utilizando Elastic Load Balancers y Auto Scaling dentro de su infraestructura para satisfacer la creciente demanda.
Cuál de las siguientes acciones permitiría a la base de datos manejar la carga de fin de mes con el menor impacto en el rendimiento?
A.
Pre-calentamiento Elastic Load Balancers, utilizando un tipo de instancia más grande, cambiando todos los volúmenes de Amazon EBS a volúmenes GP2.
B.
Realizar una migración única del clúster de base de datos a Amazon RDS y crear varias réplicas de lectura adicionales para manejar la carga durante fin de mes.
C.
Usar Amazon CloudWatch con AWS Lambda para cambiar el tipo, el tamaño o las IOPS de los volúmenes de Amazon EBS en el clúster en función de una métrica específica de CloudWatch.
D.
Reemplazar todos los volúmenes existentes de Amazon EBS por nuevos volúmenes de PIOPS que tengan el tamaño máximo de almacenamiento disponible y E/S por segundo, tomando instantáneas antes de fin de mes y revertiéndolas después.
AnswerDiscussion
Correct Answer: B
Para manejar la carga elevada durante el período de informe de fin de mes, migrar el clúster de base de datos a Amazon RDS y crear réplicas de lectura adicionales es la solución óptima. Amazon RDS es un servicio de base de datos administrado que simplifica las tareas de administración de bases de datos, como aprovisionamiento, configuración, aplicación de parches y copias de seguridad. Mediante el uso de réplicas de lectura, puede escalar las cargas de trabajo pesadas de lectura durante los períodos pico, lo que garantiza que la base de datos pueda manejar un mayor tráfico de lectura sin una degradación significativa del rendimiento. Este enfoque minimiza la sobrecarga operativa y permite un mejor manejo de los requisitos de lectura intensiva típicos durante los informes de fin de mes.
Question 106 of 529
Una empresa ejecuta una aplicación Java que tiene dependencias complejas en las máquinas virtuales que se encuentran en el centro de datos de la compañía. La aplicación es estable. pero la compañía quiere modernizar la pila de tecnología. La compañía quiere migrar la aplicación a AWS y minimizar la sobrecarga administrativa para mantener los servidores.
Qué solución cumplirá estos requisitos con los MENOS cambios de código?
A.
Migre la aplicación a Amazon Elastic Container Service (Amazon ECS) en AWS Fargate mediante AWS App2Container. Almacene imágenes de contenedores en Amazon Elastic Container Registry (Amazon ECR). Otorgue el permiso de rol de ejecución de tareas ECS 10 para acceder al repositorio de imágenes ECR. Configure Amazon ECS para usar un balanceador de carga de aplicaciones (ALB). Utilice el ALB para interactuar con la aplicación.
B.
Migre el código de la aplicación a un contenedor que se ejecute en AWS Lambda. Cree una API REST de Amazon API Gateway con integración de Lambda. Utilice API Gateway para interactuar con la aplicación.
C.
Migre la aplicación a Amazon Elastic Kubernetes Service (Amazon EKS) en grupos de nodos administrados por EKS mediante AWS App2Container. Almacene imágenes de contenedores en Amazon Elastic Container Registry (Amazon ECR). Otorgue permiso a los nodos EKS para acceder al repositorio de imágenes ECR. Utilice Amazon API Gateway para interactuar con la aplicación.
D.
Migre el código de la aplicación a un contenedor que se ejecute en AWS Lambda. Configure Lambda para usar un balanceador de carga de aplicaciones (ALB). Utilice el ALB para interactuar con la aplicación.
AnswerDiscussion
Correct Answer: A
La migración de la aplicación a Amazon Elastic Container Service (Amazon ECS) en AWS Fargate mediante el uso de AWS App2Container y el almacenamiento de imágenes de contenedores en Amazon Elastic Container Registry (Amazon ECR) cumple los requisitos con los menores cambios de código y minimiza la sobrecarga administrativa. Esta solución permite a la compañía empaquetar el código de aplicación existente en un contenedor, que se puede implementar en ECS Fargate sin la necesidad de administrar la infraestructura subyacente. Además, el uso de un balanceador de carga de aplicaciones (ALB) para interactuar con la aplicación simplifica el proceso. AWS Fargate es un motor informático sin servidor que reduce la sobrecarga operativa, por lo que es ideal para este escenario.
Question 107 of 529
Una empresa tiene una aplicación HTTP asíncrona que está alojada como una función de AWS Lambda. Un endpoint público de Amazon API Gateway invoca la función Lambda. La función Lambda y el punto final API Gateway residen en la región us-east-1. Un arquitecto de soluciones necesita rediseñar la aplicación para admitir la conmutación por error a otra región de AWS.
Qué solución cumplirá con estos requisitos?
A.
Cree un punto final de puerta de enlace API en la región us-west-2 para dirigir el tráfico a la función Lambda en us-east-1. Configure Amazon Route 53 para que utilice una política de enrutamiento de conmutación por error para enrutar el tráfico para los dos puntos finales de API Gateway.
B.
Cree una cola de Amazon Simple Queue Service (Amazon SQS). Configure API Gateway para dirigir el tráfico a la cola SQS en lugar de a la función Lambda. Configure la función Lambda para extraer mensajes de la cola para su procesamiento.
C.
Desplegar la función Lambda en la región us-west-2. Cree un punto final de puerta de enlace API en us-west-2 10 tráfico directo a la función Lambda en us-west-2. Configure AWS Global Accelerator y un balanceador de carga de aplicaciones para administrar el tráfico a través de los dos endpoints de API Gateway.
D.
Implemente la función Lambda y un punto final de API Gateway en la región us-west-2. Configure Amazon Route 53 para que utilice una política de enrutamiento de conmutación por error para enrutar el tráfico para los dos puntos finales de API Gateway.
AnswerDiscussion
Correct Answer: D
Para admitir la conmutación por error a otra región de AWS, debe implementar la función Lambda y un punto final de API Gateway en otra región (en este caso, us-west-2). Esta configuración garantiza que si la región principal (us-east-1) no está disponible, el tráfico se puede enrutar a la región de respaldo (us-west-2). La política de enrutamiento de conmutación por error de Amazon Route 53 se puede utilizar para enrutar automáticamente el tráfico a un punto final en buen estado, lo que garantiza la disponibilidad y confiabilidad en todas las regiones.
Question 108 of 529
Una empresa minorista ha estructurado sus cuentas de AWS para formar parte de una organización en AWS Organizations. La compañía ha establecido la facturación consolidada y ha mapeado sus departamentos a las siguientes OU: Finanzas, Ventas, Recursos Humanos (RRHH), Marketing y Operaciones. Cada unidad organizativa tiene varias cuentas de AWS, una para cada entorno dentro de un departamento. Estos entornos son desarrollo, prueba, preproducción y producción.
El departamento de RRHH está lanzando un nuevo sistema que se lanzará en 3 meses. En preparación, el departamento de RRHH ha adquirido varias Instancias Reservadas (RI) en su cuenta de AWS de producción. El departamento de RRHH instalará la nueva aplicación en esta cuenta. El departamento de Recursos Humanos quiere asegurarse de que otros departamentos no puedan compartir los descuentos de RI.
Qué solución cumplirá con estos requisitos?
A.
En la consola de facturación y administración de costos de AWS para la cuenta de producción del departamento de recursos humanos, desactiva el uso compartido de RI.
B.
Eliminar de la organización la cuenta AWS de producción del departamento de RRHH. Agrega la cuenta 10 solo la configuración de facturación consolidante.
C.
En la consola AWS Billing and Cost Management. Utilice la cuenta de administración de la organización 10 desactiva RI Sharing para la cuenta de producción de departamentos de recursos humanos de AWS.
D.
Crear un SCP en la organización para restringir el acceso a las IR. Aplicar el SCP a las unidades organizativas de los demás departamentos.
AnswerDiscussion
Correct Answer: C
Para evitar que otros departamentos compartan los descuentos de instancias reservadas (RI) comprados por la cuenta de AWS de producción del departamento de RRHH, la acción adecuada es usar la cuenta de administración de la organización para desactivar el uso compartido de RI para esa cuenta específica en la consola de administración de costos y facturación de AWS. Esta configuración asegura que los beneficios de RI se apliquen solo dentro de la cuenta de producción del departamento de recursos humanos, lo que impide que otras cuentas dentro de la organización accedan a estos descuentos.
Question 109 of 529
Una gran empresa está ejecutando una popular aplicación web. La aplicación se ejecuta en varias instancias de Linux de Amazon EC2 en un grupo de Auto Scaling en una subred privada. Un balanceador de carga de aplicaciones está dirigido a las instancias del grupo Auto Scaling en la subred privada. AWS Systems Manager Session Manager está configurado y AWS Systems Manager Agent se ejecuta en todas las instancias EC2.
La compañía lanzó recientemente una nueva versión de la aplicación. Algunas instancias EC2 ahora están siendo marcadas como insalubres y están siendo terminadas. Como resultado, la aplicación se está ejecutando a una capacidad reducida. Un arquitecto de soluciones intenta determinar la causa raíz analizando los registros de Amazon CloudWatch que se recopilan de la aplicación, pero los registros no son concluyentes.
Cómo debería el arquitecto de soluciones obtener acceso a una instancia EC2 para solucionar el problema?
A.
Suspenda el proceso de escalado HealthCheck del grupo Auto Scaling. Utilice el Administrador de sesiones para iniciar sesión en una instancia que esté marcada como no saludable.
B.
Habilite la protección de terminación de instancias EC2. Utilice el Administrador de sesiones para iniciar sesión en una instancia que esté marcada como no saludable.
C.
Establezca la política de terminación en OldestInstance en el grupo Auto Scaling. Use el Administrador de sesiones para iniciar sesión en una instancia que esté marcada como no saludable.
D.
Suspenda el proceso de terminación del grupo Auto Scaling. Utilice el Administrador de sesiones para iniciar sesión en una instancia que esté marcada como no saludable.
AnswerDiscussion
Correct Answer: D
Para investigar por qué las instancias están siendo marcadas como insalubres y terminadas, es crucial evitar primero su terminación. La suspensión del proceso de terminación del grupo Auto Scaling garantiza que las instancias en mal estado no se terminen inmediatamente, lo que permite al arquitecto de soluciones usar Session Manager para acceder a la instancia y realizar una solución de problemas detallada. Este enfoque mantiene las instancias disponibles para su investigación sin interferir con sus controles de salud.
Question 110 of 529
Una empresa quiere implementar una solución de AWS WAF para administrar las reglas de AWS WAF en varias cuentas de AWS. Las cuentas se administran bajo diferentes unidades organizativas en AWS Organizations.
Los administradores deben poder agregar o eliminar cuentas u unidades organizativas de los conjuntos de reglas de AWS WAF administrados según sea necesario. Los administradores también deben tener la capacidad de actualizar y corregir automáticamente las reglas de AWS WAF no conformes en todas las cuentas.
Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Utilice AWS Firewall Manager para administrar las reglas de AWS WAF en todas las cuentas de la organización. Utilice un parámetro de almacenamiento de parámetros de AWS Systems Manager para almacenar números de cuenta y unidades organizativas para administrar. Actualice el parámetro según sea necesario para agregar o eliminar cuentas u OU. Utilice una regla de Amazon EventBridge para identificar cualquier cambio en el parámetro e invocar una función de AWS Lambda para actualizar la política de seguridad en la cuenta administrativa de Firewall Manager.
B.
Implemente una regla de AWS Config para toda la organización que requiera todos los recursos de las unidades organizativas seleccionadas para asociar las reglas de AWS WAF. Implemente acciones de corrección automatizadas mediante AWS Lambda para reparar recursos no conformes. Implemente reglas de AWS WAF mediante una pila de AWS CloudFormation establecida para dirigirse a las mismas unidades organizativas donde se aplica la regla de AWS Config.
C.
Crear reglas de AWS WAF en la cuenta de administración de la organización. Utilice las variables de entorno de AWS Lambda para almacenar números de cuenta y unidades organizativas para administrar. Actualice las variables de entorno según sea necesario para agregar o eliminar cuentas u unidades organizativas. Crear roles de IAM entre cuentas en cuentas de miembros. Asume las funciones mediante AWS Security Token Service (AWS STS) en la función Lambda para crear y actualizar reglas de AWS WAF en las cuentas de miembro.
D.
Utilice AWS Control Tower para administrar las reglas de AWS WAF en todas las cuentas de la organización. Utilice AWS Key Management Service (AWS KMS) para almacenar números de cuenta y unidades organizativas para administrar. Actualice AWS KMS según sea necesario para agregar o eliminar cuentas u OU. Crear usuarios de IAM en cuentas de miembros. Permita que AWS Control Tower en la cuenta de administración utilice la clave de acceso y la clave de acceso secreta para crear y actualizar reglas de AWS WAF en las cuentas de miembro.
AnswerDiscussion
Correct Answer: A
La mejor solución es usar AWS Firewall Manager para administrar las reglas de AWS WAF en todas las cuentas de la organización. AWS Firewall Manager centraliza la configuración y administración de reglas de firewall en varias cuentas, facilitando el proceso con una sobrecarga operativa mínima. El uso de un parámetro de almacenamiento de parámetros de AWS Systems Manager para almacenar números de cuenta y unidades organizativas permite flexibilidad para agregar o eliminar cuentas u unidades organizativas según sea necesario. Una regla de Amazon EventBridge puede detectar cambios en este parámetro y activar una función de AWS Lambda para actualizar la política de seguridad en la cuenta administrativa de Firewall Manager. Esta configuración garantiza actualizaciones automáticas y corrección de reglas de AWS WAF no conformes en todas las cuentas de manera eficiente.
Question 111 of 529
Un arquitecto de soluciones está auditando la configuración de seguridad o una función de AWS Lambda para una empresa. La función Lambda recupera los últimos cambios de una base de datos de Amazon Aurora. La función Lambda y la base de datos se ejecutan en la misma VPC. Las variables de entorno Lambda proporcionan las credenciales de la base de datos a la función Lambda.
La función Lambda agrega datos y los pone a disposición en un bucket de Amazon S3 configurado para el cifrado del lado del servidor con claves de cifrado administradas de AWS KMS (SSE-KMS). Los datos no deben viajar a través de Internet. Si alguna de las credenciales de la base de datos se ve comprometida, la empresa necesita una solución que minimice el impacto del compromiso.
Qué debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Habilite la autenticación de base de datos IAM en el clúster de base de datos Aurora. Cambie el rol de IAM para la función Lambda para permitir que la función acceda a la base de datos mediante la autenticación de base de datos de IAM. Implemente un punto final de VPC de puerta de enlace para Amazon S3 en la VPC.
B.
Habilite la autenticación de base de datos IAM en el clúster de base de datos Aurora. Cambie el rol de IAM para la función Lambda para permitir que la función acceda a la base de datos mediante la autenticación de base de datos de IAM. Aplique HTTPS en la conexión a Amazon S3 durante las transferencias de datos.
C.
Guarde las credenciales de la base de datos en AWS Systems Manager Parameter Store. Configure la rotación de contraseñas en las credenciales en el almacén de parámetros. Cambie el rol de IAM para la función Lambda para permitir que la función acceda a Parameter Store. Modifique la función Lambda para recuperar las credenciales del almacén de parámetros. Implemente un punto final de VPC de puerta de enlace para Amazon S3 en la VPC.
D.
Guarde las credenciales de la base de datos en AWS Secrets Manager. Configure la rotación de contraseñas en las credenciales en Secrets Manager. Cambie el rol de IAM para la función Lambda para permitir que la función acceda a Secrets Manager. Modifique la función Lambda para recuperar las credenciales de Secrets Manager. Aplique HTTPS en la conexión a Amazon S3 durante las transferencias de datos.
AnswerDiscussion
Correct Answer: A
El mejor enfoque para garantizar tanto el acceso seguro a la base de datos Aurora como para evitar que los datos viajen a través de Internet es habilitar la autenticación de la base de datos de IAM y usar un punto final de VPC para S3. Al habilitar la autenticación de la base de datos IAM, la función Lambda puede acceder a la base de datos sin requerir credenciales incrustadas, minimizando así el impacto del potencial compromiso de credenciales. Además, la implementación de un endpoint de VPC de puerta de enlace para Amazon S3 garantiza que toda la comunicación entre la función Lambda y S3 permanezca dentro de la red de AWS, asegurando el tráfico y evitando que atraviese Internet.
Question 112 of 529
Una gran compañía de juegos móviles ha migrado con éxito toda su infraestructura local a la nube de AWS. Un arquitecto de soluciones está revisando el entorno para asegurarse de que fue construido de acuerdo con el diseño y que está funcionando en alineación con el Marco Bien Arquitectado.
Al revisar los costos mensuales anteriores en Cost Explorer, el arquitecto de soluciones advierte que la creación y posterior terminación de varios tipos de instancias grandes representan una alta proporción de los costos. El arquitecto de soluciones descubre que los desarrolladores de la compañía están lanzando nuevas instancias de Amazon EC2 como parte de sus pruebas y que los desarrolladores no están utilizando los tipos de instancias adecuados.
El arquitecto de soluciones debe implementar un mecanismo de control para limitar los tipos de instancias que solo los desarrolladores pueden lanzar.
Qué solución cumplirá con estos requisitos?
A.
Cree una regla administrada del tipo de instancia deseado en AWS Config. Configure la regla con los tipos de instancia permitidos. Adjunte la regla a un evento para que se ejecute cada vez que se inicie una nueva instancia EC2.
B.
En la consola EC2, cree una plantilla de lanzamiento que especifique los tipos de instancia permitidos. Asigne la plantilla de lanzamiento a las cuentas de IAM de los desarrolladores.
C.
Crear una nueva política de IAM. Especifique los tipos de instancia que están permitidos. Adjuntar la política a un grupo de IAM que contenga las cuentas de IAM para los desarrolladores
D.
Utilice EC2 Image Builder para crear una canalización de imágenes para los desarrolladores y asistirlos en la creación de una imagen dorada.
AnswerDiscussion
Correct Answer: C
Para controlar qué tipos de instancias pueden lanzar los desarrolladores, crear una nueva política de IAM es la solución adecuada. Esta política especificará los tipos de instancia permitidos y se adjuntará a un grupo de IAM que contenga las cuentas de IAM de los desarrolladores. Esto asegura que los desarrolladores solo puedan lanzar instancias de los tipos permitidos, evitando así la creación de instancias más grandes y costosas.
Question 113 of 529
Una empresa está desarrollando y alojando varios proyectos en la nube de AWS. Los proyectos se desarrollan en múltiples cuentas de AWS bajo la misma organización en AWS Organizations. La compañía requiere que el costo de la infraestructura en la nube se asigne al proyecto propietario. El equipo responsable de todas las cuentas de AWS ha descubierto que varias instancias de Amazon EC2 carecen de la etiqueta Project utilizada para la asignación de costos.
Qué acciones debe realizar un arquitecto de soluciones del lago para resolver el problema y evitar que suceda en el futuro? (Elija tres.)
A.
Cree una regla de AWS Config en cada cuenta para encontrar recursos con etiquetas faltantes.
B.
Cree un SCP en la organización con una acción de denegar para EC2:EjecutarInstancias si falta la etiqueta Project.
C.
Usa Amazon Inspector en la organización para encontrar recursos con etiquetas faltantes.
D.
Cree una política de IAM en cada cuenta con una acción de denegar para EC2:RunInstancias si falta la etiqueta Project.
E.
Cree un agregador de AWS Config para que la organización recopile una lista de instancias EC2 con la etiqueta Project faltante.
F.
Utilice AWS Security Hub para agregar una lista de instancias EC2 con la etiqueta Project que falta.
AnswerDiscussion
Correct Answer: A, B, E
Para garantizar que todas las instancias de Amazon EC2 en varias cuentas de AWS tengan la etiqueta Project requerida para la asignación de costos, la creación de una regla de AWS Config en cada cuenta ayudará a identificar los recursos con etiquetas faltantes. Luego, el uso de una Política de Control de Servicios (SCP) dentro de la organización de AWS puede aplicar una política para evitar la creación de instancias EC2 que carezcan de la etiqueta requerida, asegurando que las instancias futuras estén etiquetadas correctamente. Por último, se puede configurar un agregador de AWS Config para recopilar datos de conformidad con respecto a las etiquetas en todas las cuentas, proporcionando una vista centralizada para administrar y rectificar cualquier problema de etiquetado.
Question 114 of 529
Una empresa cuenta con una solución de monitoreo local que utiliza una base de datos PostgreSQL para la persistencia de eventos. La base de datos no puede escalar debido a la ingestión pesada y con frecuencia se queda sin almacenamiento.
La compañía quiere crear una solución híbrida y ya ha configurado una conexión VPN entre su red y AWS. La solución debe incluir los siguientes atributos:
• Servicios de AWS administrados para minimizar la complejidad operativa.
• Un búfer que escala automáticamente para igualar el rendimiento de los datos y no requiere administración continua.
• Una herramienta de visualización para crear dashboards para observar eventos en tiempo casi real.
• Soporte para datos JSON semiestructurados y esquemas dinámicos.
Qué combinación de componentes permitirá a la compañía crear una solución de monitoreo que satisfaga estos requisitos? (Elija dos.)
A.
Utilice Amazon Kinesis Data Firehose para almacenar en búfer eventos. Cree una función de AWS Lambda para procesar y transformar eventos.
B.
Cree una transmisión de datos de Amazon Kinesis para almacenar en búfer eventos. Cree una función de AWS Lambda para procesar y transformar eventos.
C.
Configure un clúster de base de datos de Amazon Aurora PostgreSQL para recibir eventos. Utilice Amazon QuickSight para leer desde la base de datos y crear visualizaciones y paneles casi en tiempo real.
D.
Configure Amazon Elasticsearch Service (Amazon ES) para recibir eventos. Utilice el punto final de Kibana implementado con Amazon ES para crear visualizaciones y paneles casi en tiempo real.
E.
Configure una instancia de base de datos de Amazon Neptune para recibir eventos. Utilice Amazon QuickSight para leer desde la base de datos y crear visualizaciones y paneles casi en tiempo real.
AnswerDiscussion
Correct Answer: A, D
Para diseñar una solución que cumpla con los requisitos especificados, Amazon Kinesis Data Firehose y Amazon Elasticsearch Service (Amazon ES) son los componentes adecuados. Amazon Kinesis Data Firehose es un servicio completamente administrado capaz de escalar automáticamente para igualar el rendimiento de los datos y no requiere una administración continua, lo que lo hace adecuado para eventos de almacenamiento en búfer. Además, admite el uso de funciones de AWS Lambda para procesar y transformar datos, acomodando datos JSON semiestructurados y esquemas dinámicos. Amazon Elasticsearch Service, por otro lado, es un servicio administrado que puede recibir eventos de manera efectiva y proporciona Kibana para crear visualizaciones y paneles casi en tiempo real. Esta combinación garantiza una solución escalable y administrada con una complejidad operativa mínima, al tiempo que admite datos JSON y proporciona sólidas capacidades de visualización.
Question 115 of 529
Un equipo recopila y enruta datos de comportamiento para toda una empresa. La compañía opera un entorno de VPC Multi-AZ con subredes públicas, subredes privadas y gateway de Internet. Cada subred pública también contiene una puerta de enlace NAT. La mayoría de las aplicaciones de la compañía leen y escriben en Amazon Kinesis Data Streams. La mayoría de las cargas de trabajo se ejecutan en subredes privadas.
Un arquitecto de soluciones debe revisar la infraestructura. El arquitecto de soluciones necesita reducir costos y mantener la función de las aplicaciones. El arquitecto de soluciones utiliza Cost Explorer y advierte que el costo en la categoría EC2-Otros es consistentemente alto. Una revisión adicional muestra que los cargos de Natgateway-bytes están aumentando el costo en la categoría EC2-Otros.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Habilite los registros de flujo de VPC. Utilice Amazon Athena para analizar los registros de tráfico que se puede eliminar. Asegurar que los grupos de seguridad estén bloqueando el tráfico que es responsable de altos costos.
B.
Agregue un punto de enlace de VPC de interfaz para Kinesis Data Streams a la VPC. Asegúrese de que las aplicaciones tengan los permisos de IAM correctos para usar el punto final de la VPC de la interfaz.
C.
Habilite los registros de flujo de VPC y Amazon Detective. Revise los hallazgos de Detective para detectar tráfico que no esté relacionado con Kinesis Data Streams. Configure grupos de seguridad para bloquear ese tráfico.
D.
Agregue un punto de enlace de VPC de interfaz para Kinesis Data Streams a la VPC. Asegúrese de que la directiva de punto final de VPC permita el tráfico de las aplicaciones.
AnswerDiscussion
Correct Answer: B
Agregar un punto de enlace de VPC de interfaz para Kinesis Data Flujos a la VPC permite que las aplicaciones en subredes privadas accedan directamente a Kinesis Data Flujos sin enrutar el tráfico a través de la puerta de enlace NAT, lo que reduce significativamente los costos de transferencia de datos. Esto se debe a que los datos transferidos a través de puntos finales de VPC son más baratos en comparación con los datos transferidos a través de puertas de enlace NAT. No es necesario especificar que la directiva de punto final de VPC permita el tráfico de las aplicaciones, ya que la principal preocupación es reducir los costos de puerta de enlace NAT.
Question 116 of 529
Una empresa minorista tiene un centro de datos local en Europa. La compañía también tiene una presencia en AWS multirregional que incluye las regiones eu-west-1 y us-east-1. La compañía quiere poder enrutar el tráfico de red desde su infraestructura local hacia VPC en cualquiera de esas regiones. La compañía también necesita soportar el tráfico que se enruta directamente entre VPC en esas regiones. No pueden existir puntos únicos de falla en la red.
La compañía ya ha creado dos conexiones AWS Direct Connect de 1 Gbps desde su centro de datos local. Cada conexión va a una ubicación de Direct Connect separada en Europa para una alta disponibilidad. Estas dos ubicaciones se denominan DX-A y DX-B, respectivamente. Cada región tiene una única AWS Transit Gateway configurada para enrutar todo el tráfico entre VPC dentro de esa región.
Qué solución cumplirá con estos requisitos?
A.
Cree un VIF privado desde la conexión DX-A en una puerta de enlace Direct Connect. Cree un VIF privado desde la conexión DX-B en la misma puerta de enlace Direct Connect para una alta disponibilidad. Asocie las pasarelas de tránsito eu-west-1 y us-east-1 con la puerta de enlace Direct Connect. Peer las puertas de enlace de tránsito entre sí para admitir el enrutamiento entre regiones.
B.
Cree un VIF de tránsito desde la conexión DX-A a una puerta de enlace Direct Connect. Asocie la puerta de enlace de tránsito eu-west-1 con esta puerta de enlace Direct Connect. Cree un VIF de tránsito desde la conexión DX-8 en una puerta de enlace Direct Connect independiente. Asocie la puerta de enlace de tránsito us-east-1 con esta puerta de enlace Direct Connect independiente. Peer las puertas de enlace de Direct Connect entre sí para admitir alta disponibilidad y enrutamiento entre regiones.
C.
Cree un VIF de tránsito desde la conexión DX-A a una puerta de enlace Direct Connect. Cree un VIF de tránsito desde la conexión DX-B a la misma puerta de enlace Direct Connect para una alta disponibilidad. Asocie las pasarelas de tránsito eu-west-1 y us-east-1 con esta puerta de enlace Direct Connect. Configure la puerta de enlace Direct Connect para enrutar el tráfico entre las puertas de enlace de tránsito.
D.
Cree un VIF de tránsito desde la conexión DX-A a una puerta de enlace Direct Connect. Cree un VIF de tránsito desde la conexión DX-B a la misma puerta de enlace Direct Connect para una alta disponibilidad. Asocie las pasarelas de tránsito eu-west-1 y us-east-1 con esta puerta de enlace Direct Connect. Peer las puertas de enlace de tránsito entre sí para admitir el enrutamiento entre regiones.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos de enrutar el tráfico de red entre la infraestructura local y las VPC tanto en las regiones eu-west-1 como us-east-1, incluido el tráfico enrutado directamente entre las VPC en esas regiones sin ningún punto único de falla, la solución correcta implica configurar VIF de tránsito. Específicamente, un VIF de tránsito desde ambas conexiones Direct Connect, DX-A y DX-B, en una sola puerta de enlace Direct Connect brinda alta disponibilidad. Al asociar las pasarelas de tránsito eu-west-1 y us-east-1 con esta puerta de enlace Direct Connect y uniendo las pasarelas de tránsito entre sí, se admite el enrutamiento entre regiones, cumpliendo con el requisito de alta disponibilidad y resiliencia.
Question 117 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. El equipo de seguridad de la compañía debe aprobar la creación de todos los nuevos usuarios de IAM. Cuando se crea un nuevo usuario de IAM, todos los accesos para el usuario deben eliminarse automáticamente. El equipo de seguridad deberá entonces recibir una notificación para aprobar al usuario. La compañía tiene un rastro multiregional de AWS CloudTrail en la cuenta de AWS.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Cree una regla de Amazon EventBridge (Amazon CloudWatch Events). Defina un patrón con el valor de tipo detalle establecido en AWS API Call a través de CloudTrail y un eventName de CreateUser.
B.
Configure CloudTrail para enviar una notificación del evento CreateUser a un tema de Amazon Simple Notification Service (Amazon SNS).
C.
Invoque un contenedor que se ejecute en Amazon Elastic Container Service (Amazon ECS) con tecnología AWS Fargate para eliminar el acceso.
D.
Invocar una máquina de estado AWS Step Functions para eliminar el acceso.
E.
Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de seguridad.
F.
Utilice Amazon Pinpoint para notificar al equipo de seguridad.
AnswerDiscussion
Correct Answer: A, D, E
Para cumplir con los requisitos de que el equipo de seguridad apruebe la creación de todos los nuevos usuarios de IAM mientras elimina su acceso automáticamente y notifica al equipo de seguridad, se pueden emplear los siguientes pasos: En primer lugar, crear una regla de Amazon EventBridge (Amazon CloudWatch Events) para detectar el evento CreateUser. Esta regla EventBridge (A) es necesaria para monitorear cuándo se crea un nuevo usuario de IAM. En segundo lugar, utilice Step Functions para automatizar el proceso de eliminación de acceso. AWS Step Functions (D) se puede utilizar para organizar el proceso de eliminación automática del acceso del usuario al momento de la creación. Por último, emplee Amazon Simple Notification Service (SNS) (E) para enviar una notificación al equipo de seguridad para su aprobación. SNS es muy adecuado para enviar notificaciones directamente al equipo, cumpliendo con el requisito de notificación. Pinpoint es incorrecto porque se utiliza para la participación del cliente en lugar de notificaciones para los equipos de seguridad interna. ECS con Fargate agrega complejidad innecesaria y sobrecarga para esta solución en comparación con Step Functions.
Question 118 of 529
Una empresa quiere migrar a AWS. La compañía quiere utilizar una estructura multicuenta con acceso administrado centralmente a todas las cuentas y aplicaciones. La compañía también quiere mantener el tráfico en una red privada. Se requiere autenticación multifactor (MFA) al iniciar sesión y se asignan roles específicos a grupos de usuarios.
La compañía debe crear cuentas separadas para el desarrollo. puesta en escena, producción y red compartida. La cuenta de producción y la cuenta de red compartida deben tener conectividad a todas las cuentas. La cuenta de desarrollo y la cuenta provisional deben tener acceso solo entre sí.
Qué combinación de pasos debe tomar un arquitecto de soluciones 10 para cumplir con estos requisitos? (Elija tres.)
A.
Implementar un entorno de zona de aterrizaje mediante AWS Control Tower. Inscriba cuentas e invite a cuentas existentes a la organización resultante en AWS Organizations.
B.
Habilite AWS Security Hub en todas las cuentas para administrar el acceso entre cuentas. Recopile hallazgos a través de AWS CloudTrail para forzar el inicio de sesión de MFA.
C.
Cree pasarelas de tránsito y adjuntos de VPC de puerta de enlace de tránsito en cada cuenta. Configure las tablas de ruta adecuadas.
D.
Configure y habilite AWS IAM Identity Center (AWS Single Signa-On). Crear conjuntos de permisos apropiados con MFA requerido para cuentas existentes.
E.
Habilite AWS Control Tower en todas las cuentas para administrar el enrutamiento entre cuentas. Recopile hallazgos a través de AWS CloudTrail para forzar el inicio de sesión de MFA.
F.
Crear usuarios y grupos de IAM. Configurar MFA para todos los usuarios. Configura grupos de usuarios de Amazon Cognoto e Identity pools para administrar el acceso a cuentas y entre cuentas.
AnswerDiscussion
Correct Answer: A, C, D
Para cumplir con los requisitos de una estructura multicuenta con acceso administrado centralmente y tráfico de red privada, se deben tomar los siguientes pasos. Primero, implemente un entorno de zona de aterrizaje con AWS Control Tower, ya que esto ayuda a configurar un entorno de AWS multicuenta seguro y bien diseñado. Luego, cree pasarelas de tránsito y adjuntos de VPC de puerta de enlace de tránsito en cada cuenta para garantizar el enrutamiento adecuado y la conectividad privada entre las cuentas. Por último, configure y habilite AWS IAM Identity Center (AWS Single Sign-On) para administrar el acceso de los usuarios con autenticación multifactor y asignar roles específicos a grupos de usuarios, asegurando una administración de acceso segura y centralizada.
Question 119 of 529
Una empresa ejecuta su aplicación en la región eu-west-1 y tiene una cuenta para cada uno de sus entornos: desarrollo, pruebas y producción. Todos los entornos funcionan las 24 horas del día, los 7 días de la semana mediante el uso de instancias de Amazon EC2 con estado y bases de datos de Amazon RDS para MySQL. Las bases de datos tienen entre 500 GB y 800 GB de tamaño.
El equipo de desarrollo y el equipo de pruebas trabajan en días hábiles durante el horario comercial, pero el entorno de producción opera las 24 horas del día, los 7 días de la semana. La compañía quiere reducir costos. Todos los recursos están etiquetados con una etiqueta de entorno con desarrollo, pruebas o producción como clave.
Qué debe hacer un arquitecto de soluciones para reducir costos con el MENOR esfuerzo operativo?
A.
Cree una regla de Amazon EventBridge que se ejecute una vez al día. Configure la regla para invocar una función de AWS Lambda que inicie o rastree instancias en función de mi etiqueta, día y hora.
B.
Cree una regla de Amazon EventBridge que se ejecute todos los días hábiles por la noche. Configure la regla para invocar una función de AWS Lambda que detenga instancias basadas en la etiqueta. Cree una segunda regla de EventBridge que se ejecute todos los días hábiles por la mañana. Configure la segunda regla para invocar otra función Lambda que inicie instancias basadas en la etiqueta.
C.
Cree una regla de Amazon EventBridge que se ejecute todos los días hábiles por la noche, Configure la regla para invocar una función de AWS Lambda que termine, instancias basadas en el retraso. Cree una segunda regla de EventBridge que se ejecute todos los días hábiles por la mañana. Configure la segunda regla para invocar otra función Lambda que restaure las instancias desde su última copia de seguridad basada en la etiqueta.
D.
Cree una regla de Amazon EventBridge que se ejecute cada hora. Configure la regla para invocar una función de AWS Lambda que termine o restaure instancias de su última copia de seguridad en función de la etiqueta. día y hora.
AnswerDiscussion
Correct Answer: B
Para reducir costos con el menor esfuerzo operativo, la solución debe enfocarse en administrar las instancias en función del patrón de uso de los diferentes entornos. Los entornos de desarrollo y pruebas solo son necesarios durante el horario comercial en días hábiles, mientras que el entorno de producción opera continuamente. Al crear una regla de Amazon EventBridge que se ejecuta todos los días hábiles por la noche para detener instancias y otra regla que se ejecuta todos los días hábiles por la mañana para iniciar instancias basadas en la etiqueta, la compañía puede garantizar que las instancias para desarrollo y pruebas solo se ejecuten cuando sea necesario. Este enfoque minimiza los costos innecesarios al detener instancias cuando no se están utilizando sin la complejidad de crear y restaurar instancias. Adicionalmente, preserva el estado de las instancias, asegurando la integridad de los datos y tiempos de arranque rápidos cuando sea necesario. Por lo tanto, crear reglas de EventBridge separadas para iniciar y detener instancias dos veces al día es la solución más efectiva para reducir costos con un mínimo esfuerzo operativo.
Question 120 of 529
Una empresa está construyendo una solución de software como servicio (SaaS) en AWS. La compañía ha implementado una API REST de Amazon API Gateway con integración de AWS Lambda en varias regiones de AWS y en la misma cuenta de producción.
La compañía ofrece precios escalonados que brindan a los clientes la posibilidad de pagar por la capacidad de realizar un cierto número de llamadas API por segundo. El nivel premium ofrece hasta 3,000 llamadas por segundo, y los clientes son identificados por una clave API única. Varios clientes de nivel premium en varias regiones informan que reciben respuestas de error de 429 solicitudes de demasiadas solicitudes de varios métodos API durante las horas pico de uso. Los registros indican que nunca se invoca la función Lambda.
Cuál podría ser la causa de los mensajes de error para estos clientes?
A.
La función Lambda alcanzó su límite de concurrencia.
B.
La función Lambda su límite de región para concurrencia.
C.
La compañía alcanzó su límite de cuentas API Gateway para llamadas por segundo.
D.
La compañía alcanzó su límite predeterminado por método de API Gateway para llamadas por segundo.
AnswerDiscussion
Correct Answer: C
El mensaje de error 429 Demasiadas solicitudes de API Gateway indica que la cuenta ha excedido su límite para el número de llamadas a la API por segundo. Amazon API Gateway aplica límites predeterminados de regulación a nivel de cuenta en la tasa de solicitudes. Específicamente, tiene un límite de 10 mil solicitudes por segundo por cuenta por región. Dado que el nivel premium permite hasta 3,000 llamadas por segundo y múltiples clientes premium están utilizando el servicio en diferentes regiones, es probable que el número agregado de solicitudes supere el límite de 10,000 solicitudes por segundo, resultando en los 429 errores. Esto también explica por qué no se invoca la función Lambda, ya que las solicitudes están siendo estranguladas a nivel API Gateway. Por lo tanto, la compañía alcanzó su límite de cuenta API Gateway para llamadas por segundo.
Question 121 of 529
Una compañía financiera planea migrar su aplicación web de on premise a AWS. La compañía utiliza una herramienta de seguridad de terceros para monitorear el tráfico entrante a la aplicación. La compañía ha utilizado la herramienta de seguridad durante los últimos 15 años, y la herramienta no tiene soluciones en la nube disponibles de su proveedor. El equipo de seguridad de la compañía está preocupado por cómo integrar la herramienta de seguridad con la tecnología de AWS.
La compañía planea implementar la migración de aplicaciones a AWS en instancias de Amazon EC2. Las instancias EC2 se ejecutarán en un grupo de Auto Scaling en una VPC dedicada. La compañía necesita usar la herramienta de seguridad para inspeccionar todos los paquetes que entran y salen de la VPC. Esta inspección debe ocurrir en tiempo real y no debe afectar el rendimiento de la aplicación. Un arquitecto de soluciones debe diseñar una arquitectura de destino en AWS que esté altamente disponible dentro de una región de AWS.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Implementar la herramienta de seguridad en instancias EC2 en un nuevo grupo de Auto Scaling en la VPC existente
B.
Implementar la aplicación web detrás de un balanceador de carga de red
C.
Implementar un balanceador de carga de aplicaciones frente a las instancias de la herramienta de seguridad
D.
Aprovisione un balanceador de carga de puerta de enlace para cada zona de disponibilidad para redirigir el tráfico a la herramienta de seguridad
E.
Aprovisione una puerta de enlace de tránsito para facilitar la comunicación entre VPC.
AnswerDiscussion
Correct Answer: D, E
Para cumplir con los requisitos de integrar una herramienta de seguridad no nativa de la nube de 15 años con AWS para la inspección del tráfico en un grupo de Auto Scaling dentro de una VPC dedicada, debe usar un balanceador de carga de puerta de enlace (GWLB). El GWLB facilita redirigir el tráfico sin problemas a sus instancias de herramientas de seguridad sin afectar el rendimiento de las aplicaciones. Además, el aprovisionamiento de una puerta de enlace de tránsito ayudará a facilitar la comunicación entre las VPC, lo cual es importante para garantizar la alta disponibilidad y el enrutamiento adecuado del tráfico a través de la herramienta de inspección de seguridad en varias VPC dentro de la región de AWS.
Question 122 of 529
Una empresa ha comprado electrodomésticos de diferentes proveedores. Todos los electrodomésticos cuentan con sensores IoT. Los sensores envían información de estado en los formatos propietarios de los proveedores a una aplicación heredada que analiza la información en JSON. El análisis es simple, pero cada proveedor tiene un formato único. Una vez al día, la aplicación analiza todos los registros JSON y los almacena en una base de datos relacional para su análisis.
La compañía necesita diseñar una nueva solución de análisis de datos que pueda entregar más rápido y optimizar los costos.
Qué solución cumplirá con estos requisitos?
A.
Conecte los sensores de IoT a AWS IoT Core. Establezca una regla para invocar una función de AWS Lambda para analizar la información y guardar un archivo.csv en Amazon. S3 Utilice AWS Glue para catalogar los archivos. Utilice Amazon Athena y Amazon QuickSight para el análisis.
B.
Migre el servidor de aplicaciones a AWS Fargate, que recibirá la información de los sensores de IoT y analizará la información en un formato relacional. Guarde la información analizada en Amazon Redshlft para su análisis.
C.
Cree un servidor AWS Transfer para SFTP. Actualice el código del sensor de IoT para enviar la información como un archivo.csv a través de SFTP al servidor. Utilice AWS Glue para catalogar los archivos. Utilice Amazon Athena para el análisis.
D.
Utilice AWS Snowball Edge para recopilar datos de los sensores de IoT directamente para realizar análisis locales. Recopile periódicamente los datos en Amazon Redshift para realizar análisis globales.
AnswerDiscussion
Correct Answer: A
La solución más efectiva aprovecha AWS IoT Core para conectar los sensores de IoT. Esta configuración permite la recopilación de datos en tiempo real y el procesamiento inmediato. Al invocar una función de AWS Lambda para analizar los datos y guardarlos como un archivo.csv en Amazon S3, la solución garantiza que los datos se manejen de manera eficiente. AWS Glue se puede utilizar para catalogar los archivos, lo que facilita consultas y análisis sin problemas con Amazon Athena y Amazon QuickSight. Esta arquitectura optimiza los costos y ofrece un rápido análisis de datos mediante el uso de servicios escalables y sin servidor de AWS.
Question 123 of 529
Una empresa está migrando algunas de sus aplicaciones a AWS. La compañía quiere migrar y modernizar las aplicaciones rápidamente después de que finalice las estrategias de redes y seguridad. La compañía ha establecido una conexión AWS Direct Connect en una cuenta de red central.
La compañía espera tener cientos de cuentas de AWS y VPC en un futuro próximo. La red corporativa debe poder acceder a los recursos en AWS sin problemas y también debe poder comunicarse con todas las VPC. La compañía también quiere enrutar sus recursos en la nube a Internet a través de su centro de datos local.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Cree una puerta de enlace Direct Connect en la cuenta central. En cada una de las cuentas, cree una propuesta de asociación utilizando la puerta de enlace Direct Connect y el ID de cuenta para cada puerta de enlace privada virtual.
B.
Cree una puerta de enlace Direct Connect y una puerta de enlace de tránsito en la cuenta de red central. Conecte la puerta de enlace de tránsito a la puerta de enlace Direct Connect mediante un VIF de tránsito.
C.
Aprovisionar una puerta de enlace a Internet. Conecte la puerta de enlace de Internet a las subredes. Permitir el tráfico de Internet a través de la puerta de enlace.
D.
Comparta la puerta de enlace de tránsito con otras cuentas. Conecte VPC a la puerta de enlace de tránsito.
E.
Aprovisione el peering de VPC según sea necesario.
F.
Aprovisionar solo subredes privadas. Abra la ruta necesaria en la puerta de enlace de tránsito y la puerta de enlace del cliente para permitir que el tráfico de Internet saliente de AWS fluya a través de los servicios NAT que se ejecutan en el centro de datos.
AnswerDiscussion
Correct Answer: B, D, F
Para cumplir con los requisitos de la compañía de migrar y modernizar las aplicaciones rápidamente, al tiempo que se garantiza un acceso sin interrupciones a los recursos de AWS y la comunicación entre las VPC, y el enrutamiento de los recursos de la nube a Internet a través del centro de datos local, se pueden seguir los siguientes pasos: Crear una puerta de enlace Direct Connect y una puerta de enlace de tránsito en la cuenta de red central. Esto permite conectar el centro de datos local a los recursos de AWS. Comparta la puerta de enlace de tránsito con otras cuentas y adjunte VPC a ella, lo que permite la comunicación entre todas las VPC. Aprovisione solo subredes privadas y configure las rutas necesarias en la puerta de enlace de tránsito y la puerta de enlace del cliente para enrutar el tráfico de Internet saliente desde AWS a través de los servicios NAT en el centro de datos.
Question 124 of 529
Una empresa tiene cientos de cuentas de AWS. La compañía implementó recientemente un proceso interno centralizado para la compra de nuevas Instancias Reservadas y la modificación de las Instancias Reservadas existentes. Este proceso requiere que todas las unidades de negocio que quieran comprar o modificar Instancias reservadas envíen solicitudes a un equipo dedicado para adquisiciones. Anteriormente, las unidades de negocio compraban directamente o modificaban instancias reservadas en sus propias cuentas de AWS de forma autónoma.
Un arquitecto de soluciones necesita hacer cumplir el nuevo proceso de la manera más segura posible.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Asegúrese de que todas las cuentas de AWS formen parte de una organización en AWS Organizations con todas las funciones habilitadas.
B.
Utilice AWS Config para informar sobre el archivo adjunto de una política de IAM que deniegue el acceso a la acción ec2:PurchaseServedInstancesOffering y a la acción EC2:ModifyReservedInances.
C.
En cada cuenta de AWS, cree una política de IAM que deniegue la acción EC2:PurchaseServedInstancesOffering y la acción EC2:ModifyReservedInances.
D.
Cree un SCP que deniegue la acción EC2:PurchaseServedInstancesOffering y la acción EC2:ModifyReservedInstancias. Adjuntar el SCP a cada OU de la organización.
E.
Asegúrese de que todas las cuentas de AWS formen parte de una organización de AWS Organizations que utilice la función de facturación consolidada.
AnswerDiscussion
Correct Answer: A, D
Para hacer cumplir el nuevo proceso de compra centralizado de la manera más segura, el arquitecto de soluciones debe asegurarse de que todas las cuentas de AWS formen parte de una organización en AWS Organizations con todas las funciones habilitadas. Esto centraliza la gestión y el control en todas las cuentas. Después, crear una SCP (Service Control Policy) que niegue las acciones `EC2:PurchaseServedInstancesOffering` y `EC2:ModifyReservedInstances` y adjuntarlo a cada unidad organizativa asegura que todas las unidades de negocio se adhieran al nuevo proceso, impidiendo efectivamente acciones autónomas por unidades individuales.
Question 125 of 529
Una empresa está ejecutando una aplicación crítica que utiliza una base de datos de Amazon RDS para MySQL para almacenar datos. La instancia de base de datos RDS se implementa en modo Multi-AZ.
Una reciente prueba de failover de bases de datos RDS causó una interrupción de 40 segundos en la aplicación. Un arquitecto de soluciones necesita diseñar una solución para reducir el tiempo de interrupción a menos de 20 segundos.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Usar Amazon ElastiCache para Memcached frente a la base de datos
B.
Utilice Amazon ElastiCache para Redis frente a la base de datos
C.
Use RDS Proxy frente a la base de datos.
D.
Migre la base de datos a Amazon Aurora MySQL.
E.
Crea una réplica de Amazon Aurora.
F.
Crear una réplica de lectura de RDS para MySQL
AnswerDiscussion
Correct Answer: C, D, E
Para reducir el tiempo de interrupción a menos de 20 segundos para una aplicación crítica que utilice Amazon RDS para MySQL en modo Multi-AZ, el enfoque más efectivo consiste en: 1) Usar RDS Proxy, que ayuda a administrar y agrupar las conexiones de bases de datos, acelerando el proceso de conmutación por error al redirigir rápidamente el tráfico a la instancia en buen estado; 2) Migrar la base de datos a Amazon Aurora MySQL, que generalmente tiene capacidades de conmutación por error más rápidas en comparación con las instancias RDS estándar; y 3) Crear una réplica de Amazon Aurora, que puede hacerse cargo de la instancia principal mucho más rápidamente que réplicas de lectura MySQL tradicionales debido a su diseño para alta disponibilidad y failover de baja latencia.
Question 126 of 529
Una compañía asociada de AWS está creando un servicio en organizaciones de AWS utilizando su organización llamada org1. Este servicio requiere que la compañía asociada tenga acceso a los recursos de AWS en una cuenta de cliente, que se encuentra en una organización separada llamada org2. La empresa debe establecer el acceso de seguridad de menor privilegio mediante una API o herramienta de línea de comandos a la cuenta del cliente.
Cuál es la forma MÁS segura de permitir que org1 acceda a recursos en org2?
A.
El cliente debe proporcionar a la compañía asociada sus claves de acceso a la cuenta de AWS para iniciar sesión y realizar las tareas requeridas.
B.
El cliente debe crear un usuario de IAM y asignar los permisos requeridos al usuario de IAM. Luego, el cliente debe proporcionar las credenciales a la compañía asociada para iniciar sesión y realizar las tareas requeridas.
C.
El cliente debe crear un rol de IAM y asignar los permisos requeridos al rol de IAM. A continuación, la empresa asociada debe utilizar el nombre de recurso de Amazon (ARN) del rol de IAM al solicitar acceso para realizar las tareas requeridas.
D.
El cliente debe crear un rol de IAM y asignar los permisos requeridos al rol de IAM. A continuación, la empresa asociada debe utilizar el nombre de recurso de Amazon (ARN) del rol de IAM, incluido el ID externo en la política de confianza del rol de IAM, al solicitar acceso para realizar las tareas requeridas.
AnswerDiscussion
Correct Answer: D
La forma más segura de permitir que una empresa asociada de AWS acceda a los recursos de una cuenta de cliente dentro de una organización de AWS separada es utilizar un rol de IAM con los permisos adecuados. El cliente debe crear un rol de IAM y asignar los permisos requeridos al rol de IAM. A continuación, la empresa asociada debe utilizar el nombre de recurso de Amazon (ARN) del rol de IAM, incluido el ID externo en la política de confianza del rol de IAM, al solicitar acceso para realizar las tareas requeridas. Este enfoque asegura que la empresa asociada solo pueda acceder a los recursos que necesita y solo desde la cuenta específica del cliente, minimizando el riesgo de brechas de seguridad.
Question 127 of 529
Una empresa de entrega necesita migrar su aplicación de planificación de rutas de terceros a AWS. El tercero suministra una imagen Docker soportada de un registro público. La imagen puede ejecutarse en tantos contenedores como sea necesario para generar el mapa de ruta.
La compañía ha dividido el área de entrega en secciones con hubs de suministro para que los conductores de reparto recorran la distancia más corta posible desde los hubs hasta los clientes. Para reducir el tiempo necesario para generar mapas de ruta, cada sección utiliza su propio conjunto de contenedores Docker con una configuración personalizada que procesa pedidos solo en el área de la sección.
La compañía necesita la capacidad de asignar recursos de manera rentable en función de la cantidad de contenedores en funcionamiento.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en Amazon EC2. Utilice la CLI de Amazon EKS para lanzar la aplicación de planificación en pods mediante la opción --tags para asignar una etiqueta personalizada al pod.
B.
Cree un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en AWS Fargate. Utilice la CLI de Amazon EKS para lanzar la aplicación de planificación. Utilice la llamada a la API de recursos de etiquetas de AWS CLI para asignar una etiqueta personalizada al pod.
C.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS) en Amazon EC2. Utilice la CLI de AWS con run-tasks establecidas en true para lanzar la aplicación de planificación mediante la opción --tags para asignar una etiqueta personalizada a la tarea.
D.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Utilice el comando run-task de la CLI de AWS y establezca enableECSManagedTags en true para lanzar la aplicación de planificación. Utilice la opción --tags para asignar una etiqueta personalizada a la tarea.
AnswerDiscussion
Correct Answer: D
El uso de Amazon Elastic Container Service (Amazon ECS) con AWS Fargate es la solución óptima para este escenario porque minimiza la sobrecarga operativa. AWS Fargate le permite ejecutar contenedores sin administrar la infraestructura subyacente, lo que hace que sea más fácil y rentable escalar en función del número de contenedores en ejecución. Además, el comando run-task de AWS CLI le permite lanzar la aplicación de planificación con etiquetas administradas de manera efectiva. Esta configuración simplifica la administración de recursos y garantiza una experiencia perfecta en el manejo de múltiples contenedores Docker con una configuración personalizada para cada sección.
Question 128 of 529
Una empresa de software aloja una aplicación en AWS con recursos en varias cuentas y regiones de AWS. La aplicación se ejecuta en un grupo de instancias de Amazon EC2 en una VPC de aplicación ubicada en la región us-east-1 con un bloque CIDR IPv4 de 10.10.0.0/16. En otra cuenta de AWS, una VPC de servicios compartidos se encuentra en la región us-east-2 con un bloque CIDR IPv4 de 10.10.10.0/24. Cuando un ingeniero en la nube usa AWS CloudFormation para intentar unir la VPC de la aplicación con la VPC de servicios compartidos, un mensaje de error indica un error de interconexión.
Qué factores podrían causar este error? (Elija dos.)
A.
Los rangos de CIDR IPv4 de las dos VPC se superponen
B.
Los VPC no están en la misma región
C.
Una o ambas cuentas no tienen acceso a una puerta de enlace de Internet
D.
Una de las VPC no se compartió a través de AWS Resource Access Manager
E.
El rol de IAM en la cuenta de aceptador de pares no tiene los permisos correctos
AnswerDiscussion
Correct Answer: A, E
El error al unir las VPC podría deberse a la superposición de rangos CIDR de IPv4 y permisos de IAM incorrectos. La aplicación VPC utiliza un bloque CIDR de 10.10.0.0/16, y la VPC de servicios compartidos usa un bloque CIDR de 10.10.10.0/24. Estos rangos se superponen ya que 10.10.10.0/24 cae dentro del rango 10.10.0.0/16, lo que puede causar conflictos de enrutamiento. Además, garantizar que el rol de IAM en la cuenta de aceptador de pares tenga los permisos correctos es crucial para que la conexión de interconexión de VPC se establezca con éxito.
Question 129 of 529
Una auditoría externa de la aplicación sin servidor de una empresa revela políticas de IAM que otorgan demasiados permisos. Estas políticas se adjuntan a los roles de ejecución de AWS Lambda de la compañía. Cientos de funciones Lambda de la compañía tienen amplios permisos de acceso, como acceso completo a buckets de Amazon S3 y tablas de Amazon DynamoDB. La empresa quiere que cada función tenga sólo los permisos mínimos que la función necesita para completar su tarea.
Un arquitecto de soluciones debe determinar qué permisos necesita cada función Lambda.
Qué debe hacer el arquitecto de soluciones para cumplir con este requisito con la MENOR cantidad de esfuerzo?
A.
Configure Amazon CodeGuru para perfilar las funciones de Lambda y buscar llamadas a la API de AWS. Crear un inventario de las llamadas API y recursos requeridos para cada función Lambda. Cree nuevas políticas de acceso a IAM para cada función Lambda. Revisar las nuevas políticas para asegurar que cumplan con los requisitos de negocio de la compañía.
B.
Activa el registro de AWS CloudTrail para la cuenta de AWS. Utilice AWS Identity and Access Management Access Analyzer para generar políticas de acceso de IAM basadas en la actividad registrada en el registro de CloudTrail. Revisar las políticas generadas para asegurar que cumplan con los requisitos de negocio de la compañía.
C.
Activa el registro de AWS CloudTrail para la cuenta de AWS. Cree un script para analizar el registro de CloudTrail, busque llamadas a la API de AWS por función de ejecución de Lambda y cree un informe resumido. Revisar el informe. Cree políticas de acceso de IAM que proporcionen permisos más restrictivos para cada función Lambda.
D.
Activa el registro de AWS CloudTrail para la cuenta de AWS. Exporte los registros de CloudTrail a Amazon S3. Utilice Amazon EMR para procesar los registros de CloudTrail en Amazon S3 y producir un informe de las llamadas a la API y los recursos utilizados por cada función de ejecución. Crear una nueva política de acceso a IAM para cada función. Exporte los roles generados a un bucket S3. Revisar las políticas generadas para asegurar que cumplan con los requisitos de negocio de la compañía.
AnswerDiscussion
Correct Answer: B
Para determinar los permisos mínimos necesarios para cada función de Lambda con el mínimo esfuerzo, debe aprovechar los servicios de AWS que analizan y generan políticas automáticamente. Al activar el registro de AWS CloudTrail, puede rastrear y registrar las llamadas a la API realizadas por las funciones de Lambda. AWS Identity and Access Management (IAM) Access Analyzer puede usar estos datos de registro para generar automáticamente políticas basadas en el uso real, asegurando que cada función tenga solo los permisos que necesita. Este método reduce el esfuerzo manual que implica analizar y crear políticas, convirtiéndola en la solución más eficiente.
Question 130 of 529
Un arquitecto de soluciones debe analizar las instancias de Amazon EC2 de una empresa y los volúmenes de Amazon Elastic Block Store (Amazon EBS) para determinar si la empresa está utilizando los recursos de manera eficiente. La compañía está ejecutando varias instancias EC2 grandes y de alta memoria para alojar clústeres de bases de datos que se implementan en configuraciones activas/pasivas. La utilización de estas instancias EC2 varía según las aplicaciones que utilizan las bases de datos, y la compañía no ha identificado un patrón.
El arquitecto de soluciones debe analizar el entorno y tomar medidas con base en los hallazgos.
Qué solución cumple con estos requisitos de manera más rentable?
A.
Cree un panel mediante AWS Systems Manager OpsCenter. Configure visualizaciones para las métricas de Amazon CloudWatch asociadas con las instancias EC2 y sus volúmenes de EBS. Revise el tablero periódicamente e identifique los patrones de uso. Tamaño correcto de las instancias EC2 en función de los picos en las métricas.
B.
Active la supervisión detallada de Amazon CloudWatch para las instancias EC2 y sus volúmenes de EBS. Crear y revisar un panel basado en las métricas. Identificar patrones de uso. Tamaño correcto de las instancias EC2 en función de los picos en las métricas.
C.
Instale el agente de Amazon CloudWatch en cada una de las instancias EC2. Encienda AWS Compute Optimizer y déjelo funcionar durante al menos 12 horas. Revise las recomendaciones de Compute Optimizer y dimensiona correctamente las instancias de EC2 según las indicaciones.
D.
Inscríbase en el plan AWS Enterprise Support. Activa AWS Trusted Advisor. Espera 12 horas. Revise las recomendaciones de Trusted Advisor y ajuste el tamaño correcto de las instancias EC2 según las indicaciones.
AnswerDiscussion
Correct Answer: C
La solución más rentable para analizar las instancias de Amazon EC2 de la compañía y los volúmenes de Amazon EBS es instalar el agente de Amazon CloudWatch en cada una de las instancias EC2, activar AWS Compute Optimizer y dejar que se ejecute durante al menos 12 horas. AWS Compute Optimizer aprovecha los algoritmos de aprendizaje automático para generar recomendaciones para dimensionar correctamente las instancias EC2 en función del uso de recursos. Este enfoque es simplificado, eficiente y permite una utilización optimizada de los recursos sin la necesidad de un amplio monitoreo manual o planes de soporte, lo que lo convierte en la opción más rentable.
Question 131 of 529
Una empresa utiliza AWS Organizations para una configuración multicuenta en la nube de AWS. La compañía utiliza AWS Control Tower para la gobernanza y utiliza AWS Transit Gateway para la conectividad de VPC en todas las cuentas.
En una cuenta de aplicaciones de AWS, el equipo de aplicaciones de la compañía ha implementado una aplicación web que utiliza AWS Lambda y Amazon RDS. Los administradores de bases de datos de la compañía tienen una cuenta DBA separada y utilizan la cuenta para administrar centralmente todas las bases de datos en toda la organización. Los administradores de la base de datos utilizan una instancia de Amazon EC2 que se implementa en la cuenta de DBA para acceder a una base de datos RDS que se implementa en la cuenta de la aplicación.
El equipo de aplicaciones ha almacenado las credenciales de la base de datos como secretos en AWS Secrets Manager en la cuenta de la aplicación. El equipo de aplicaciones está compartiendo manualmente los secretos con los administradores de la base de datos. Los secretos están encriptados por la clave administrada por AWS predeterminada para Secrets Manager en la cuenta de la aplicación. Un arquitecto de soluciones necesita implementar una solución que brinde a los administradores de bases de datos acceso a la base de datos y elimine la necesidad de compartir manualmente los secretos.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS Resource Access Manager (AWS RAM) para compartir los secretos de la cuenta de la aplicación con la cuenta de DBA. En la cuenta de DBA, cree un rol de IAM denominado DBA-Admin. Otorgar al rol los permisos necesarios para acceder a los secretos compartidos. Adjunte el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.
B.
En la cuenta de la aplicación, cree un rol de IAM que se llame DBA-Secret. Otorgar al rol los permisos necesarios para acceder a los secretos. En la cuenta de DBA, cree un rol de IAM denominado DBA-Admin. Otorgue al rol de administrador de DBA los permisos necesarios para asumir el rol de DBA secreto en la cuenta de la aplicación. Adjuntar el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas
C.
En la cuenta de DBA, cree un rol de IAM que se llame DBA-Admin. Otorgue al rol los permisos necesarios para acceder a los secretos y a la clave administrada por defecto de AWS en la cuenta de la aplicación. En la cuenta de la aplicación, adjunte políticas basadas en recursos a la clave para permitir el acceso desde la cuenta de DBA. Adjunte el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.
D.
En la cuenta de DBA, cree un rol de IAM denominado DBA-Admin. Otorgar al rol los permisos necesarios para acceder a los secretos en la cuenta de la aplicación. Adjunte un SCP a la cuenta de la aplicación para permitir el acceso a los secretos de la cuenta DBA. Adjunte el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.
AnswerDiscussion
Correct Answer: B
Para cumplir con el requisito de eliminar el intercambio manual de secretos y permitir que los administradores de bases de datos accedan a la base de datos, la solución implica crear roles de IAM que faciliten el acceso seguro a través de las cuentas. En la cuenta de la aplicación, se crea un rol de IAM denominado DBA-Secret con permisos para acceder a los secretos. En la cuenta de DBA, se crea un rol de IAM denominado DBA-Admin con permisos para asumir el rol de DBA secreto en la cuenta de la aplicación. Al asociar la función DBA-Admin a la instancia EC2, los administradores pueden acceder a los secretos de forma segura sin compartirlos manualmente, lo que garantiza que el acceso entre cuentas se administre correctamente.
Question 132 of 529
Una empresa administra varias cuentas de AWS mediante AWS Organizations. Bajo la OU raíz, la compañía tiene dos OU: Investigación y DataOps.
Debido a los requisitos regulatorios, todos los recursos que la compañía despliega en la organización deben residir en la Región ap-Northeast-1. Además, las instancias EC2 que la compañía implementa en la unidad organizativa de DataOps deben usar una lista predefinida de tipos de instancias.
Un arquitecto de soluciones debe implementar una solución que aplique estas restricciones. La solución debe maximizar la eficiencia operativa y minimizar el mantenimiento continuo.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Cree un rol de IAM en una cuenta bajo la OU de DataOps. Utilice la clave de condición ec2:InstanceType en una política en línea en el rol para restringir el acceso a un tipo de instancia específico.
B.
Cree un usuario de IAM en todas las cuentas bajo la unidad organizativa raíz. Utilice la clave de condición aws:RequestedRegion en una política en línea en cada usuario para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1.
C.
Crear un SCP. Utilice la clave de condición aws:RequestedRegion para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1. Aplicar el SCP a la unidad OU raíz.
D.
Crear un SCP. Utilice la clave de condición EC2:Region para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1. Aplicar el SCP a la unidad organizativa raíz, la unidad organizativa DataOps y la unidad organizativa de investigación.
E.
Crear un SCP. Utilice la clave de condición ec2:InstanceType para restringir el acceso a tipos de instancia específicos. Aplicar el SCP a la unidad OU de DataOps.
AnswerDiscussion
Correct Answer: C, E
Para cumplir con los requisitos reglamentarios y garantizar que la solución maximice la eficiencia operativa y minimice el mantenimiento continuo, se deben tomar los siguientes pasos. Primero, cree una Política de control de servicios (SCP) utilizando la clave de condición AWS:RequestedRegion para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1 y aplicar este SCP a la Unidad Organizacional (OU) raíz. Esto garantiza que todos los recursos desplegados en la organización residan en la región ap-northeast-1. En segundo lugar, cree otro SCP usando la clave de condición EC2:InstanceType para restringir el acceso a tipos de instancias EC2 específicos y aplicar esta política a la unidad organizativa DataOps. Esto garantiza que las instancias EC2 en la unidad organizativa de DataOps utilicen solo la lista predefinida de tipos de instancias. Estos pasos hacen cumplir efectivamente las restricciones requeridas mientras minimizan el mantenimiento.
Question 133 of 529
Una empresa ejecuta una aplicación sin servidor en una sola región de AWS. La aplicación accede a URL externas y extrae metadatos de esos sitios. La compañía utiliza un tema Amazon Simple Notification Service (Amazon SNS) para publicar URL en una cola de Amazon Simple Queue Service (Amazon SQS). Una función de AWS Lambda utiliza la cola como fuente de eventos y procesa las URL de la cola. Los resultados se guardan en un bucket de Amazon S3.
La compañía quiere procesar cada URL en otras Regiones para comparar posibles diferencias en la localización del sitio. Las URL deben ser publicadas desde la Región existente. Los resultados deben escribirse en el bucket S3 existente en la Región actual.
Qué combinación de cambios producirá una implementación multiregional que cumpla con estos requisitos? (Elija dos.)
A.
Despliegue la cola SQS con la función Lambda en otras regiones.
B.
Suscríbase el tema SNS en cada Región a la cola SQS.
C.
Suscríbase la cola SQS en cada Región al tema SNS.
D.
Configure la cola SQS para publicar URL en temas de SNS en cada región.
E.
Desplegar el tema SNS y la función Lambda en otras regiones.
AnswerDiscussion
Correct Answer: A, C
Para lograr la implementación en varias regiones, se deben realizar dos cambios clave. En primer lugar, es esencial desplegar la cola SQS con la función Lambda a otras regiones. Esto permite que el procesamiento de URL se produzca en otras regiones, lo que permite comparar las diferencias de localización del sitio. En segundo lugar, suscribir la cola SQS en cada Región al tema SNS asegura que las URL publicadas desde la Región existente puedan procesarse en todas las demás Regiones. Esta integración cumple con los requisitos de procesar URL en varias regiones mientras publica los resultados en un solo bucket S3 en la región actual.
Question 134 of 529
Una empresa ejecuta una aplicación ETL sin estado patentada en instancias de Linux de Amazon EC2. La aplicación es un binario de Linux, y el código fuente no se puede modificar. La aplicación es de un solo subproceso, utiliza 2 GB de RAM y consume mucha CPU. La aplicación está programada para ejecutarse cada 4 horas y se ejecuta hasta por 20 minutos. Un arquitecto de soluciones quiere revisar la arquitectura para la solución.
Qué estrategia debe utilizar el arquitecto de soluciones?
A.
Utilice AWS Lambda para ejecutar la aplicación. Utilice Amazon CloudWatch Logs para invocar la función Lambda cada 4 horas.
B.
Utilice AWS Batch para ejecutar la aplicación. Utilice una máquina de estado AWS Step Functions para invocar el trabajo por lotes de AWS cada 4 horas.
C.
Utilice AWS Fargate para ejecutar la aplicación. Utilice Amazon EventBridge (Amazon CloudWatch Events) para invocar la tarea de Fargate cada 4 horas.
D.
Utilice instancias puntuales de Amazon EC2 para ejecutar la aplicación. Utilice AWS CodeDeploy para implementar y ejecutar la aplicación cada 4 horas.
AnswerDiscussion
Correct Answer: C
Para una aplicación ETL altamente intensiva de CPU, de un solo subproceso y sin estado que se ejecuta cada 4 horas durante hasta 20 minutos, AWS Fargate es una opción ideal. AWS Fargate es adecuado para aplicaciones contenerizadas, lo que elimina la necesidad de administrar la infraestructura de servidores subyacente. Puede manejar de manera eficiente tareas intensivas en CPU dentro de un entorno contenerizado. Amazon EventBridge (anteriormente Amazon CloudWatch Events) es ideal para programar tareas a intervalos fijos, como cada 4 horas. Esta combinación garantiza una solución escalable, rentable y administrada donde la aplicación se ejecuta en un modo sin servidor, incurriendo en costos solo cuando la tarea está activa.
Question 135 of 529
Una compañía está creando una secuela de un popular juego en línea. Un gran número de usuarios de todo el mundo jugarán el juego dentro de la primera semana después del lanzamiento. Actualmente, el juego consta de los siguientes componentes desplegados en una sola región de AWS:
• Bucket de Amazon S3 que almacena activos del juego
• Tabla de Amazon DynamoDB que almacena las puntuaciones de los jugadores
Un arquitecto de soluciones necesita diseñar una solución multi-región que reduzca la latencia, mejore la confiabilidad y requiera el menor esfuerzo para implementarla.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una distribución de Amazon CloudFront para servir activos desde el bucket de S3. Configure la replicación entre regiones S3. Cree una nueva tabla de DynamoDB en una nueva región. Utilice la nueva tabla como destino de réplica para tablas globales de DynamoDB.
B.
Cree una distribución de Amazon CloudFront para servir activos desde el bucket de S3. Configure la replicación de S3 en la misma región. Cree una nueva tabla de DynamoDB en una nueva región. Configure la replicación asincrónica entre las tablas de DynamoDB mediante AWS Database Migration Service (AWS DMS) con captura de datos de cambio (CDC).
C.
Cree otro bucket S3 en una nueva región y configure S3 Cross-Region Replication entre los buckets. Cree una distribución de Amazon CloudFront y configure la conmutación por error de origen con dos orígenes que accedan a los buckets de S3 en cada región. Configure tablas globales de DynamoDB habilitando Amazon DynamoDB streams y agregue una tabla de réplica en una nueva región.
D.
Cree otro bucket S3 en la región sinusoidal y configure la replicación S3 de la misma región entre los buckets. Cree una distribución de Amazon CloudFront y configure la conmutación por error de origen con dos orígenes que accedan a los buckets de S3. Cree una nueva tabla de DynamoDB en una nueva región. Utilice la nueva tabla como destino de réplica para tablas globales de DynamoDB.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos de reducir la latencia, mejorar la confiabilidad y requerir el menor esfuerzo, la mejor solución es crear una distribución de Amazon CloudFront para servir activos desde el bucket S3. CloudFront almacenará en caché el contenido en ubicaciones de borde a nivel global, reduciendo la latencia para los usuarios. Además, la configuración de S3 Cross-Region Replication asegurará que los activos del juego se almacenen en varias regiones, mejorando la confiabilidad. Para el componente DynamoDB, el uso de tablas globales de DynamoDB y la configuración de una nueva tabla en una nueva región como destino de réplica aprovecha la funcionalidad integrada para la replicación de datos en varias regiones, lo que reduce la complejidad y el esfuerzo de configuración. Esta configuración aborda los objetivos clave de manera efectiva sin agregar complejidades innecesarias.
Question 136 of 529
Una compañía tiene una aplicación de sitio web local que proporciona información de bienes raíces para posibles inquilinos y compradores. El sitio web utiliza un backend Java y una base de datos NoSQL MongoDB para almacenar datos de suscriptores.
La compañía necesita migrar toda la aplicación a AWS con una estructura similar. La aplicación debe implementarse para una alta disponibilidad, y la empresa no puede realizar cambios en la aplicación.
Qué solución cumplirá con estos requisitos?
A.
Utilice un clúster de base de datos de Amazon Aurora como base de datos para los datos del suscriptor. Implemente instancias de Amazon EC2 en un grupo de Auto Scaling en varias zonas de disponibilidad para la aplicación backend Java.
B.
Utilice MongoDB en instancias de Amazon EC2 como base de datos para los datos del suscriptor. Implemente instancias EC2 en un grupo de Auto Scaling en una única zona de disponibilidad para la aplicación backend Java.
C.
Configure Amazon DocumentDB (con compatibilidad con MongoDB) con instancias del tamaño adecuado en varias zonas de disponibilidad como base de datos para los datos del suscriptor. Implemente instancias de Amazon EC2 en un grupo de Auto Scaling en varias zonas de disponibilidad para la aplicación backend Java.
D.
Configure Amazon DocumentDB (con compatibilidad con MongoDB) en modo de capacidad bajo demanda en varias zonas de disponibilidad como base de datos para los datos del suscriptor. Implemente instancias de Amazon EC2 en un grupo de Auto Scaling en varias zonas de disponibilidad para la aplicación backend Java.
AnswerDiscussion
Correct Answer: C
La compañía necesita migrar su backend Java y su base de datos MongoDB a AWS sin realizar ningún cambio en la aplicación. Amazon DocumentDB (con compatibilidad con MongoDB) está diseñado específicamente para ser compatible con MongoDB, lo que lo convierte en una opción adecuada para los datos del suscriptor sin necesidad de ningún cambio de aplicación. Al implementar Amazon DocumentDB con instancias del tamaño adecuado en varias zonas de disponibilidad, la compañía garantiza una alta disponibilidad. Para la aplicación backend Java, la implementación de instancias de Amazon EC2 en un grupo de Auto Scaling en varias zonas de disponibilidad también proporcionará alta disponibilidad y escalabilidad. Esta configuración cumple con todos los requisitos especificados por la empresa.
Question 137 of 529
Una empresa de marketing digital tiene múltiples cuentas de AWS que pertenecen a varios equipos. El equipo creativo utiliza un bucket de Amazon S3 en su cuenta de AWS para almacenar de forma segura imágenes y archivos multimedia que se utilizan como contenido para las campañas de marketing de la compañía. El equipo creativo quiere compartir el bucket S3 con el equipo de estrategia para que el equipo de estrategia pueda ver los objetos.
Un arquitecto de soluciones ha creado un rol de IAM que se denomina strategy_revisor en la cuenta Strategy. El arquitecto de soluciones también ha configurado una clave personalizada de AWS Key Management Service (AWS KMS) en la cuenta Creative y ha asociado la clave con el bucket S3. Sin embargo, cuando los usuarios de la cuenta Strategy asumen el rol de IAM e intentan acceder a objetos en el bucket S3, reciben un error Acceso denegado.
El arquitecto de soluciones debe asegurarse de que los usuarios de la cuenta Strategy puedan acceder al bucket S3. La solución debe proporcionar a estos usuarios sólo los permisos mínimos que necesitan.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Cree una política de bucket que incluya permisos de lectura para el bucket S3. Establezca el principal de la política de bucket en el ID de cuenta de la cuenta Strategy.
B.
Actualice el rol de IAM strategy_reviewer para otorgar permisos completos para el bucket S3 y para otorgar permisos de descifrado para la clave KMS personalizada.
C.
Actualice la política de claves KMS personalizada en la cuenta de Creative para otorgar permisos de descifrado al rol de IAM strategy_revisor.
D.
Cree una política de bucket que incluya permisos de lectura para el bucket S3. Establezca el principio de la política de bucket a un usuario anónimo.
E.
Actualice la política de claves KMS personalizada en la cuenta de Creative para otorgar permisos de cifrado al rol de IAM strategy_reviewer.
F.
Actualice el rol de IAM strategy_reviewer para otorgar permisos de lectura para el bucket S3 y para otorgar permisos de descifrado para la clave KMS personalizada.
AnswerDiscussion
Correct Answer: A, C, F
Para permitir que el equipo de Strategy acceda a los objetos del bucket S3, el arquitecto de soluciones debe seguir los siguientes pasos: 1) Crear una política de bucket que incluya permisos de lectura para el bucket S3 y establecer el principal de la política de bucket en el ID de cuenta de la cuenta Strategy. Esto garantiza que la cuenta Strategy tenga el acceso necesario al bucket S3. 2) Actualice la política de claves KMS personalizada en la cuenta Creative para otorgar permisos de descifrado al rol de IAM strategy_reviewer. Esto permite al equipo de Strategy descifrar los objetos en el bucket S3. 3) Actualizar el rol strategy_reviewer IAM para otorgar permisos de lectura para el bucket S3 y descifrar permisos para la clave KMS personalizada, lo que le da al equipo de Estrategia los permisos necesarios para leer y descifrar los objetos. Estas acciones proporcionan los permisos mínimos necesarios sin otorgar acceso excesivo.
Question 138 of 529
Una empresa de ciencias de la vida está utilizando una combinación de herramientas de código abierto para administrar flujos de trabajo de análisis de datos y contenedores Docker que se ejecutan en servidores en su centro de datos local para procesar datos genómicos. Los datos de secuenciación se generan y almacenan en una red de área de almacenamiento local (SAN), y luego se procesan los datos. Los equipos de investigación y desarrollo se encuentran con problemas de capacidad y han decidido rediseñar su plataforma de análisis genómico en AWS para escalar en función de las demandas de carga de trabajo y reducir el tiempo de respuesta de semanas a días.
La compañía cuenta con una conexión AWS Direct Connect de alta velocidad. Los secuenciadores generarán alrededor de 200 GB de datos para cada genoma, y los trabajos individuales pueden tardar varias horas en procesar los datos con la capacidad de cómputo ideal. El resultado final se almacenará en Amazon S3. La empresa está esperando 10-15 solicitudes de empleo cada día.
Qué solución cumple con estos requisitos?
A.
Utilice los dispositivos AWS Snowball Edge programados regularmente para transferir los datos de secuenciación a AWS. Cuando AWS recibe el dispositivo Snowball Edge y los datos se cargan en Amazon S3, utilice eventos S3 para activar una función de AWS Lambda para procesar los datos.
B.
Utilice AWS Data Pipeline para transferir los datos de secuenciación a Amazon S3. Utilice eventos S3 para activar un grupo de Amazon EC2 Auto Scaling para lanzar instancias EC2 de AMI personalizadas que ejecuten los contenedores Docker para procesar los datos.
C.
Utilice AWS DataSync para transferir los datos de secuenciación a Amazon S3. Utilice eventos S3 para activar una función de AWS Lambda que inicie un flujo de trabajo de AWS Step Functions. Almacene las imágenes de Docker en Amazon Elastic Container Registry (Amazon ECR) y active AWS Batch para ejecutar el contenedor y procesar los datos de secuenciación.
D.
Utilice una puerta de enlace de archivos de AWS Storage Gateway para transferir los datos de secuenciación a Amazon S3. Utilice eventos S3 para activar un trabajo por lotes de AWS que se ejecute en instancias de Amazon EC2 que ejecutan los contenedores Docker para procesar los datos.
ResponderDiscusión
Correct Answer: C
La mejor solución aprovecha AWS DataSync para transferir los datos de secuenciación a Amazon S3. DataSync está diseñado para una transferencia de datos rápida y segura desde el almacenamiento local a AWS. El uso de eventos S3 para activar una función de AWS Lambda que inicia un flujo de trabajo de AWS Step Functions proporciona una canalización de procesamiento de datos escalable y automatizada. Las imágenes de Docker almacenadas en Amazon Elastic Container Registry (Amazon ECR) pueden ser activadas por AWS Batch para ejecutar contenedores y procesar los datos de secuenciación, manejando de manera eficiente la capacidad informática y la programación de trabajos requeridos. Este enfoque garantiza una integración perfecta, escalabilidad y tiempos de procesamiento reducidos.
Question 139 of 529
Una empresa ejecuta una aplicación de administración de contenido en una sola instancia de Windows Amazon EC2 en un entorno de desarrollo. La aplicación lee y escribe contenido estático en un volumen de Amazon Elastic Block Store (Amazon EBS) de 2 TB que se adjunta a la instancia como dispositivo raíz. La compañía planea implementar esta aplicación en producción como una solución de alta disponibilidad y tolerante a fallas que se ejecuta en al menos tres instancias EC2 en múltiples zonas de disponibilidad.
Un arquitecto de soluciones debe diseñar una solución que une todas las instancias que ejecutan la aplicación a un dominio de Active Directory. La solución también debe implementar ACL de Windows para controlar el acceso al contenido del archivo. La aplicación siempre debe mantener exactamente el mismo contenido en todas las instancias en ejecución en cualquier momento dado.
Qué solución cumplirá estos requisitos con la menor sobrecarga de administración?
A.
Cree un recurso compartido de archivos de Amazon Elastic File System (Amazon EFS). Cree un grupo de Auto Scaling que se extienda a través de tres zonas de disponibilidad y mantenga un tamaño mínimo de tres instancias. Implemente un script de datos de usuario para instalar la aplicación, unir la instancia al dominio AD y montar el recurso compartido de archivos EFS.
B.
Cree una nueva AMI a partir de la instancia EC2 actual que se esté ejecutando. Cree un sistema de archivos Amazon FSx for Lustre. Cree un grupo de Auto Scaling que se extienda a través de tres zonas de disponibilidad y mantenga un tamaño mínimo de tres instancias. Implemente un script de datos de usuario para unir la instancia al dominio AD y montar el sistema de archivos FSx for Lustre.
C.
Cree un sistema de archivos Amazon FSx para Windows File Server. Cree un grupo de Auto Scaling que se extienda a través de tres zonas de disponibilidad y mantenga un tamaño mínimo de tres instancias. Implementar un script de datos de usuario para instalar la aplicación y montar el sistema de archivos FSx para Windows File Server. Realice una unión de dominio sin fisuras para unir la instancia al dominio AD.
D.
Cree una nueva AMI a partir de la instancia EC2 actual que se esté ejecutando. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Cree un grupo de Auto Scaling que se extienda a través de tres zonas de disponibilidad y mantenga un tamaño mínimo de tres instancias. Realice una unión de dominio sin fisuras para unir la instancia al dominio AD.
ResponderDiscusión
Correct Answer: C
Para lograr una alta disponibilidad y tolerancia a fallas, al tiempo que se garantiza el mismo contenido en todas las instancias en ejecución en un entorno Windows, la solución óptima es usar Amazon FSx para Windows File Server. Este servicio está diseñado específicamente para cargas de trabajo basadas en Windows y es compatible con las Listas de Control de Acceso (ACL) de Windows, que son esenciales para controlar el acceso al contenido de los archivos. También se integra a la perfección con Active Directory para operaciones de unión a dominios. El uso de un grupo de Auto Scaling en varias zonas de disponibilidad garantiza que el sistema esté altamente disponible. Por lo tanto, la creación de un FSx para Windows File Server, la configuración de un grupo de Auto Scaling, el uso de datos de usuario para la instalación de la aplicación y la realización de una unión de dominio perfecta cumple con todos los requisitos dados con una sobrecarga de administración mínima.
Question 140 of 529
Una empresa basada en software como servicio (SaaS) proporciona una solución de administración de casos a los clientes A3 parte de la solución. La compañía utiliza un servidor de Protocolo Simple de Transferencia de Correo (SMTP) independiente para enviar mensajes de correo electrónico desde una aplicación. La aplicación también almacena una plantilla de correo electrónico para mensajes de correo electrónico de acuse de recibo que llenan los datos del cliente antes de que la aplicación envíe el mensaje de correo electrónico al cliente.
La compañía planea migrar esta funcionalidad de mensajería a la nube de AWS y necesita minimizar la sobrecarga operativa.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Configure un servidor SMTP en instancias de Amazon EC2 mediante una AMI de AWS Marketplace. Almacene la plantilla de correo electrónico en un bucket de Amazon S3. Cree una función de AWS Lambda para recuperar la plantilla del bucket S3 y fusionar los datos del cliente de la aplicación con la plantilla. Utilice un SDK en la función Lambda para enviar el mensaje de correo electrónico.
B.
Configure Amazon Simple Email Service (Amazon SES) para enviar mensajes de correo electrónico. Almacene la plantilla de correo electrónico en un bucket de Amazon S3. Cree una función de AWS Lambda para recuperar la plantilla del bucket S3 y fusionar los datos del cliente de la aplicación con la plantilla. Utilice un SDK en la función Lambda para enviar el mensaje de correo electrónico.
C.
Configure un servidor SMTP en instancias de Amazon EC2 mediante una AMI de AWS Marketplace. Almacene la plantilla de correo electrónico en Amazon Simple Email Service (Amazon SES) con parámetros para los datos del cliente. Cree una función de AWS Lambda para llamar a la plantilla de SES y pasar los datos del cliente para reemplazar los parámetros. Utilice el servidor SMTP de AWS Marketplace para enviar el mensaje de correo electrónico.
D.
Configure Amazon Simple Email Service (Amazon SES) para enviar mensajes de correo electrónico. Almacene la plantilla de correo electrónico en Amazon SES con parámetros para los datos del cliente. Cree una función de AWS Lambda para llamar a la operación de la API SendTemplateDemail y pasar los datos del cliente para reemplazar los parámetros y el destino del correo electrónico.
ResponderDiscusión
Correct Answer: D
La solución más rentable para migrar la funcionalidad de mensajería a la nube de AWS y minimizar la sobrecarga operativa es usar Amazon Simple Email Service (Amazon SES) para enviar mensajes de correo electrónico. Al almacenar la plantilla de correo electrónico en Amazon SES con parámetros para los datos del cliente y usar una función de AWS Lambda para llamar a la operación de la API SendTemplateDemaile, pasando los datos del cliente para reemplazar los parámetros y el destino del correo electrónico, la empresa puede aprovechar un servicio completamente administrado. Esto elimina la necesidad de configurar y administrar un servidor SMTP en instancias EC2, lo que puede ser costoso y requerir más mantenimiento.
Question 141 of 529
Una empresa está procesando videos en la nube de AWS mediante el uso de instancias de Amazon EC2 en un grupo de Auto Scaling. Se necesitan 30 minutos para procesar un video Varias instancias EC2 se escalan dentro y fuera dependiendo de la cantidad de videos en una cola de Amazon Simple Queue Service (Amazon SQS).
La compañía ha configurado la cola SQS con una política de redrive que especifica una cola de destino de letra muerta y un MaxReceiveCount de 1. La compañía ha establecido el tiempo de espera de visibilidad para la cola SQS en 1 hora. La compañía ha configurado una alarma de Amazon CloudWatch para notificar al equipo de desarrollo cuando hay mensajes en la cola de letra muerta.
Varias veces durante el día. el equipo de desarrollo recibe notificación de que los mensajes están en la cola de letra muerta y que los videos no han sido procesados propiedad. Una investigación no encuentra errores en los registros de la aplicación.
Cómo puede la empresa resolver este problema?
A.
Encienda la protección de terminación para las instancias EC2
B.
Actualizar el tiempo de espera de visibilidad para la cola SQS a 3 horas
C.
Configurar la protección escalable para las instancias durante el procesamiento
D.
Actualice la política de reconducción y establezca MaxReceiveCount en 0.
ResponderDiscusión
Correct Answer: C
La compañía puede resolver el problema configurando la protección escalable para las instancias durante el procesamiento. Esto asegurará que las instancias no se terminen mientras están procesando videos. La terminación de instancias en medio del procesamiento puede resultar en un trabajo incompleto y hacer que los mensajes se muevan a la cola de letra muerta. Al proteger las instancias de la terminación durante el procesamiento, la compañía puede evitar estas interrupciones y garantizar que los videos se procesen correctamente. Opciones como activar la protección de terminación para todas las instancias o cambiar la política de retransmisión no abordarán la causa raíz del problema, que es la terminación prematura de las instancias durante el procesamiento.
Question 142 of 529
Una compañía ha desarrollado API que utilizan Amazon API Gateway con endpoints regionales. Las API llaman a las funciones de AWS Lambda que utilizan mecanismos de autenticación de API Gateway. Después de una revisión de diseño, un arquitecto de soluciones identifica un conjunto de APIs que no requieren acceso público.
El arquitecto de soluciones debe diseñar una solución para que el conjunto de APIs sea accesible solo desde una VPC. Todas las API deben ser llamadas con un usuario autenticado
Qué solución cumplirá estos requisitos con la MENOR cantidad de esfuerzo?
A.
Cree un balanceador de carga de aplicaciones (ALB) interno. Crear un grupo objetivo. Seleccione la función Lambda para llamar. Utilice el nombre DNS de ALB para llamar a la API desde la VPC.
B.
Elimine la entrada DNS que está asociada con la API en API Gateway. Crea una zona alojada en Amazon Route 53. Crear un registro CNAME en la zona alojada. Actualice la API en API Gateway con el registro CNAME. Utilice el registro CNAME para llamar a la API desde la VPC.
C.
Actualice el punto final de API de Regional a privado en API Gateway. Crear un punto final de VPC de interfaz en la VPCrear una política de recursos y adjuntarla a la API. Utilice el punto final de VPC para llamar a la API desde la VPC.
D.
Implemente las funciones Lambda dentro de la VPC Aprovisione una instancia EC2 e instale un servidor Apache. Desde el servidor Apache, llame a las funciones Lambda. Utilice el registro CNAME interno de la instancia EC2 para llamar a la API desde la VPC.
ResponderDiscusión
Correct Answer: C
Para que un conjunto de API sea accesible solo desde una VPC con el menor esfuerzo, el mejor enfoque es actualizar el punto final de API de Regional a privado en API Gateway. A continuación, cree un punto final de VPC de interfaz en la VPC y adjunte una política de recursos a la API. Esto garantiza que las API sean accesibles solo desde la VPC, aprovechando los endpoints de VPC sin necesidad de infraestructura adicional como equilibradores de carga o instancias EC2. Este método es más eficiente y sencillo para restringir el acceso mientras se mantiene la autenticación y la seguridad necesarias.
Question 143 of 529
Un servicio meteorológico proporciona mapas meteorológicos de alta resolución desde una aplicación web alojada en AWS en la región eu-west-1. Los mapas meteorológicos se actualizan con frecuencia y se almacenan en Amazon S3 junto con contenido HTML estático. La aplicación web está liderada por Amazon CloudFront.
La compañía se expandió recientemente para atender a los usuarios de la región us-este-1, y estos nuevos usuarios informan que ver sus respectivos mapas meteorológicos es lento de vez en cuando.
Qué combinación de pasos resolverá los problemas de rendimiento us-east-1? (Elija dos.)
A.
Configure el endpoint de AWS Global Accelerator para el bucket S3 en eu-west-1. Configure grupos de terminales para los puertos TCP 80 y 443 en us-east-1.
B.
Cree un nuevo bucket S3 en us-east-1. Configure la replicación entre regiones de S3 para sincronizar desde el bucket S3 en eu-west-1.
C.
Utilice Lambda @Edge para modificar solicitudes de Norteamérica para usar el punto final S3 Transfer Acceleration en us-east-1.
D.
Utilice Lambda @Edge para modificar solicitudes de Norteamérica para usar el bucket S3 en us-east-1.
E.
Configure el endpoint de AWS Global Accelerator para us-east-1 como origen en la distribución de CloudFront. Utilice Lambda @Edge para modificar solicitudes de Norteamérica para utilizar el nuevo origen.
ResponderDiscusión
Correct Answer: B, D
Para resolver los problemas de rendimiento de los usuarios en us-east-1, crear un nuevo bucket S3 en us-east-1 y configurar la replicación entre regiones para sincronizarla con el bucket S3 en eu-west-1 ayuda a entregar el contenido desde una ubicación geográficamente más cercana, reduciendo así la latencia. Además, el uso de Lambda @Edge para modificar las solicitudes de Norteamérica para usar el bucket S3 en us-east-1 garantiza que las solicitudes se dirijan al bucket apropiado en función de la región del usuario, mejorando aún más el rendimiento al minimizar el tiempo de recuperación.
Question 144 of 529
Un arquitecto de soluciones está investigando un problema en el que una empresa no puede establecer nuevas sesiones en Amazon Workspaces. Un análisis inicial indica que el problema involucra perfiles de usuario. El entorno de Amazon Workspaces está configurado para utilizar Amazon FSx para Windows File Server como almacenamiento compartido de perfiles. El sistema de archivos FSx para Windows File Server está configurado con 10 TB de almacenamiento.
El arquitecto de soluciones descubre que el file system ha alcanzado su máxima capacidad. El arquitecto de soluciones debe asegurarse de que los usuarios puedan recuperar el acceso. La solución también debe evitar que el problema vuelva a ocurrir.
Qué solución cumplirá con estos requisitos?
A.
Eliminar perfiles de usuario antiguos para crear espacio. Migre los perfiles de usuario a un sistema de archivos Amazon FSx for Lustre.
B.
Aumente la capacidad mediante el comando update-file-system. Implemente una métrica de Amazon CloudWatch que supervise el espacio libre. Utilice Amazon EventBridge para invocar una función de AWS Lambda para aumentar la capacidad según sea necesario.
C.
Supervise el sistema de archivos mediante la métrica FreeStorage Capacity en Amazon CloudWatch. Utilice AWS Step Functions para aumentar la capacidad según sea necesario.
D.
Eliminar perfiles de usuario antiguos para crear espacio. Cree un sistema de archivos FSx adicional para Windows File Server. Actualizar la redirección del perfil de usuario para que el 50% de los usuarios utilicen el nuevo sistema de archivos.
ResponderDiscusión
Correct Answer: B
Para abordar el problema de que el sistema de archivos alcance su capacidad máxima y evitar que vuelva a ocurrir, la mejor solución es aumentar la capacidad del sistema de archivos y configurar el monitoreo y el escalado automático. Mediante el uso del comando update-file-system, se puede aumentar la capacidad de almacenamiento. La implementación de una métrica de Amazon CloudWatch para monitorear el espacio libre permite una administración proactiva y usar Amazon EventBridge para activar una función de AWS Lambda para aumentar automáticamente la capacidad según sea necesario garantiza que el sistema de archivos no vuelva a alcanzar la capacidad completa. Esta combinación aborda tanto la necesidad inmediata de más almacenamiento como proporciona una solución robusta para prevenir problemas futuros.
Question 145 of 529
Una empresa de entrega internacional aloja un sistema de administración de entregas en AWS. Los conductores utilizan el sistema para subir la confirmación de entrega. La confirmación incluye la firma del destinatario o una foto del paquete con el destinatario. El dispositivo portátil del conductor carga firmas y fotos a través de FTP a una sola instancia de Amazon EC2. Cada dispositivo portátil guarda un archivo en un directorio basado en el usuario que ha iniciado sesión y el nombre del archivo coincide con el número de entrega. La instancia EC2 luego agrega metadatos al archivo después de consultar una base de datos central para extraer información de entrega. A continuación, el archivo se coloca en Amazon S3 para archivarlo.
A medida que la compañía se expande, los conductores informan que el sistema está rechazando las conexiones. El servidor FTP está teniendo problemas debido a conexiones caídas y problemas de memoria en respuesta a estos problemas, un ingeniero de sistemas programa una tarea cron para reiniciar la instancia EC2 cada 30 minutos. El equipo de facturación informa que los archivos no siempre están en el archivo y que el sistema central no siempre está actualizado.
Un arquitecto de soluciones necesita diseñar una solución que maximice la escalabilidad para garantizar que el archivo siempre reciba los archivos y que los sistemas estén siempre actualizados. Los dispositivos portátiles no se pueden modificar, por lo que la compañía no puede implementar una nueva aplicación.
Qué solución cumplirá con estos requisitos?
A.
Cree una AMI de la instancia EC2 existente. Cree un grupo de Auto Scaling de instancias EC2 detrás de un balanceador de carga de aplicaciones. Configure el grupo Auto Scaling para que tenga un mínimo de tres instancias.
B.
Utilice la familia AWS Transfer para crear un servidor FTP que coloque los archivos en Amazon Elastic File System (Amazon EFS). Monte el volumen EFS en la instancia EC2 existente. Apunte la instancia EC2 a la nueva ruta para el procesamiento de archivos.
C.
Utilice la familia AWS Transfer para crear un servidor FTP que coloque los archivos en Amazon S3. Utilice una notificación de eventos S3 a través de Amazon Simple Notification Service (Amazon SNS) para invocar una función de AWS Lambda. Configure la función Lambda para agregar los metadatos y actualizar el sistema de entrega.
D.
Actualice los dispositivos portátiles para colocar los archivos directamente en Amazon S3. Utilice una notificación de eventos S3 a través de Amazon Simple Queue Service (Amazon SQS) para invocar una función de AWS Lambda. Configure la función Lambda para agregar los metadatos y actualizar el sistema de entrega.
ResponderDiscusión
Correct Answer: C
Dado que los dispositivos portátiles no se pueden modificar, la solución debe evitar dependencias en una sola instancia EC2, lo que actualmente está causando problemas de escalabilidad. El uso de la familia AWS Transfer para crear un servidor FTP que coloque los archivos en Amazon S3 aprovecha la escalabilidad y durabilidad de S3. Una notificación de eventos S3 a través de Amazon Simple Notification Service (SNS) puede entonces invocar una función de AWS Lambda para agregar metadatos y actualizar el sistema de entrega. Esto asegura que el archivo siempre reciba los archivos y que los sistemas estén siempre actualizados sin modificar los dispositivos portátiles o depender de un solo punto de falla.
Question 146 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. La aplicación se ejecuta en contenedores en un clúster de Amazon Elastic Container Service (Amazon ECS). Las tareas ECS utilizan el tipo de lanzamiento Fargate. Los datos de la aplicación son relacionales y se almacenan en Amazon Aurora MySQL. Para cumplir con los requisitos reglamentarios, la aplicación debe poder recuperarse en una región de AWS separada en caso de falla de la aplicación. En caso de falla, no se pueden perder datos.
Qué solución cumplirá estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Aprovisione una réplica de Aurora en una región diferente.
B.
Configure AWS DataSync para la replicación continua de los datos en una región diferente.
C.
Configure AWS Database Migration Service (AWS DMS) para realizar una replicación continua de los datos en una región diferente.
D.
Utilice Amazon Data Lifecycle Manager (Amazon DLM) para programar una instantánea cada 5 minutos.
ResponderDiscusión
Correct Answer: A
El aprovisionamiento de una réplica Aurora en una región diferente garantiza que los datos se repliquen de forma continua y asincrónica en la réplica. Esta configuración permite la promoción de la réplica a la base de datos primaria con cero pérdida de datos en caso de falla. Las réplicas de Aurora están diseñadas para manejar este escenario con una sobrecarga operativa mínima, ya que Aurora administra automáticamente el proceso de replicación y conmutación por error, proporcionando una solución administrada que cumple con los requisitos de no pérdida de datos y recuperación entre regiones.
Question 147 of 529
Una compañía de servicios financieros recibe una fuente de datos regular de su socio de servicio de tarjetas de crédito. Se envían aproximadamente 5,000 registros cada 15 minutos en texto sin formato, entregados a través de HTTPS directamente en un bucket de Amazon S3 con cifrado del lado del servidor. Este feed contiene datos confidenciales del número de cuenta principal (PAN) de la tarjeta de crédito. La compañía necesita enmascarar automáticamente el PAN antes de enviar los datos a otro bucket S3 para un procesamiento interno adicional. La compañía también necesita eliminar y fusionar campos específicos, y luego transformar el registro en formato JSON. Además, es probable que se agreguen alimentaciones adicionales en el futuro, por lo que cualquier diseño debe ser fácilmente expandible.
Qué soluciones cumplirán con estos requisitos?
A.
Invoque una función de AWS Lambda en la entrega de archivos que extrae cada registro y lo escribe en una cola de Amazon SQS. Invoque otra función Lambda cuando lleguen nuevos mensajes a la cola SQS para procesar los registros, escribiendo los resultados en una ubicación temporal en Amazon S3. Invocar una función Lambda final una vez que la cola SQS esté vacía para transformar los registros en formato JSON y enviar los resultados a otro bucket S3 para su procesamiento interno.
B.
Invoque una función de AWS Lambda en la entrega de archivos que extrae cada registro y lo escribe en una cola de Amazon SQS. Configure una aplicación contenedora de AWS Fargate para escalar automáticamente a una sola instancia cuando la cola SQS contenga mensajes. Tener el proceso de solicitud de cada registro, y transformar el registro en formato JSON. Cuando la cola esté vacía, envíe los resultados a otro bucket S3 para su procesamiento interno y reduzca la escala de la instancia de AWS Fargate.
C.
Cree un rastreador de AWS Glue y un clasificador personalizado basado en los formatos de alimentación de datos y cree una definición de tabla para que coincida. Invoque una función de AWS Lambda en la entrega de archivos para iniciar un trabajo ETL de AWS Glue para transformar todo el registro de acuerdo con los requisitos de procesamiento y transformación. Defina el formato de salida como JSON. Una vez completado, haga que el trabajo ETL envíe los resultados a otro bucket S3 para su procesamiento interno.
D.
Cree un rastreador de AWS Glue y un clasificador personalizado basado en los formatos de alimentación de datos y cree una definición de tabla para que coincida. Realizar una consulta de Amazon Athena en la entrega de archivos para iniciar un trabajo ETL de Amazon EMR para transformar todo el registro de acuerdo con los requisitos de procesamiento y transformación. Defina el formato de salida como JSON. Una vez completado, envíe los resultados a otro bucket S3 para su procesamiento interno y escale el clúster de EMR.
ResponderDiscusión
Correct Answer: C
La solución más adecuada implica el uso de AWS Glue, un servicio ETL administrado que está diseñado para manejar tareas de extracción, transformación y carga. Esta solución implica invocar un trabajo ETL de AWS Glue que puede transformar los datos de acuerdo con los requisitos, incluido el enmascaramiento de información confidencial, la eliminación y fusión de campos y la conversión de registros en formato JSON. AWS Glue es fácilmente escalable y se puede ampliar para manejar fuentes de datos adicionales en el futuro. El uso de AWS Glue para estas tareas garantiza que la empresa pueda administrar de manera eficiente la transformación de datos con una sobrecarga operativa mínima.
Question 148 of 529
Una empresa quiere usar AWS para crear una solución de continuidad del negocio en caso de que falle la aplicación local principal de la compañía. La aplicación se ejecuta en servidores físicos que también ejecutan otras aplicaciones. La aplicación local que la compañía planea migrar utiliza una base de datos MySQL como data store. Todas las aplicaciones locales de la compañía utilizan sistemas operativos compatibles con Amazon EC2.
Qué solución logrará el objetivo de la compañía con la menor sobrecarga operativa?
A.
Instale AWS Replication Agent en los servidores de origen, incluidos los servidores MySQL. Configure la replicación para todos los servidores. Lanzar instancias de prueba para taladros regulares. Corte a las instancias de prueba para fallar sobre la carga de trabajo en el caso de un evento de falla.
B.
Instale AWS Replication Agent en los servidores de origen, incluidos los servidores MySQL. Inicialice AWS Elastic Disaster Recovery en la región de AWS de destino. Defina la configuración de lanzamiento. Realice frecuentemente failover y fallback desde el punto más reciente en el tiempo.
C.
Cree servidores de replicación de AWS Database Migration Service (AWS DMS) y un clúster de base de datos Amazon Aurora MySQL de destino para alojar la base de datos. Cree una tarea de replicación DMS para copiar los datos existentes en el clúster de base de datos de destino. Cree una tarea local de captura de datos de cambio (CDC) de AWS Schema Conversion Tool (AWS SCT) para mantener los datos sincronizados. Instale el resto del software en instancias EC2 comenzando con una AMI base compatible.
D.
Implemente una puerta de enlace de volumen de AWS Storage Gateway in situ. Montar volúmenes en todos los servidores locales. Instale la aplicación y la base de datos MySQL en los nuevos volúmenes. Tome instantáneas regulares. Instale todo el software en las instancias EC2 comenzando con una AMI base compatible. Iniciar una puerta de enlace de volumen en una instancia EC2. Restaure los volúmenes a partir de la última instantánea. Monte los nuevos volúmenes en las instancias EC2 en caso de un evento de falla.
ResponderDiscusión
Correct Answer: B
La opción más adecuada para lograr la continuidad del negocio con la menor sobrecarga operativa implica el uso de AWS Elastic Disaster Recovery. Esto permite a la compañía instalar AWS Replication Agent en los servidores de origen, incluidos los servidores MySQL, e inicializar AWS Elastic Disaster Recovery en la región de AWS correspondiente. La solución requiere definir los ajustes de lanzamiento y mantener una sincronización regular, lo que minimiza la necesidad de configuraciones complejas y administración continua. Otras opciones implican esfuerzos manuales adicionales y continuos, como configurar y administrar tareas de AWS DMS o configurar y mantener AWS Storage Gateway, lo que introduce más sobrecarga operativa.
Question 149 of 529
Una empresa está sujeta a auditorías regulatorias de su información financiera. Los auditores externos que utilizan una sola cuenta de AWS necesitan acceder a la cuenta de AWS de la compañía. Un arquitecto de soluciones debe proporcionar a los auditores acceso seguro y de solo lectura a la cuenta de AWS de la compañía. La solución debe cumplir con las mejores prácticas de seguridad de AWS.
Qué solución cumplirá con estos requisitos?
A.
En la cuenta de AWS de la compañía, cree políticas de recursos para todos los recursos de la cuenta para otorgar acceso a la cuenta de AWS de los auditores. Asigne un ID externo único a la política de recursos.
B.
En la cuenta de AWS de la compañía, cree un rol de IAM que confíe en la cuenta de AWS de los auditores. Cree una política de IAM que tenga los permisos requeridos. Adjuntar la política al rol. Asigne un ID externo único a la política de confianza del rol.
C.
En la cuenta de AWS de la compañía, cree un usuario de IAM. Adjuntar las políticas de IAM requeridas al usuario de IAM. Crear claves de acceso API para el usuario de IAM. Compartir las claves de acceso con los auditores.
D.
En la cuenta de AWS de la compañía, cree un grupo de IAM que tenga los permisos requeridos. Crear un usuario de IAM en la cuenta de la compañía para cada auditor. Agregar los usuarios de IAM al grupo de IAM.
ResponderDiscusión
Correct Answer: B
Para cumplir con el requisito de proporcionar a los auditores externos acceso seguro y de solo lectura a la cuenta de AWS de la compañía y cumplir con las mejores prácticas de seguridad de AWS, la solución implica crear un rol de IAM que confíe en la cuenta de AWS de los auditores. Este rol debe tener una política de IAM con los permisos específicos necesarios para el acceso de solo lectura. La política de confianza del rol debe incluir un ID externo único para mayor seguridad. Este enfoque asegura que los auditores puedan asumir el rol y acceder a los recursos sin compartir claves de acceso o crear usuarios individuales de IAM para cada auditor, lo que mejora la seguridad y la manejabilidad.
Question 150 of 529
Una empresa tiene una plataforma de negociación sensible a la latencia que utiliza Amazon DynamoDB como backend de almacenamiento. La compañía configuró la tabla DynamoDB para usar el modo de capacidad bajo demanda. Un arquitecto de soluciones necesita diseñar una solución para mejorar el rendimiento de la plataforma de negociación. La nueva solución debe garantizar una alta disponibilidad para la plataforma de trading.
Qué solución cumplirá estos requisitos con la MENOR latencia?
A.
Cree un clúster de acelerador DynamoDB (DAX) de dos nodos. Configure una aplicación para leer y escribir datos mediante DAX.
B.
Cree un clúster de acelerador DynamoDB (DAX) de tres nodos. Configure una aplicación para leer datos mediante DAX y escribir datos directamente en la tabla de DynamoDB.
C.
Cree un clúster de acelerador DynamoDB (DAX) de tres nodos. Configure una aplicación para leer datos directamente desde la tabla DynamoDB y escribir datos mediante DAX.
D.
Cree un clúster DynamoDB Accelerator (DAX) de un solo nodo. Configure una aplicación para leer datos mediante DAX y escribir datos directamente en la tabla de DynamoDB.
ResponderDiscusión
Correct Answer: B
Para mejorar el rendimiento de la plataforma de trading sensible a la latencia al tiempo que se garantiza una alta disponibilidad, la mejor solución es crear un clúster DynamoDB Accelerator (DAX) de tres nodos. La aplicación debe configurarse para leer datos usando DAX y escribir datos directamente en la tabla DynamoDB. Esta configuración aprovecha los beneficios de DAX para el rendimiento de lectura sin la sobrecarga de latencia de las operaciones de escritura a través de DAX. Además, un clúster de tres nodos proporciona alta disponibilidad, como se recomienda para entornos de producción.
Question 151 of 529
Una empresa ha migrado una aplicación desde las instalaciones a AWS. El frontend de la aplicación es un sitio web estático que se ejecuta en dos instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). El backend de la aplicación es una aplicación Python que se ejecuta en tres instancias EC2 detrás de otro ALB. Las instancias EC2 son instancias bajo demanda de uso general grandes que se dimensionaron para cumplir con las especificaciones locales para el uso máximo de la aplicación.
La aplicación promedia cientos de miles de solicitudes cada mes. Sin embargo, la aplicación se utiliza principalmente durante la hora del almuerzo y recibe un tráfico mínimo durante el resto del día.
Un arquitecto de soluciones necesita optimizar el costo de infraestructura de la aplicación sin afectar negativamente la disponibilidad de la aplicación.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Cambie todas las instancias EC2 para calcular instancias optimizadas que tengan el mismo número de núcleos que las instancias EC2 existentes.
B.
Mueva el frontend de la aplicación a un sitio web estático alojado en Amazon S3.
C.
Implemente el frontend de la aplicación mediante AWS Elastic Beanstalk. Utilice el mismo tipo de instancia para los nodos.
D.
Cambie todas las instancias EC2 de backend a Instancias puntuales.
E.
Implemente la aplicación Python de backend en instancias EC2 con ráfagas de propósito general que tengan el mismo número de núcleos que las instancias EC2 existentes.
ResponderDiscusión
Correct Answer: B, E
Para optimizar el costo de infraestructura de la aplicación sin afectar negativamente la disponibilidad de la aplicación, el mejor enfoque consiste en mover la interfaz de la aplicación a un sitio web estático alojado en Amazon S3 e implementar la aplicación Python backend en instancias EC2 con ráfagas de propósito general. Alojar la interfaz estática en Amazon S3 es más rentable y escalable en comparación con ejecutarla en instancias EC2. Para el backend, las instancias burstable de propósito general ofrecen una solución rentable, ya que manejan cargas de trabajo variables de manera eficiente acumulando créditos durante un uso bajo y utilizándolos durante picos, alineándose así con el patrón de uso de la aplicación.
Question 152 of 529
Una empresa está ejecutando una plataforma de venta de entradas para eventos en AWS y quiere optimizar la rentabilidad de la plataforma. La plataforma se implementa en Amazon Elastic Kubernetes Service (Amazon EKS) con Amazon EC2 y está respaldada por una instancia de base de datos de Amazon RDS para MySQL. La compañía está desarrollando nuevas funciones de aplicación para ejecutarse en Amazon EKS con AWS Fargate.
La plataforma experimenta altos picos de demanda poco frecuentes. Los aumentos en la demanda dependen de las fechas de los eventos.
Qué solución proporcionará la configuración MÁS rentable para la plataforma?
A.
Adquiera instancias reservadas estándar para las instancias EC2 que el clúster EKS utiliza en su carga de línea base. Escale el clúster con Instancias puntuales para manejar picos. Compre instancias reservadas All Upfront de 1 año para la base de datos para cumplir con la carga máxima prevista para el año.
B.
Compra Planes de Ahorro de Computación para la carga media prevista del clúster EKS. Escale el clúster con Reservas de capacidad bajo demanda según las fechas de los eventos para los picos. Compre instancias reservadas sin adelantado de 1 año para que la base de datos cumpla con la carga base predicha. Escale temporalmente las réplicas de lectura de bases de datos durante los picos.
C.
Adquiera planes de ahorro de instancias EC2 para la carga base prevista del clúster EKS. Escale el clúster con Instancias puntuales para manejar picos. Adquiera todas las instancias reservadas iniciales de 1 año para que la base de datos cumpla con la carga base predicha. Escale temporalmente la instancia de base de datos manualmente durante los picos.
D.
Compra Planes de Ahorro de Computación para la carga base prevista del clúster EKS. Escale el clúster con Instancias puntuales para manejar picos. Adquiera todas las instancias reservadas iniciales de 1 año para que la base de datos cumpla con la carga base predicha. Escale temporalmente la instancia de base de datos manualmente durante los picos.
ResponderDiscusión
Correct Answer: D
La configuración más rentable implica el uso de planes de ahorro de cómputos para la carga base prevista del clúster de EKS, ya que estos planes proporcionan flexibilidad y se aplican al uso de EC2 y AWS Fargate. Escalar el clúster con instancias puntuales es una forma rentable de manejar picos, ya que las instancias puntuales son considerablemente menos costosas que las instancias bajo demanda, aunque conllevan un riesgo de interrupción, su uso en un clúster escalable y sin estado se puede administrar de manera efectiva. Para la base de datos, la compra de instancias reservadas All Upfront de 1 año para la carga base prevista garantiza ahorros de costos a lo largo del tiempo. El escalado temporal de la instancia de base de datos manualmente durante los picos permite una capacidad adicional durante los períodos de alta demanda sin incurrir en costos permanentes innecesarios.
Question 153 of 529
Una empresa ha implementado una aplicación en AWS Elastic Beanstalk. La aplicación utiliza Amazon Aurora para la capa de base de datos. Una distribución de Amazon CloudFront sirve solicitudes web e incluye el nombre de dominio de Elastic Beanstalk como servidor de origen. La distribución se configura con un nombre de dominio alternativo que los visitantes utilizan cuando acceden a la aplicación.
Cada semana, la empresa saca de servicio la aplicación para el mantenimiento de rutina. Durante el tiempo que la aplicación no está disponible, la compañía quiere que los visitantes reciban un mensaje informativo en lugar de un mensaje de error de CloudFront.
Un arquitecto de soluciones crea un bucket de Amazon S3 como primer paso en el proceso.
Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con los requisitos? (Elija tres.)
A.
Cargue contenido informativo estático en el bucket S3.
B.
Cree una nueva distribución de CloudFront. Establezca el cubo S3 como origen.
C.
Establezca el bucket S3 como un segundo origen en la distribución original de CloudFront. Configure la distribución y el bucket S3 para usar una identidad de acceso de origen (OAI).
D.
Durante el mantenimiento semanal, edite el comportamiento de caché predeterminado para usar el origen S3. Revertir el cambio cuando se complete el mantenimiento.
E.
Durante el mantenimiento semanal, cree un comportamiento de caché para el origen S3 en la nueva distribución. Establezca el patrón de ruta en\ Establezca la prioridad en 0. Elimine el comportamiento de la caché cuando se complete el mantenimiento.
F.
Durante el mantenimiento semanal, configure Elastic Beanstalk para que sirva el tráfico desde el bucket S3.
ResponderDiscusión
Correct Answer: A, C, D
Para cumplir con los requisitos, siga estos pasos: Primero, cargue contenido informativo estático al bucket S3, que se mostrará durante el mantenimiento. A continuación, establezca el bucket S3 como un segundo origen en la distribución original de CloudFront y configure ambos para usar una identidad de acceso de origen (OAI) para asegurar el acceso. Finalmente, durante el mantenimiento semanal, edite el comportamiento de caché predeterminado para usar el origen S3 y revertir este cambio una vez que se complete el mantenimiento. Este enfoque garantiza que los visitantes reciban el mensaje informativo del bucket S3 sin encontrar un error de CloudFront.
Question 154 of 529
Una empresa brinda a los usuarios la posibilidad de subir imágenes desde una aplicación personalizada. El proceso de carga invoca una función de AWS Lambda que procesa y almacena la imagen en un bucket de Amazon S3. La aplicación invoca la función Lambda usando una función específica versión ARN.
La función Lambda acepta parámetros de procesamiento de imágenes mediante el uso de variables de entorno. La compañía a menudo ajusta las variables de entorno de la función Lambda para lograr una salida óptima de procesamiento de imágenes. La compañía prueba diferentes parámetros y publica una nueva versión de función con las variables de entorno actualizadas después de validar los resultados. Este proceso de actualización también requiere cambios frecuentes en la aplicación personalizada para invocar la nueva versión de función ARN. Estos cambios provocan interrupciones para los usuarios.
Un arquitecto de soluciones necesita simplificar este proceso para minimizar las interrupciones para los usuarios.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Modificar directamente las variables de entorno de la versión de la función Lambda publicada. Utilice la versión SLUREST para probar los parámetros de procesamiento de imágenes.
B.
Cree una tabla de Amazon DynamoDB para almacenar los parámetros de procesamiento de imágenes. Modifique la función Lambda para recuperar los parámetros de procesamiento de imágenes de la tabla DynamoDB.
C.
Codifique directamente los parámetros de procesamiento de imágenes dentro de la función Lambda y elimine las variables de entorno. Publicar una nueva versión de función cuando la compañía actualice los parámetros.
D.
Cree un alias de función Lambda. Modificar la aplicación cliente para utilizar la función alias ARN. Reconfigure el alias Lambda para que apunte a nuevas versiones de la función cuando la empresa termine de probar.
ResponderDiscusión
Correct Answer: D
Para minimizar la interrupción y la sobrecarga operativa, usar un alias de función Lambda es la solución más efectiva. Al crear un alias, la aplicación personalizada puede hacer referencia al alias de manera consistente y el alias se puede actualizar para apuntar a nuevas versiones de funciones según sea necesario. Este enfoque elimina la necesidad de modificar la aplicación cliente cada vez que se actualizan las variables de entorno y se publica una nueva versión de función. Permite actualizaciones y pruebas continuas de nuevos parámetros simplemente cambiando a qué versión apunta el alias, asegurando una interrupción mínima para los usuarios.
Question 155 of 529
Una compañía global de medios está planeando una implementación en varias regiones de una aplicación. Las tablas globales de Amazon DynamoDB respaldarán la implementación para mantener la experiencia del usuario consistente en los dos continentes donde se concentran los usuarios. Cada implementación tendrá un balanceador de carga de aplicaciones (ALB) público. La compañía administra el DNS público internamente. La compañía quiere que la aplicación esté disponible a través de un dominio apex.
Qué solución cumplirá estos requisitos con el MENOR esfuerzo?
A.
Migre el DNS público a Amazon Route 53. Crear registros CNAME para que el dominio apex apunte al ALB. Utilice una política de enrutamiento de geolocalización para enrutar el tráfico en función de la ubicación del usuario.
B.
Coloque un balanceador de carga de red (NLB) frente al DNS público ALMigrate a Amazon Route 53. Cree un registro CNAME para que el dominio apex apunte a la dirección IP estática del NLB. Utilice una política de enrutamiento de geolocalización para enrutar el tráfico en función de la ubicación del usuario.
C.
Cree un acelerador de AWS Global Accelerator con varios grupos de endpoints que se dirijan a endpoints en las regiones de AWS adecuadas. Utilice la dirección IP estática del acelerador para crear un registro en DNS público para el dominio apex.
D.
Cree una API de Amazon API Gateway respaldada por AWS Lambda en una de las regiones de AWS. Configure una función Lambda para enrutar el tráfico a las implementaciones de aplicaciones mediante el método round robin. Cree registros CNAME para que el dominio apex apunte a la URL de la API.
ResponderDiscusión
Correct Answer: C
Para que la aplicación esté disponible a través de un dominio apex con el menor esfuerzo, la mejor solución es usar un AWS Global Accelerator. Este enfoque implica la creación de un acelerador global de AWS con múltiples grupos de endpoints dirigidos a las regiones de AWS adecuadas. El acelerador proporciona una dirección IP estática, que luego se puede usar para crear un registro A en el DNS público para el dominio apex. Este método elimina la necesidad de registros CNAME, que no están permitidos para dominios apex, y simplifica el proceso de implementación al enrutar automáticamente el tráfico en función de la salud y la geografía. Los métodos alternativos implican más configuración manual y problemas potenciales de latencia.
Question 156 of 529
Una empresa está desarrollando una nueva API sin servidor mediante el uso de Amazon API Gateway y AWS Lambda. La compañía integró las funciones de Lambda con API Gateway para usar varias bibliotecas compartidas y clases personalizadas.
Un arquitecto de soluciones necesita simplificar la implementación de la solución y optimizar la reutilización del código.
Qué solución cumplirá con estos requisitos?
A.
Implemente las bibliotecas compartidas y las clases personalizadas en una imagen de Docker. Almacene la imagen en un cubo S3. Cree una capa Lambda que utilice la imagen Docker como fuente. Implemente las funciones Lambda de la API como paquetes Zip. Configure los paquetes para usar la capa Lambda.
B.
Implemente las bibliotecas compartidas y las clases personalizadas en una imagen de Docker. Sube la imagen a Amazon Elastic Container Registry (Amazon ECR). Cree una capa Lambda que utilice la imagen Docker como fuente. Implemente las funciones Lambda de la API como paquetes Zip. Configure los paquetes para usar la capa Lambda.
C.
Implemente las bibliotecas compartidas y las clases personalizadas en un contenedor Docker en Amazon Elastic Container Service (Amazon ECS) mediante el tipo de lanzamiento de AWS Fargate. Implemente las funciones Lambda de la API como paquetes Zip. Configure los paquetes para usar el contenedor desplegado como una capa Lambda.
D.
Despliegue las bibliotecas compartidas, las clases personalizadas y el código para las funciones Lambda de la API en una imagen Docker. Sube la imagen a Amazon Elastic Container Registry (Amazon ECR). Configure las funciones Lambda de la API para usar la imagen Docker como paquete de implementación.
ResponderDiscusión
Correct Answer: D
Para simplificar la implementación y optimizar la reutilización del código, implementar las bibliotecas compartidas, las clases personalizadas y el código para las funciones de Lambda en una imagen Docker y almacenar esta imagen en Amazon Elastic Container Registry (ECR) es la solución más eficiente. Este método permite a la compañía consolidar todas las dependencias y código en una sola imagen de contenedor, que luego puede ser utilizada directamente por las funciones de Lambda. Este enfoque elimina las limitaciones en torno a las capas Lambda que no admiten imágenes Docker, lo que garantiza un proceso de implementación simplificado y reutilizable.
Question 157 of 529
Una empresa manufacturera está construyendo una solución de inspección para su fábrica. La compañía cuenta con cámaras IP al final de cada línea de montaje. La compañía ha utilizado Amazon SaeMaker para entrenar un modelo de aprendizaje automático (ML) para identificar defectos comunes a partir de imágenes fijas.
La compañía quiere proporcionar retroalimentación local a los trabajadores de la fábrica cuando se detecta un defecto. La compañía debe poder proporcionar esta retroalimentación incluso si la conectividad a Internet de la fábrica no funciona. La compañía cuenta con un servidor Linux local que aloja una API que proporciona retroalimentación local a los trabajadores.
Cómo debería implementar la compañía el modelo ML para cumplir con estos requisitos?
A.
Configure una transmisión de video de Amazon Kinesis desde cada cámara IP a AWS. Utilice instancias de Amazon EC2 para tomar imágenes fijas de las transmisiones. Sube las imágenes a un bucket de Amazon S3. Implementar un punto final de SAGeMaker con el modelo ML. Invoque una función de AWS Lambda para llamar al punto final de inferencia cuando se carguen nuevas imágenes. Configure la función Lambda para llamar a la API local cuando se detecte un defecto.
B.
Implementar AWS IoT Greengrass en el servidor local. Despliegue el modelo ML en el servidor Greengrass. Cree un componente Greengrass para tomar imágenes fijas de las cámaras y ejecutar inferencia. Configure el componente para llamar a la API local cuando se detecte un defecto.
C.
Solicite un dispositivo AWS Snowball. Implemente un punto final de SageMaker, el modelo ML y una instancia de Amazon EC2 en el dispositivo Snowball. Toma imágenes fijas de las cámaras. Ejecute la inferencia de la instancia EC2. Configure la instancia para llamar a la API local cuando se detecte un defecto.
D.
Implemente dispositivos Amazon Monitron en cada cámara IP. Implementar una puerta de enlace de Amazon Monitron en las instalaciones. Implemente el modelo ML en los dispositivos de Amazon Monitron. Utilice las alarmas de estado de estado de Amazon Monitron para llamar a la API local desde una función de AWS Lambda cuando se detecte un defecto.
ResponderDiscusión
Correct Answer: B
Para implementar el modelo ML y proporcionar retroalimentación local a los trabajadores de la fábrica incluso cuando la conectividad a Internet de la fábrica no funciona, la compañía debería usar AWS IoT Greengrass. AWS IoT Greengrass se puede implementar en el servidor Linux local para permitir que la compañía ejecute el modelo ML localmente. Puede manejar tomar imágenes fijas de las cámaras IP, ejecutar inferencias y llamar a la API local para proporcionar retroalimentación cuando se detecta un defecto. Esta configuración garantiza que los trabajadores de la fábrica reciban retroalimentación en tiempo real sin depender de una conexión a Internet.
Question 158 of 529
Un arquitecto de soluciones debe crear un caso de negocio para la migración del centro de datos local de una empresa a la nube de AWS. El arquitecto de soluciones utilizará una base de datos de gestión de configuración (CMDB) para exportar todos los servidores de la compañía para crear el caso.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Utilice AWS Well-Architected Tool para importar los datos de CMDB para realizar un análisis y generar recomendaciones.
B.
Utilice el Evaluador de Migración para realizar un análisis. Utilice la plantilla de importación de datos para cargar los datos de la exportación CMDB.
C.
Implementar reglas de coincidencia de recursos. Utilice la exportación CMDB y la API masiva de lista de precios de AWS para consultar los datos de CMDB contra los servicios de AWS de forma masiva.
D.
Utilice AWS Application Discovery Service para importar los datos de CMDB para realizar un análisis.
ResponderDiscusión
Correct Answer: B
La solución más rentable para crear un caso de negocio para la migración de datos locales a la nube de AWS mediante el uso de una exportación CMDB de todos los servidores de la compañía es AWS Migration Evaluator. Esta herramienta está diseñada específicamente para ayudar a las empresas a analizar sus entornos actuales, incluidos los datos de herramientas de terceros como las CMDB, y proporcionar estimaciones detalladas de costos y recomendaciones para migrar a AWS. Se trata de un servicio complementario que genera un reporte integral con proyecciones de costos y ahorros, lo que lo convierte en una opción ideal para crear un caso de negocio para la migración.
Question 159 of 529
Una empresa tiene un sitio web que se ejecuta en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). Las instancias están en un grupo de Auto Scaling. El ALB está asociado con una ACL web de AWS WAF.
El sitio web a menudo encuentra ataques en la capa de aplicación. Los ataques producen aumentos repentinos y significativos en el tráfico en el servidor de aplicaciones. Los registros de acceso muestran que cada ataque se origina en diferentes direcciones IP. Un arquitecto de soluciones necesita implementar una solución para mitigar estos ataques.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una alarma de Amazon CloudWatch que monitoree el acceso al servidor. Establezca un umbral basado en el acceso por dirección IP. Configure una acción de alarma que agregue la dirección IP a la lista de denegar de ACL web.
B.
Implemente AWS Shield Advanced además de AWS WAF. Agregar el ALB como recurso protegido.
C.
Cree una alarma de Amazon CloudWatch que supervise las direcciones IP de los usuarios. Establezca un umbral basado en el acceso por dirección IP. Configure la alarma para invocar una función de AWS Lambda para agregar una regla de denegar en la tabla de rutas de subred del servidor de aplicaciones para cualquier dirección IP que active la alarma.
D.
Inspeccione los registros de acceso para encontrar un patrón de direcciones IP que lanzaron los ataques. Utilice una política de enrutamiento de geolocalización de Amazon Route 53 para denegar el tráfico de los países que alojan esas direcciones IP.
ResponderDiscusión
Correct Answer: B
Para mitigar los ataques de capa de aplicaciones con la menor sobrecarga operativa, la implementación de AWS Shield Advanced además de AWS WAF proporciona una protección integral. AWS Shield Advanced ofrece protección DDoS avanzada y se integra sin problemas con AWS WAF para abordar los exploits web. Al agregar el balanceador de carga de aplicaciones como recurso protegido, los ataques pueden detectarse dinámicamente y mitigarse automáticamente, minimizando la carga operativa.
Question 160 of 529
Una empresa tiene una aplicación crítica en la que el nivel de datos se implementa en una sola región de AWS. El nivel de datos utiliza una tabla de Amazon DynamoDB y un clúster de base de datos MySQL de Amazon Aurora. La versión actual del motor Aurora MySQL soporta una base de datos global. El nivel de aplicación ya está implementado en dos regiones.
La política de la compañía establece que las aplicaciones críticas deben tener componentes de nivel de aplicación y componentes de nivel de datos implementados en dos regiones. El RTO y el RPO no deben ser más de unos minutos cada uno. Un arquitecto de soluciones debe recomendar una solución para que el nivel de datos cumpla con la política de la compañía.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Agregar otra región al clúster de base de datos Aurora MySQL
B.
Agregar otra región a cada tabla en el clúster de base de datos Aurora MySQL
C.
Configurar copias de seguridad programadas entre regiones para la tabla DynamoDB y el clúster de base de datos Aurora MySQL
D.
Convierta la tabla existente de DynamoDB en una tabla global agregando otra región a su configuración
E.
Utilice Amazon Route 53 Application Recovery Controller para automatizar la copia de seguridad y recuperación de bases de datos en la región secundaria
ResponderDiscusión
Correct Answer: A, D
Para cumplir con la política de la compañía de implementar componentes de nivel de datos y aplicaciones en dos regiones con un RTO y un RPO de no más de unos pocos minutos, necesitamos agregar regiones adicionales tanto al clúster de base de datos de Amazon Aurora MySQL como a la tabla DynamoDB. Agregar otra región al clúster de base de datos Aurora MySQL permitirá que los datos de Aurora MySQL se repliquen en todas las regiones, admitiendo operaciones globales de lectura y escritura y proporcionando alta disponibilidad. La conversión de la tabla existente de DynamoDB en una tabla global agregando otra región garantiza que los datos se repliquen en varias regiones de AWS, lo que permite una alta disponibilidad y un acceso de baja latencia.
Question 161 of 529
Una empresa de telecomunicaciones está ejecutando una aplicación en AWS. La compañía ha establecido una conexión AWS Direct Connect entre el centro de datos local de la compañía y AWS. La compañía implementó la aplicación en instancias de Amazon EC2 en varias zonas de disponibilidad detrás de un balanceador de carga de aplicaciones (ALB) interno. Los clientes de la compañía se conectan desde la red local mediante HTTPS. El TLS termina en el ALB. La compañía tiene múltiples grupos objetivo y utiliza el enrutamiento basado en rutas para reenviar solicitudes basadas en la ruta URL.
La compañía planea implementar un dispositivo de firewall local con una lista de permisos basada en la dirección IP. Un arquitecto de soluciones debe desarrollar una solución que permita el flujo de tráfico a AWS desde la red local para que los clientes puedan seguir accediendo a la aplicación.
Qué solución cumplirá con estos requisitos?
A.
Configure el ALB existente para usar direcciones IP estáticas. Asigne direcciones IP en varias zonas de disponibilidad al ALB. Agregue las direcciones IP ALB al dispositivo de firewall.
B.
Cree un balanceador de carga de red (NLB). Asocie el NLB con una dirección IP estática en varias zonas de disponibilidad. Cree un grupo de destino de tipo ALB para el NLB y agregue las direcciones IP NLB existentes al dispositivo de firewall. Actualizar los clientes para conectarse a la NLB.
C.
Cree un balanceador de carga de red (NLB). Asocie el LNB con una dirección IP estática en varias zonas de disponibilidad. Agregar los grupos objetivo existentes al NLB. Actualizar los clientes para conectarse a la NLB. Eliminar el ALB Agregue las direcciones IP NLB al dispositivo de firewall.
D.
Cree un balanceador de carga de puerta de enlace (GWLB). Asigne direcciones IP estáticas al GWLB en varias zonas de disponibilidad. Cree un grupo objetivo de tipo ALB para el GWLB y agregue el ALB existente. Agregue las direcciones IP GWLB al dispositivo de firewall. Actualizar los clientes para conectarse al GWLB.
ResponderDiscusión
Correct Answer: B
La compañía de telecomunicaciones necesita permitir el flujo de tráfico a AWS desde la red local mediante un dispositivo de firewall local. El firewall se puede configurar con una lista de permisos basada en direcciones IP, pero los ALB no admiten direcciones IP estáticas, lo que hace que la opción A sea inadecuada. Para cumplir con los requisitos de la compañía, se puede usar un balanceador de carga de red (NLB) ya que puede tener direcciones IP estáticas. Al crear un grupo objetivo de tipo ALB para el NLB y agregar el ALB existente, el dispositivo de firewall puede incluir en la lista blanca las direcciones IP estáticas del NLB, y los clientes pueden conectarse a la NLB, que enruta el tráfico al ALB. Esta configuración conserva las capacidades de enrutamiento basadas en rutas del ALB, lo que convierte a la opción B en la solución adecuada.
Question 162 of 529
Una empresa ejecuta una aplicación en una flota de instancias de Amazon EC2 que se encuentran en subredes privadas detrás de un balanceador de carga de aplicaciones (ALB) orientado a Internet. El ALB es el origen de una distribución de Amazon CloudFront. Una ACL web de AWS WAF que contiene varias reglas administradas de AWS está asociada con la distribución de CloudFront.
La empresa necesita una solución que impida que el tráfico de internet acceda directamente al ALB.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una nueva ACL web que contenga las mismas reglas que contiene la ACL web existente. Asociar la nueva web ACL con el ALB.
B.
Asociar el ACL web existente con el ALB.
C.
Agregue una regla de grupo de seguridad al ALB para permitir el tráfico de la lista de prefijos administrados por AWS solo para CloudFront.
D.
Agregue una regla de grupo de seguridad al ALB para permitir solo los diversos rangos de direcciones IP de CloudFront.
ResponderDiscusión
Correct Answer: C
Para evitar que el tráfico de Internet acceda directamente al ALB mientras requiere la menor sobrecarga operativa, la mejor solución es agregar una regla de grupo de seguridad al ALB que permita el tráfico solo de la lista de prefijos administrados por AWS para CloudFront. Esto asegura que solo el tráfico enrutado a través de CloudFront pueda llegar al ALB y que ningún tráfico directo de Internet pueda acceder a él. El uso de la lista de prefijos administrados de AWS simplifica el mantenimiento, ya que AWS lo actualiza automáticamente, lo que reduce la necesidad de actualizaciones manuales de los rangos de direcciones IP.
Question 163 of 529
Una empresa está ejecutando una aplicación que utiliza un clúster de Amazon ElastiCache para Redis como capa de almacenamiento en caché. Una reciente auditoría de seguridad reveló que la compañía ha configurado el cifrado en reposo para ElastiCache. Sin embargo, la compañía no configuró ElastiCache para utilizar el cifrado en tránsito. Adicionalmente, los usuarios pueden acceder a la caché sin autenticación.
Un arquitecto de soluciones debe realizar cambios para requerir la autenticación del usuario y para garantizar que la empresa esté utilizando cifrado de extremo a extremo.
Qué solución cumplirá con estos requisitos?
A.
Crea un token AUTH. Almacene el token en AWS System Manager Parameter Store, como un parámetro cifrado. Cree un nuevo clúster con AUTH y configure el cifrado en tránsito. Actualice la aplicación para recuperar el token AUTH del almacén de parámetros cuando sea necesario y para usar el token AUTH para la autenticación.
B.
Crea un token AUTH. Almacene el token en AWS Secrets Manager. Configure el clúster existente para usar el token AUTH y configure el cifrado en tránsito. Actualice la aplicación para recuperar el token AUTH de Secrets Manager cuando sea necesario y para usar el token AUTH para la autenticación.
C.
Crear un certificado SSL. Almacene el certificado en AWS Secrets Manager. Cree un nuevo clúster y configure el cifrado en tránsito. Actualiza la aplicación para recuperar el certificado SSL de Secrets Manager cuando sea necesario y usar el certificado para la autenticación.
D.
Crear un certificado SSL. Almacene el certificado en AWS Systems Manager Parameter Store, como parámetro avanzado cifrado. Actualice el clúster existente para configurar el cifrado en tránsito. Actualice la aplicación para recuperar el certificado SSL de Parameter Store cuando sea necesario y para usar el certificado para la autenticación.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de autenticación de usuario y cifrado de extremo a extremo, cree un token AUTH para usarlo en la autenticación y almacénelo de forma segura como parámetro cifrado en AWS Systems Manager Parameter Store. Cree un nuevo clúster de ElastiCache con el token AUTH configurado y habilite el cifrado en tránsito. Esto asegura que tanto el cifrado en tránsito como la autenticación usando el token AUTH estén configurados correctamente. Actualice la aplicación para recuperar el token AUTH de Parameter Store cuando sea necesario y para usar el token para la autenticación. Este enfoque garantiza que el acceso a la caché sea seguro y cifrado de extremo a extremo.
Question 164 of 529
Una empresa ejecuta una carga de trabajo informática mediante el uso de instancias puntuales de Amazon EC2 que se encuentran en un grupo de Auto Scaling. La plantilla de lanzamiento utiliza dos grupos de ubicación y un único tipo de instancia.
Recientemente, un sistema de monitoreo informó fallas de lanzamiento de instancias de Auto Scaling que se correlacionaban con tiempos de espera más largos para los usuarios del sistema. La compañía necesita mejorar la confiabilidad general de la carga de trabajo.
Qué solución cumplirá con este requisito?
A.
Reemplace la plantilla de lanzamiento por una configuración de lanzamiento para usar un grupo de Auto Scaling que utilice la selección de tipo de instancia basada en atributos.
B.
Cree una nueva versión de la plantilla de lanzamiento que utilice la selección de tipo de instancia basada en atributos. Configure el grupo Auto Scaling para usar la nueva versión de la plantilla de lanzamiento.
C.
Actualice el grupo Auto Scaling de la plantilla de lanzamiento para aumentar el número de grupos de ubicación.
D.
Actualice la plantilla de lanzamiento para usar un tipo de instancia más grande.
ResponderDiscusión
Correct Answer: B
Para mejorar la fiabilidad general de la carga de trabajo que se ejecuta en las instancias puntuales de Amazon EC2, la mejor solución es utilizar la selección de tipos de instancia basada en atributos. Este enfoque permite a Amazon EC2 seleccionar automáticamente entre una amplia gama de tipos de instancias en función de atributos definidos, como vCPU, memoria y otras características. Esto aumenta las posibilidades de encontrar capacidad informática disponible y reduce la probabilidad de fallas en el lanzamiento de instancias debido a la terminación o falta de disponibilidad de instancias puntuales. Crear una nueva versión de plantilla de lanzamiento con selección de tipo de instancia basada en atributos y configurar el grupo Auto Scaling para usar esta nueva versión permitirá que el sistema se adapte a la disponibilidad cambiante y mejore la confiabilidad.
Question 165 of 529
Una empresa está migrando una carga de trabajo de procesamiento de documentos a AWS. La compañía ha actualizado muchas aplicaciones para usar de forma nativa la API de Amazon S3 para almacenar, recuperar y modificar documentos que genera un servidor de procesamiento a una velocidad de aproximadamente 5 documentos cada segundo. Una vez finalizado el procesamiento del documento, los clientes pueden descargar los documentos directamente desde Amazon S3.
Durante la migración, la compañía descubrió que no podía actualizar de inmediato el servidor de procesamiento que genera muchos documentos para soportar la API S3. El servidor se ejecuta en Linux y requiere un rápido acceso local a los archivos que el servidor genera y modifica. Cuando el servidor termine de procesarse, los archivos deben estar disponibles para el público para su descarga en un plazo de 30 minutos.
Qué solución cumplirá estos requisitos con la MENOR cantidad de esfuerzo?
A.
Migre la aplicación a una función de AWS Lambda. Utilice el SDK de AWS para Java para generar, modificar y acceder a los archivos que la compañía almacena directamente en Amazon S3.
B.
Configure una puerta de enlace de archivos de Amazon S3 y configure un recurso compartido de archivos que esté vinculado al almacén de documentos. Monte el recurso compartido de archivos en una instancia de Amazon EC2 mediante NFS. Cuando se produzcan cambios en Amazon S3, inicie una llamada a la API RefreshCache para actualizar S3 File Gateway.
C.
Configure Amazon FSx para Lustre con una política de importación y exportación. Vincular el nuevo sistema de archivos a un bucket S3. Instale el cliente Lustre y monte el almacén de documentos en una instancia de Amazon EC2 mediante NFS.
D.
Configure AWS DataSync para conectarse a una instancia de Amazon EC2. Configure una tarea para sincronizar los archivos generados hacia y desde Amazon S3.
ResponderDiscusión
Correct Answer: B
La mejor solución para este escenario es configurar una puerta de enlace de archivos de Amazon S3 y configurar un recurso compartido de archivos que esté vinculado al almacén de documentos. El servidor de procesamiento, que no se puede actualizar para usar la API S3 inmediatamente y requiere un rápido acceso local a los archivos, puede montar el recurso compartido de archivos en una instancia de Amazon EC2 mediante NFS. S3 File Gateway proporciona una manera de administrar y sincronizar de manera eficiente el sistema de archivos local con el bucket S3, cumpliendo tanto con los requisitos de acceso rápido a archivos locales como haciendo que los archivos estén disponibles para los clientes en 30 minutos.
Question 166 of 529
Una empresa de entrega está ejecutando una solución sin servidor en la nube de AWS. La solución administra los datos del usuario, la información de entrega y los detalles de compras anteriores. La solución consiste en varios microservicios. El servicio de usuario central almacena datos confidenciales en una tabla de Amazon DynamoDB. Varios de los otros microservicios almacenan una copia de partes de los datos sensibles en diferentes servicios de almacenamiento.
La empresa necesita la capacidad de eliminar la información del usuario a petición. Tan pronto como el servicio central de usuario elimine a un usuario, todos los demás microservicios también deben eliminar su copia de los datos inmediatamente.
Qué solución cumplirá con estos requisitos?
A.
Active las transmisiones de DynamoDB en la tabla DynamoDB. Cree un desencadenador de AWS Lambda para la transmisión de DynamoDB que publicará eventos sobre la eliminación de usuarios en una cola de Amazon Simple Queue Service (Amazon SQS). Configure cada microservicio para sondear la cola y eliminar al usuario de la tabla DynamoDB.
B.
Configure las notificaciones de eventos de DynamoDB en la tabla DynamoDB. Cree un tema de Amazon Simple Notification Service (Amazon SNS) como destino para la notificación de eventos de DynamoDB. Configure cada microservicio para suscribirse al tema SNS y eliminar al usuario de la tabla DynamoDB.
C.
Configure el servicio de usuario central para publicar un evento en un bus de eventos personalizado de Amazon EventBridge cuando la empresa elimine a un usuario. Cree una regla EventBridge para cada microservicio para que coincida con el patrón de eventos de eliminación de usuario e invoque la lógica en el microservicio para eliminar al usuario de la tabla de DynamoDB.
D.
Configure el servicio de usuario central para que publique un mensaje en una cola de Amazon Simple Queue Service (Amazon SQS) cuando la empresa borre a un usuario. Configure cada microservicio para crear un filtro de eventos en la cola SQS y eliminar al usuario de la tabla DynamoDB.
ResponderDiscusión
Correct Answer: C
La solución requiere la eliminación inmediata de la información del usuario en múltiples microservicios una vez que el servicio de usuario central elimina a un usuario. Cada microservicio debe ser notificado instantáneamente para eliminar su copia de los datos. El mejor enfoque es usar Amazon EventBridge porque está diseñado para crear aplicaciones basadas en eventos y puede manejar patrones de eventos complejos. Cuando el servicio de usuario central elimina a un usuario, puede publicar un evento en un autobús de eventos EventBridge personalizado. Luego, las reglas de EventBridge se pueden configurar para cada microservicio para que coincidan con el evento de eliminación de usuario e invoquen la lógica necesaria para eliminar los datos de usuario de sus respectivos servicios de almacenamiento. Esto garantiza que todos los microservicios sean notificados instantáneamente y puedan realizar las eliminaciones requeridas sin depender de mecanismos de sondeo o lidiar con las limitaciones de SQS en un patrón de fan-out.
Question 167 of 529
Una empresa está ejecutando una aplicación web en una VPC. La aplicación web se ejecuta en un grupo de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). El ALB está utilizando AWS WAF.
Un cliente externo necesita conectarse a la aplicación web. La compañía debe proporcionar direcciones IP a todos los clientes externos.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Reemplace el ALB por un balanceador de carga de red (NLB). Asigne una dirección IP elástica al NLB.
B.
Asignar una dirección IP elástica. Asigne la dirección IP elástica al ALProporcione la dirección IP elástica al cliente.
C.
Cree un acelerador estándar de AWS Global Accelerator. Especifique el ALB como punto final del acelerador. Proporcionar las direcciones IP del acelerador al cliente.
D.
Configure una distribución de Amazon CloudFront. Establezca el ALB como origen. Haga ping al nombre DNS de la distribución para determinar la dirección IP pública de la distribución. Proporcionar la dirección IP al cliente.
ResponderDiscusión
Correct Answer: C
Para cumplir con el requisito de proporcionar direcciones IP con la menor sobrecarga operativa, la mejor solución es usar AWS Global Accelerator con Application Load Balancer (ALB) como punto final. AWS Global Accelerator proporciona direcciones IP estáticas y enruta el tráfico de manera óptima a los endpoints ALB, minimizando los esfuerzos de configuración y mantenimiento. Las IP elásticas no se pueden asignar directamente a un ALB, y los balanceadores de carga de red no se pueden usar con AWS WAF, lo que hace que las otras opciones sean menos adecuadas.
Question 168 of 529
Una compañía tiene algunas cuentas de AWS para el desarrollo y quiere trasladar su aplicación de producción a AWS. La compañía necesita aplicar el cifrado de Amazon Elastic Block Store (Amazon EBS) en reposo solo cuentas de producción actuales y cuentas de producción futuras. La compañía necesita una solución que incluya planos y barandales incorporados.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Utilice AWS CloudFormation StackSets para implementar reglas de AWS Config en cuentas de producción.
B.
Cree una nueva zona de aterrizaje de AWS Control Tower en una cuenta de desarrollador existente. Crear OU para cuentas. Agregar cuentas de producción y desarrollo a las OU de producción y desarrollo, respectivamente.
C.
Cree una nueva zona de aterrizaje de AWS Control Tower en la cuenta de administración de la compañía. Agregar cuentas de producción y desarrollo a las OU de producción y desarrollo. respectivamente.
D.
Invite a cuentas existentes a unirse a la organización en AWS Organizations. Cree SCP para garantizar el cumplimiento.
E.
Cree una barandilla desde la cuenta de administración para detectar el cifrado de EBS.
F.
Cree una baranda de protección para la unidad organizativa de producción para detectar el cifrado EBS.
ResponderDiscusión
Correct Answer: C, D, F
Para cumplir con los requisitos, primero, cree una nueva zona de aterrizaje de AWS Control Tower en la cuenta de administración de la compañía para garantizar la gobernanza central y la aplicación de políticas. A continuación, invite a cuentas existentes a unirse a la organización en AWS Organizations y crear políticas de control de servicios (SCP) para garantizar el cumplimiento de las reglas de la organización. Por último, crear una barandilla para la Unidad Organizacional (OU) de producción para detectar el cifrado EBS en reposo, asegurando que el cifrado se aplique específicamente para las cuentas de producción. Este enfoque aprovecha los planos y barandas integrados de AWS Control Tower, lo que garantiza el cumplimiento actual y futuro dentro de las cuentas de producción.
Question 169 of 529
Una empresa está ejecutando una aplicación web con estado crítico en dos instancias Linux Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB) con una base de datos de Amazon RDS para MySQL. La compañía aloja los registros DNS para la aplicación en Amazon Route 53. Un arquitecto de soluciones debe recomendar una solución para mejorar la resiliencia de la aplicación.
La solución debe cumplir con los siguientes objetivos:
• Nivel de aplicación: RPO de 2 minutos. RTO de 30 minutos
• Nivel de base de datos: RPO de 5 minutos. RTO de 30 minutos
La compañía no quiere realizar cambios significativos en la arquitectura de aplicaciones existente. La compañía debe garantizar una latencia óptima después de una conmutación por error.
Qué solución cumplirá con estos requisitos?
A.
Configure las instancias EC2 para usar AWS Elastic Disaster Recovery. Cree una réplica de lectura entre regiones para la instancia de base de datos de RDS. Crear un ALB en una segunda región de AWS. Cree un endpoint de AWS Global Accelerator y asocie el endpoint con los ALB. Actualice los registros DNS para que apunten al punto final de Global Accelerator.
B.
Configure las instancias EC2 para usar Amazon Data Lifecycle Manager (Amazon DLM) para tomar instantáneas de los volúmenes de EBS. Configure los respaldos automatizados de RDS. Configure la replicación de backup en una segunda región de AWS. Crear un ALB en la segunda Región. Cree un endpoint de AWS Global Accelerator y asocie el endpoint con los ALB. Actualice los registros DNS para que apunten al punto final de Global Accelerator.
C.
Cree un plan de copia de seguridad en AWS Backup para las instancias EC2 y la instancia de base de datos RDS. Configure la replicación de backup en una segunda región de AWS. Crear un ALB en la segunda Región. Configure una distribución de Amazon CloudFront frente al ALB. Actualice los registros DNS para que apunten a CloudFront.
D.
Configure las instancias EC2 para usar Amazon Data Lifecycle Manager (Amazon DLM) para tomar instantáneas de los volúmenes de EBS. Cree una réplica de lectura entre regiones para la instancia de base de datos de RDS. Crear un ALB en una segunda región de AWS. Cree un endpoint de AWS Global Accelerator y asocie el endpoint con los ALB.
ResponderDiscusión
Correct Answer: A
La solución requiere garantizar una latencia óptima después de una conmutación por error y cumplir con los objetivos específicos de RPO y RTO tanto para los niveles de aplicaciones como de bases de datos. El uso de AWS Elastic Disaster Recovery (DRS) para instancias EC2 proporciona una solución integral y eficiente para la recuperación ante desastres, lo que garantiza que el estado de las instancias se mantenga de manera consistente, lo que DLM y las soluciones de backup por sí solas podrían no lograr tan rápidamente. La creación de una réplica de lectura entre regiones para la instancia de base de datos RDS garantiza que la base de datos pueda cumplir con los RPO y RTO requeridos. Además, el uso de AWS Global Accelerator ayuda a optimizar la latencia y proporcionar failovers rápidas y confiables al dirigir el tráfico a las instancias ALB en buen estado. Esta arquitectura general cumple con los objetivos de resiliencia de manera efectiva sin realizar cambios significativos en la infraestructura existente.
Question 170 of 529
Un arquitecto de soluciones quiere optimizar los costos y dimensionar adecuadamente las instancias de Amazon EC2 en una sola cuenta de AWS. El arquitecto de soluciones quiere asegurarse de que las instancias estén optimizadas en función de la CPU, la memoria y las métricas de red.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Adquiera AWS Business Support o AWS Enterprise Support para la cuenta.
B.
Active AWS Trusted Advisor y revise las recomendaciones de “Instancias Amazon EC2 de baja utilización”.
C.
Instale el agente de Amazon CloudWatch y configure la recopilación de métricas de memoria en las instancias EC2.
D.
Configure AWS Compute Optimizer en la cuenta de AWS para recibir hallazgos y recomendaciones de optimización.
E.
Cree un plan de ahorro de instancias EC2 para las regiones de AWS, las familias de instancias y los sistemas operativos de interés.
ResponderDiscusión
Correct Answer: C, D
Para optimizar los costos y dimensionar adecuadamente las instancias de Amazon EC2 en función de las métricas de CPU, memoria y red, el arquitecto de soluciones debe configurar AWS Compute Optimizer e instalar el agente de Amazon CloudWatch. AWS Compute Optimizer proporciona recomendaciones basadas en aprendizaje automático para tipos de instancias óptimos, y la instalación del agente de CloudWatch permite recopilar métricas de memoria, lo que mejora estas recomendaciones.
Question 171 of 529
Una empresa utiliza un repositorio de AWS CodeCommit. La compañía debe almacenar una copia de seguridad de los datos que se encuentran en el repositorio en una segunda región de AWS.
Qué solución cumplirá con estos requisitos?
A.
Configure AWS Elastic Disaster Recovery para replicar los datos del repositorio CodeCommit en la segunda región.
B.
Utilice AWS Backup para hacer una copia de seguridad del repositorio CodeCommit en un horario de horas. Cree una copia entre regiones en la segunda región.
C.
Cree una regla de Amazon EventBridge para invocar AWS CodeBuild cuando la empresa envíe código al repositorio. Usa CodeBuild para clonar el repositorio. Crear un archivo.zip del contenido. Copia el archivo en un bucket S3 en la segunda Región.
D.
Cree un flujo de trabajo de AWS Step Functions en un horario de horas para tomar una instantánea del repositorio CodeCommit. Configurar el flujo de trabajo para copiar la instantánea en un bucket S3 en la segunda región
ResponderDiscusión
Correct Answer: C
Para realizar una copia de seguridad de un repositorio de AWS CodeCommit y asegurarse de que la copia de seguridad se almacene en una segunda región de AWS, puede configurar una regla de Amazon EventBridge para activar AWS CodeBuild cada vez que se envíe código al repositorio. CodeBuild puede entonces clonar el repositorio, crear un archivo.zip del contenido y copiar el archivo en un bucket S3 en la segunda región. Este método permite realizar copias de seguridad automáticas y consistentes alineadas con la arquitectura basada en eventos proporcionada por los servicios de AWS.
Question 172 of 529
Una empresa tiene múltiples unidades de negocio que cada una tiene cuentas separadas en AWS. Cada unidad de negocio administra su propia red con varias VPC que tienen rangos CIDR que se superponen. El equipo de marketing de la compañía ha creado una nueva aplicación interna y quiere que la aplicación sea accesible para todas las demás unidades de negocio. La solución debe utilizar únicamente direcciones IP privadas.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Indique a cada unidad de negocio que agregue una gama CIDR secundaria única a la VPC de la unidad de negocio. Peer las VPC y utilizar una puerta de enlace NAT privada en el rango secundario para enrutar el tráfico al equipo de marketing.
B.
Cree una instancia de Amazon EC2 para que sirva como dispositivo virtual en la VPC de la cuenta de marketing. Cree una conexión VPN de sitio a sitio de AWS entre el equipo de marketing y la VPC de cada unidad de negocio. Realizar NAT cuando sea necesario.
C.
Cree un servicio de endpoint de AWS PrivateLink para compartir la aplicación de marketing. Otorgar permiso a cuentas específicas de AWS para conectarse al servicio. Crear endpoints de interfaz de VPC en otras cuentas para acceder a la aplicación mediante el uso de direcciones IP privadas.
D.
Cree un balanceador de carga de red (NLB) frente a la aplicación de marketing en una subred privada. Crear una API de puerta de enlace API. Utilice la integración privada de Amazon API Gateway para conectar la API a NLB. Activar autorización de IAM para la API. Otorgar acceso a las cuentas de las otras unidades de negocio.
ResponderDiscusión
Correct Answer: C
Para que una aplicación interna sea accesible a múltiples unidades de negocio con la menor sobrecarga operativa, la mejor solución es usar AWS PrivateLink. Al crear un servicio de endpoint de AWS PrivateLink para la aplicación de marketing, se puede otorgar permiso a cuentas de AWS específicas para conectarse al servicio. Esto permite a las otras unidades de negocio crear endpoints de interfaz de VPC en sus propias cuentas para acceder a la aplicación mediante direcciones IP privadas. Este enfoque evita la necesidad de pares de VPC complejos, configuraciones NAT o infraestructura adicional, minimizando así la sobrecarga operativa.
Question 173 of 529
Una empresa necesita auditar la postura de seguridad de una cuenta de AWS recién adquirida. El equipo de seguridad de datos de la compañía requiere una notificación solo cuando un bucket de Amazon S3 se expone públicamente. La compañía ya ha establecido un tema de Amazon Simple Notification Service (Amazon SNS) que tiene suscrita la dirección de correo electrónico del equipo de seguridad de datos.
Qué solución cumplirá con estos requisitos?
A.
Cree una notificación de evento S3 en todos los buckets S3 para el evento isPublic. Seleccione el tema SNS como destino para las notificaciones de eventos.
B.
Cree un analizador en AWS Identity and Access Management Access Analyzer. Cree una regla de Amazon EventBridge para el tipo de evento “Búsqueda de Access Analyzer” con un filtro para “isPublic: true”. Seleccione el tema SNS como el objetivo de la regla EventBridge.
C.
Cree una regla de Amazon EventBridge para el tipo de evento “Llamada a la API de nivel de cubo a través de CloudTrail” con un filtro para “PutBucketPolicy”. Seleccione el tema SNS como el objetivo de la regla EventBridge.
D.
Active AWS Config y agregue la regla habilitada para cloudtrail-s3-dataevents-enabled. Cree una regla de Amazon EventBridge para el tipo de evento “Estado de reevaluación de reglas de configuración” con un filtro para “NON_COMpliant”. Seleccione el tema SNS como el objetivo de la regla EventBridge.
ResponderDiscusión
Correct Answer: B
Para recibir notificaciones cuando un bucket de Amazon S3 se expone públicamente, crear un analizador en AWS Identity and Access Management Access Analyzer y configurar una regla de Amazon EventBridge para el tipo de evento 'Access Analyzer Finding' con un filtro para 'isPublic: true' es la solución más efectiva. Este enfoque garantiza el monitoreo continuo de las configuraciones de control de acceso y activa notificaciones al tema SNS cada vez que se detecta un bucket de acceso público.
Question 174 of 529
Un arquitecto de soluciones necesita evaluar la cartera de aplicaciones y bases de datos de una empresa recién adquirida. El arquitecto de soluciones debe crear un caso de negocio para migrar la cartera a AWS. La compañía recién adquirida ejecuta aplicaciones en un centro de datos local. El centro de datos no está bien documentado. El arquitecto de soluciones no puede determinar de inmediato cuántas aplicaciones y bases de datos existen. El tráfico para las aplicaciones es variable. Algunas aplicaciones son procesos por lotes que se ejecutan al final de cada mes.
El arquitecto de soluciones debe comprender mejor la cartera antes de que pueda comenzar una migración a AWS.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS Server Migration Service (AWS SMS) y AWS Database Migration Service (AWS DMS) para evaluar la migración. Utilice AWS Service Catalog para comprender las dependencias de las aplicaciones y bases de datos.
B.
Utilice AWS Application Migration Service. Ejecute agentes en la infraestructura local. Administre los agentes mediante AWS Migration Hub. Utilice AWS Storage Gateway para evaluar las necesidades de almacenamiento local y las dependencias de las bases de datos.
C.
Utilice Migration Evaluator para generar una lista de servidores. Crear un informe para un caso de negocio. Utilice AWS Migration Hub para ver la cartera. Utilice AWS Application Discovery Service para comprender las dependencias de las aplicaciones.
D.
Utilice AWS Control Tower en la cuenta de destino para generar una cartera de aplicaciones. Utilice AWS Server Migration Service (AWS SMS) para generar informes más profundos y un caso de negocio. Utilice una zona de aterrizaje para cuentas y recursos básicos.
ResponderDiscusión
Correct Answer: C
Para obtener una comprensión integral de una cartera de aplicaciones y bases de datos locales, es crucial evaluar tanto la infraestructura como las dependencias. Migration Evaluator ayuda a generar una lista de servidores y proporciona un informe detallado, que es esencial para crear un caso de negocio. AWS Migration Hub permite ver la cartera general y administrar migraciones. AWS Application Discovery Service proporciona información sobre las dependencias de las aplicaciones, lo que es crucial para una evaluación precisa. Estas herramientas combinadas ofrecen un enfoque sólido para comprender y planificar la migración.
Question 175 of 529
Una empresa tiene una aplicación que se ejecuta como ReplicaSet de varios pods en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). El clúster EKS tiene nodos en varias zonas de disponibilidad. La aplicación genera muchos archivos pequeños que deben ser accesibles en todas las instancias en ejecución de la aplicación. La compañía necesita hacer una copia de seguridad de los archivos y conservar las copias de seguridad durante 1 año.
Qué solución cumplirá con estos requisitos al tiempo que proporciona el rendimiento de almacenamiento MÁS RÁPIDO?
A.
Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS) y un destino de montaje para cada subred que contenga nodos en el clúster EKS. Configure el ReplicaSet para montar el sistema de archivos. Dirigir la aplicación para almacenar archivos en el sistema de archivos. Configure AWS Backup para realizar copias de seguridad y conservar copias de los datos durante 1 año.
B.
Cree un volumen de Amazon Elastic Block Store (Amazon EBS). Habilite la función de conexión múltiple de EBS. Configure ReplicaSet para montar el volumen de EBS. Dirigir la aplicación para almacenar archivos en el volumen de EBS. Configure AWS Backup para realizar copias de seguridad y conservar copias de los datos durante 1 año.
C.
Cree un bucket de Amazon S3. Configure ReplicaSet para montar el bucket S3. Dirija la aplicación para que almacene archivos en el bucket S3. Configure S3 Versionado para conservar copias de los datos. Configure una política de ciclo de vida de S3 para eliminar objetos después de 1 año.
D.
Configure ReplicaSet para usar el almacenamiento disponible en cada uno de los pods de aplicaciones en ejecución para almacenar los archivos localmente. Utilice una herramienta de terceros para hacer una copia de seguridad del clúster EKS durante 1 año.
ResponderDiscusión
Correct Answer: A
La solución debe soportar la aplicación que se ejecuta en múltiples zonas de disponibilidad y proporcionar un rendimiento de almacenamiento rápido. Amazon Elastic File System (EFS) cumple estos requisitos, ya que proporciona almacenamiento de archivos compartidos que es altamente disponible y duradero en múltiples AZ. EFS ofrece altos niveles de rendimiento agregado e IOPS, lo que lo hace adecuado para aplicaciones que generan muchos archivos pequeños accesibles en varias instancias. Además, AWS Backup se puede configurar para realizar copias de seguridad y conservar copias de los datos durante 1 año. Esto hace que EFS sea la elección óptima para el escenario dado.
Question 176 of 529
Una compañía dirige un centro de atención al cliente que acepta llamadas y envía automáticamente a todos los clientes una encuesta de experiencia administrada, interactiva y bidireccional por mensaje de texto. Las aplicaciones que dan soporte al centro de atención al cliente se ejecutan en máquinas que la compañía aloja en un centro de datos local. El hardware que utiliza la compañía es antiguo, y la compañía está experimentando tiempo de inactividad con el sistema. La compañía quiere migrar el sistema a AWS para mejorar la confiabilidad.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa continua?
A.
Utilice Amazon Connect para reemplazar el hardware antiguo del centro de llamadas. Usa Amazon Pinpoint para enviar encuestas por mensajes de texto a los clientes.
B.
Utilice Amazon Connect para reemplazar el hardware antiguo del centro de llamadas. Utilice Amazon Simple Notification Service (Amazon SNS) para enviar encuestas por mensajes de texto a los clientes.
C.
Migre el software del centro de llamadas a instancias de Amazon EC2 que se encuentran en un grupo de Auto Scaling. Utilice las instancias EC2 para enviar encuestas por mensajes de texto a los clientes.
D.
Utilice Amazon Pinpoint para reemplazar el hardware antiguo del centro de llamadas y enviar encuestas por mensajes de texto a los clientes.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos con la menor sobrecarga operativa continua, la compañía debe usar Amazon Connect para reemplazar el antiguo hardware del call center, y Amazon Pinpoint para enviar encuestas por mensajes de texto a los clientes. Amazon Connect es un servicio de centro de contacto totalmente administrado y basado en la nube que simplifica la configuración y gestión de las interacciones con los clientes. Amazon Pinpoint está diseñado para enviar mensajes específicos y personalizados, incluidas encuestas interactivas de experiencias bidireccionales. Esta combinación aprovecha los servicios completamente administrados, lo que reduce la necesidad de que la compañía administre infraestructura o tareas operativas significativas.
Question 177 of 529
Una empresa está construyendo un centro de llamadas utilizando Amazon Connect. El equipo de operaciones de la compañía está definiendo una estrategia de recuperación ante desastres (DR) en todas las regiones de AWS. El centro de contacto tiene decenas de flujos de contacto, cientos de usuarios y decenas de números telefónicos reclamados.
Qué solución proporcionará a DR el RTO MÁS BAJO?
A.
Cree una función de AWS Lambda para verificar la disponibilidad de la instancia de Amazon Connect y enviar una notificación al equipo de operaciones en caso de indisponibilidad. Cree una regla de Amazon EventBridge para invocar la función Lambda cada 5 minutos. Después de la notificación, indique al equipo de operaciones que use la consola de administración de AWS para aprovisionar una nueva instancia de Amazon Connect en una segunda región. Implemente los flujos de contacto, los usuarios y los números de teléfono reclamados mediante una plantilla de AWS CloudFormation.
B.
Aprovisione una nueva instancia de Amazon Connect con todos los usuarios existentes en una segunda región. Cree una función de AWS Lambda para verificar la disponibilidad de la instancia de Amazon Connect. Cree una regla de Amazon EventBridge para invocar la función Lambda cada 5 minutos. En caso de que surja algún problema, configure la función Lambda para implementar una plantilla de AWS CloudFormation que aprovisione flujos de contacto y números reclamados en la segunda región.
C.
Aprovisione una nueva instancia de Amazon Connect con todos los flujos de contacto existentes y los números de teléfono reclamados en una segunda región. Cree una comprobación de estado de Amazon Route 53 para la URL de la instancia de Amazon Connect. Cree una alarma de Amazon CloudWatch para comprobar el estado fallido. Cree una función de AWS Lambda para implementar una plantilla de AWS CloudFormation que aprovisione a todos los usuarios. Configure la alarma para invocar la función Lambda.
D.
Aprovisione una nueva instancia de Amazon Connect con todos los usuarios existentes y flujos de contacto en una segunda región. Cree una comprobación de estado de Amazon Route 53 para la URL de la instancia de Amazon Connect. Cree una alarma de Amazon CloudWatch para comprobar el estado fallido. Cree una función de AWS Lambda para implementar una plantilla de AWS CloudFormation que aprovisione los números de teléfono reclamados. Configure la alarma para invocar la función Lambda.
ResponderDiscusión
Correct Answer: D
La solución que proporcionará el objetivo de tiempo de recuperación (RTO) más bajo para una estrategia de recuperación ante desastres en Amazon Connect es tener una instancia en espera ya aprovisionada con la mayoría de los componentes preconfigurados. En este escenario, es fundamental aprovisionar una nueva instancia de Amazon Connect con todos los usuarios y flujos de contacto existentes en una segunda región. Al configurar una comprobación de estado de Amazon Route 53 y usar una alarma de Amazon CloudWatch para monitorear los problemas, cualquier falla puede activar rápidamente una función de AWS Lambda para implementar el componente faltante restante, que en este caso son los números de teléfono reclamados. Esta configuración garantiza que el proceso de recuperación sea rápido ya que la mayoría de los elementos ya están en su lugar, lo que reduce el tiempo necesario para restaurar completamente la funcionalidad.
Question 178 of 529
Una empresa ejecuta una aplicación en AWS. La compañía selecciona datos de varias fuentes diferentes. La compañía utiliza algoritmos patentados para realizar transformaciones y agregaciones de datos. Después de que la compañía realiza procesos ETL, la compañía almacena los resultados en tablas Amazon Redshift. La compañía vende estos datos a otras empresas. La compañía descarga los datos como archivos de las tablas de Amazon Redshift y transmite los archivos a varios clientes de datos mediante FTP. El número de clientes de datos ha crecido significativamente. La gestión de los clientes de datos se ha vuelto difícil.
La compañía utilizará AWS Data Exchange para crear un producto de datos que la compañía pueda usar para compartir datos con los clientes. La compañía quiere confirmar las identidades de los clientes antes de que la compañía comparta datos. Los clientes también necesitan acceder a los datos más recientes cuando la empresa publica los datos.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Utilice AWS Data Exchange para API para compartir datos con los clientes. Configurar la verificación de suscripción. En la cuenta de AWS de la empresa que produce los datos, cree una integración del servicio API de Amazon API Gateway Data API con Amazon Redshift. Requerir que los clientes de datos se suscriban al producto de datos.
B.
En la cuenta de AWS de la compañía que produce los datos, cree un área de datos de AWS Data Exchange conectando AWS Data Exchange al clúster de Redshift. Configurar la verificación de suscripción. Requerir que los clientes de datos se suscriban al producto de datos.
C.
Descargue periódicamente los datos de las tablas de Amazon Redshift a un bucket de Amazon S3. Utilice AWS Data Exchange for S3 para compartir datos con los clientes. Configurar la verificación de suscripción. Requerir que los clientes de datos se suscriban al producto de datos.
D.
Publique los datos de Amazon Redshift en un Open Data en AWS Data Exchange. Exigir a los clientes que se suscriban al producto de datos en AWS Data Exchange. En la cuenta de AWS de la compañía que produce los datos, adjunte políticas basadas en recursos de IAM a las tablas de Amazon Redshift para permitir el acceso solo a cuentas de AWS verificadas.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos con la menor sobrecarga operativa y garantizar que los clientes tengan acceso a los datos más recientes mientras confirman sus identidades, usar AWS Data Exchange para crear una conexión de datashare al clúster de Redshift es la solución más eficiente. Este enfoque permite que los datos se compartan directamente desde Amazon Redshift sin pasos adicionales como exportar datos a S3 o administrar API externas, minimizando así la sobrecarga operativa. La configuración de la verificación de suscripción garantiza que solo los clientes validados puedan acceder a los datos.
Question 179 of 529
Un arquitecto de soluciones está diseñando una solución para procesar eventos. La solución debe tener la capacidad de escalar dentro y fuera en función del número de eventos que recibe la solución. Si se produce un error de procesamiento, el evento debe pasar a una cola separada para su revisión.
Qué solución cumplirá con estos requisitos?
A.
Enviar los detalles del evento a un tema de Amazon Simple Notification Service (Amazon SNS). Configure una función de AWS Lambda como suscriptor del tema SNS para procesar los eventos. Agregue un destino en caso de fallo a la función. Establezca una cola de Amazon Simple Queue Service (Amazon SQS) como destino.
B.
Publique eventos en una cola de Amazon Simple Queue Service (Amazon SQS). Cree un grupo de Auto Scaling de Amazon EC2. Configure el grupo Auto Scaling para escalar de entrada y salida en función de la métrica ApprogetageOfOldestMessage de la cola. Configure la aplicación para escribir mensajes fallidos en una cola de letra muerta.
C.
Escribir eventos en una tabla de Amazon DynamoDB. Configure una transmisión de DynamoDB para la tabla. Configure la transmisión para invocar una función de AWS Lambda. Configure la función Lambda para procesar los eventos.
D.
Publica eventos en un autobús de eventos Amazon EventBndge. Cree y ejecute una aplicación en una instancia de Amazon EC2 con un grupo de Auto Scaling que esté detrás de un balanceador de carga de aplicaciones (ALB). Establezca el ALB como el objetivo del autobús de eventos. Configure el bus de eventos para reintentar eventos. Escribir mensajes en una cola de letra muerta si la aplicación no puede procesar los mensajes.
ResponderDiscusión
Correct Answer: A
La mejor solución para procesar eventos con escalado automático basado en el número de eventos y la capacidad de manejar errores de procesamiento moviendo eventos a una cola separada es usar Amazon SNS con una función de AWS Lambda. En esta configuración, los eventos se envían a un tema de Amazon SNS, que activa una función de AWS Lambda para procesar los eventos. AWS Lambda escala automáticamente en función del número de eventos, lo que garantiza un manejo eficiente de diferentes cargas de eventos. Además, AWS Lambda admite la configuración de un destino en caso de fallo, donde se puede establecer una cola separada de Amazon SQS como destino para los eventos que no se procesan. Esta configuración cumple con todos los requisitos: se escala de manera eficiente en función del número de eventos y proporciona una cola separada para revisar los errores de procesamiento.
Question 180 of 529
Una empresa ejecuta un motor de procesamiento en la nube de AWS. El motor procesa datos ambientales de centros logísticos para calcular un índice de sustentabilidad. La compañía cuenta con millones de dispositivos en centros logísticos que se encuentran repartidos por toda Europa. Los dispositivos envían información al motor de procesamiento a través de una API RESTful.
La API experimenta ráfagas impredecibles de tráfico. La empresa debe implementar una solución para procesar todos los datos que los dispositivos envían al motor de procesamiento. La pérdida de datos es inaceptable.
Qué solución cumplirá con estos requisitos?
A.
Cree un balanceador de carga de aplicaciones (ALB) para la API RESTful. Cree una cola de Amazon Simple Queue Service (Amazon SQS). Cree un oyente y un grupo objetivo para el ALB Agregue la cola SQS como destino. Utilice un contenedor que se ejecute en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate para procesar los mensajes en la cola.
B.
Cree una API HTTP de Amazon API Gateway que implemente la API RESTful. Cree una cola de Amazon Simple Queue Service (Amazon SQS). Cree una integración de servicio API Gateway con la cola SQS. Cree una función de AWS Lambda para procesar mensajes en la cola SQS.
C.
Cree una API REST de Amazon API Gateway que implemente la API RESTful. Cree una flota de instancias de Amazon EC2 en un grupo de Auto Scaling. Cree una integración de proxy de grupo API Gateway Auto Scaling. Utilice las instancias EC2 para procesar los datos entrantes.
D.
Cree una distribución de Amazon CloudFront para la API RESTful. Cree una transmisión de datos en Amazon Kinesis Data Stream. Establezca el flujo de datos como el origen de la distribución. Cree una función de AWS Lambda para consumir y procesar datos en el flujo de datos.
ResponderDiscusión
Correct Answer: B
En este escenario, usar la API HTTP de Amazon API Gateway integrada con Amazon Simple Queue Service (SQS) es la solución óptima. API Gateway proporciona una interfaz escalable para manejar ráfagas de tráfico de manera eficiente. SQS actúa como búfer para almacenar datos entrantes, asegurando que no se pierdan datos durante los picos de tráfico. AWS Lambda puede procesar los mensajes de la cola SQS, proporcionando una solución informática sin servidor que escala automáticamente según sea necesario. Esta combinación garantiza la durabilidad de los datos y un procesamiento confiable sin pérdidas.
Question 181 of 529
Una empresa está diseñando su configuración de red en la nube de AWS. La compañía utiliza AWS Organizations para administrar una configuración multicuenta. La compañía cuenta con tres OU. Cada unidad organizativa contiene más de 100 cuentas de AWS. Cada cuenta tiene una única VPC y todas las VPC de cada unidad organizativa están en la misma región de AWS.
Los rangos CIDR para todas las cuentas de AWS no se superponen. La compañía necesita implementar una solución en la que las VPC en la misma unidad organizativa puedan comunicarse entre sí pero no puedan comunicarse con VPC en otras unidades organizativas.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un conjunto de pila de AWS CloudFormation que establezca pares de VPC entre cuentas en cada unidad organizativa. Aprovisione el conjunto de pila en cada unidad organizativa.
B.
En cada unidad organizativa, cree una cuenta de red dedicada que tenga una sola VPC. Comparta esta VPC con todas las demás cuentas de la unidad organizativa mediante AWS Resource Access Manager (AWS RAM). Cree una conexión de interconexión de VPC entre la cuenta de red y cada cuenta de la unidad organizativa.
C.
Aprovisione una puerta de enlace de tránsito en una cuenta en cada unidad organizativa. Comparta la puerta de enlace de tránsito en toda la organización mediante AWS Resource Access Manager (AWS RAM). Cree adjuntos de VPC de puerta de enlace de tránsito para cada VPC.
D.
En cada unidad organizativa, cree una cuenta de red dedicada que tenga una sola VPC. Establecer una conexión VPN entre la cuenta de red y las otras cuentas en la unidad organizativa. Utilice software de enrutamiento de terceros para enrutar el tráfico transitivo entre las VPC.
ResponderDiscusión
Correct Answer: C
Aprovisionar una puerta de enlace de tránsito en una cuenta de cada unidad organizativa y compartir la puerta de enlace de tránsito en toda la organización mediante el uso de AWS Resource Access Manager (AWS RAM) es la solución óptima. Esta configuración permite que las VPC dentro de la misma unidad organizativa se comuniquen entre sí mientras las aíslan de las VPC en diferentes unidades organizativas. AWS Transit Gateway simplifica la arquitectura de red al actuar como un concentrador que interconecta las VPC, evitando la complejidad y limitando las restricciones del emparejamiento de VPC. Además, este método minimiza la sobrecarga operativa en comparación con la administración de numerosas conexiones de interconexión de VPC individuales o VPN con software de enrutamiento de terceros.
Question 182 of 529
Una empresa está migrando una aplicación a AWS. Quiere utilizar los servicios totalmente gestionados tanto como sea posible durante la migración. La empresa necesita almacenar documentos importantes de gran tamaño dentro de la aplicación con los siguientes requisitos:
1. Los datos deben ser altamente duraderos y disponibles
2. Los datos siempre deben estar encriptados en reposo y en tránsito
3. La clave de cifrado debe ser administrada por la empresa y rotada periódicamente
Cuál de las siguientes soluciones debería recomendar el arquitecto de soluciones?
A.
Implemente la puerta de enlace de almacenamiento en AWS en modo de puerta de enlace de archivos. Utilice el cifrado de volúmenes de Amazon EBS con una clave de AWS KMS para cifrar los volúmenes de la puerta de enlace de almacenamiento.
B.
Utilice Amazon S3 con una política de bucket para aplicar HTTPS para las conexiones al bucket y para aplicar el cifrado del lado del servidor y AWS KMS para el cifrado de objetos.
C.
Utilice Amazon DynamoDB con SSL para conectarse a DynamoDB. Utilice una clave de AWS KMS para cifrar objetos DynamoDB en reposo.
D.
Implemente instancias con volúmenes de Amazon EBS conectados para almacenar estos datos. Utilice el cifrado de volumen de EBS con una clave de AWS KMS para cifrar los datos.
ResponderDiscusión
Correct Answer: B
Amazon S3 es un servicio totalmente administrado diseñado para almacenar y recuperar cualquier cantidad de datos en cualquier momento. S3 proporciona alta durabilidad y disponibilidad para los datos almacenados. También es compatible con el cifrado del lado del servidor y le permite aplicar el cifrado en tránsito mediante una política de bucket para aplicar HTTPS para las conexiones. Además, la integración de AWS Key Management Service (KMS) permite a la compañía administrar y rotar periódicamente las claves de cifrado. Por lo tanto, cumple con todos los requisitos especificados de alta durabilidad, disponibilidad y administración de cifrado.
Question 183 of 529
La API pública de una empresa se ejecuta como tareas en Amazon Elastic Container Service (Amazon ECS). Las tareas se ejecutan en AWS Fargate detrás de un balanceador de carga de aplicaciones (ALB) y se configuran con Service Auto Scaling para las tareas basadas en la utilización de la CPU. Este servicio ha estado funcionando bien desde hace varios meses.
Recientemente, el rendimiento de la API se ralentizó y dejó inutilizable la aplicación. La compañía descubrió que se había producido un número significativo de ataques de inyección SQL contra la API y que el servicio API se había escalado a su cantidad máxima.
Un arquitecto de soluciones necesita implementar una solución que evite que los ataques de inyección SQL lleguen al servicio de API de ECS. La solución debe permitir el tránsito legítimo y maximizar la eficiencia operativa.
Qué solución cumple con estos requisitos?
A.
Cree una nueva ACL web de AWS WAF para monitorear las solicitudes HTTP y las solicitudes HTTPS que se reenvían al ALB frente a las tareas de ECS.
B.
Cree una nueva implementación de AWS WAF Bot Control. Agregue una regla en el grupo de reglas administradas de AWS WAF Bot Control para monitorear el tráfico y permitir solo el tráfico legítimo al ALB frente a las tareas de ECS.
C.
Cree una nueva ACL web de AWS WAF. Agregue una nueva regla que bloquee las solicitudes que coincidan con el grupo de reglas de la base de datos SQL. Establezca la ACL web para permitir el resto del tráfico que no coincida con esas reglas. Adjuntar la ACL web al ALB frente a las tareas de ECS.
D.
Cree una nueva ACL web de AWS WAF. Cree un nuevo conjunto de IP vacío en AWS WAF. Agregue una nueva regla a la ACL web para bloquear las solicitudes que se originan a partir de direcciones IP en el nuevo conjunto de IP. Cree una función de AWS Lambda que raspe los registros de API en busca de direcciones IP que envían ataques de inyección SQL y agregue esas direcciones IP al conjunto de IP. Adjuntar la ACL web al ALB frente a las tareas de ECS.
ResponderDiscusión
Correct Answer: C
Para evitar ataques de inyección SQL mientras se permite el tráfico legítimo y se maximiza la eficiencia operativa, la mejor solución consiste en crear una nueva ACL web de AWS WAF y agregar una regla que bloquee las solicitudes que coincidan con el grupo de reglas de la base de datos SQL. El grupo de reglas de base de datos SQL contiene reglas predefinidas para bloquear patrones de solicitud que podrían explotar bases de datos SQL, como los ataques de inyección SQL. Adjuntar esta ACL web al balanceador de carga de aplicaciones garantiza que las solicitudes dañinas se bloqueen antes de llegar a las tareas de ECS, evitando así ataques y manteniendo el rendimiento del servicio API.
Question 184 of 529
Una compañía ambiental está desplegando sensores en las principales ciudades de todo el país para medir la calidad del aire. Los sensores se conectan a AWS IoT Core para ingerir lecturas de datos de series temporales. La compañía almacena los datos en Amazon DynamoDB.
Para la continuidad del negocio, la compañía debe tener la capacidad de ingerir y almacenar datos en dos regiones de AWS.
Qué solución cumplirá con estos requisitos?
A.
Cree una política de enrutamiento de conmutación por error de alias de Amazon Route 53 con valores para puntos finales de datos de AWS IoT Core en ambas regiones Migrar datos a tablas globales de Amazon Aurora.
B.
Cree una configuración de dominio para AWS IoT Core en cada región. Cree una política de enrutamiento basada en latencia de Amazon Route 53. Utilice puntos finales de datos de AWS IoT Core en ambas regiones como valores. Migre los datos a Amazon MemoryDB para Redis y configure la replicación entre regiones.
C.
Cree una configuración de dominio para AWS IoT Core en cada región. Cree una comprobación de estado de Amazon Route 53 que evalúe el estado de la configuración del dominio. Cree una política de enrutamiento de conmutación por error con valores para el nombre de dominio a partir de las configuraciones de dominio AWS IoT Core. Actualice la tabla DynamoDB a una tabla global.
D.
Cree una política de enrutamiento basada en latencia de Amazon Route 53. Utilice puntos finales de datos de AWS IoT Core en ambas regiones como valores. Configure transmisiones de DynamoDB y replicación de datos entre regiones.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de ingerir y almacenar datos en dos regiones de AWS, debe configurar un dominio para AWS IoT Core en cada región y garantizar la continuidad del negocio a través de un mecanismo de conmutación por error. El uso de comprobaciones de estado de Amazon Route 53 y una política de enrutamiento de conmutación por error garantiza que se puedan ingerir datos si una región deja de estar disponible. La actualización de DynamoDB a una tabla global proporciona una replicación entre regiones sin problemas, lo que permite almacenar los datos de manera consistente en todas las regiones. Esta configuración garantiza una alta disponibilidad y redundancia de datos, cumpliendo con los requisitos de la compañía.
Question 185 of 529
Una empresa utiliza AWS Organizations para una configuración multicuenta en la nube de AWS. El equipo financiero de la compañía cuenta con una aplicación de procesamiento de datos que utiliza AWS Lambda y Amazon DynamoDB. El equipo de marketing de la compañía quiere acceder a los datos que se almacenan en la tabla DynamoDB.
La tabla DynamoDB contiene datos confidenciales. El equipo de marketing solo puede tener acceso a atributos específicos de datos en la tabla DynamoDB. El equipo de finanzas y el equipo de marketing tienen cuentas de AWS separadas.
Qué debe hacer un arquitecto de soluciones para proporcionar al equipo de marketing el acceso adecuado a la tabla DynamoDB?
A.
Cree un SCP para otorgar acceso a la cuenta de AWS del equipo de marketing a los atributos específicos de la tabla DynamoDB. Adjuntar el SCP a la OU del equipo de finanzas.
B.
Cree un rol de IAM en la cuenta del equipo financiero mediante las condiciones de política de IAM para atributos específicos de DynamoDB (control de acceso detallado). Establecer confianza con la cuenta del equipo de marketing. En la cuenta del equipo de marketing, cree un rol de IAM que tenga permisos para asumir el rol de IAM en la cuenta del equipo de finanzas.
C.
Cree una política de IAM basada en recursos que incluya condiciones para atributos específicos de DynamoDB (control de acceso detallado). Adjunte la política a la tabla DynamoDB. En la cuenta del equipo de marketing, cree un rol de IAM que tenga permisos para acceder a la tabla DynamoDB en la cuenta del equipo de finanzas.
D.
Cree un rol de IAM en la cuenta del equipo de finanzas para acceder a la tabla DynamoDB. Utilice un límite de permisos de IAM para limitar el acceso a los atributos específicos. En la cuenta del equipo de marketing, cree un rol de IAM que tenga permisos para asumir el rol de IAM en la cuenta del equipo de finanzas.
ResponderDiscusión
Correct Answer: B
Para proporcionar al equipo de marketing acceso a atributos específicos en la tabla DynamoDB mientras se garantiza la seguridad y el control de acceso adecuado, el mejor enfoque es crear un rol de IAM en la cuenta del equipo de finanzas con condiciones de política para un control de acceso detallado. Este rol debe establecer confianza con la cuenta del equipo de marketing. La cuenta del equipo de marketing debería entonces poder asumir este rol, permitiéndoles el acceso necesario determinado por las políticas establecidas. Esta configuración aprovecha los roles de IAM y las condiciones de política de manera efectiva para controlar el acceso y garantizar que solo los atributos requeridos sean accesibles, manteniendo la confidencialidad de los datos.
Question 186 of 529
Un arquitecto de soluciones está creando una aplicación que almacena objetos en un bucket de Amazon S3. El arquitecto de soluciones debe implementar la aplicación en dos regiones de AWS que se utilizarán simultáneamente. Los objetos en los dos cubos S3 deben permanecer sincronizados entre sí.
Qué combinación de pasos cumplirá estos requisitos con la menor sobrecarga operativa? (Elija tres.)
A.
Crear un punto de acceso multi-región S3 Cambiar la aplicación para referirse al punto de acceso multi-región
B.
Configurar la replicación entre regiones S3 (CRR) bidireccional entre los dos buckets S3
C.
Modificar la aplicación para almacenar objetos en cada bucket S3
D.
Crear una regla de ciclo de vida de S3 para cada bucket S3 para copiar objetos de un bucket S3 al otro bucket S3
E.
Habilitar versiones de S3 para cada bucket S3
F.
Configurar una notificación de evento para cada bucket de S3 para invocar una función de AWS Lambda para copiar objetos de un bucket S3 al otro bucket S3
ResponderDiscusión
Correct Answer: A, B, E
Para garantizar que los objetos de los dos buckets S3 permanezcan sincronizados entre sí mientras se minimiza la sobrecarga operativa, debe tomar los siguientes pasos: 1. Cree un Punto de Acceso Multi-Región S3. Esto permite que la aplicación se refiera a un único punto final global para acceder al servicio S3, simplificando la configuración de la aplicación y la administración del tráfico. 2. Configure la replicación entre regiones (CRR) S3 bidireccional. Esto asegura que cualquier cambio realizado en un bucket S3 se replique automáticamente en el otro bucket, manteniéndolos sincronizados. 3. Habilite el control de versiones de S3 para ambos buckets S3. El control de versiones es un requisito previo para habilitar la replicación entre regiones, ya que ayuda a rastrear los cambios en los objetos y garantizar la coherencia de los datos entre los dos buckets.
Question 187 of 529
Una empresa tiene una plataforma IoT que se ejecuta en un entorno local. La plataforma consiste en un servidor que se conecta a dispositivos IoT mediante el protocolo MQTT. La plataforma recopila datos de telemetría de los dispositivos al menos una vez cada 5 minutos. La plataforma también almacena metadatos de dispositivos en un clúster MongoDB.
Una aplicación que se instala en una máquina local ejecuta trabajos periódicos para agregar y transformar la telemetría y los metadatos del dispositivo. La aplicación crea informes que los usuarios ven mediante otra aplicación web que se ejecuta en la misma máquina local. Los trabajos periódicos tardan entre 120 y 600 segundos en ejecutarse. Sin embargo, la aplicación web siempre se está ejecutando.
La compañía está moviendo la plataforma a AWS y debe reducir la sobrecarga operativa de la pila.
Qué combinación de pasos cumplirá estos requisitos con la menor sobrecarga operativa? (Elija tres.)
A.
Utilice las funciones de AWS Lambda para conectarse a los dispositivos IoT
B.
Configurar los dispositivos IoT para publicarlos en AWS IoT Core
C.
Escribir los metadatos en una base de datos MongoDB autoadministrada en una instancia de Amazon EC2
D.
Escribir los metadatos en Amazon DocumentDB (con compatibilidad con MongoDB)
E.
Utilice las máquinas de estado de AWS Step Functions con tareas de AWS Lambda para preparar los informes y escribir los informes en Amazon S3. Utilice Amazon CloudFront con un origen S3 para servir los informes
F.
Utilice un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) con instancias de Amazon EC2 para preparar los informes. Usar un controlador de ingreso en el clúster EKS para servir los informes
ResponderDiscusión
Correct Answer: B, D, E
Para cumplir con los requisitos con la menor sobrecarga operativa, primero configure los dispositivos IoT para publicarlos en AWS IoT Core, que es un servicio administrado diseñado para manejar la conectividad IoT de manera transparente y segura. A continuación, para manejar los metadatos del dispositivo de manera eficiente, use Amazon DocumentDB (con compatibilidad con MongoDB), un servicio de base de datos totalmente administrado, escalable y de alta disponibilidad que es compatible con sus cargas de trabajo MongoDB existentes. Por último, utilice AWS Step Functions junto con AWS Lambda para preparar y escribir los informes en Amazon S3. Step Functions puede organizar los pasos de su flujo de trabajo, mientras que Lambda le permite ejecutar código sin aprovisionar servidores. El uso de Amazon CloudFront para servir los informes almacenados en S3 garantiza un acceso rápido y confiable a los informes con un mantenimiento mínimo.
Question 188 of 529
Una compañía global de fabricación planea migrar la mayoría de sus aplicaciones a AWS. Sin embargo, la compañía está preocupada por las aplicaciones que necesitan permanecer dentro de un país específico o en el centro de datos local central de la compañía debido a los requisitos reglamentarios de datos o requisitos de latencia de milisegundos de un solo dígito. A la compañía también le preocupan las aplicaciones que aloja en algunos de sus sitios de fábrica, donde existe una infraestructura de red limitada.
La compañía quiere una experiencia de desarrollador consistente para que sus desarrolladores puedan construir aplicaciones una vez e implementarlas en las instalaciones, en la nube o en una arquitectura híbrida. Los desarrolladores deben poder utilizar las mismas herramientas, API y servicios que les son familiares.
Qué solución proporcionará una experiencia híbrida consistente para cumplir con estos requisitos?
A.
Migre todas las aplicaciones a la región de AWS más cercana que cumpla con las normas. Configure una conexión AWS Direct Connect entre el centro de datos central local y AWS. Implemente una puerta de enlace de Direct Connect.
B.
Utilice los dispositivos optimizados para el almacenamiento de AWS Snowball Edge para las aplicaciones que tienen requisitos reglamentarios de datos o requisitos de latencia de milisegundos de un solo dígito. Conserva los dispositivos en las instalaciones. Implemente AWS Wavelength para alojar las cargas de trabajo en los sitios de fábrica.
C.
Instale AWS Outposts para las aplicaciones que tengan requisitos reglamentarios de datos o requisitos de latencia de milisegundos de un solo dígito. Utilice los dispositivos optimizados para computación de AWS Snowball Edge para alojar las cargas de trabajo en los sitios de fábrica.
D.
Migre las aplicaciones que tienen requisitos normativos de datos o requisitos de latencia de milisegundos de un solo dígito a una zona local de AWS. Implemente AWS Wavelength para alojar las cargas de trabajo en los sitios de fábrica.
ResponderDiscusión
Correct Answer: C
Para proporcionar una experiencia híbrida consistente y cumplir con los requisitos reglamentarios de datos o las necesidades de latencia, la compañía debe usar AWS Outposts para aplicaciones que requieran cumplimiento de datos y rendimiento de milisegundos de un solo dígito y baja latencia, ya que Outposts se pueden instalar en las instalaciones. Para sitios de fábrica con infraestructura de red limitada, el uso de dispositivos AWS Snowball Edge Compute Optimized es adecuado porque proporcionan capacidades de computación y almacenamiento locales y pueden ejecutar cargas de trabajo incluso con malas condiciones de red. Esta combinación permite a los desarrolladores utilizar las mismas herramientas, API y servicios de AWS en entornos locales y en la nube, lo que garantiza una experiencia de desarrollo unificada.
Question 189 of 529
Una empresa está actualizando una aplicación que los clientes utilizan para realizar pedidos en línea. El número de ataques a la aplicación por parte de malos actores ha aumentado recientemente.
La compañía alojará la aplicación actualizada en un clúster de Amazon Elastic Container Service (Amazon ECS). La compañía utilizará Amazon DynamoDB para almacenar datos de aplicaciones. Un balanceador de carga de aplicaciones (ALB) público proporcionará a los usuarios finales acceso a la aplicación. La compañía debe prevenir ataques y garantizar la continuidad del negocio con interrupciones mínimas del servicio durante un ataque en curso.
Qué combinación de pasos cumplirá con estos requisitos de manera más rentable? (Elija dos.)
A.
Cree una distribución de Amazon CloudFront con el ALB como origen. Agregue un encabezado personalizado y un valor aleatorio en el dominio de CloudFront. Configure el ALB para reenviar condicionalmente el tráfico si el encabezado y el valor coinciden.
B.
Implementar la aplicación en dos regiones de AWS. Configure Amazon Route 53 para enrutar a ambas regiones con el mismo peso.
C.
Configurar el escalado automático para las tareas de Amazon ECS Cree un clúster de acelerador de DynamoDB (DAX).
D.
Configure Amazon ElastiCache para reducir la sobrecarga en DynamoDB.
E.
Implemente una ACL web de AWS WAF que incluya un grupo de reglas apropiado. Asocie la ACL web con la distribución de Amazon CloudFront.
ResponderDiscusión
Correct Answer: A, E
Para prevenir ataques y garantizar la continuidad del negocio con interrupciones mínimas del servicio durante un ataque continuo, dos medidas son rentables y están alineadas con los requisitos. Primero, crear una distribución de Amazon CloudFront con el ALB como origen, agregar un encabezado personalizado y un valor aleatorio en el dominio de CloudFront y configurar el ALB para reenviar tráfico condicionalmente si el encabezado y el valor coinciden ayudan a filtrar las solicitudes potencialmente maliciosas. Esta configuración proporciona una capa de seguridad contra ataques. En segundo lugar, implementar una ACL web de AWS WAF que incluya un grupo de reglas apropiado y asociarlo con la distribución de Amazon CloudFront agrega una capa adicional de protección bloqueando patrones de ataque comunes como la inyección SQL y el cross-site scripting (XSS). Esta combinación garantiza que el sistema esté bien protegido en el front-end (CloudFront y WAF) al tiempo que aborda los requisitos de rentabilidad y seguridad.
Question 190 of 529
Una empresa ejecuta una aplicación web en AWS. La aplicación web ofrece contenido estático de un bucket de Amazon S3 que está detrás de una distribución de Amazon CloudFront. La aplicación sirve contenido dinámico mediante el uso de un balanceador de carga de aplicaciones (ALB) que distribuye las solicitudes a una flota de instancias de Amazon EC2 en grupos de Auto Scaling. La aplicación utiliza una configuración de nombre de dominio en Amazon Route 53.
Algunos usuarios reportaron problemas ocasionales cuando los usuarios intentaban acceder al sitio web durante las horas pico. Un equipo de operaciones descubrió que el ALB a veces devolvía errores HTTP 503 Service Unavailable. La compañía quiere mostrar una página de mensaje de error personalizada cuando ocurren estos errores. La página debe mostrarse inmediatamente para este código de error.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Configure una política de enrutamiento de conmutación por error de Route 53. Configure una comprobación de estado para determinar el estado del punto final de ALB y para la conmutación por error al punto final del bucket S3 de conmutación por error.
B.
Cree una segunda distribución de CloudFront y un sitio web estático de S3 para alojar la página de error personalizada. Configure una política de enrutamiento de conmutación por error de Route 53. Utilice una configuración activo-pasiva entre las dos distribuciones.
C.
Cree un grupo de origen de CloudFront que tenga dos orígenes. Establezca el punto final de ALB como origen primario. Para el origen secundario, establezca un bucket S3 que esté configurado para alojar un sitio web estático Configure la conmutación por error de origen para la distribución de CloudFront. Actualice el sitio web estático de S3 para incorporar la página de error personalizada.
D.
Cree una función CloudFront que valide cada código de respuesta HTTP que devuelve el ALB. Cree un sitio web estático de S3 en un bucket S3. Cargue la página de error personalizada en el bucket S3 como conmutación por error. Actualiza la función para leer el bucket S3 y servir la página de error a los usuarios finales.
ResponderDiscusión
Correct Answer: C
La mejor solución para cumplir con el requisito de mostrar una página de mensaje de error personalizada inmediatamente cuando se produce un error HTTP 503 es crear un grupo de origen de CloudFront con dos orígenes. El punto final ALB se establecerá como el origen principal, y un bucket S3 que aloja un sitio web estático con la página de error personalizada se establecerá como origen secundario. Al configurar la conmutación por error de origen para la distribución de CloudFront, CloudFront cambiará automáticamente al origen secundario y servirá la página de error personalizada rápidamente cada vez que el origen primario devuelva un código de error 503. Este enfoque minimiza la sobrecarga operativa al aprovechar las capacidades integradas de CloudFront para la conmutación por error de origen y las respuestas de error personalizadas, lo que garantiza una experiencia perfecta para los usuarios durante las horas pico cuando ocurren errores.
Question 191 of 529
Una empresa planea migrar una aplicación a AWS. La aplicación se ejecuta como un contenedor Docker y utiliza un recurso compartido de archivos NFS versión 4.
Un arquitecto de soluciones debe diseñar una solución contenerizada segura y escalable que no requiera aprovisionamiento o administración de la infraestructura subyacente.
Qué solución cumplirá con estos requisitos?
A.
Implemente los contenedores de aplicaciones mediante Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate. Utilice Amazon Elastic File System (Amazon EFS) para almacenamiento compartido. Haga referencia al ID del sistema de archivos EFS, el punto de montaje del contenedor y el rol de IAM de autorización EFS en la definición de tarea ECS.
B.
Implemente los contenedores de aplicaciones mediante Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate. Utilice Amazon FSx for Lustre para almacenamiento compartido. Haga referencia al ID del sistema de archivos FSx para Lustre, el punto de montaje del contenedor y el rol de IAM de autorización FSx para Lustre en la definición de tarea ECS.
C.
Implemente los contenedores de aplicaciones mediante Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento de Amazon EC2 y el escalado automático activados. Utilice Amazon Elastic File System (Amazon EFS) para almacenamiento compartido. Monte el sistema de archivos EFS en las instancias del contenedor ECS. Agregue el rol de IAM de autorización EFS al perfil de instancia EC2.
D.
Implemente los contenedores de aplicaciones mediante Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento de Amazon EC2 y el escalado automático activados. Utilice volúmenes de Amazon Elastic Block Store (Amazon EBS) con Multi-Attach habilitado para almacenamiento compartido. Adjunte los volúmenes de EBS a instancias de contenedor ECS. Agregue el rol IAM de autorización de EBS a un perfil de instancia de EC2.
ResponderDiscusión
Correct Answer: A
Para migrar una aplicación que se ejecuta como un contenedor Docker con recurso compartido de archivos NFS versión 4 a AWS sin requerir la administración o el aprovisionamiento de la infraestructura subyacente, la mejor solución es usar Amazon ECS con el tipo de lanzamiento Fargate. Amazon EFS proporciona un servicio de almacenamiento de archivos escalable diseñado específicamente para ser utilizado con NFS, lo que lo convierte en una opción ideal para el almacenamiento compartido en este contexto. Amazon ECS con Fargate resume la administración de servidores, lo que permite a la empresa centrarse en implementar y administrar aplicaciones en lugar de la infraestructura subyacente. Al hacer referencia al ID del sistema de archivos EFS, el punto de montaje del contenedor y el rol de IAM de autorización EFS en la definición de tarea de ECS, esta configuración garantiza una solución en contenedores segura y escalable.
Question 192 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. La lógica empresarial principal se ejecuta en un conjunto de instancias de Amazon EC2 en un grupo de Auto Scaling. Un balanceador de carga de aplicaciones (ALB) distribuye el tráfico a las instancias EC2. Amazon Route 53 registro api.example.com está apuntando a la ALB.
El equipo de desarrollo de la compañía realiza importantes actualizaciones a la lógica de negocio. La compañía tiene una regla de que cuando se implementan cambios, solo el 10% de los clientes pueden recibir la nueva lógica durante una ventana de prueba. Un cliente debe usar la misma versión de la lógica de negocio durante la ventana de prueba.
Cómo debería implementar la compañía las actualizaciones para cumplir con estos requisitos?
A.
Cree un segundo ALB e implemente la nueva lógica en un conjunto de instancias EC2 en un nuevo grupo de Auto Scaling. Configure el ALB para distribuir el tráfico a las instancias EC2. Actualice el registro Route 53 para usar el enrutamiento ponderado y señale el registro a ambos ALB.
B.
Cree un segundo grupo objetivo al que haga referencia el Aldeploy la nueva lógica a instancias EC2 en este nuevo grupo objetivo. Actualice la regla de escucha ALB para usar grupos objetivo ponderados. Configurar la adherencia del grupo objetivo de ALB.
C.
Cree una nueva configuración de lanzamiento para el grupo Auto Scaling. Especifique la configuración de inicio para usar la política AutoScalingRollingUpdate y establezca la opción MaxBatchSize en 10. Reemplace la configuración de inicio en el grupo Auto Scaling. Desplegar los cambios.
D.
Cree un segundo grupo de Auto Scaling al que haga referencia el ALB. Implemente la nueva lógica en un conjunto de instancias EC2 en este nuevo grupo de Auto Scaling. Cambie el algoritmo de enrutamiento ALB a solicitudes menos pendientes (LOR). Configurar la adherencia de la sesión ALB.
ResponderDiscusión
Correct Answer: B
Para cumplir con el requisito de que solo el 10% de los clientes reciban la nueva lógica de negocio durante una ventana de prueba y que se adhieran a la misma versión en toda la ventana, la compañía debe crear un segundo grupo objetivo en el ALB e implementar la nueva lógica en él. El uso de grupos objetivo ponderados y la configuración de la adherencia del grupo objetivo ALB garantiza que un porcentaje específico de tráfico se dirija a la nueva lógica y que cada cliente continúe enrutándose a la misma instancia de la lógica de negocio.
Question 193 of 529
Una gran empresa educativa introdujo recientemente Amazon Workspaces para proporcionar acceso a aplicaciones internas en múltiples universidades. La compañía está almacenando perfiles de usuario en un sistema de archivos de Amazon FSx para Windows File Server. El sistema de archivos está configurado con un alias DNS y está conectado a un Active Directory autoadministrado. A medida que más usuarios comienzan a usar los espacios de trabajo, el tiempo de inicio de sesión aumenta a niveles inaceptables.
Una investigación revela una degradación en el rendimiento del sistema de archivos. La compañía creó el sistema de archivos en almacenamiento HDD con un rendimiento de 16 MBps. Un arquitecto de soluciones debe mejorar el rendimiento del sistema de archivos durante una ventana de mantenimiento definida.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos con el MENOR esfuerzo administrativo?
A.
Utilice AWS Backup para crear una copia de seguridad puntual del sistema de archivos. Restaure la copia de seguridad a un nuevo sistema de archivos FSx para Windows File Server. Seleccione SSD como el tipo de almacenamiento. Seleccione 32 MBps como capacidad de rendimiento. Cuando se complete el proceso de copia de seguridad y restauración, ajuste el alias DNS en consecuencia. Eliminar el sistema de archivos original.
B.
Desconectar a los usuarios del sistema de archivos. En la consola de Amazon FSx, actualice la capacidad de rendimiento a 32 MBps. Actualice el tipo de almacenamiento a SSD. Vuelva a conectar a los usuarios al sistema de archivos.
C.
Implementar un agente AWS DataSync en una nueva instancia de Amazon EC2. Crear una tarea. Configure el sistema de archivos existente como ubicación de origen. Configure un nuevo sistema de archivos FSx para Windows File Server con almacenamiento SSD y 32 MBps de rendimiento como ubicación de destino. Programar la tarea. Cuando se complete la tarea, ajuste el alias DNS en consecuencia. Eliminar el sistema de archivos original.
D.
Habilite las copias de sombra en el sistema de archivos existente mediante un comando de Windows PowerShell. Programe el trabajo de shadow copy para crear una copia de seguridad puntual del sistema de archivos. Elija restaurar versiones anteriores. Cree un nuevo sistema de archivos FSx para Windows File Server con almacenamiento SSD y 32 MBps de rendimiento. Cuando se complete el trabajo de copia, ajuste el alias DNS. Eliminar el sistema de archivos original.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos de mejora del rendimiento con el menor esfuerzo administrativo, el mejor enfoque es actualizar la capacidad de rendimiento y el tipo de almacenamiento directamente dentro de la consola de Amazon FSx. Al desconectar a los usuarios temporalmente, aumentar la capacidad de rendimiento a 32 MBps y actualizar el tipo de almacenamiento a SSD, el rendimiento del sistema de archivos se puede mejorar significativamente sin necesidad de crear y administrar copias de seguridad, implementar agentes adicionales o manejar procesos de restauración complejos. Este método aprovecha las capacidades integradas de Amazon FSx para realizar actualizaciones eficientes y minimiza la sobrecarga administrativa.
Question 194 of 529
Una empresa aloja una aplicación en AWS. La aplicación lee y escribe objetos que se almacenan en un solo bucket de Amazon S3. La compañía debe modificar la aplicación para implementar la aplicación en dos regiones de AWS.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Configure una distribución de Amazon CloudFront con el bucket S3 como origen. Implementar la aplicación en una segunda región Modifique la aplicación para usar la distribución CloudFront. Utilice AWS Global Accelerator para acceder a los datos del bucket S3.
B.
Crea un nuevo bucket S3 en una segunda Región. Configure la replicación bidireccional de S3 entre regiones (CRR) entre el bucket S3 original y el nuevo bucket S3. Configure un Punto de Acceso Multi-Región S3 que utilice ambos buckets S3. Implemente una aplicación modificada en ambas regiones.
C.
Crear un nuevo bucket S3 en una segunda región Implemente la aplicación en la segunda región. Configure la aplicación para usar el nuevo bucket S3. Configure S3 Cross-Region Replication (CRR) desde el bucket S3 original al nuevo bucket S3.
D.
Configure un punto final de puerta de enlace S3 con el bucket S3 como origen. Desplegar la aplicación en una segunda región. Modifique la aplicación para usar el nuevo punto final de puerta de enlace S3. Utilice S3 Intelligent-Tiering en el bucket S3.
ResponderDiscusión
Correct Answer: B
Para cumplir con el requisito de implementar la aplicación en dos regiones de AWS con la menor sobrecarga operativa, la mejor solución es crear un nuevo bucket S3 en la segunda región y configurar la replicación bidireccional de S3 Cross-Region (CRR) entre el bucket S3 original y el nuevo bucket S3. Además, la configuración de un Punto de Acceso Multi-Región S3 que utiliza ambos buckets S3 simplifica el acceso desde la aplicación. Esta configuración garantiza que los datos se sincronicen en ambas regiones y proporciona una forma perfecta para que la aplicación interactúe con los datos, minimizando así la sobrecarga operativa involucrada en la administración manual de la consistencia de los datos.
Question 195 of 529
Una compañía de juegos en línea necesita realojar su plataforma de juegos en AWS. La aplicación de juegos de la compañía requiere procesamiento de computación de alto rendimiento (HPC) y tiene una tabla de clasificación que cambia con frecuencia. Una instancia de Ubuntu que está optimizada para la generación de cómputos aloja una aplicación Node.js para la visualización de juegos. El estado del juego se rastrea en una instancia de Redis local.
La empresa necesita una estrategia de migración que optimice el rendimiento de las aplicaciones.
Qué solución cumplirá con estos requisitos?
A.
Cree un grupo de Auto Scaling de instancias puntuales de Amazon EC2 m5.large detrás de un balanceador de carga de aplicaciones. Utilice un clúster de Amazon ElastlCache para Redis para mantener la tabla de clasificación.
B.
Cree un grupo de Auto Scaling de instancias puntuales de Amazon EC2 c5.large detrás de un balanceador de carga de aplicaciones. Utilice un clúster de Amazon OpenSearch Service para mantener la tabla de clasificación.
C.
Cree un grupo de Auto Scaling de instancias bajo demanda de Amazon EC2 c5.large detrás de un balanceador de carga de aplicaciones. Utilice un clúster de Amazon ElastiCache para Redis para mantener la tabla de clasificación.
D.
Cree un grupo de Auto Scaling de instancias m5.large de Amazon EC2 bajo demanda detrás de un balanceador de carga de aplicaciones. Utilice una tabla de Amazon DynamoDB para mantener la tabla de clasificación.
ResponderDiscusión
Correct Answer: C
Las instancias bajo demanda de Amazon EC2 c5.large optimizadas para computación proporcionarán la computación de alto rendimiento necesaria para la aplicación de juegos. El uso de un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones garantiza escalabilidad y confiabilidad. Además, Amazon ElastiCache para Redis es ideal para mantener la tabla de clasificación que cambia con frecuencia debido a su baja latencia y alto rendimiento.
Question 196 of 529
Un arquitecto de soluciones está diseñando una aplicación para aceptar entradas de hojas de horas de los empleados en sus dispositivos móviles. Las hojas de horas se enviarán semanalmente, y la mayoría de las presentaciones se realizarán el viernes. Los datos deben ser almacenados en un formato que permita a los administradores de nóminas ejecutar informes mensuales. La infraestructura debe estar altamente disponible y escalar para que coincida con la tasa de datos entrantes y solicitudes de informes.
Qué combinación de pasos cumple con estos requisitos al tiempo que minimiza la sobrecarga operativa? (Elija dos.)
A.
Implemente la aplicación en instancias bajo demanda de Amazon EC2 con equilibrio de carga en varias zonas de disponibilidad. Utilice Amazon EC2 Auto Scaling programado para agregar capacidad antes del alto volumen de envíos los viernes.
B.
Implemente la aplicación en un contenedor con Amazon Elastic Container Service (Amazon ECS) con equilibrio de carga en varias zonas de disponibilidad. Uso del Servicio Programado
Auto Scaling para agregar capacidad antes del alto volumen de envíos los viernes.
C.
Implemente el front-end de la aplicación en un bucket de Amazon S3 servido por Amazon CloudFront. Implementar el backend de la aplicación mediante Amazon API Gateway con una integración de proxy AWS Lambda.
D.
Almacene los datos de envío de hojas de horas en Amazon Redshift. Utilice Amazon QuickSight para generar los informes utilizando Amazon Redshift como fuente de datos.
E.
Almacene los datos de envío de la hoja de horas en Amazon S3. Utilice Amazon Athena y Amazon QuickSight para generar los informes utilizando Amazon S3 como fuente de datos.
ResponderDiscusión
Correct Answer: B, E
La implementación de la aplicación en un contenedor con Amazon Elastic Container Service (ECS) con equilibrio de carga en varias zonas de disponibilidad garantiza una alta disponibilidad y permite el escalado automático para manejar la carga esperada los viernes. Esta configuración minimiza la sobrecarga operativa porque ECS administra la orquestación de contenedores y el escalado programado puede manejar las horas pico sin intervención manual. El almacenamiento de los datos de envío de hojas de horas en Amazon S3 y el uso de Amazon Athena para generar informes a través de Amazon QuickSight también minimiza la sobrecarga operativa. S3 es altamente duradero y rentable para almacenar grandes cantidades de datos, mientras que Athena proporciona un servicio de consultas sin servidor que escala automáticamente. El uso de QuickSight para la generación de informes reduce aún más la necesidad de administrar una infraestructura de informes compleja.
Question 197 of 529
Una empresa está almacenando datos confidenciales en un bucket de Amazon S3. La compañía debe registrar todas las actividades de los objetos en el bucket S3 y debe conservar los registros durante 5 años. El equipo de seguridad de la compañía también debe recibir una notificación por correo electrónico cada vez que se intente eliminar datos en el bucket S3.
Qué combinación de pasos cumplirá con estos requisitos de manera más rentable? (Elija tres.)
A.
Configure AWS CloudTrail para registrar eventos de datos de S3.
B.
Configure el registro de acceso al servidor S3 para el bucket S3.
C.
Configure Amazon S3 para enviar eventos de eliminación de objetos a Amazon Simple Email Service (Amazon SES).
D.
Configure Amazon S3 para enviar eventos de eliminación de objetos a un bus de eventos de Amazon EventBridge que se publique en un tema de Amazon Simple Notification Service (Amazon SNS).
E.
Configure Amazon S3 para enviar los registros a Amazon Timestream con almacenamiento de datos en niveles.
F.
Configure un nuevo bucket S3 para almacenar los registros con una política de ciclo de vida de S3.
ResponderDiscusión
Correct Answer: B, D, F
Para cumplir con los requisitos de manera rentable, es adecuada la siguiente combinación de pasos: Configurar el registro de acceso al servidor S3 para que el bucket S3 registre todas las actividades, ya que es más económico que CloudTrail. Configure Amazon S3 para enviar eventos de eliminación de objetos a un bus de eventos de Amazon EventBridge que publique en un tema de Amazon Simple Notification Service (SNS), asegurando que el equipo de seguridad reciba notificaciones por correo electrónico para los intentos de eliminación. Configure un nuevo bucket S3 para almacenar los registros con una política de ciclo de vida de S3 para hacer la transición automática de los registros a una clase de almacenamiento más rentable, asegurando que los registros se almacenen de manera rentable durante los 5 años requeridos.
Question 198 of 529
Una empresa está construyendo un entorno híbrido que incluye servidores en un centro de datos local y en la nube de AWS. La compañía ha implementado instancias de Amazon EC2 en tres VPC. Cada VPC se encuentra en una región de AWS diferente. La compañía ha establecido un AWS Direct. Conecte la conexión al centro de datos desde la región más cercana al centro de datos.
La empresa necesita que los servidores del centro de datos local tengan acceso a las instancias EC2 en las tres VPC. Los servidores en el centro de datos local también deben tener acceso a los servicios públicos de AWS.
Qué combinación de pasos cumplirá con estos requisitos con el menor costo? (Elija dos.)
A.
Cree una puerta de enlace de Direct Connect en la región más cercana al centro de datos. Conecte la conexión Direct Connect a la puerta de enlace Direct Connect. Utilice la puerta de enlace Direct Connect para conectar las VPC en las otras dos regiones.
B.
Configure conexiones adicionales de Direct Connect desde el centro de datos local a las otras dos regiones.
C.
Crear un VIF privado. Establezca una conexión VPN de sitio a sitio de AWS a través del VIF privado a las VPC en las otras dos regiones.
D.
Crear un VIF público. Establezca una conexión VPN de sitio a sitio de AWS a través del VIF público a las VPC en las otras dos regiones.
E.
Utilice el emparejamiento de VPC para establecer una conexión entre las VPC a través de las regiones Cree un VIF privado con la conexión Direct Connect existente para conectarse a las VPC interconectados.
ResponderDiscusión
Correct Answer: A, E
Para cumplir con los requisitos con el menor costo, debe crear una puerta de enlace de Direct Connect y usar el peering de VPC. La puerta de enlace Direct Connect permite el acceso global y puede conectar varias VPC en diferentes regiones a su centro de datos local, lo que reduce la necesidad de conexiones Direct Connect adicionales. El emparejamiento de VPC le permite establecer conexiones entre VPC en todas las regiones. Esta combinación aprovecha las conexiones existentes y reduce la necesidad de infraestructura adicional, cumpliendo con los requisitos de manera rentable.
Question 199 of 529
Una empresa está utilizando una organización en AWS Organizations para administrar cientos de cuentas de AWS. Un arquitecto de soluciones está trabajando en una solución para proporcionar protección básica para las 10 principales vulnerabilidades de aplicaciones web del Open Web Application Security Project (OWASP). El arquitecto de soluciones está utilizando AWS WAF para todas las distribuciones existentes y nuevas de Amazon CloudFront que se implementan dentro de la organización.
Qué combinación de pasos debe tomar el arquitecto de soluciones para proporcionar la protección de línea base? (Elija tres.)
A.
Habilitar AWS Config en todas las cuentas
B.
Habilitar Amazon GuardDuty en todas las cuentas
C.
Habilitar todas las funciones para la organización
D.
Utilice AWS Firewall Manager para implementar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront
E.
Utilice AWS Shield Advanced para implementar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront
F.
Utilice AWS Security Hub para implementar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront
ResponderDiscusión
Correct Answer: A, C, D
Para proporcionar protección básica para las 10 principales vulnerabilidades de aplicaciones web de OWASP mediante AWS WAF en todas las distribuciones de CloudFront en una organización, se deben seguir los siguientes pasos: Habilitar AWS Config en todas las cuentas permite a AWS Firewall Manager detectar los recursos recién creados y proporciona las comprobaciones de cumplimiento necesarias. Se requiere habilitar todas las funciones en las organizaciones de AWS para aprovechar las capacidades de AWS Firewall Manager. El uso de AWS Firewall Manager para implementar reglas de AWS WAF garantiza una aplicación coherente de las medidas de seguridad en todas las cuentas y distribuciones de CloudFront. Esta combinación proporciona una protección integral de línea base según sea necesario.
Question 200 of 529
Un arquitecto de soluciones ha implementado una solución de identidad federada SAML 2.0 con el proveedor de identidad local (IdP) de su compañía para autenticar el acceso de los usuarios al entorno de AWS. Cuando el arquitecto de soluciones prueba la autenticación a través del portal web de identidad federada, se otorga acceso al entorno de AWS. Sin embargo, cuando los usuarios de prueba intentan autenticarse a través del portal web de identidad federada, no pueden acceder al entorno de AWS.
Qué elementos debe verificar el arquitecto de soluciones para garantizar que la federación de identidades esté configurada correctamente? (Elija tres.)
A.
La política de permisos del usuario de IAM ha permitido el uso de la federación SAML para ese usuario.
B.
Los roles de IAM creados para la política de confianza de los usuarios federados o grupos federados han establecido al proveedor SAML como el principal.
B. Los usuarios de prueba no están en el grupo AWSFederatedUsers en el IdP de la compañía.
C.
El portal web llama a la API AWS STS AssumeRoleWithSAML con el ARN del proveedor SAML, el ARN del rol de IAM y la aserción SAML del IdP.
D.
Se puede acceder al nombre de host DNS del IdP local desde las VPC del entorno de AWS.
E.
El IdP de la compañía define aserciones SAML que mapean correctamente a usuarios o grupos. En la empresa a los roles de IAM con los permisos adecuados.
ResponderDiscusión
Correct Answer: B, C, E
Para garantizar que la federación de identidades esté configurada correctamente, el arquitecto de soluciones debe verificar que los roles de IAM creados para usuarios o grupos federados tengan políticas de confianza que establezcan al proveedor SAML como principal. A continuación, confirme que el portal web llame correctamente a la API AWS STS AssumeRoleWithSAML, pasando el ARN del proveedor SAML, el ARN del rol de IAM y la aserción SAML del IdP. Por último, asegúrese de que el IdP de la compañía proporcione aserciones SAML que asignen correctamente a los usuarios o grupos a roles de IAM con los permisos necesarios en AWS.
Question 201 of 529
Un arquitecto de soluciones necesita mejorar una aplicación alojada en la nube de AWS. La aplicación utiliza una instancia de base de datos MySQL de Amazon Aurora que está experimentando conexiones sobrecargadas. La mayoría de las operaciones de la aplicación insertan registros en la base de datos. La aplicación almacena actualmente las credenciales en un archivo de configuración basado en texto.
El arquitecto de soluciones necesita implementar una solución para que la aplicación pueda manejar la carga de conexión actual. La solución debe mantener las credenciales seguras y debe proporcionar la capacidad de rotar las credenciales automáticamente de forma regular.
Qué solución cumplirá con estos requisitos?
A.
Implementar una capa de proxy de Amazon RDS. Delante de la instancia de base de datos. Almacene las credenciales de conexión como secreto en AWS Secrets Manager.
B.
Implemente una capa de proxy de Amazon RDS frente a la instancia de base de datos. Almacenar las credenciales de conexión en AWS Systems Manager Parameter Store
C.
Crea una réplica de Aurora. Almacenar las credenciales de conexión como secreto en AWS Secrets Manager
D.
Crea una réplica de Aurora. Almacene las credenciales de conexión en AWS Systems Manager Parameter Store.
AnswerDiscussion
Correct Answer: A
La solución adecuada implica implementar una capa de proxy de Amazon RDS frente a la instancia de base de datos y almacenar las credenciales de conexión como secreto en AWS Secrets Manager. RDS Proxy ayuda a administrar un mayor número de conexiones estableciendo un grupo de conexiones y reutilizando estas conexiones, manejando de manera efectiva cargas altas y reduciendo la sobrecarga de memoria y CPU asociada con la apertura de nuevas conexiones. Además, AWS Secrets Manager proporciona un método seguro para almacenar credenciales y admite la rotación automática de estas credenciales, mejorando la seguridad y el cumplimiento.
Question 202 of 529
Una empresa necesita construir una solución de recuperación ante desastres (DR) para su sitio web de comercio electrónico. La aplicación web está alojada en una flota de instancias t3.large de Amazon EC2 y utiliza una instancia de base de datos de Amazon RDS para MySQL. Las instancias EC2 se encuentran en un grupo de Auto Scaling que se extiende a través de varias zonas de disponibilidad.
En caso de desastre, la aplicación web debe fallar al entorno secundario con un RPO de 30 segundos y un RTO de 10 minutos.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Utilizar la infraestructura como código (IaC) para proveer la nueva infraestructura en la Región RD. Cree una réplica de lectura entre regiones para la instancia de base de datos. Configure un plan de copia de seguridad en AWS Backup para crear copias de seguridad entre regiones para las instancias EC2 y la instancia de base de datos. Cree una expresión cron para realizar copias de seguridad de las instancias EC2 y de la instancia de base de datos cada 30 segundos en la región DR. Recupere las instancias EC2 del último backup de EC2. Utilice una política de enrutamiento de geolocalización de Amazon Route 53 para conmutar automáticamente por error a la región de RD en caso de desastre.
B.
Utilizar la infraestructura como código (IaC) para proveer la nueva infraestructura en la Región RD. Cree una réplica de lectura entre regiones para la instancia de base de datos. Configure AWS Elastic Disaster Recovery para replicar continuamente las instancias EC2 en la región de recuperación ante desastres. Ejecute las instancias EC2 a la capacidad mínima en la Región DR. Utilice una política de enrutamiento de conmutación por error de Amazon Route 53 para conmutar automáticamente por error a la región de recuperación ante desastres en caso de desastre. Aumente la capacidad deseada del grupo Auto Scaling.
C.
Configure un plan de copia de seguridad en AWS Backup para crear copias de seguridad entre regiones para las instancias EC2 y la instancia de base de datos. Cree una expresión cron para realizar copias de seguridad de las instancias EC2 y de la instancia de base de datos cada 30 segundos en la región DR. Utilizar la infraestructura como código (IaC) para proveer la nueva infraestructura en la Región RD. Restaure manualmente los datos respaldados en nuevas instancias. Utilice una política de enrutamiento simple de Amazon Route 53 para fallar automáticamente a la región DR en caso de desastre.
D.
Utilizar la infraestructura como código (IaC) para proveer la nueva infraestructura en la Región RD. Cree una base de datos global de Amazon Aurora. Configure AWS Elastic Disaster Recovery para replicar continuamente las instancias EC2 en la región de recuperación ante desastres. Ejecute el grupo Auto Scaling de instancias EC2 a plena capacidad en la región DR. Utilice una política de enrutamiento de conmutación por error de Amazon Route 53 para conmutar automáticamente por error a la región de recuperación ante desastres en caso de desastre.
AnswerDiscussion
Correct Answer: B
Para construir una solución rentable de recuperación ante desastres con un RPO de 30 segundos y un RTO de 10 minutos, la compañía debe utilizar la infraestructura como código (IAC) para aprovisionar la nueva infraestructura en la Región DR. La creación de una réplica de lectura entre regiones para la base de datos garantiza que la base de datos se replique y se mantenga sincronizada dentro del RPO requerido. AWS Elastic Disaster Recovery puede replicar continuamente las instancias EC2 en la región de recuperación ante desastres, lo que garantiza la disponibilidad de los datos más recientes. La ejecución de las instancias EC2 con la capacidad mínima en la región DR minimiza los costos, y el uso de una política de enrutamiento de conmutación por error de Amazon Route 53 permite la conmutación por error automática a la región DR, cumpliendo con los requisitos de RTO de manera eficiente.
Question 203 of 529
Una empresa está planeando una migración única de una base de datos MySQL local a Amazon Aurora MySQL en la región us-east-1. La conexión a internet actual de la compañía tiene un ancho de banda limitado. La base de datos MySQL local tiene un tamaño de 60 TB. La compañía estima que tomará un mes transferir los datos a AWS a través de la conexión a Internet actual. La empresa necesita una solución de migración que migre la base de datos más rápidamente.
Qué solución migrará la base de datos en la MENOR cantidad de tiempo?
A.
Solicite una conexión AWS Direct Connect de 1 Gbps entre el centro de datos local y AWS. Utilice AWS Database Migration Service (AWS DMS) para migrar la base de datos MySQL local a Aurora MySQL.
B.
Utilice AWS DataSync con la conexión a Internet actual para acelerar la transferencia de datos entre el centro de datos local y AWS. Utilice AWS Application Migration Service para migrar la base de datos MySQL local a Aurora MySQL.
C.
Ordene un dispositivo AWS Snowball Edge. Cargue los datos en un bucket de Amazon S3 mediante la interfaz S3. Utilice AWS Database Migration Service (AWS DMS) para migrar los datos de Amazon S3 a Aurora MySQL.
D.
Ordene un dispositivo AWS Snowball. Cargue los datos en un bucket de Amazon S3 mediante el adaptador S3 para Snowball. Utilice AWS Application Migration Service para migrar los datos de Amazon S3 a Aurora MySQL.
AnswerDiscussion
Correct Answer: C
Para una migración única de una gran base de datos MySQL de 60 TB con ancho de banda limitado de Internet, la opción más rápida sería usar un dispositivo AWS Snowball Edge. El dispositivo Snowball Edge puede transferir grandes cantidades de datos de forma segura y rápida a AWS. Una vez que los datos están en Amazon S3, AWS Database Migration Service (AWS DMS) se utiliza para migrarlos a Amazon Aurora MySQL. Este método evita las limitaciones del ancho de banda limitado de la conexión a Internet actual y acelera significativamente el proceso de migración.
Question 204 of 529
Una empresa tiene una aplicación en la nube de AWS. La aplicación se ejecuta en una flota de 20 instancias de Amazon EC2. Las instancias EC2 son persistentes y almacenan datos en varios volúmenes conectados de Amazon Elastic Block Store (Amazon EBS).
La compañía debe mantener copias de seguridad en una región de AWS separada. La compañía debe poder recuperar las instancias EC2 y su configuración dentro de 1 día hábil, con pérdida de datos de no más de 1 día. La compañía cuenta con personal limitado y necesita una solución de respaldo que optimice la eficiencia operativa y el costo. La compañía ya ha creado una plantilla de AWS CloudFormation que puede implementar la configuración de red requerida en una región secundaria.
Qué solución cumplirá con estos requisitos?
A.
Cree una segunda plantilla de CloudFormation que pueda recrear las instancias EC2 en la región secundaria. Ejecute instantáneas diarias de varios volúmenes mediante runbooks de AWS Systems Manager Automation. Copia las instantáneas a la Región secundaria. En caso de falla, inicie las plantillas de CloudFormation, restaure los volúmenes de EBS a partir de instantáneas y transfiera el uso a la región secundaria.
B.
Utilice Amazon Data Lifecycle Manager (Amazon DLM) para crear instantáneas diarias de varios volúmenes de los volúmenes de EBS. En caso de que se produzca un error, inicie la plantilla de CloudFormation y utilice Amazon DLM para restaurar los volúmenes de EBS y transferir el uso a la región secundaria.
C.
Utilice AWS Backup para crear un plan de copia de seguridad diario programado para las instancias EC2. Configure la tarea de copia de seguridad para copiar las copias de seguridad en una bóveda en la región secundaria. En caso de que se produzca un error, inicie la plantilla de CloudFormation, restaure los volúmenes y configuraciones de instancias desde el almacén de copia de seguridad y transfiera el uso a la región secundaria.
D.
Implementar instancias EC2 del mismo tamaño y configuración en la región secundaria. Configure AWS DataSync diariamente para copiar datos de la región principal a la región secundaria. En caso de falla, inicie la plantilla CloudFormation y transfiera el uso a la Región secundaria.
AnswerDiscussion
Correct Answer: C
AWS Backup es un servicio integral y centralizado que puede administrar copias de seguridad en varios servicios de AWS, incluidas instancias EC2 y volúmenes de EBS. Al crear un plan de copia de seguridad diario programado, AWS Backup garantiza que tanto las instancias como los volúmenes de datos sean respaldados regularmente. Las copias de seguridad se pueden configurar para que se almacenen en una bóveda en una región secundaria de AWS, que cumple con el requisito de mantener copias de seguridad en una región separada. En caso de falla, la combinación de AWS Backup y la plantilla de CloudFormation permite la restauración rápida tanto de las configuraciones de instancias como de los datos, lo que garantiza un tiempo de inactividad mínimo y pérdida de datos. Esta solución optimiza la eficiencia operativa y el costo, alineándose con las necesidades de la compañía. Otras opciones no abordan completamente el requisito de restaurar tanto las configuraciones de instancias como los volúmenes de datos de manera eficiente mientras se mantienen las copias de seguridad en una región separada.
Question 205 of 529
Una empresa está diseñando un nuevo sitio web que aloja contenido estático. El sitio web dará a los usuarios la posibilidad de subir y descargar archivos grandes. De acuerdo con los requisitos de la empresa, todos los datos deben estar encriptados en tránsito y en reposo. Un arquitecto de soluciones está creando la solución mediante Amazon S3 y Amazon CloudFront.
Qué combinación de pasos cumplirá con los requisitos de cifrado? (Elija tres.)
A.
Active el cifrado del lado del servidor S3 para el bucket S3 que utiliza la aplicación web.
B.
Agregar un atributo de política de “aws:SecureTransport”: “true” para operaciones de lectura y escritura en las ACL S3.
C.
Cree una política de bucket que deniegue cualquier operación no cifrada en el bucket S3 que utilice la aplicación web.
D.
Configure el cifrado en reposo en CloudFront mediante el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS).
E.
Configurar la redirección de solicitudes HTTP a solicitudes HTTPS en CloudFront.
F.
Utilice la opción RequiresSL en la creación de URL prefirmadas para el bucket S3 que utiliza la aplicación web.
AnswerDiscussion
Correct Answer: A, C, E
Para cumplir con los requisitos de cifrado de un sitio web alojado en Amazon S3 y Amazon CloudFront, se deben tomar los siguientes pasos: (1) Habilitar el cifrado del lado del servidor en el bucket S3 garantiza que todos los datos almacenados en S3 estén cifrados en reposo. (2) Crear una política de bucket que niegue cualquier operación no cifrada garantiza que solo se puedan cargar o acceder a los datos cifrados, reforzando las políticas de seguridad. (3) Configurar CloudFront para redirigir las solicitudes HTTP a HTTPS garantiza que todos los datos en el tránsito está encriptado de forma segura, evitando así que cualquier dato interceptado sea legible. Estas medidas en conjunto aseguran el cumplimiento de los requisitos de cifrado tanto para los datos en reposo como en tránsito.
Question 206 of 529
Una empresa está implementando una arquitectura sin servidor mediante el uso de funciones de AWS Lambda que necesitan acceder a una instancia de base de datos de Microsoft SQL Server en Amazon RDS. La compañía cuenta con entornos separados para el desarrollo y la producción, incluyendo un clon del sistema de base de datos.
Los desarrolladores de la compañía pueden acceder a las credenciales de la base de datos de desarrollo. Sin embargo, las credenciales para la base de datos de producción deben estar encriptadas con una clave a la que solo puedan acceder los miembros del grupo de usuarios de IAM del equipo de seguridad de TI. Esta llave debe rotarse de forma regular.
Qué debe hacer un arquitecto de soluciones en el entorno de producción para cumplir con estos requisitos?
A.
Almacene las credenciales de la base de datos en el almacén de parámetros de AWS Systems Manager mediante un parámetro SecureString cifrado por una clave administrada por el cliente de AWS Key Management Service (AWS KMS). Adjunte un rol a cada función Lambda para proporcionar acceso al parámetro SecureString. Restringir el acceso al parámetro SecureString y a la clave administrada por el cliente para que solo el equipo de seguridad de TI pueda acceder al parámetro y a la clave.
B.
Cifrar las credenciales de la base de datos mediante la clave Lambda predeterminada de AWS Key Management Service (AWS KMS). Almacenar las credenciales en las variables de entorno de cada función Lambda. Cargue las credenciales de las variables de entorno en el código Lambda. Restringir el acceso a la clave KMS para que solo el equipo de seguridad de TI pueda acceder a la clave.
C.
Almacene las credenciales de la base de datos en las variables de entorno de cada función Lambda. Cifrar las variables de entorno mediante una clave administrada por el cliente de AWS Key Management Service (AWS KMS). Restringir el acceso a la clave administrada por el cliente para que solo el equipo de seguridad de TI pueda acceder a la clave.
D.
Almacene las credenciales de la base de datos en AWS Secrets Manager como un secreto asociado a una clave administrada por el cliente de AWS Key Management Service (AWS KMS). Adjunte un rol a cada función Lambda para proporcionar acceso al secreto. Restringir el acceso al secreto y a la clave administrada por el cliente para que solo el equipo de seguridad de TI pueda acceder al secreto y a la clave.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos, las credenciales de la base de datos deben almacenarse de forma segura y asociarse con una clave que pueda rotarse regularmente. AWS Secrets Manager está diseñado específicamente para administrar información confidencial, como credenciales de bases de datos, con soporte integrado para la rotación de claves mediante claves administradas por el cliente de AWS Key Management Service (AWS KMS). Esta configuración garantiza que solo el equipo de seguridad de TI pueda acceder tanto al secreto como a la clave, cumpliendo con los requisitos de seguridad para los entornos de producción.
Question 207 of 529
Una empresa minorista en línea está migrando su aplicación.NET local heredada a AWS. La aplicación se ejecuta en servidores web frontend con equilibrio de carga, servidores de aplicaciones con equilibrio de carga y una base de datos Microsoft SQL Server.
La compañía quiere utilizar los servicios administrados de AWS cuando sea posible y no quiere reescribir la aplicación. Un arquitecto de soluciones necesita implementar una solución para resolver problemas de escalado y minimizar los costos de licencia a medida que la aplicación escala.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Implemente instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones para el nivel web y para el nivel de aplicación. Utilice Amazon Aurora PostgreSQL con Babelfish activado para reorganizar la base de datos de SQL Server.
B.
Cree imágenes de todos los servidores mediante AWS Database Migration Service (AWS DMS). Implementar instancias de Amazon EC2 basadas en las importaciones locales. Implemente las instancias en un grupo de Auto Scaling detrás de un balanceador de carga de red para el nivel web y para el nivel de aplicación. Utilice Amazon DynamoDB como nivel de base de datos.
C.
Containerizar el nivel de interfaz web y el nivel de aplicación. Aprovisione un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Cree un grupo de Auto Scaling detrás de un balanceador de carga de red para el nivel web y para el nivel de aplicación. Utilice Amazon RDS para SQL Server para alojar la base de datos.
D.
Separe las funciones de la aplicación en funciones de AWS Lambda. Utilice Amazon API Gateway para el nivel de interfaz web y el nivel de aplicación. Migre los datos a Amazon S3. Usa Amazon Athena para consultar los datos.
AnswerDiscussion
Correct Answer: A
La solución más rentable implica implementar instancias EC2 en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones para manejar los niveles web y de aplicaciones. El uso de Amazon Aurora PostgreSQL con Babelfish permitirá reorganizar la base de datos SQL Server heredada con cambios mínimos en el código de la aplicación existente. Este enfoque aprovecha los servicios administrados de AWS, aborda problemas de escalado y minimiza los costos de licencia sin la necesidad de reescrituras significativas de la aplicación.
Question 208 of 529
Un proveedor de software como servicio (SaaS) expone las API a través de un balanceador de carga de aplicaciones (ALB). El ALB se conecta a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) que se implementa en la región us-east-1. Las API expuestas contienen el uso de algunos métodos REST no estándar: LINK, UNLINK, LOCK y UNLOCK.
Los usuarios fuera de los Estados Unidos están reportando tiempos de respuesta largos e inconsistentes para estas API. Un arquitecto de soluciones necesita resolver este problema con una solución que minimice la sobrecarga operativa.
Qué solución cumple con estos requisitos?
A.
Agregue una distribución de Amazon CloudFront. Configure el ALB como origen.
B.
Agregue un punto de enlace de API optimizado para el borde de Amazon API Gateway para exponer las API. Configure el ALB como el objetivo.
C.
Agregue un acelerador en AWS Global Accelerator. Configure el ALB como origen.
D.
Implemente las API en dos regiones de AWS adicionales: eu-west-1 y ap-southeast-2. Agregue registros de enrutamiento basados en latencia en Amazon Route 53.
AnswerDiscussion
Correct Answer: C
Para mitigar los problemas de latencia para usuarios fuera de los Estados Unidos, usar AWS Global Accelerator es ideal. Global Accelerator mejora la disponibilidad y el rendimiento de las aplicaciones al enrutar el tráfico a través de las rutas de red de mejor rendimiento y de menor latencia, aprovechando la vasta red global de AWS. Esto aborda directamente la necesidad de tiempos de respuesta consistentes y mejorados sin la necesidad de volver a desplegarse en múltiples regiones, minimizando así la sobrecarga operativa. Está diseñado para trabajar con infraestructuras existentes como el balanceador de carga de aplicaciones, asegurando que soporta los métodos REST no estándar requeridos de manera efectiva.
Question 209 of 529
Una empresa ejecuta una aplicación IoT en la nube de AWS. La compañía cuenta con millones de sensores que recopilan datos de casas en Estados Unidos. Los sensores utilizan el protocolo MQTT para conectar y enviar datos a un broker MQTT personalizado. El broker MQTT almacena los datos en una única instancia de Amazon EC2. Los sensores se conectan al broker a través del dominio llamado iot.example.com. La compañía utiliza Amazon Route 53 como su servicio DNS. La compañía almacena los datos en Amazon DynamoDB.
En varias ocasiones, la cantidad de datos ha sobrecargado al broker MQTT y ha resultado en la pérdida de datos del sensor. La empresa debe mejorar la confiabilidad de la solución.
Qué solución cumplirá con estos requisitos?
A.
Cree un balanceador de carga de aplicaciones (ALB) y un grupo de Auto Scaling para el broker MQTT. Utilice el grupo Auto Scaling como destino para el ALB. Actualice el registro DNS en Route 53 a un registro de alias. Apunte el registro de alias al ALB. Utilice el broker MQTT para almacenar los datos.
B.
Configure AWS IoT Core para recibir los datos del sensor. Cree y configure un dominio personalizado para conectarse a AWS IoT Core. Actualice el registro DNS en Route 53 para que apunte al punto final de AWS IoT Core Data-ATS. Configure una regla de AWS IoT para almacenar los datos.
C.
Cree un balanceador de carga de red (NLB). Establezca el broker MQTT como el objetivo. Cree un acelerador de AWS Global Accelerator. Establezca el NLB como punto final para el acelerador. Actualizar el registro DNS en Route 53 a un registro de respuesta multivalue. Establezca las direcciones IP de Global Accelerator como valores. Utilice el broker MQTT para almacenar los datos.
D.
Configure AWS IoT Greengrass para recibir los datos del sensor. Actualice el registro DNS en Route 53 para que apunte al punto final de AWS IoT Greengrass. Configure una regla de AWS IoT para invocar una función de AWS Lambda para almacenar los datos.
AnswerDiscussion
Correct Answer: B
El problema es que la única instancia EC2 que aloja el broker MQTT personalizado está sobrecargada. Para mejorar la confiabilidad de la solución, es más apropiado aprovechar los servicios administrados de AWS diseñados para el manejo de datos de IoT. AWS IoT Core es un servicio administrado diseñado específicamente para manejar datos de IoT de forma segura y confiable. Al utilizar AWS IoT Core, la compañía puede escalar la solución automáticamente y manejar la afluencia de datos de manera más eficiente. Además, AWS IoT Core ofrece reglas integradas para procesar y enrutar los datos entrantes, incluida la capacidad de almacenarlos directamente en Amazon DynamoDB según lo requiera la empresa. Esto garantiza una alta disponibilidad, confiabilidad y procesamiento de datos eficiente, abordando el problema principal de sobrecargar el broker MQTT existente.
Question 210 of 529
Una empresa cuenta con instancias de Amazon EC2 basadas en Linux. Los usuarios deben acceder a las instancias usando SSH con pares de claves SSH EC2. Cada máquina requiere un par de claves EC2 único.
La compañía quiere implementar una política de rotación de claves que, previa solicitud, rote automáticamente todos los pares de claves EC2 y mantenga las claves en un lugar encriptado de forma segura. La compañía aceptará menos de 1 minuto de tiempo de inactividad durante la rotación de llaves.
Qué solución cumplirá con estos requisitos?
A.
Almacene todas las claves en AWS Secrets Manager. Defina un programa de rotación de Secrets Manager para invocar una función de AWS Lambda para generar nuevos pares de claves. Reemplace las claves públicas en las instancias EC2. Actualiza las claves privadas en Secrets Manager.
B.
Almacene todas las claves en Parameter Store, una capacidad de AWS Systems Manager, como una cadena. Defina una ventana de mantenimiento de Systems Manager para invocar una función de AWS Lambda para generar nuevos pares de claves. Reemplace las claves públicas en las instancias EC2. Actualiza las claves privadas en Parameter Store.
C.
Importe los pares de claves EC2 en AWS Key Management Service (AWS KMS). Configure la rotación automática de llaves para estos pares de llaves. Cree una regla programada de Amazon EventBridge para invocar una función de AWS Lambda para iniciar la rotación de claves en AWS KMS.
D.
Agregue todas las instancias EC2 a Fleet Manager, una capacidad de AWS Systems Manager. Defina una ventana de mantenimiento de Systems Manager para emitir un documento de comando de ejecución de Systems Manager para generar nuevos pares de claves y rotar las claves públicas a todas las instancias en Fleet Manager.
AnswerDiscussion
Correct Answer: A
Para implementar una política de rotación de claves para instancias de Amazon EC2 basadas en Linux con pares de claves únicos, almacenar las claves de forma segura y rotarlas automáticamente a pedido con un tiempo de inactividad mínimo, usar AWS Secrets Manager es la solución óptima. AWS Secrets Manager puede almacenar y administrar de forma segura el acceso a secretos, como pares de claves. Puede invocar una función de AWS Lambda para generar nuevos pares de claves, actualizar claves públicas en las instancias EC2 y actualizar claves privadas de forma segura dentro de Secrets Manager. Esta configuración garantiza que las llaves se roten de forma automática y segura con un tiempo de inactividad mínimo.
Question 211 of 529
Una empresa quiere migrar a AWS. La compañía está ejecutando miles de máquinas virtuales en un entorno VMware ESXi. La compañía no tiene una base de datos de administración de configuración y tiene poco conocimiento sobre la utilización de la cartera de VMware.
Un arquitecto de soluciones debe proporcionar a la compañía un inventario preciso para que la compañía pueda planificar una migración rentable.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Utilice AWS Systems Manager Patch Manager para implementar Migration Evaluator en cada VM. Revise los datos recopilados en Amazon QuickSight. Identificar servidores que tienen una alta utilización. Elimine los servidores que tienen alta utilización de la lista de migración. Importe los datos a AWS Migration Hub.
B.
Exporte la cartera de VMware a un archivo.csv. Verifique la utilización del disco para cada servidor. Elimine los servidores que tengan una alta utilización. Exporte los datos a AWS Application Migration Service. Utilice AWS Server Migration Service (AWS SMS) para migrar los servidores restantes.
C.
Implemente el recopilador sin agente de Migration Evaluator en el hipervisor ESXi. Revisar los datos recopilados en Evaluador de Migración. Identificar servidores inactivos. Elimine los servidores inactivos de la lista de migración. Importe los datos a AWS Migration Hub.
D.
Implemente el agente de AWS Application Migration Service en cada máquina virtual. Cuando se recopilan los datos, utilice Amazon Redshift para importar y analizar los datos. Utilice Amazon QuickSight para la visualización de datos.
AnswerDiscussion
Correct Answer: C
Para lograr un inventario preciso con la menor sobrecarga operativa, implementar el recopilador sin agente de Migration Evaluator en el hipervisor ESXi es la mejor solución. Este enfoque aprovecha un recopilador sin agente, lo que reduce la necesidad de implementar agentes de VM individuales y minimizar las tareas operativas. Los datos recopilados se pueden revisar directamente dentro de Migration Evaluator, lo que permite identificar fácilmente los servidores inactivos y una integración perfecta con AWS Migration Hub para planificar la migración.
Question 212 of 529
Una empresa ejecuta un microservicio como una función de AWS Lambda. El microservicio escribe datos en una base de datos SQL local que admite un número limitado de conexiones simultáneas. Cuando el número de invocaciones de funciones Lambda es demasiado alto, la base de datos se bloquea y causa tiempo de inactividad de la aplicación. La compañía tiene una conexión AWS Direct Connect entre la VPC de la compañía y el centro de datos local. La compañía quiere proteger la base de datos de los bloqueos.
Qué solución cumplirá con estos requisitos?
A.
Escriba los datos en una cola de Amazon Simple Queue Service (Amazon SQS). Configure la función Lambda para leer desde la cola y escribir en la base de datos existente. Establezca un límite de concurrencia reservado en la función Lambda que sea menor que el número de conexiones que admite la base de datos.
B.
Cree un nuevo clúster de base de datos sin servidor de Amazon Aurora. Utilice AWS DataSync para migrar los datos de la base de datos existente a Aurora Serverless. Reconfigure la función Lambda para escribir en Aurora.
C.
Cree una instancia de base de datos proxy de Amazon RDS. Adjunte la instancia de base de datos RDS Proxy a la instancia de base de datos de Amazon RDS. Reconfigure la función Lambda para escribir en la instancia de base de datos RDS Proxy.
D.
Escriba los datos en un tema de Amazon Simple Notification Service (Amazon SNS). Invoque la función Lambda para escribir en la base de datos existente cuando el tema reciba nuevos mensajes. Configure la concurrencia aprovisionada para que la función Lambda sea igual al número de conexiones que admite la base de datos.
AnswerDiscussion
Correct Answer: A
Para proteger la base de datos SQL local de bloqueos debidos a un elevado número de invocaciones de funciones Lambda, la mejor solución es escribir los datos en una cola de Amazon Simple Queue Service (Amazon SQS) y configurar la función Lambda para que lea desde la cola y escriba en la base de datos existente. Al establecer un límite de concurrencia reservado en la función Lambda que sea menor que el número de conexiones que admite la base de datos, se evita que la base de datos se vea abrumada por demasiadas conexiones simultáneas. Este enfoque asegura que la base de datos opera dentro de su capacidad mientras que la cola SQS administra el flujo de datos entrantes.
Question 213 of 529
Una empresa utiliza una solución de visualización de datos Grafana que se ejecuta en una sola instancia de Amazon EC2 para monitorear el estado de las cargas de trabajo de AWS de la compañía. La compañía ha invertido tiempo y esfuerzo para crear cuadros de mando que la compañía quiere conservar. Los paneles deben estar altamente disponibles y no pueden estar inactivos por más de 10 minutos. La compañía necesita minimizar el mantenimiento continuo.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Migre a paneles de Amazon CloudWatch. Recrea los dashboards para que coincidan con los dashboards Grafana existentes. Utilice cuadros de mando automáticos cuando sea posible.
B.
Cree un espacio de trabajo de Grafana administrado por Amazon. Configure una nueva fuente de datos de Amazon CloudWatch. Exportar cuadros de mando desde la instancia existente de Grafana. Importe los paneles al nuevo espacio de trabajo.
C.
Crear una AMI que tenga Grafana preinstalado. Almacene los paneles existentes en Amazon Elastic File System (Amazon EFS). Cree un grupo de Auto Scaling que utilice la nueva AMI. Establezca el número mínimo, deseado y máximo de instancias del grupo Auto Scaling en uno. Cree un balanceador de carga de aplicaciones que sirva al menos a dos zonas de disponibilidad.
D.
Configure AWS Backup para hacer una copia de seguridad de la instancia EC2 que ejecuta Grafana una vez por hora. Restaure la instancia EC2 a partir de la instantánea más reciente en una zona de disponibilidad alternativa cuando sea necesario.
AnswerDiscussion
Correct Answer: B
Amazon Managed Grafana proporciona un servicio Grafana completamente administrado que descarga la sobrecarga operativa de administrar, mantener y escalar la infraestructura de Grafana. Esto garantiza una alta disponibilidad y minimiza el tiempo de inactividad para cumplir con el requisito de la compañía de no estar inactivo por más de 10 minutos. Adicionalmente, exportar los dashboards de la instancia existente de Grafana e importarlos al nuevo espacio de trabajo Managed Grafana preserva el tiempo y el esfuerzo invertidos en la creación de los dashboards. Otras opciones requieren un mantenimiento continuo significativo o no garantizan la disponibilidad requerida.
Question 214 of 529
Una empresa necesita migrar su base de datos de transacciones de clientes desde las instalaciones a AWS. La base de datos reside en una instancia de base de datos Oracle que se ejecuta en un servidor Linux. De acuerdo con un nuevo requisito de seguridad, la empresa debe rotar la contraseña de la base de datos cada año.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Convierta la base de datos a Amazon DynamoDB mediante la herramienta de conversión de esquemas de AWS (AWS SCT). Almacene la contraseña en AWS Systems Manager Parameter Store. Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda para la rotación anual de passtard.
B.
Migre la base de datos a Amazon RDS para Oracle. Almacene la contraseña en AWS Secrets Manager. Enciende la rotación automática. Configure un horario de rotación anual.
C.
Migre la base de datos a una instancia de Amazon EC2. Utilice AWS Systems Manager Parameter Store para mantener y rotar la cadena de conexión mediante una función de AWS Lambda en un horario anual.
D.
Migre la base de datos a Amazon Neptune mediante la herramienta de conversión de esquemas de AWS (AWS SCT). Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda para la rotación anual de contraseñas.
AnswerDiscussion
Correct Answer: B
La migración de la base de datos a Amazon RDS para Oracle y el uso de AWS Secrets Manager con rotación automática activada y configurada para un programa anual proporciona la menor sobrecarga operativa. AWS Secrets Manager está diseñado para administrar y rotar automáticamente las contraseñas de las bases de datos, lo que simplifica el proceso de administración y garantiza el cumplimiento de los requisitos de seguridad de la compañía para rotar la contraseña de la base de datos cada año. Este enfoque aprovecha los servicios administrados que minimizan la necesidad de intervención manual y administración de infraestructura adicional en comparación con otras opciones.
Question 215 of 529
Un arquitecto de soluciones está diseñando una estructura de cuentas de AWS para una empresa que consta de múltiples equipos. Todos los equipos trabajarán en la misma región de AWS. La compañía necesita una VPC que esté conectada a la red local. La compañía espera menos de 50 Mbps de tráfico total hacia y desde la red local.
Qué combinación de pasos cumplirá con estos requisitos de manera más rentable? (Elija dos.)
A.
Cree una plantilla de AWS CloudFormation que aprovisione una VPC y las subredes requeridas. Implemente la plantilla en cada cuenta de AWS.
B.
Cree una plantilla de AWS CloudFormation que aprovisione una VPC y las subredes requeridas. Implemente la plantilla en una cuenta de servicios compartidos. Comparta las subredes mediante AWS Resource Access Manager.
C.
Utilice AWS Transit Gateway junto con una VPN de sitio a sitio de AWS para la conectividad a la red local. Comparta la puerta de enlace de tránsito mediante AWS Resource Access Manager.
D.
Utilice la VPN de sitio a sitio de AWS para la conectividad a la red local.
E.
Utilice AWS Direct Connect para la conectividad a la red local.
AnswerDiscussion
Correct Answer: B, D
Para cumplir con los requisitos de manera rentable, el mejor enfoque incluye la creación de una VPC compartida para todos los equipos y el uso de la VPN de sitio a sitio de AWS para la conectividad a la red local. Compartir la VPC y las subredes simplifica la administración y optimiza la utilización de recursos entre equipos, mientras que la VPN de sitio a sitio de AWS proporciona un medio rentable de conectarse a la red local a los niveles de tráfico esperados sin incurrir en los costos más altos asociados con AWS Direct Connect o la complejidad de AWS Transit Gateway.
Question 216 of 529
Un arquitecto de soluciones en una gran empresa necesita configurar la seguridad de red para el tráfico saliente a Internet desde todas las cuentas de AWS dentro de una organización en AWS Organizations. La organización tiene más de 100 cuentas de AWS y las cuentas se enrutan entre sí mediante un AWS Transit Gateway centralizado. Cada cuenta tiene tanto una puerta de enlace de Internet como una puerta de enlace NAT para el tráfico saliente a Internet. La compañía implementa recursos solo en una sola región de AWS.
La compañía necesita la capacidad de agregar filtros basados en reglas administrados centralmente en todo el tráfico saliente a Internet para todas las cuentas de AWS en la organización. La carga máxima de tráfico saliente no superará los 25 Gbps en cada Zona de Disponibilidad.
Qué solución cumple con estos requisitos?
A.
Cree una nueva VPC para el tráfico saliente a Internet. Conecte la puerta de enlace de tránsito existente a la nueva VPC. Configure una nueva puerta de enlace NAT. Cree un grupo de Auto Scaling de instancias de Amazon EC2 que ejecuten un proxy de Internet de código abierto para el filtrado basado en reglas en todas las zonas de disponibilidad de la región. Modifique todas las rutas predeterminadas para que apunten al grupo Auto Scaling del proxy.
B.
Cree una nueva VPC para el tráfico saliente a Internet. Conecte la puerta de enlace de tránsito existente a la nueva VPC. Configure una nueva puerta de enlace NAT. Utilice un firewall de AWS Network Firewall para el filtrado basado en reglas. Cree puntos finales de Network Firewall en cada zona de disponibilidad. Modifique todas las rutas predeterminadas para que apunten a los puntos finales del Firewall de red.
C.
Cree un firewall de AWS Network Firewall para el filtrado basado en reglas en cada cuenta de AWS. Modifique todas las rutas predeterminadas para que apunten a los firewalls de Firewall de red en cada cuenta.
D.
En cada cuenta de AWS, cree un grupo de Auto Scaling de instancias de Amazon EC2 optimizadas para la red que ejecuten un proxy de Internet de código abierto para el filtrado basado en reglas. Modifique todas las rutas predeterminadas para que apunten al grupo Auto Scaling del proxy.
AnswerDiscussion
Correct Answer: B
La mejor solución para configurar el filtrado basado en reglas administrado centralmente en todo el tráfico saliente a Internet para todas las cuentas de AWS en la organización es crear una nueva VPC específicamente para el tráfico saliente. Conecte la puerta de enlace de tránsito existente a esta nueva VPC y configure una nueva puerta de enlace NAT para la conectividad de salida. AWS Network Firewall es un servicio administrado diseñado para tales fines y garantiza la administración centralizada de las políticas de seguridad de la red. Cree puntos finales de Network Firewall en cada zona de disponibilidad y modifique todas las rutas predeterminadas para que apunten a estos endpoints. Esta configuración proporciona una forma robusta, escalable y administrada centralmente de manejar la seguridad del tráfico saliente.
Question 217 of 529
Una empresa utiliza un equilibrador de carga para distribuir el tráfico a las instancias de Amazon EC2 en una sola zona de disponibilidad. La compañía está preocupada por la seguridad y quiere que un arquitecto de soluciones rediseñe la solución para cumplir con los siguientes requisitos:
• Las solicitudes entrantes deben filtrarse para detectar ataques de vulnerabilidad comunes.
• Las solicitudes rechazadas deben enviarse a una aplicación de auditoría de terceros.
• Todos los recursos deben estar altamente disponibles.
Qué solución cumple con estos requisitos?
A.
Configure un grupo de Auto Scaling Multi-AZ usando la AMI de la aplicación. Cree un balanceador de carga de aplicaciones (ALB) y seleccione el grupo de Auto Scaling creado anteriormente como destino. Utilice Amazon Inspector para supervisar el tráfico a las instancias ALB y EC2. Crear una ACL web en WAF. Cree un AWS WAF utilizando la ACL web y ALB. Utilice una función de AWS Lambda para enviar frecuentemente el informe de Amazon Inspector a la aplicación de auditoría de terceros.
B.
Configure un balanceador de carga de aplicaciones (ALB) y agregue las instancias EC2 como destinos. Crear una ACL web en WAF. Cree un AWS WAF con el nombre de ACL y ALB web y habilite el registro con Amazon CloudWatch Logs. Utilice una función de AWS Lambda para enviar frecuentemente los registros a la aplicación de auditoría de terceros.
C.
Configure un balanceador de carga de aplicaciones (ALB) junto con un grupo de destino que agregue las instancias EC2 como destinos. Cree una manguera de seguridad de datos de Amazon Kinesis con el destino de la aplicación de auditoría de terceros. Crear una ACL web en WAF. Cree un AWS WAF utilizando la ACL y ALB web y luego habilite el registro seleccionando Kinesis Data Firehose como destino. Suscríbase a AWS Managed Rules en AWS Marketplace, eligiendo el WAF como suscriptor.
D.
Configure un grupo de Auto Scaling Multi-AZ usando la AMI de la aplicación. Cree un balanceador de carga de aplicaciones (ALB) y seleccione el grupo de Auto Scaling creado anteriormente como destino. Cree una manguera de seguridad de datos de Amazon Kinesis con un destino de la aplicación de auditoría de terceros. Crear una ACL web en WAF. Cree un AWS WAF con WebACL y ALB y luego habilite el registro seleccionando Kinesis Data Firehose como destino. Suscríbase a AWS Managed Rules en AWS Marketplace, eligiendo el WAF como suscriptor.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos, la solución debe incluir características para filtrar las solicitudes entrantes para detectar vulnerabilidades comunes, enviar solicitudes rechazadas a una aplicación de auditoría de terceros y garantizar una alta disponibilidad. La configuración de un grupo de Auto Scaling Multi-AZ utilizando la AMI de la aplicación garantiza una alta disponibilidad. Crear un balanceador de carga de aplicaciones (ALB) y seleccionar el grupo Auto Scaling como destino distribuye el tráfico de manera efectiva. El uso de AWS WAF junto con una ACL web filtra las solicitudes entrantes para detectar vulnerabilidades. Las solicitudes rechazadas se pueden registrar y enviar a una aplicación de auditoría de terceros a través de Amazon Kinesis Data Firehose. Esta configuración satisface todos los requisitos especificados.
Question 218 of 529
Una empresa está ejecutando una aplicación en la nube de AWS. La aplicación consiste en microservicios que se ejecutan en una flota de instancias de Amazon EC2 en varias zonas de disponibilidad detrás de un balanceador de carga de aplicaciones. La compañía agregó recientemente una nueva API REST que se implementó en Amazon API Gateway. Algunos de los microservicios más antiguos que se ejecutan en instancias EC2 necesitan llamar a esta nueva API.
La compañía no quiere que la API sea accesible desde la Internet pública y no quiere que los datos propietarios atraviesen la Internet pública.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una conexión VPN de sitio a sitio de AWS entre la VPC y la puerta de enlace API. Utilice API Gateway para generar una clave API única para cada microservicio. Configure los métodos API para requerir la clave.
B.
Cree un punto de enlace de VPC de interfaz para API Gateway y establezca una política de punto final para permitir solo el acceso a la API específica. Agregue una política de recursos a API Gateway para permitir solo el acceso desde el punto de enlace de VPC. Cambie el tipo de punto final de API Gateway a privado.
C.
Modifique la puerta de enlace API para usar la autenticación IAM. Actualice la política de IAM para el rol de IAM que se asigna a las instancias EC2 para permitir el acceso a la puerta de enlace API. Mueva la puerta de enlace API a una nueva VPImplementar una puerta de enlace de tránsito y conectar las VPC.
D.
Cree un acelerador en AWS Global Accelerator y conecte el acelerador a API Gateway. Actualice la tabla de rutas para todas las subredes de VPC con una ruta a la dirección IP de punto final de Global Accelerator creada. Agregue una clave API para cada servicio a usar para la autenticación.
AnswerDiscussion
Correct Answer: B
Para evitar que la API sea accesible desde la Internet pública y garantizar que los datos propietarios no atraviesen la Internet pública, crear una interfaz VPC endpoint para API Gateway es la mejor opción. Esta configuración permite una comunicación segura y privada entre los microservicios más antiguos en instancias EC2 y la nueva API. Al establecer una política de punto final para permitir solo el acceso a la API específica y agregar una política de recursos a API Gateway para permitir solo el acceso desde el punto de enlace de la VPC, el tráfico permanece dentro de la red interna de AWS. Cambiar el tipo de punto final de API Gateway a privado garantiza que no sea accesible desde Internet público, cumpliendo con los requisitos de seguridad especificados.
Question 219 of 529
Una compañía ha establecido toda su infraestructura en AWS. La compañía utiliza instancias de Amazon EC2 para alojar su sitio web de comercio electrónico y utiliza Amazon S3 para almacenar datos estáticos. Tres ingenieros de la compañía manejan la administración y el desarrollo de la nube a través de una cuenta de AWS. Ocasionalmente, un ingeniero altera la configuración de un grupo de seguridad EC2 de otro ingeniero y causa problemas de incumplimiento en el entorno.
Un arquitecto de soluciones debe configurar un sistema que rastrea los cambios que realizan los ingenieros. El sistema debe enviar alertas cuando los ingenieros realicen cambios no conformes en la configuración de seguridad para las instancias EC2.
Cuál es la manera MÁS RÁPIDA para que el arquitecto de soluciones cumpla con estos requisitos?
A.
Configure AWS Organizations para la empresa. Aplique SCP para gobernar y realizar un seguimiento de los cambios de grupos de seguridad no conformes que se realicen en la cuenta de AWS.
B.
Habilite AWS CloudTrail para capturar los cambios en los grupos de seguridad EC2. Habilite las reglas de Amazon CloudWatch para proporcionar alertas cuando se detecten configuraciones de seguridad no conformes.
C.
Habilite los SCP en la cuenta de AWS para proporcionar alertas cuando se realicen cambios en el entorno en grupos de seguridad no conformes.
D.
Habilite AWS Config en los grupos de seguridad EC2 para realizar un seguimiento de los cambios no conformes. Envíe los cambios como alertas a través de un tema Amazon Simple Notification Service (Amazon SNS).
AnswerDiscussion
Correct Answer: D
Para realizar un seguimiento de los cambios y enviar alertas cuando se realizan cambios no conformes en la configuración de seguridad de EC2, habilitar AWS Config en los grupos de seguridad de EC2 es la solución más rápida y efectiva. AWS Config monitorea y registra continuamente sus configuraciones de recursos de AWS y las evalúa en función de la configuración deseada. Puede detectar cambios no conformes y enviar alertas a través de un tema de Amazon Simple Notification Service (SNS). Este enfoque proporciona tanto el seguimiento en tiempo real de los cambios como los mecanismos de alerta necesarios de la manera más eficiente.
Question 220 of 529
Una empresa cuenta con sensores IoT que monitorean los patrones de tráfico en toda una gran ciudad. La compañía quiere leer y recopilar datos de los sensores y realizar agregaciones en los datos.
Un arquitecto de soluciones diseña una solución en la que los dispositivos IoT se transmiten a Amazon Kinesis Data Streams. Varias aplicaciones están leyendo de la corriente. Sin embargo, varios consumidores están experimentando estrangulamiento y periódicamente se encuentran con un error ReadProvisiedThreadOutputExceeded.
Qué acciones debe tomar el arquitecto de soluciones para resolver este problema? (Elija tres.)
A.
Reshard la corriente para aumentar el número de fragmentos en la corriente.
B.
Utilice la Biblioteca de Productores de Kinesis (KPL). Ajustar la frecuencia de sondeo.
C.
Utilice a los consumidores con la función de fan-out mejorada.
D.
Reshard la corriente para reducir el número de fragmentos en la corriente.
E.
Utilice un mecanismo de reintento de error y retroceso exponencial en la lógica del consumidor.
F.
Configure la transmisión para usar la partición dinámica.
AnswerDiscussion
Correct Answer: A, C, E
Para resolver los errores de estrangulamiento y lecturaProvisionedThroughputExceeded en Amazon Kinesis Data Stream, el arquitecto de soluciones debe volver a archivar la transmisión para aumentar el número de fragmentos, ya que esto mejorará la capacidad de rendimiento general de la transmisión. El uso de consumidores con la función de fan-out mejorada permite que varios consumidores lean simultáneamente desde el mismo shard, reduciendo las limitaciones de capacidad de lectura y minimizando el estrangulamiento. Adicionalmente, implementar un reintento de error con mecanismo de retroceso exponencial en la lógica del consumidor ayuda a administrar los errores de estrangulamiento al reintentar operaciones de lectura con retrasos incrementales, evitando abrumar el sistema.
Question 221 of 529
Una empresa utiliza AWS Organizations para administrar sus cuentas de AWS. La compañía necesita una lista de todas sus instancias de Amazon EC2 que tienen un uso subutilizado de CPU o memoria. La compañía también necesita recomendaciones sobre cómo reducir el tamaño de estas instancias subutilizadas.
Qué solución cumplirá estos requisitos con el MENOR esfuerzo?
A.
Instale una herramienta de monitoreo de CPU y memoria desde AWS Marketplace en todas las instancias EC2. Almacenar los hallazgos en Amazon S3. Implementar un script de Python para identificar instancias subutilizadas. Consulte la información de precios de instancias EC2 para obtener recomendaciones sobre las opciones de reducción de tamaño.
B.
Instale el agente de Amazon CloudWatch en todas las instancias EC2 mediante AWS Systems Manager. Recupere las recomendaciones de optimización de recursos de AWS Cost Explorer en la cuenta de administración de la organización. Utilice las recomendaciones para reducir el tamaño de las instancias infrautilizadas en todas las cuentas de la organización.
C.
Instale el agente de Amazon CloudWatch en todas las instancias EC2 mediante AWS Systems Manager. Recupere las recomendaciones de optimización de recursos de AWS Cost Explorer en cada cuenta de la organización. Utilice las recomendaciones para reducir el tamaño de las instancias infrautilizadas en todas las cuentas de la organización.
D.
Instale el agente de Amazon CloudWatch en todas las instancias EC2 mediante AWS Systems Manager. Cree una función de AWS Lambda para extraer el uso de CPU y memoria de todas las instancias EC2. Almacene los hallazgos como archivos en Amazon S3. Usa Amazon Athena para encontrar instancias subutilizadas. Consulte la información de precios de instancias EC2 para obtener recomendaciones sobre las opciones de reducción de tamaño.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos con el menor esfuerzo, la solución más eficiente es instalar el agente de Amazon CloudWatch en todas las instancias EC2 usando AWS Systems Manager y luego recuperar las recomendaciones de optimización de recursos de AWS Cost Explorer en la cuenta de administración de la organización. Este enfoque aprovecha los servicios y herramientas de AWS existentes, eliminando la necesidad de instalaciones adicionales o scripts personalizados. Al usar la cuenta de administración centralizada, puede administrar y reducir de manera eficiente las instancias infrautilizadas en todas las cuentas dentro de la organización con una sobrecarga administrativa mínima.
Question 222 of 529
Una empresa quiere ejecutar un paquete de software de análisis de red personalizado para inspeccionar el tráfico a medida que el tráfico sale y entra en una VPC. La compañía ha implementado la solución mediante el uso de AWS CloudFormation en tres instancias de Amazon EC2 en un grupo de Auto Scaling. Todo el enrutamiento de red se ha establecido para dirigir el tráfico a las instancias EC2.
Cada vez que el software de análisis deja de funcionar, el grupo Auto Scaling reemplaza una instancia. Las rutas de red no se actualizan cuando se produce el reemplazo de instancias.
Qué combinación de pasos resolverá este problema? (Elija tres.)
A.
Cree alarmas basadas en las métricas de verificación de estado de EC2 que harán que el grupo Auto Scaling reemplace la instancia fallida.
B.
Actualice la plantilla de CloudFormation para instalar el agente de Amazon CloudWatch en las instancias EC2. Configure el agente de CloudWatch para enviar métricas de proceso para la aplicación.
C.
Actualice la plantilla de CloudFormation para instalar AWS Systems Manager Agent en las instancias EC2. Configure Systems Manager Agent para enviar métricas de proceso para la aplicación.
D.
Cree una alarma para la métrica personalizada en Amazon CloudWatch para los escenarios de error. Configure la alarma para publicar un mensaje en un tema de Amazon Simple Notification Service (Amazon SNS).
E.
Cree una función de AWS Lambda que responda al mensaje Amazon Simple Notification Service (Amazon SNS) para sacar la instancia de servicio. Actualice las rutas de red para que apunten a la instancia de reemplazo.
F.
En la plantilla CloudFormation, escriba una condición que actualice las rutas de red cuando se inicie una instancia de reemplazo.
AnswerDiscussion
Correct Answer: B, D, E
Para abordar el problema en el que las rutas de red no se actualizan cuando se reemplaza una instancia, es necesaria una combinación de pasos. En primer lugar, la actualización de la plantilla de CloudFormation para instalar el agente de Amazon CloudWatch en las instancias EC2 permite recopilar métricas de proceso para la aplicación, lo que garantiza una supervisión adecuada del rendimiento del software. En segundo lugar, crear una alarma para la métrica personalizada en Amazon CloudWatch para escenarios de error y configurarla para publicar un mensaje en un tema de Amazon Simple Notification Service (Amazon SNS) garantiza que cualquier problema detectado active notificaciones. En tercer lugar, la creación de una función de AWS Lambda que responda al mensaje de Amazon SNS para sacar la instancia de servicio y actualizar las rutas de red para que apunten a la instancia de reemplazo garantiza que los cambios de enrutamiento se manejen automáticamente cada vez que se produce un reemplazo de instancia. Esta combinación aborda de manera efectiva el problema de actualización de rutas de red tras el reemplazo de instancias.
Question 223 of 529
Una compañía está desarrollando una nueva aplicación de video bajo demanda que se basa en microservicios. La aplicación tendrá 5 millones de usuarios en el lanzamiento y tendrá 30 millones de usuarios después de 6 meses. La compañía ha implementado la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. La compañía desarrolló la aplicación mediante el uso de servicios ECS que utilizan el protocolo HTTPS.
Un arquitecto de soluciones necesita implementar actualizaciones en la aplicación mediante el uso de implementaciones azul/verde. La solución debe distribuir el tráfico a cada servicio ECS a través de un balanceador de carga. La aplicación debe ajustar automáticamente el número de tareas en respuesta a una alarma de Amazon CloudWatch.
Qué solución cumplirá con estos requisitos?
A.
Configure los servicios ECS para usar el tipo de implementación azul/verde y un balanceador de carga de red. Solicitar aumentos a la cuota de servicio para tareas por servicio para satisfacer la demanda.
B.
Configure los servicios ECS para usar el tipo de implementación azul/verde y un balanceador de carga de red. Implemente el grupo Auto Scaling para cada servicio ECS mediante el escalador automático de clúster.
C.
Configure los servicios ECS para usar el tipo de implementación azul/verde y un balanceador de carga de aplicaciones. Implemente un grupo de Auto Scaling para cada servicio ECS mediante el escalador automático de clúster.
D.
Configure los servicios ECS para usar el tipo de implementación azul/verde y un balanceador de carga de aplicaciones. Implemente Service Auto Scaling para cada servicio ECS.
AnswerDiscussion
Correct Answer: D
La solución requiere implementaciones azul/verde, soporte de protocolo HTTPS y ajuste automático de tareas basado en alarmas de CloudWatch. Los balanceadores de carga de aplicaciones (ALB) son adecuados para el tráfico HTTPS y proporcionan funciones avanzadas de enrutamiento necesarias para implementaciones azul/verdes. Dado que AWS Fargate no admite el escalado automático de clústeres, pero sí admite el escalado automático de servicios, configurar los servicios ECS para usar un balanceador de carga de aplicaciones e implementar Service Auto Scaling es la solución adecuada para cumplir con estos requisitos.
Question 224 of 529
Una empresa está ejecutando una aplicación contenerizada en la nube de AWS. La aplicación se ejecuta mediante Amazon Elastic Container Service (Amazon ECS) en un conjunto de instancias de Amazon EC2. Las instancias EC2 se ejecutan en un grupo de Auto Scaling.
La compañía utiliza Amazon Elastic Container Registry (Amazon ECR) para almacenar sus imágenes de contenedores. Cuando se carga una nueva versión de imagen, la nueva versión de imagen recibe una etiqueta única.
La compañía necesita una solución que inspeccione nuevas versiones de imágenes para detectar vulnerabilidades y exposiciones comunes. La solución debe eliminar automáticamente nuevas etiquetas de imagen que tengan hallazgos de gravedad Crítica o Alta. La solución también deberá notificar al equipo de desarrollo cuando se produzca dicha eliminación.
Qué solución cumple con estos requisitos?
A.
Configurar escaneo al empujar en el repositorio. Utilice Amazon EventBridge para invocar una máquina de estado de AWS Step Functions cuando se complete un escaneo para imágenes que tengan hallazgos de gravedad crítica o alta. Utilice la máquina de estado Step Functions para eliminar la etiqueta de imagen de esas imágenes y notificar al equipo de desarrollo a través de Amazon Simple Notification Service (Amazon SNS).
B.
Configurar escaneo al empujar en el repositorio. Configure los resultados del análisis para que se envíen a una cola de Amazon Simple Queue Service (Amazon SQS). Invoque una función de AWS Lambda cuando se agrega un nuevo mensaje a la cola SQS. Utilice la función Lambda para eliminar la etiqueta de imagen para las imágenes que tienen hallazgos de gravedad Crítica o Alta. Notificar al equipo de desarrollo mediante Amazon Simple Email Service (Amazon SES).
C.
Programe una función de AWS Lambda para iniciar un escaneo manual de imágenes cada hora. Configure Amazon EventBridge para que invoque otra función Lambda cuando se complete una exploración. Utilice la segunda función Lambda para eliminar la etiqueta de imagen para las imágenes que tienen hallazgos de gravedad Crítica o Alta. Notificar al equipo de desarrollo mediante Amazon Simple Notification Service (Amazon SNS).
D.
Configurar escaneo periódico de imágenes en el repositorio. Configure los resultados del análisis para agregarlos a una cola de Amazon Simple Queue Service (Amazon SQS). Invoque una máquina de estado de AWS Step Functions cuando se agrega un nuevo mensaje a la cola de SQS. Utilice la máquina de estado Step Functions para eliminar la etiqueta de imagen para las imágenes que tienen hallazgos de gravedad Crítica o Alta. Notificar al equipo de desarrollo mediante Amazon Simple Email Service (Amazon SES).
AnswerDiscussion
Correct Answer: A
La solución correcta implica configurar scan on push en el repositorio, ya que asegura que las imágenes se escaneen inmediatamente cuando se cargan. El uso de Amazon EventBridge para invocar una máquina de estado AWS Step Functions cuando se completa un escaneo permite la automatización en el procesamiento de los resultados del escaneo. La máquina de estado Step Functions puede manejar tanto la eliminación de etiquetas de imagen con hallazgos severos como la notificación al equipo de desarrollo a través de Amazon SNS. Este enfoque cumple con todos los requisitos: escaneo automatizado, eliminación automatizada de imágenes problemáticas y notificación al desarrollador sobre tales eliminaciones.
Question 225 of 529
Una empresa ejecuta muchas cargas de trabajo en AWS y utiliza AWS Organizations para administrar sus cuentas. Las cargas de trabajo están alojadas en Amazon EC2. AWS Fargate. y AWS Lambda. Algunas de las cargas de trabajo tienen una demanda impredecible. Las cuentas registran un alto uso en algunos meses y un bajo uso en otros meses.
La compañía quiere optimizar sus costos de cómputos en los próximos 3 años. Un arquitecto de soluciones obtiene un promedio de 6 meses para cada una de las cuentas de la organización para calcular el uso.
Qué solución proporcionará el mayor ahorro de costos para todo el uso de cómputos de la organización?
A.
Compre instancias reservadas para la organización para que coincidan con el tamaño y el número de las instancias EC2 más comunes de las cuentas de los miembros.
B.
Adquirir un Plan de Ahorro de Cómputos para la organización desde la cuenta de administración utilizando la recomendación a nivel de cuenta de administración.
C.
Compra de Instancias Reservadas para cada cuenta de miembro que tuvo un alto uso de EC2 de acuerdo con los datos de los últimos 6 meses.
D.
Adquiera un Plan de Ahorro de Instancia EC2 para cada cuenta de miembro de la cuenta de administración basado en los datos de uso de EC2 de los últimos 6 meses.
AnswerDiscussion
Correct Answer: B
Para optimizar los costos de cómputos durante los próximos tres años para las cargas de trabajo alojadas en Amazon EC2, AWS Fargate y AWS Lambda, considerando que algunas cargas de trabajo tienen una demanda impredecible con un uso alto y bajo en diferentes meses, la mejor solución es comprar un plan de ahorro de cómputos para la organización desde la cuenta de administración. Los planes de ahorro de cómputos brindan la mayor flexibilidad y pueden cubrir el uso en EC2, Fargate y Lambda, lo cual es esencial dada la variedad de servicios informáticos utilizados y la demanda impredecible. También se aplican automáticamente a cualquier instancia EC2, independientemente de su familia, tamaño, región o tenencia, lo que las hace adecuadas para la optimización de costos en toda la organización.
Question 226 of 529
Una empresa tiene cientos de cuentas de AWS. La compañía utiliza una organización en AWS Organizations para administrar todas las cuentas. La compañía ha activado todas las funciones.
Un equipo de finanzas ha asignado un presupuesto diario para los costos de AWS. El equipo de finanzas debe recibir una notificación por correo electrónico si los costos de AWS de la organización superan el 80% del presupuesto asignado. Un arquitecto de soluciones necesita implementar una solución para rastrear los costos y entregar las notificaciones.
Qué solución cumplirá con estos requisitos?
A.
En la cuenta de administración de la organización, utilice AWS Budget para crear un presupuesto que tenga un periodo diario. Agregue un umbral de alerta y establezca el valor en 80%. Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas.
B.
En la cuenta de administración de la organización, configure la función de vista organizativa para AWS Trusted Advisor. Crear un informe de vista organizacional para la optimización de costos. Establezca un umbral de alerta del 80%. Configurar las preferencias de notificación. Agregar las direcciones de correo electrónico del equipo de finanzas.
C.
Registre la organización con AWS Control Tower. Activa el control de costos opcional (baranda de protección). Establezca un parámetro de control (baranda) de 80%. Configurar las preferencias de notificación de control (baranda). Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas.
D.
Configure las cuentas de miembro para guardar un informe diario de costos y uso de AWS en un bucket de Amazon S3 en la cuenta de administración de la organización. Utilice Amazon EventBridge para programar una consulta diaria de Amazon Athena para calcular los costos de la organización. Configure Athena para enviar una alerta de Amazon CloudWatch si los costos totales son más del 80% del presupuesto asignado. Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de notificar al equipo financiero si los costos de AWS de la organización superan el 80% del presupuesto diario asignado, la mejor solución es usar los presupuestos de AWS en la cuenta de administración de la organización. AWS Budget le permite crear un presupuesto que puede realizar un seguimiento diario de los costos y establecer umbrales de alerta. Al establecer el umbral en 80%, se puede activar una alerta. Amazon Simple Notification Service (Amazon SNS) se puede utilizar para enviar notificaciones por correo electrónico al equipo de finanzas, asegurando que estén informados cuando los costos se acerquen al límite especificado. Esta solución es directa y eficiente para el escenario dado.
Question 227 of 529
Una compañía brinda servicios de subasta para obras de arte y tiene usuarios en Norteamérica y Europa. La compañía aloja su aplicación en instancias de Amazon EC2 en la región us-east-1. Los artistas suben fotos de su trabajo como archivos de imagen de gran tamaño. de alta resolución desde sus teléfonos móviles a un bucket centralizado de Amazon S3 creado en la región us-east-1. Los usuarios en Europa están reportando un rendimiento lento para sus subidas de imágenes.
Cómo puede un arquitecto de soluciones mejorar el rendimiento del proceso de carga de imágenes?
A.
Vuelva a implementar la aplicación para usar cargas multiparte de S3.
B.
Cree una distribución de Amazon CloudFront y apunte a la aplicación como un origen personalizado.
C.
Configure los buckets para usar S3 Transfer Acceleration.
D.
Cree un grupo de Auto Scaling para las instancias EC2 y cree una política de escalado.
AnswerDiscussion
Correct Answer: C
Para mejorar el rendimiento de las cargas de imágenes para usuarios en Europa, configurar el bucket para usar S3 Transfer Acceleration es la solución más efectiva. S3 Transfer Acceleration utiliza la red global de ubicaciones de borde de Amazon CloudFront para enrutar los datos al bucket S3, reduciendo significativamente la latencia y acelerando la transferencia de datos, especialmente para archivos grandes que se cargan desde regiones alejadas de la ubicación del bucket S3.
Question 228 of 529
Una empresa quiere contenerizar una aplicación web de varios niveles y trasladar la aplicación de un centro de datos local a AWS. La aplicación incluye niveles de aplicaciones web y bases de datos. La compañía necesita hacer que la aplicación sea tolerante a fallas y escalable. Algunos datos a los que se accede con frecuencia siempre deben estar disponibles en todos los servidores de aplicaciones. Los servidores web frontend necesitan persistencia de sesión y deben escalar para satisfacer los aumentos en el tráfico.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa continua?
A.
Ejecute la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Utilice Amazon Elastic File System (Amazon EFS) para los datos a los que se accede con frecuencia entre los niveles web y de aplicaciones. Almacene los datos de sesión del servidor web frontend en Amazon Simple Queue Service (Amazon SQS).
B.
Ejecute la aplicación en Amazon Elastic Container Service (Amazon ECS) en Amazon EC2. Utilice Amazon ElastiCache for Redis para almacenar en caché los datos de sesión del servidor web frontend. Utilice Amazon Elastic Block Store (Amazon EBS) con conexión múltiple en instancias EC2 que se distribuyen en varias zonas de disponibilidad.
C.
Ejecute la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS). Configure Amazon EKS para utilizar grupos de nodos administrados. Utilice ReplicaSets para ejecutar los servidores web y las aplicaciones. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Monte el sistema de archivos EFS en todos los pods EKS para almacenar los datos de sesión del servidor web frontend.
D.
Implemente la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS). Configure Amazon EKS para utilizar grupos de nodos administrados. Ejecute los servidores web y la aplicación como implementaciones de Kubernetes en el clúster de EKS. Almacene los datos de sesión del servidor web frontend en una tabla de Amazon DynamoDB. Cree un volumen de Amazon Elastic File System (Amazon EFS) que todas las aplicaciones montarán en el momento de la implementación.
AnswerDiscussion
Correct Answer: D
La ejecución de la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS) con grupos de nodos administrados y el uso de implementaciones de Kubernetes para los servidores web y los niveles de aplicaciones garantiza la escalabilidad y la tolerancia a fallos. El almacenamiento de los datos de sesión del servidor web frontend en Amazon DynamoDB proporciona una solución de almacenamiento confiable y rápida adecuada para la persistencia de la sesión, mientras que Amazon Elastic File System (Amazon EFS) proporciona almacenamiento compartido entre nodos para los datos que necesita la aplicación, lo cual es esencial para la tolerancia a fallas. Esta solución aprovecha los servicios administrados para minimizar la sobrecarga operativa.
Question 229 of 529
Un arquitecto de soluciones planea migrar bases de datos críticas de Microsoft SQL Server a AWS. Debido a que las bases de datos son sistemas heredados, el arquitecto de soluciones moverá las bases de datos a una arquitectura de datos moderna. El arquitecto de soluciones debe migrar las bases de datos con un tiempo de inactividad casi nulo.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS Application Migration Service y la herramienta de conversión de esquemas de AWS (AWS SCT). Realice una actualización in place antes de la migración. Exporte los datos migrados a Amazon Aurora Serverless después del cambio de posición. Vuelva a apuntar las aplicaciones a Amazon Aurora.
B.
Utilice AWS Database Migration Service (AWS DMS) para realojar la base de datos. Establezca Amazon S3 como objetivo. Configure la replicación de captura de datos de cambio (CDC). Cuando el origen y el destino estén completamente sincronizados, cargue los datos de Amazon S3 en una instancia de base de datos de Amazon RDS para Microsoft SQL Server.
C.
Utilice herramientas de alta disponibilidad de bases de datos nativas. Conecte el sistema de origen a una instancia de base de datos de Amazon RDS para Microsoft SQL Server. Configure la replicación en consecuencia. Cuando finalice la replicación de datos, realice la transición de la carga de trabajo a una instancia de base de datos de Amazon RDS para Microsoft SQL Server.
D.
Utilice AWS Application Migration Service. Rehospedar el servidor de base de datos en Amazon EC2. Cuando termine la replicación de datos, desconecte la base de datos y muévala a una instancia de base de datos de Amazon RDS para Microsoft SQL Server. Vuelva a conectar la base de datos y luego cortar todas las redes.
AnswerDiscussion
Correct Answer: B
La solución adecuada para migrar bases de datos de Microsoft SQL Server a AWS con un tiempo de inactividad casi nulo es utilizar AWS Database Migration Service (AWS DMS). AWS DMS admite la replicación continua de datos, capturando los cambios continuos en la base de datos de origen y aplicándolos al destino, lo que garantiza una sincronización casi en tiempo real. AWS DMS se puede configurar para usar Amazon S3 como almacenamiento intermedio antes de cargar los datos en una instancia de base de datos de Amazon RDS para Microsoft SQL Server. Esta opción respalda el requisito de tiempo de inactividad mínimo durante el proceso de migración.
Question 230 of 529
El arquitecto de soluciones de una empresa está analizando los costos de un entorno multiaplicación. El entorno se implementa en varias zonas de disponibilidad en una sola región de AWS. Después de una reciente adquisición, la compañía administra dos organizaciones en AWS Organizations. La compañía ha creado múltiples aplicaciones de proveedores de servicios como servicios de punto final de VPC con tecnología AWS PrivateLink en una organización. La compañía ha creado múltiples aplicaciones de consumo de servicios en la otra organización.
Los cargos por transferencia de datos son mucho más altos de lo que esperaba la compañía, y el arquitecto de soluciones necesita reducir los costos. El arquitecto de soluciones debe recomendar pautas para que los desarrolladores sigan cuando implementen servicios. Estas pautas deben minimizar los cargos por transferencia de datos para todo el entorno.
Qué lineamientos cumplen con estos requisitos? (Elija dos.)
A.
Utilice AWS Resource Access Manager para compartir las subredes que alojan las aplicaciones del proveedor de servicios con otras cuentas de la organización.
B.
Coloque las aplicaciones del proveedor de servicios y las aplicaciones de consumo de servicios en cuentas de AWS en la misma organización.
C.
Desactive el equilibrio de carga entre zonas para el balanceador de carga de red en todas las implementaciones de aplicaciones de proveedores de servicios.
D.
Asegúrese de que los recursos informáticos del consumidor del servicio utilicen el servicio de punto final específico de la zona de disponibilidad mediante el nombre DNS local del punto final.
E.
Crear un Plan de Ahorro que brinde una cobertura adecuada para el uso planificado de transferencia de datos de la Zona de Interdisponibilidad de la organización.
AnswerDiscussion
Correct Answer: C, D
Para minimizar los cargos por transferencia de datos, es esencial limitar el tráfico de la Zona de Disponibilidad Cruzada (AZ) ya que las transferencias de datos entre AZ incurren en costos adicionales. Desactivar el equilibrio de carga entre zonas para el balanceador de carga de red (NLB) en todas las implementaciones de aplicaciones de proveedores de servicios garantiza que las solicitudes se manejen dentro de la misma AZ, lo que reduce los datos transferidos a través de las AZ, lo que reduce los costos. Además, garantizar que los recursos informáticos del consumidor de servicios utilicen el servicio de punto final específico de la zona de disponibilidad mediante el nombre DNS local del punto final dirige el tráfico dentro de la misma AZ, minimizando de manera efectiva las costosas transferencias de datos entre zonas de disponibilidad.
Question 231 of 529
Una compañía tiene una base de datos Microsoft SQL Server local que escribe una exportación nocturna de 200 GB a una unidad local. La compañía quiere trasladar las copias de seguridad a un almacenamiento en la nube más robusto en Amazon S3. La compañía ha establecido una conexión AWS Direct Connect de 10 Gbps entre el centro de datos local y AWS.
Qué solución cumple con estos requisitos de manera más rentable?
A.
Crea un nuevo bucket S3. Implemente una puerta de enlace de archivos de AWS Storage Gateway dentro de la VPC conectada a la conexión Direct Connect. Crear un nuevo recurso compartido de archivos SMB. Escriba exportaciones nocturnas de bases de datos al nuevo recurso compartido de archivos SMB.
B.
Cree un sistema de archivos Amazon FSx para Windows File Server Single-AZ dentro de la VPC que esté conectada a la conexión Direct Connect. Crear un nuevo recurso compartido de archivos SMB. Escriba exportaciones nocturnas de bases de datos a un recurso compartido de archivos SMB en el sistema de archivos Amazon FSx. Habilite copias de seguridad nocturnas.
C.
Cree un sistema de archivos Multi-AZ de Amazon FSx para Windows File Server dentro de la VPC que esté conectada a la conexión Direct Connect. Crear un nuevo recurso compartido de archivos SMB. Escriba exportaciones nocturnas de bases de datos a un recurso compartido de archivos SMB en el sistema de archivos Amazon FSx. Habilite copias de seguridad nocturnas.
D.
Crea un nuevo bucket S3. Implemente una puerta de enlace de volumen de AWS Storage Gateway dentro de la VPC conectada a la conexión Direct Connect. Crear un nuevo recurso compartido de archivos SMB. Escriba exportaciones nocturnas de bases de datos al nuevo recurso compartido de archivos SMB en la puerta de enlace de volumen y automatice copias de estos datos en un bucket S3.
AnswerDiscussion
Correct Answer: A
La solución más rentable para que una empresa mueva exportaciones nocturnas de 200 GB de datos de una base de datos de Microsoft SQL Server a Amazon S3 implica el uso de AWS Storage Gateway con una puerta de enlace de archivos. La implementación de una puerta de enlace de archivos de AWS Storage Gateway dentro de la VPC conectada a la conexión AWS Direct Connect y la creación de un recurso compartido de archivos SMB permite escribir directamente las exportaciones nocturnas de la base de datos a un recurso compartido de archivos SMB. Esto evita la complejidad y la infraestructura adicionales al tiempo que garantiza una transferencia e integración eficientes con Amazon S3. El uso de una puerta de enlace de archivos es más adecuado para el acceso a nivel de archivo, lo que lo convierte en la opción más rentable y adecuada para los requisitos de la compañía.
Question 232 of 529
Una empresa necesita establecer una conexión desde su centro de datos local a AWS. La compañía necesita conectar todas sus VPC que se encuentran en diferentes regiones de AWS con capacidades de enrutamiento transitivo entre redes de VPC. La compañía también debe reducir los costos de tráfico saliente de la red, aumentar el rendimiento del ancho de banda y proporcionar una experiencia de red consistente para los usuarios finales.
Qué solución cumplirá con estos requisitos?
A.
Cree una conexión VPN de sitio a sitio de AWS entre el centro de datos local y una nueva VPC central. Cree conexiones de interconexión de VPC que se inicien desde la VPC central a todas las demás VPC.
B.
Cree una conexión de AWS Direct Connect entre el centro de datos local y AWS. Aprovisione un VIF de tránsito y conéctelo a una puerta de enlace Direct Connect. Conecte la puerta de enlace Direct Connect a todas las demás VPC mediante una puerta de enlace de tránsito en cada región.
C.
Cree una conexión VPN de sitio a sitio de AWS entre el centro de datos local y una nueva vPuse una puerta de enlace de tránsito con enrutamiento dinámico. Conecte la puerta de enlace de tránsito a todas las demás VPC.
D.
Cree una conexión de AWS Direct Connect entre el centro de datos local y AWS. Establezca una conexión VPN de sitio a sitio de AWS entre todas las VPC de cada región. Cree conexiones de interconexión de VPC que se inicien desde la VPC central a todas las demás VPC.
AnswerDiscussion
Correct Answer: B
La empresa necesita una solución que proporcione un alto rendimiento de ancho de banda, reduzca los costos de tráfico de salida de la red y ofrezca una experiencia de red consistente para los usuarios finales en diferentes regiones de AWS. La mejor solución es crear una conexión AWS Direct Connect entre el centro de datos local y AWS. Al aprovisionar una interfaz virtual de tránsito (VIF) y conectarla a una puerta de enlace Direct Connect, la compañía puede lograr una comunicación rápida, confiable y rentable. La puerta de enlace Direct Connect se puede conectar a todas las demás VPC mediante una puerta de enlace de tránsito en cada región, ofreciendo las capacidades de enrutamiento transitivo requeridas entre redes VPC.
Question 233 of 529
Una empresa está migrando sus cargas de trabajo de desarrollo y producción a una nueva organización en AWS Organizations. La compañía ha creado una cuenta de miembro separada para el desarrollo y una cuenta de miembro separada para la producción. La facturación consolidada está vinculada a la cuenta de administración. En la cuenta de administración, un arquitecto de soluciones necesita crear un usuario de IAM que pueda detener o cancelar recursos en ambas cuentas de miembro.
Qué solución cumplirá con este requisito?
A.
Crear un usuario de IAM y un rol entre cuentas en la cuenta de administración. Configure el rol entre cuentas con el acceso de menor privilegio a las cuentas de miembro.
B.
Crear un usuario de IAM en cada cuenta de miembro. En la cuenta de administración, cree un rol multicuenta que tenga menos acceso de privilegios. Otorgue a los usuarios de IAM acceso al rol de cuentas cruzadas mediante el uso de una política de confianza.
C.
Crear un usuario de IAM en la cuenta de administración. En las cuentas de miembro, cree un grupo de IAM que tenga menos acceso de privilegio. Agregar el usuario de IAM de la cuenta de administración a cada grupo de IAM en las cuentas de miembro.
D.
Crear un usuario de IAM en la cuenta de administración. En las cuentas de miembro, cree roles entre cuentas que tengan menos acceso de privilegios. Otorgue al usuario de IAM acceso a los roles mediante una política de confianza.
AnswerDiscussion
Correct Answer: D
Para cumplir con el requisito de permitir que un usuario de IAM en la cuenta de administración detenga o termine recursos tanto en cuentas de miembros de desarrollo como de producción, el enfoque correcto es crear el usuario de IAM en la cuenta de administración. Luego, en cada cuenta de miembro, cree roles entre cuentas con los permisos necesarios para detener o terminar recursos. Estos roles deben tener políticas de confianza que otorguen el acceso necesario al usuario de IAM en la cuenta de administración. Esta configuración garantiza que la cuenta de administración pueda controlar de forma segura los recursos en las cuentas de los miembros mientras se adhiere al principio de menor privilegio.
Question 234 of 529
Una empresa quiere utilizar AWS para la recuperación ante desastres para una aplicación local. La compañía cuenta con cientos de servidores basados en Windows que ejecutan la aplicación. Todos los servidores montan un recurso compartido común.
La empresa cuenta con un RTO de 15 minutos y un RPO de 5 minutos. La solución debe admitir capacidades nativas de failover y fallback.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree una puerta de enlace de archivos de AWS Storage Gateway. Programe copias de seguridad diarias de servidores Windows. Guarde los datos en Amazon S3. Durante un desastre, recupere los servidores locales de la copia de seguridad. Durante el tailback, ejecute los servidores locales en instancias de Amazon EC2.
B.
Cree un conjunto de plantillas de AWS CloudFormation para crear infraestructura. Replique todos los datos en Amazon Elastic File System (Amazon EFS) mediante AWS DataSync. Durante un desastre, utilice AWS CodePipeline para implementar las plantillas para restaurar los servidores locales. Fallar los datos mediante DataSync.
C.
Cree una canalización de AWS Cloud Development Kit (AWS CDK) para crear un entorno activo-activo de varios sitios en AWS. Replique datos en Amazon S3 mediante el comando s3 sync. Durante un desastre, intercambie puntos finales de DNS para que apunten a AWS. Fallar los datos mediante el comando s3 sync.
D.
Utilice AWS Elastic Disaster Recovery para replicar los servidores locales. Replique datos en un sistema de archivos de Amazon FSx para Windows File Server mediante AWS DataSync. Monte el sistema de archivos en servidores de AWS. Durante un desastre, realice la conmutación por error de los servidores locales a AWS. Fallar en servidores nuevos o existentes mediante Elastic Disaster Recovery.
AnswerDiscussion
Correct Answer: D
El uso de AWS Elastic Disaster Recovery para replicar los servidores locales y replicar datos en un servidor de archivos de Amazon FSx para Windows mediante AWS DataSync cumple con los requisitos de manera más rentable. Este enfoque garantiza capacidades nativas de failover y fallback al tiempo que admite el RTO de la compañía de 15 minutos y el RPO de 5 minutos. Al montar el file system en servidores AWS y fallar sobre los servidores locales en AWS durante un desastre, la empresa puede mantener la continuidad operativa. Si no vuelve a servidores nuevos o existentes mediante Elastic Disaster Recovery, se garantiza una transición sin problemas a las operaciones normales.
Question 235 of 529
Una compañía ha construido un clúster de computación de alto rendimiento (HPC) en AWS para una carga de trabajo estrechamente acoplada que genera una gran cantidad de archivos compartidos almacenados en Amazon EFS. El clúster funcionaba bien cuando el número de instancias de Amazon EC2 en el clúster era de 100. Sin embargo, cuando la compañía aumentó el tamaño del clúster a 1.000 instancias EC2, el rendimiento general estuvo muy por debajo de las expectativas.
Qué colección de opciones de diseño debe hacer un arquitecto de soluciones para lograr el máximo rendimiento del clúster de HPC? (Elija tres.)
A.
Asegúrese de que el clúster de HPC se inicie dentro de una sola zona de disponibilidad.
B.
Inicie las instancias EC2 y conecte interfaces de red elásticas en múltiplos de cuatro.
C.
Seleccione los tipos de instancias EC2 con un Elastic Fabric Adapter (EFA) habilitado.
D.
Asegúrese de que el clúster se lance en varias zonas de disponibilidad.
E.
Reemplace Amazon EFS por varios volúmenes de Amazon EBS en un arreglo RAID.
F.
Reemplace Amazon EFS por Amazon FSx para Lustre.
AnswerDiscussion
Correct Answer: A, C, F
Para lograr el máximo rendimiento del clúster HPC, tres opciones clave de diseño son esenciales: garantizar que el clúster HPC se lance dentro de una única zona de disponibilidad para minimizar la latencia de la red y maximizar el ancho de banda ya que todas las instancias están en la misma ubicación; seleccionar tipos de instancias EC2 con un adaptador de tejido elástico (EFA) habilitado para beneficiarse de la comunicación de baja latencia y alto ancho de banda entre instancias esenciales para cargas de trabajo HPC; y reemplazar Amazon EFS por Amazon FSx for Lustre, un sistema de archivos de alto rendimiento optimizado específicamente para cargas de trabajo de HPC, mejorar el rendimiento para la gran cantidad de archivos compartidos generados por la carga de trabajo.
Question 236 of 529
Una empresa está diseñando una estructura de AWS Organizations. La compañía quiere estandarizar un proceso para aplicar etiquetas en toda la organización. La compañía requerirá etiquetas con valores específicos cuando un usuario cree un nuevo recurso. Cada una de las unidades organizativas de la compañía tendrá valores de etiqueta únicos.
Qué solución cumplirá con estos requisitos?
A.
Utilice un SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Cree una política de etiquetas que incluya los valores de etiqueta que la compañía ha asignado a cada unidad organizativa. Adjunte las políticas de etiquetas a las unidades de servicio.
B.
Utilice un SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Cree una política de etiquetas que incluya los valores de etiqueta que la compañía ha asignado a cada unidad organizativa. Adjunte las políticas de etiquetas a la cuenta de administración de la organización.
C.
Utilice un SCP para permitir la creación de recursos solo cuando los recursos tengan las etiquetas requeridas. Cree una política de etiquetas que incluya los valores de etiqueta que la compañía ha asignado a cada unidad organizativa. Adjunte las políticas de etiquetas a las unidades de servicio.
D.
Utilice un SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Definir la lista de etiquetas. Adjuntar el SCP a las OU.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos de estandarizar un proceso de aplicación de etiquetas con valores específicos únicos para cada unidad organizativa, se utilizaría una Política de Control de Servicios (SCP) para denegar la creación de recursos que no tengan las etiquetas requeridas. A continuación, se crean políticas de etiqueta que incluyen los valores de etiqueta específicos para cada unidad organizativa. Al adjuntar estas políticas de etiquetas a las unidades organizativas respectivas, se asegura de que cada unidad organizativa se adhiera a la estrategia de etiquetado requerida, proporcionando control granular y personalización sin comprometer la estandarización general.
Question 237 of 529
Una compañía cuenta con más de 10,000 sensores que envían datos a un servidor Apache Kafka local mediante el protocolo Message Queue Server Telemetry Transport (MQTT). El servidor Kafka local transforma los datos y luego almacena los resultados como objetos en un bucket de Amazon S3.
Recientemente, el servidor Kafka se estrelló. La compañía perdió los datos del sensor mientras se restauraba el servidor. Un arquitecto de soluciones debe crear un nuevo diseño en AWS que sea altamente disponible y escalable para evitar una ocurrencia similar.
Qué solución cumplirá con estos requisitos?
A.
Inicie dos instancias de Amazon EC2 para alojar el servidor Kafka en una configuración activa/en espera en dos zonas de disponibilidad. Crea un nombre de dominio en Amazon Route 53. Cree una política de conmutación por error de Route 53. Enrutar los sensores para enviar los datos al nombre de dominio.
B.
Migre el servidor Kafka local a Amazon Managed Streaming para Apache Kafka (Amazon MSK). Cree un balanceador de carga de red (NLB) que apunte al broker de Amazon MSK. Habilite las comprobaciones de estado de NLB. Enrutar los sensores para enviar los datos a la NLB.
C.
Implemente AWS IoT Core y conéctelo a una transmisión de entrega de Amazon Kinesis Data Firehose. Utilice una función de AWS Lambda para manejar la transformación de datos. Enrute los sensores para enviar los datos a AWS IoT Core.
D.
Implemente AWS IoT Core y lance una instancia de Amazon EC2 para alojar el servidor Kafka. Configure AWS IoT Core para enviar los datos a la instancia EC2. Enrute los sensores para enviar los datos a AWS IoT Core.
AnswerDiscussion
Correct Answer: C
Implementar AWS IoT Core junto con Amazon Kinesis Data Firehose y AWS Lambda para la transformación de datos es la mejor solución. AWS IoT Core está diseñado específicamente para manejar el protocolo MQTT, lo que lo hace altamente adecuado para datos de sensores. Además, esta solución proporciona escalabilidad y alta disponibilidad, evitando problemas de pérdida de datos experimentados con el servidor Kafka en las instalaciones. El uso de los servicios administrados de AWS reduce significativamente la sobrecarga operativa y garantiza que el sistema sea resiliente y eficiente en el procesamiento y almacenamiento de datos en Amazon S3.
Question 238 of 529
Recientemente, una empresa comenzó a alojar nuevas cargas de trabajo de aplicaciones en la nube de AWS. La compañía está utilizando instancias de Amazon EC2. Sistemas de archivos de Amazon Elastic File System (Amazon EFS) e instancias de base de datos de Amazon RDS.
Para cumplir con los requisitos regulatorios y comerciales, la empresa debe realizar los siguientes cambios para las copias de seguridad de datos:
• Las copias de seguridad deben conservarse en función de los requisitos diarios, semanales y mensuales personalizados.
• Las copias de seguridad deben replicarse en al menos otra región de AWS inmediatamente después de la captura.
• La solución de backup debe proporcionar una única fuente de estado de backup en todo el entorno de AWS.
• La solución de backup debe enviar notificaciones inmediatas en caso de fallo de cualquier backup de recursos.
Qué combinación de pasos cumplirá estos requisitos con la MENOR cantidad de gastos generales operativos? (Elija tres.)
A.
Cree un plan de AWS Backup con una regla de respaldo para cada uno de los requisitos de retención.
B.
Configure un plan de AWS Backup para copiar copias de seguridad en otra región.
C.
Cree una función de AWS Lambda para replicar copias de seguridad en otra región y enviar notificaciones si se produce un error.
D.
Agregue un tema Amazon Simple Notification Service (Amazon SNS) al plan de copia de seguridad para enviar una notificación de trabajos terminados que tengan algún estado excepto BACKUP_JOB_COMPLETED.
E.
Cree una política de ciclo de vida de instantáneas de Amazon Data Lifecycle Manager (Amazon DLM) para cada uno de los requisitos de retención.
F.
Configure instantáneas de RDS en cada base de datos.
AnswerDiscussion
Correct Answer: A, B, D
Para cumplir con los requisitos, la creación de un plan de AWS Backup con una regla de respaldo para cada uno de los requisitos de retención garantiza que los backups se gestionen de acuerdo con los horarios diarios, semanales y mensuales personalizados. La configuración de un plan de AWS Backup para copiar copias de seguridad en otra región cumple con el requisito de replicar backups en al menos otra región de AWS inmediatamente después de la captura. Agregar un tema Amazon Simple Notification Service (Amazon SNS) al plan de copia de seguridad para enviar una notificación de trabajos terminados que tienen cualquier estado excepto BACKUP_JOB_COMPLETED garantiza notificaciones inmediatas en caso de falla de cualquier copia de seguridad de recursos.
Question 239 of 529
Una compañía está desarrollando un dispositivo de reporte de genes que recopilará información genómica para ayudar a los investigadores a recolectar grandes muestras de datos de una población diversa. El dispositivo empujará 8 KB de datos genómicos cada segundo a una plataforma de datos que necesitará procesar y analizar los datos y proporcionar información a los investigadores. La plataforma de datos debe cumplir con los siguientes requisitos:
• Proporcionar análisis casi en tiempo real de los datos genómicos entrantes
• Asegurar que los datos sean flexibles, paralelos y duraderos
• Entregar resultados de procesamiento a un almacén de datos
Qué estrategia debe utilizar un arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice Amazon Kinesis Data Firehose para recopilar los datos de los sensores entrantes, analizarlos con clientes de Kinesis y guardar los resultados en una instancia de Amazon RDS.
B.
Utilice Amazon Kinesis Data Streams para recopilar los datos de los sensores entrantes, analizarlos con clientes de Kinesis y guardar los resultados en un clúster de Amazon Redshift mediante Amazon EMR.
C.
Utilice Amazon S3 para recopilar los datos de los dispositivos entrantes, analizar los datos de Amazon SQS con Kinesis y guardar los resultados en un clúster de Amazon Redshift.
D.
Utilice una puerta de enlace de API de Amazon para poner las solicitudes en una cola de Amazon SQS, analizar los datos con una función de AWS Lambda y guardar los resultados en un clúster de Amazon Redshift mediante Amazon EMR.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos de análisis casi en tiempo real, flexibilidad, paralelismo y durabilidad, Amazon Kinesis Data Stream es una opción adecuada para recopilar datos de sensores entrantes. Kinesis Data Streams puede manejar grandes cantidades de datos de streaming a la vez que proporciona la escala y el paralelismo necesarios. Para el análisis y el procesamiento, la utilización de clientes de Kinesis garantiza que el trabajo pesado se realice en tiempo real. Por último, el uso de Amazon Redshift, que es una potente solución de almacenamiento de datos, garantiza que los resultados se almacenen de manera eficiente y estén listos para consultas y análisis complejos, cumpliendo así con los requisitos del almacén de datos.
Question 240 of 529
Un arquitecto de soluciones necesita definir una arquitectura de referencia para una solución para aplicaciones de tres niveles con aplicaciones web y capas de datos NoSQL. La arquitectura de referencia debe cumplir con los siguientes requisitos:
• Alta disponibilidad dentro de una región de AWS
• Capaz de conmutar por error en 1 minuto a otra región de AWS para la recuperación ante desastres
• Proporcionar la solución más eficiente al tiempo que minimiza el impacto en la experiencia del usuario
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Utilice una política de enrutamiento ponderada de Amazon Route 53 establecida en 100/0 en las dos regiones seleccionadas. Establezca el tiempo de vida (TTL) en 1 hora.
B.
Utilice una política de enrutamiento de conmutación por error de Amazon Route 53 para la conmutación por error de la región principal a la región de recuperación ante desastres. Establezca el Tiempo en Vivo (TTL) en 30 segundos.
C.
Utilice una tabla global dentro de Amazon DynamoDB para que se pueda acceder a los datos en las dos regiones seleccionadas.
D.
Haga una copia de seguridad de los datos de una tabla de Amazon DynamoDB en la región principal cada 60 minutos y, a continuación, escriba los datos en Amazon S3. Utilice la replicación entre regiones S3 para copiar los datos de la región primaria a la región de recuperación ante desastres. Haga que un script importe los datos a DynamoDB en un escenario de recuperación ante desastres.
E.
Implemente un modelo de espera activa utilizando grupos de Auto Scaling para las capas web y de aplicaciones en varias zonas de disponibilidad en las regiones. Utilice instancias reservadas zonales para el número mínimo de servidores e instancias bajo demanda para cualquier recurso adicional.
F.
Utilice grupos de Auto Scaling para las capas web y de aplicaciones en varias zonas de disponibilidad en las regiones. Utilice Instancias puntuales para los recursos necesarios.
AnswerDiscussion
Correct Answer: B, C, E
Para cumplir con los requisitos de alta disponibilidad dentro de una región de AWS, la capacidad de conmutación por error en 1 minuto a otra región de AWS para la recuperación ante desastres y proporcionar la solución más eficiente al tiempo que minimiza el impacto del usuario, utilice una política de enrutamiento de conmutación por error de Amazon Route 53 establecida en un tiempo de vida (TTL) de 30 segundos. Esto permite una rápida conmutación por error entre regiones. Implemente una tabla global dentro de Amazon DynamoDB para un acceso a los datos sin problemas en todas las regiones, lo que garantiza la coherencia de los datos y la alta disponibilidad. Por último, implemente un modelo de espera activa utilizando grupos de Auto Scaling para las capas web y de aplicaciones en varias zonas de disponibilidad en las regiones, utilizando instancias reservadas zonales para lograr una mayor rentabilidad e instancias bajo demanda para recursos adicionales según sea necesario.
Question 241 of 529
Una empresa fabrica vehículos inteligentes. La compañía utiliza una aplicación personalizada para recopilar datos del vehículo. Los vehículos utilizan el protocolo MQTT para conectarse a la aplicación. La empresa procesa los datos en intervalos de 5 minutos. Luego, la compañía copia los datos telemáticos del vehículo al almacenamiento local. Las aplicaciones personalizadas analizan estos datos para detectar anomalías.
El número de vehículos que envían datos crece constantemente. Los vehículos más nuevos generan grandes volúmenes de datos. La solución de almacenamiento local no es capaz de escalar para el tráfico pico, lo que resulta en la pérdida de datos. La compañía debe modernizar la solución y migrar la solución a AWS para resolver los desafíos de escalado.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Utilice AWS IoT Greengrass para enviar los datos del vehículo a Amazon Managed Streaming para Apache Kafka (Amazon MSK). Cree una aplicación Apache Kafka para almacenar los datos en Amazon S3. Utilice un modelo preentrenado en Amazon SAGeMaker para detectar anomalías.
B.
Utilice AWS IoT Core para recibir los datos del vehículo. Configure reglas para enrutar datos a una transmisión de entrega de Amazon Kinesis Data Firehose que almacene los datos en Amazon S3. Cree una aplicación de análisis de datos de Amazon Kinesis que lea desde la transmisión de entrega para detectar anomalías.
C.
Utilice AWS IoT FleetWise para recopilar los datos del vehículo. Enviar los datos a una transmisión de datos de Amazon Kinesis. Utilice una transmisión de entrega de Amazon Kinesis Data Firehose para almacenar los datos en Amazon S3. Utilice las transformadas de aprendizaje automático integradas en AWS Glue para detectar anomalías.
D.
Utilice Amazon MQ para RabbitMQ para recopilar los datos del vehículo. Envíe los datos a una transmisión de entrega de Amazon Kinesis Data Firehose para almacenar los datos en Amazon S3. Utilice Amazon Lookout for Metrics para detectar anomalías.
AnswerDiscussion
Correct Answer: B
La solución más adecuada implica el uso de AWS IoT Core, ya que maneja datos de dispositivos IoT como los vehículos inteligentes en cuestión y es compatible con el protocolo MQTT que utilizan los vehículos. AWS IoT Core puede recibir y procesar estos datos de manera eficiente. Al configurar reglas para enrutar los datos a Amazon Kinesis Data Firehose, los datos se pueden transferir y almacenar de manera eficiente en Amazon S3. Para la detección de anomalías, Amazon Kinesis Data Analytics proporciona una solución robusta y escalable para analizar los datos en tiempo real, lo que reduce la sobrecarga operativa en comparación con las soluciones personalizadas.
Question 242 of 529
Durante una auditoría, un equipo de seguridad descubrió que un equipo de desarrollo estaba poniendo claves de acceso secretas de usuario de IAM en su código y luego comprometiéndolas en un repositorio de AWS CodeCommit. El equipo de seguridad quiere encontrar y remediar automáticamente instancias de esta vulnerabilidad de seguridad.
Qué solución garantizará que las credenciales estén debidamente aseguradas automáticamente?
A.
Ejecute un script todas las noches con AWS Systems Manager Run Command para buscar credenciales en las instancias de desarrollo. Si se encuentra, use AWS Secrets Manager para rotar las credenciales
B.
Utilice una función programada de AWS Lambda para descargar y escanear el código de la aplicación desde CodeCommit. Si se encuentran credenciales, genere nuevas credenciales y guárdalas en AWS KMS.
C.
Configure Amazon Macie para buscar credenciales en los repositorios de CodeCommit. Si se encuentran credenciales, active una función de AWS Lambda para deshabilitar las credenciales y notificar al usuario.
D.
Configure un desencadenador CodeCommit para invocar una función de AWS Lambda para escanear nuevos envíos de código en busca de credenciales. Si se encuentran credenciales, desactívelas en AWS IAM y notifíquelas al usuario.
AnswerDiscussion
Correct Answer: D
La solución correcta es configurar un disparador CodeCommit para invocar una función de AWS Lambda para escanear nuevos envíos de código en busca de credenciales. Este enfoque garantiza la supervisión en tiempo real y la corrección inmediata al deshabilitar las credenciales en AWS IAM y notificar al usuario, evitando así que las credenciales se expongan en el repositorio.
Question 243 of 529
Una empresa tiene un lago de datos en Amazon S3 al que deben acceder cientos de aplicaciones en muchas cuentas de AWS. La política de seguridad de la información de la compañía establece que no se debe acceder al bucket S3 a través de Internet público y que cada aplicación debe tener los permisos mínimos necesarios para funcionar.
Para cumplir con estos requisitos, un arquitecto de soluciones planea usar un punto de acceso S3 que está restringido a VPC específicas para cada aplicación.
Qué combinación de pasos debe tomar el arquitecto de soluciones para implementar esta solución? (Elija dos.)
A.
Cree un punto de acceso S3 para cada aplicación en la cuenta de AWS propietaria del bucket S3. Configure cada punto de acceso para que solo sea accesible desde la VPC de la aplicación. Actualice la política de bucket para requerir acceso desde un punto de acceso.
B.
Cree un punto final de interfaz para Amazon S3 en la VPC de cada aplicación. Configure la directiva de punto final para permitir el acceso a un punto de acceso S3. Cree un adjunto de puerta de enlace de VPC para el endpoint S3.
C.
Crear un punto de enlace para Amazon S3 en la VPN de cada aplicaciónConfigure la política de endpoints para permitir el acceso a un punto de acceso S3. Especifique la tabla de rutas que se utiliza para acceder al punto de acceso.
D.
Cree un punto de acceso S3 para cada aplicación en cada cuenta de AWS y adjunte los puntos de acceso al bucket S3. Configure cada punto de acceso para que solo sea accesible desde la VPC de la aplicación. Actualice la política de bucket para requerir acceso desde un punto de acceso.
E.
Cree un punto final de puerta de enlace para Amazon S3 en la VPC del lago de datos. Adjunte una política de punto final para permitir el acceso al bucket S3. Especifique la tabla de rutas que se utiliza para acceder al bucket.
AnswerDiscussion
Correct Answer: A, C
Para otorgar acceso seguro al lago de datos de Amazon S3 desde varias aplicaciones en varias cuentas de AWS, es necesario tomar dos pasos clave. Primero, cree un punto de acceso S3 para cada aplicación en la cuenta de AWS que sea propietaria del bucket S3 y configure estos puntos de acceso para que solo sean accesibles desde la VPC de la aplicación. Esto asegura que el acceso está restringido y se minimizan los permisos. En segundo lugar, cree un punto de enlace para Amazon S3 en la VPC de cada aplicación y configure la política de punto final para permitir el acceso a los puntos de acceso S3. Especificar la tabla de rutas ayuda a administrar el flujo de tráfico de forma segura y garantiza el cumplimiento de las políticas de seguridad de la compañía al mantener el acceso a través de la red interna de AWS y no a través de Internet pública.
Question 244 of 529
Una compañía ha desarrollado una solución híbrida entre su centro de datos y AWS. La compañía utiliza instancias de Amazon VPC y Amazon EC2 que envían registros de aplicaciones a Amazon CloudWatch. Las instancias EC2 leen datos de múltiples bases de datos relacionales que están alojadas en las instalaciones.
La compañía quiere monitorear qué instancias EC2 están conectadas a las bases de datos en tiempo casi real. La compañía ya cuenta con una solución de monitoreo que utiliza Splunk en las instalaciones. Un arquitecto de soluciones necesita determinar cómo enviar tráfico de red a Splunk.
Cómo debe el arquitecto de soluciones cumplir con estos requisitos?
A.
Habilite los registros de flujos de VPC y envíelos a CloudWatch. Cree una función de AWS Lambda para exportar periódicamente los registros de CloudWatch a un bucket de Amazon S3 mediante la función de exportación predefinida. Genere credenciales de AWS ACCESS_KEY y SECRET_KEY. Configure Splunk para sacar los registros del bucket S3 mediante esas credenciales.
B.
Cree una transmisión de entrega de Amazon Kinesis Data Firehose con Splunk como destino. Configure una función de AWS Lambda de preprocesamiento con un procesador de flujo de Kinesis Data Firehose que extrae eventos de registro individuales de registros enviados por los filtros de suscripción de CloudWatch Logs. Habilite los registros de flujos de VPC y envíelos a CloudWatch. Cree una suscripción a CloudWatch Logs que envíe eventos de registro a la transmisión de entrega de Kinesis Data Firehose.
C.
Pida a la compañía registrar cada solicitud que se haga en las bases de datos junto con la dirección IP de la instancia EC2. Exporte los registros de CloudWatch a un bucket de Amazon S3. Utilice Amazon Athena para consultar los registros agrupados por nombre de base de datos. Exporte los resultados de Athena a otro cubo S3. Invoque una función de AWS Lambda para enviar automáticamente cualquier archivo nuevo que se ponga en el bucket S3 a Splunk.
D.
Envíe los registros de CloudWatch a una transmisión de datos de Amazon Kinesis con Amazon Kinesis Data Analytics para aplicaciones SQL. Configure una ventana deslizante de 1 minuto para recopilar los eventos. Cree una consulta SQL que utilice la plantilla de detección de anomalías para monitorear cualquier anomalía de tráfico de red en tiempo casi real. Envía el resultado a una transmisión de entrega de Amazon Kinesis Data Firehose con Splunk como destino.
AnswerDiscussion
Correct Answer: B
Para lograr una supervisión casi en tiempo real del tráfico de red desde instancias de Amazon EC2 hasta bases de datos locales, la mejor solución es utilizar una transmisión de entrega de Amazon Kinesis Data Firehose con Splunk como destino. Esta configuración permite la integración de registros de flujo de VPC y CloudWatch Logs, que se pueden procesar usando una función de AWS Lambda para el preprocesamiento. El flujo de entrega de Kinesis Data Firehose está diseñado de manera efectiva para la entrega de registros casi en tiempo real, especialmente cuando se analiza el tráfico de red. Esta solución es óptima porque aprovecha los servicios de AWS existentes para el procesamiento de registros y la entrega a Splunk casi en tiempo real, minimizando la complejidad y asegurando un manejo eficiente de los datos.
Question 245 of 529
Una empresa cuenta con cinco equipos de desarrollo que cada uno ha creado cinco cuentas de AWS para desarrollar y alojar aplicaciones. Para realizar un seguimiento de los gastos, los equipos de desarrollo inician sesión en cada cuenta cada mes, registran el costo actual desde la consola de administración de costos y facturación de AWS y proporcionan la información al equipo financiero de la compañía.
La compañía tiene estrictos requisitos de cumplimiento y necesita garantizar que los recursos se creen solo en las regiones de AWS en los Estados Unidos. No obstante, se han creado algunos recursos en otras Regiones.
Un arquitecto de soluciones necesita implementar una solución que brinde al equipo financiero la capacidad de rastrear y consolidar los gastos de todas las cuentas. La solución también debe garantizar que la compañía pueda crear recursos solo en Regiones en Estados Unidos.
Qué combinación de pasos cumplirá estos requisitos de la manera MÁS eficiente desde el punto de vista operativo? (Elija tres.)
A.
Crear una nueva cuenta para que sirva como cuenta de administración. Cree un bucket de Amazon S3 para el equipo de finanzas. Utilice los informes de costos y uso de AWS para crear informes mensuales y almacenar los datos en el bucket S3 del equipo financiero.
B.
Crear una nueva cuenta para que sirva como cuenta de administración. Implementar una organización en AWS Organizations con todas las funciones habilitadas. Invitar a todas las cuentas existentes a la organización. Asegúrese de que cada cuenta acepte la invitación.
C.
Crear una unidad organizativa que incluya a todos los equipos de desarrollo. Crear un SCP que permita la creación de recursos sólo en Regiones que se encuentran en Estados Unidos. Aplicar el SCP a la OU.
D.
Crear una unidad organizativa que incluya a todos los equipos de desarrollo. Crear un SCP que niegue la creación de recursos en Regiones que se encuentran fuera de Estados Unidos. Aplicar el SCP a la OU.
E.
Crear un rol de IAM en la cuenta de administración. Adjunte una política que incluya permisos para ver la consola de Facturación y Administración de Costos. Permitir que los usuarios del equipo financiero asuman el rol. Utilice AWS Cost Explorer y la consola de facturación y administración de costos para analizar los costos.
F.
Cree un rol de IAM en cada cuenta de AWS. Adjunte una política que incluya permisos para ver la consola de Facturación y Administración de Costos. Permitir que los usuarios del equipo financiero asuman el rol.
AnswerDiscussion
Correct Answer: B, D, E
Para cumplir con los requisitos de manera eficiente, primero, cree una nueva cuenta que sirva como cuenta de administración e implemente una organización en AWS Organizations con todas las funciones habilitadas. Invitar a todas las cuentas existentes a la organización para centralizar la gestión. Después, crear una unidad organizativa que incluya a todos los equipos de desarrollo y aplique un SCP que niegue explícitamente la creación de recursos en Regiones fuera de Estados Unidos. Finalmente, cree un rol de IAM en la cuenta de administración con permisos para ver la consola de Billing and Cost Management y permitir que los usuarios del equipo financiero asuman esta función para analizar costos usando AWS Cost Explorer y la consola de Billing and Cost Management.
Question 246 of 529
Una empresa necesita crear y administrar varias cuentas de AWS para varios departamentos desde una ubicación central. El equipo de seguridad requiere acceso de solo lectura a todas las cuentas desde su propia cuenta de AWS. La compañía está utilizando AWS Organizations y creó una cuenta para el equipo de seguridad.
Cómo debe un arquitecto de soluciones cumplir con estos requisitos?
A.
Utilice la función OrganizationAccountAccessRole IAM para crear una nueva política de IAM con acceso de solo lectura en cada cuenta de miembro. Establecer una relación de confianza entre la política de IAM en cada cuenta de miembro y la cuenta de seguridad. Pida al equipo de seguridad que utilice la política de IAM para obtener acceso.
B.
Utilice el rol OrganizationAccountAccessRole IAM para crear un nuevo rol de IAM con acceso de solo lectura en cada cuenta de miembro. Establecer una relación de confianza entre el rol de IAM en cada cuenta de miembro y la cuenta de seguridad. Pídale al equipo de seguridad que use el rol de IAM para obtener acceso.
C.
Pídale al equipo de seguridad que use AWS Security Token Service (AWS STS) para llamar a la API AssumeRole para el rol de IAM de OrganizationAccountAccessRole en la cuenta de administración desde la cuenta de seguridad. Utilice las credenciales temporales generadas para obtener acceso.
D.
Pídale al equipo de seguridad que use AWS Security Token Service (AWS STS) para llamar a la API AssumeRole para el rol de IAM de OrganizationAccountAccessRole en la cuenta de miembro desde la cuenta de seguridad. Utilice las credenciales temporales generadas para obtener acceso.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos, el arquitecto de soluciones debe aprovechar OrganizationAccountAccessRole para crear un nuevo rol de IAM con acceso de solo lectura en cada cuenta de miembro. Este rol de IAM permitirá al equipo de seguridad ver los recursos sin realizar ninguna modificación. Al establecer una relación de confianza entre el rol de solo lectura en cada cuenta de miembro y la cuenta de seguridad, el equipo de seguridad puede asumir el rol y obtener acceso de solo lectura. Este enfoque sigue las mejores prácticas de AWS para el acceso entre cuentas al delegar permisos a través de roles de IAM, lo que garantiza que el equipo de seguridad tenga la visibilidad necesaria sin privilegios excesivos.
Question 247 of 529
Una gran empresa ejecuta cargas de trabajo en VPC que se implementan en cientos de cuentas de AWS. Cada VPC consta de subredes públicas y subredes privadas que abarcan varias zonas de disponibilidad. Las puertas de enlace NAT se implementan en las subredes públicas y permiten la conectividad saliente a Internet desde las subredes privadas.
Un arquitecto de soluciones está trabajando en un diseño de cubo y radio. Todas las subredes privadas en las VPC radiales deben enrutar el tráfico a Internet a través de una VPC de salida. El arquitecto de soluciones ya ha implementado una puerta de enlace NAT en una VPC de salida en una cuenta central de AWS.
Qué conjunto de pasos adicionales debe tomar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree conexiones entre pares entre la VPC de salida y las VPC radiales. Configure el enrutamiento requerido para permitir el acceso a Internet.
B.
Cree una puerta de enlace de tránsito y compártala con las cuentas de AWS existentes. Conecte las VPC existentes a la puerta de enlace de tránsito. Configure el enrutamiento requerido para permitir el acceso a Internet.
C.
Cree una puerta de enlace de tránsito en cada cuenta. Conecte la puerta de enlace NAT a las pasarelas de tránsito. Configure el enrutamiento requerido para permitir el acceso a Internet.
D.
Cree una conexión AWS PrivateLink entre la VPC de salida y las VPC habladas. Configure el enrutamiento requerido para permitir el acceso a Internet.
AnswerDiscussion
Correct Answer: B
Con cientos de VPC en varias cuentas de AWS, la forma más eficiente de administrar la conectividad es mediante el uso de una puerta de enlace de tránsito. Una puerta de enlace de tránsito actúa como un concentrador central que simplifica y consolida las conexiones de interconexión de VPC en una arquitectura de concentrador y radio, permitiendo que todas las VPC se comuniquen entre sí y enruten el tráfico a través de la VPC de salida central con la puerta de enlace NAT para acceso a Internet. Esto elimina la necesidad de crear y administrar numerosas conexiones entre pares, y se escala bien con una gran cantidad de VPC y cuentas.
Question 248 of 529
Una empresa educativa está ejecutando una aplicación web utilizada por estudiantes universitarios de todo el mundo. La aplicación se ejecuta en un clúster de Amazon Elastic Container Service (Amazon ECS) en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones (ALB). Un administrador del sistema detecta un pico semanal en el número de intentos fallidos de inicio de sesión, lo que abruma el servicio de autenticación de la aplicación. Todos los intentos fallidos de inicio de sesión se originan en aproximadamente 500 direcciones IP diferentes que cambian cada semana. Un arquitecto de soluciones debe evitar que los intentos fallidos de inicio de sesión abrumen al servicio de autenticación.
Qué solución cumple con estos requisitos con la mayor eficiencia operativa?
A.
Utilice AWS Firewall Manager para crear un grupo de seguridad y una política de grupo de seguridad para denegar el acceso desde las direcciones IP.
B.
Cree una ACL web de AWS WAF con una regla basada en la tasa y establezca la acción de regla en Bloquear. Conecte la ACL web al ALB.
C.
Utilice AWS Firewall Manager para crear un grupo de seguridad y una política de grupo de seguridad para permitir el acceso solo a rangos CIDR específicos.
D.
Cree una ACL web de AWS WAF con una regla de coincidencia de conjuntos de IP y establezca la acción de regla en Bloquear. Conecte la ACL web al ALB.
AnswerDiscussion
Correct Answer: B
La solución más eficiente desde el punto de vista operativo para evitar que los intentos fallidos de inicio de sesión abrumen al servicio de autenticación es crear una ACL web de AWS WAF con una regla basada en la tasa y establecer la acción de la regla en Bloquear. La regla basada en la tasa le permite monitorear la tasa de solicitudes de diferentes direcciones IP y bloquear aquellas que excedan un umbral. Esto es ideal para manejar escenarios con una gran cantidad de direcciones IP cambiantes, ya que puede ajustarse dinámicamente a patrones de ataque sin necesidad de actualizaciones manuales. Conectar la ACL web al balanceador de carga de aplicaciones (ALB) garantiza que el tráfico se bloquee antes de llegar a la aplicación, reduciendo así la carga en el servicio de autenticación.
Question 249 of 529
Una compañía opera una solución de software como servicio (SaaS) local que ingiere varios archivos diariamente. La compañía proporciona múltiples endpoints SFTP públicos a sus clientes para facilitar las transferencias de archivos. Los clientes agregan las direcciones IP de punto final SFTP a su lista de permisos de firewall para el tráfico saliente. No se permiten cambios en las direcciones IP de punto final SFTP.
La compañía quiere migrar la solución SaaS a AWS y disminuir la sobrecarga operativa del servicio de transferencia de archivos.
Qué solución cumple con estos requisitos?
A.
Registre el bloque de direcciones IP propiedad del cliente en la cuenta de AWS de la compañía. Cree direcciones IP elásticas desde el grupo de direcciones y asígnelas a un endpoint de AWS Transfer para SFTP. Utilice AWS Transfer para almacenar los archivos en Amazon S3.
B.
Agregue una subred que contenga el bloque de direcciones IP propiedad del cliente a una VPC. Cree direcciones IP elásticas desde el grupo de direcciones y asígnelas a un balanceador de carga de aplicaciones (ALB). Inicie instancias EC2 que alojen servicios FTP en un grupo de Auto Scaling detrás de ALStore los archivos en volúmenes adjuntos de Amazon Elastic Block Store (Amazon EBS).
C.
Registre el bloque de direcciones IP propiedad del cliente con Amazon Route 53. Cree registros de alias en Route 53 que apunten a un balanceador de carga de red (NLB). Inicie instancias EC2 que alojen servicios FTP en un grupo de Auto Scaling detrás del NLB. Almacene los archivos en Amazon S3.
D.
Registre el bloque de direcciones IP propiedad del cliente en la cuenta de AWS de la compañía. Cree direcciones IP elásticas a partir del grupo de direcciones y asígnelas a un endpoint de VPC de Amazon S3. Habilite el soporte SFTP en el bucket S3.
AnswerDiscussion
Correct Answer: A
Para cumplir con los requisitos, la empresa debe registrar el bloque de direcciones IP propiedad del cliente en su cuenta de AWS, crear direcciones IP elásticas a partir de este grupo de direcciones y asignarlas a un endpoint de AWS Transfer for SFTP. AWS Transfer para SFTP es un servicio completamente administrado que permite transferencias seguras de archivos directamente a Amazon S3, lo que reduce significativamente la sobrecarga operativa. Este enfoque permite a los clientes continuar usando sus listas de permisos de firewall existentes sin necesidad de cambios, lo que garantiza una migración perfecta a la nube.
Question 250 of 529
Una empresa tiene una nueva aplicación que necesita ejecutarse en cinco instancias de Amazon EC2 en una sola región de AWS. La aplicación requiere conexiones de red de alto rendimiento y baja latencia entre todas las instancias EC2 donde se ejecutará la aplicación. No se requiere que la aplicación sea tolerante a fallas.
Qué solución cumplirá con estos requisitos?
A.
Lanzar cinco nuevas instancias EC2 en un grupo de ubicación de clúster. Asegúrese de que el tipo de instancia EC2 admita redes mejoradas.
B.
Inicie cinco nuevas instancias EC2 en un grupo de Auto Scaling en la misma zona de disponibilidad. Adjunte una interfaz de red elástica adicional a cada instancia EC2.
C.
Lanzar cinco nuevas instancias EC2 en un grupo de ubicación de particiones. Asegúrese de que el tipo de instancia EC2 admita redes mejoradas.
D.
Lanza cinco nuevas instancias EC2 en un grupo de colocación diferencial. Adjunte una interfaz de red elástica adicional a cada instancia EC2.
AnswerDiscussion
Correct Answer: A
Para lograr conexiones de red de alto rendimiento y baja latencia entre todas las instancias, la mejor opción es lanzar las instancias EC2 en un grupo de ubicación de clúster. Los grupos de ubicación de clústeres están diseñados para proporcionar el máximo rendimiento de red posible entre instancias. Garantizar que el tipo de instancia EC2 admita redes mejoradas mejora aún más el rendimiento de la red. Otras opciones, como los grupos de Auto Scaling, los grupos de ubicación de particiones o los grupos de ubicación de propagación, no se dirigen específicamente a los requisitos de red de alto rendimiento y baja latencia.
Question 251 of 529
Una compañía está creando una API REST para compartir información con seis de sus socios con sede en Estados Unidos. La compañía ha creado un endpoint regional de Amazon API Gateway. Cada uno de los seis socios accederá a la API una vez al día para publicar cifras de ventas diarias.
Después de la implementación inicial, la compañía observa 1,000 solicitudes por segundo que se originan en 500 direcciones IP diferentes en todo el mundo. La compañía cree que este tráfico se origina en una botnet y quiere asegurar su API al tiempo que minimiza los costos.
Qué enfoque debe tomar la empresa para asegurar su API?
A.
Cree una distribución de Amazon CloudFront con la API como origen. Cree una ACL web de AWS WAF con una regla para bloquear clientes que envíen más de cinco solicitudes por día. Asociar la ACL web con la distribución CloudFront. Configurar CloudFront con una identidad de acceso de origen (OAI) y asociarla con la distribución. Configure API Gateway para garantizar que solo la OAI pueda ejecutar el método POST.
B.
Cree una distribución de Amazon CloudFront con la API como origen. Cree una ACL web de AWS WAF con una regla para bloquear clientes que envíen más de cinco solicitudes por día. Asociar la ACL web con la distribución CloudFront. Agregue un encabezado personalizado a la distribución de CloudFront rellenada con una clave API. Configure la API para que requiera una clave API en el método POST.
C.
Cree una ACL web de AWS WAF con una regla para permitir el acceso a las direcciones IP utilizadas por los seis socios. Asociar la ACL web con la API. Crear una política de recursos con un límite de solicitudes y asociarla con la API. Configure la API para que requiera una clave API en el método POST.
D.
Cree una ACL web de AWS WAF con una regla para permitir el acceso a las direcciones IP utilizadas por los seis socios. Asociar la ACL web con la API. Crear un plan de uso con un límite de solicitud y asociarlo con la API. Cree una clave API y agréguela al plan de uso.
AnswerDiscussion
Correct Answer: D
La compañía debe crear una ACL web AWS WAF con una regla para permitir el acceso a las direcciones IP utilizadas por los seis socios y asociar la ACL web con la API. Adicionalmente, crear un plan de uso con un límite de solicitud y asociarlo con la API ayudará a administrar y restringir el uso, evitando el uso excesivo de recursos. El plan de uso proporciona limitación y cuotas para controlar la tasa de solicitudes, mientras que las claves API permiten rastrear y controlar el acceso. Este enfoque combinado ayuda a proteger la API contra el acceso no autorizado y el tráfico de botnet, asegurando que solo los seis socios puedan acceder a ella con un costo mínimo.
Question 252 of 529
Una empresa utiliza un clúster de base de datos de Amazon Aurora PostgreSQL para aplicaciones en una sola región de AWS. El equipo de base de datos de la compañía debe monitorear toda la actividad de datos en todas las bases de datos.
Qué solución logrará este objetivo?
A.
Configure una tarea de captura de datos de cambio (CDC) de AWS Database Migration Service (AWS DMS). Especifique el clúster de base de datos Aurora como origen. Especifique Amazon Kinesis Data Firehose como destino. Utilice Kinesis Data Firehose para cargar los datos en un clúster de Amazon OpenSearch Service para analizarlos más a fondo.
B.
Inicie un flujo de actividad de base de datos en el clúster de base de datos Aurora para capturar el flujo de actividad en Amazon EventBridge. Defina una función de AWS Lambda como destino para EventBridge. Programe la función Lambda para descifrar los mensajes de EventBridge y publicar toda la actividad de la base de datos en Amazon S3 para su posterior análisis.
C.
Inicie una transmisión de actividad de base de datos en el clúster de base de datos Aurora para enviar la transmisión de actividad a una transmisión de datos de Amazon Kinesis. Configure Amazon Kinesis Data Firehose para consumir la transmisión de datos de Kinesis y entregar los datos a Amazon S3 para su posterior análisis.
D.
Configure una tarea de captura de datos de cambio (CDC) de AWS Database Migration Service (AWS DMS). Especifique el clúster de base de datos Aurora como origen. Especifique Amazon Kinesis Data Firehose como destino. Utilice Kinesis Data Firehose para cargar los datos en un clúster de Amazon Redshift. Ejecute consultas en los datos de Amazon Redshift para determinar las actividades de la base de datos en la base de datos Aurora.
AnswerDiscussion
Correct Answer: C
Para monitorear toda la actividad de datos en todas las bases de datos de un clúster de base de datos de Amazon Aurora PostgreSQL, iniciar un flujo de actividad de base de datos para enviar el flujo de actividad a un flujo de datos de Amazon Kinesis es la solución más adecuada. Esta transmisión puede ser consumida por Amazon Kinesis Data Firehose y entregarla a Amazon S3 para su posterior análisis. Esta solución aprovecha la integración nativa de AWS y proporciona un método sencillo para evaluar la actividad de la base de datos. El uso de Kinesis Data Firehose permite una entrega y almacenamiento de datos sin problemas, lo que facilita la supervisión y el análisis eficientes de la actividad de la base de datos.
Question 253 of 529
Una compañía de entretenimiento lanzó recientemente un nuevo juego. Para garantizar una buena experiencia para los jugadores durante el período de lanzamiento, la compañía implementó una cantidad estática de 12 instancias r6g.16xlarge (optimizadas para memoria) de Amazon EC2 detrás de un balanceador de carga de red. El equipo de operaciones de la compañía utilizó el agente de Amazon CloudWatch y una métrica personalizada para incluir la utilización de la memoria en su estrategia de monitoreo.
El análisis de las métricas de CloudWatch del periodo de lanzamiento mostró un consumo en aproximadamente una cuarta parte de la CPU y la memoria que esperaba la compañía. La demanda inicial del juego ha disminuido y se ha vuelto más variable. La compañía decide utilizar un grupo de Auto Scaling que monitorea el consumo de CPU y memoria para escalar dinámicamente la flota de instancias. Un arquitecto de soluciones necesita configurar el grupo Auto Scaling para satisfacer la demanda de la manera más rentable.
Qué solución cumplirá con estos requisitos?
A.
Configure el grupo Auto Scaling para implementar instancias c6g.4xlarge (optimizadas para computación). Configure una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.
B.
Configure el grupo Auto Scaling para implementar instancias m6g.4xlarge (propósito general). Configure una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.
C.
Configure el grupo Auto Scaling para implementar instancias r6g.4xlarge (optimizadas para memoria). Configure una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.
D.
Configure el grupo Auto Scaling para implementar instancias r6g.8xlarge (optimizadas para memoria). Configure una capacidad mínima de 2, una capacidad deseada de 2 y una capacidad máxima de 6.
AnswerDiscussion
Correct Answer: C
La compañía de entretenimiento implementó inicialmente 12 instancias r6g.16xlarge, que están optimizadas para la memoria, pero descubrió que solo se estaba utilizando aproximadamente una cuarta parte de la CPU y la memoria. Para cumplir con los requisitos de una manera rentable y al mismo tiempo mantener las mismas características de rendimiento, tiene sentido cambiar a instancias más pequeñas. Las instancias r6g.4xlarge son una cuarta parte del tamaño de las instancias r6g.16xlarge, lo que se alinea con el patrón de uso observado. La configuración del grupo Auto Scaling con una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12 usando instancias r6g.4xlarge permitirá que el sistema escale de manera eficiente y rentable en función de la demanda fluctuante. Esta configuración garantiza un uso eficiente de los recursos sin sobreaprovisionamiento ni incurrir en costos innecesarios.
Question 254 of 529
Una compañía de servicios financieros cargó millones de operaciones bursátiles históricas en una tabla de Amazon DynamoDB. La tabla utiliza el modo de capacidad bajo demanda. Una vez al día a medianoche, se cargan en la mesa algunos millones de registros nuevos. La actividad de lectura de aplicaciones contra la mesa ocurre en ráfagas a lo largo del día. y se busca repetidamente un conjunto limitado de teclas. La compañía necesita reducir los costos asociados con DynamoDB.
Qué estrategia debería recomendar un arquitecto de soluciones para cumplir con este requisito?
A.
Implementar un clúster de Amazon ElastiCache frente a la tabla de DynamoDB
B.
Desplegar el acelerador DynamoDB (DAX). Configure el escalado automático de DynamoDB. Compra Planes de Ahorro en Cost Explorer.
C.
Utilice el modo de capacidad aprovisionada. Compra Planes de Ahorro en Cost Explorer.
D.
Desplegar el acelerador DynamoDB (DAX). Utilice el modo de capacidad aprovisionada. Configure el escalado automático de DynamoDB.
AnswerDiscussion
Correct Answer: D
Para reducir los costos mientras se manejan actividades de lectura frecuentes y en ráfagas, es apropiado implementar DynamoDB Accelerator (DAX), ya que proporciona una caché en memoria que reduce significativamente la latencia de lectura y mejora el rendimiento de los datos a los que se accede con frecuencia. El uso del modo de capacidad aprovisionada permite el control de costos al establecer una capacidad predecible en lugar de pagar bajo demanda, lo que suele ser más costoso. El escalado automático optimiza aún más los costos al ajustar la capacidad aprovisionada en función de la carga de trabajo real, asegurando que los recursos se asignen de manera eficiente sin sobreaprovisionamiento.
Question 255 of 529
Una empresa está creando un servicio de registro centralizado que se ejecuta en Amazon EC2 que recibirá y analizará registros de cientos de cuentas de AWS. AWS PrivateLink se está utilizando para proporcionar conectividad entre los servicios del cliente y el servicio de registro.
En cada cuenta de AWS con un cliente, se ha creado un punto final de interfaz para el servicio de registro y está disponible. El servicio de registro que se ejecuta en instancias EC2 con un balanceador de carga de red (NLB) se implementa en diferentes subredes. Los clientes no pueden enviar registros mediante el endpoint de VPC.
Qué combinación de pasos debe tomar un arquitecto de soluciones para resolver este problema? (Elija dos.)
A.
Verifique que el NACL esté conectado a la subred del servicio de registro para permitir las comunicaciones hacia y desde las subredes NLB. Verifique que el NACL esté conectado a la subred NLB para permitir las comunicaciones hacia y desde las subredes del servicio de registro que se ejecutan en instancias EC2.
B.
Verifique que el NACL esté conectado a las subredes del servicio de registro para permitir las comunicaciones hacia y desde las subredes de punto final de la interfaz. Verifique que el NACL esté conectado a la subred de punto final de la interfaz para permitir las comunicaciones hacia y desde las subredes del servicio de registro que se ejecutan en instancias EC2.
C.
Verifique el grupo de seguridad para el servicio de registro que se ejecuta en las instancias EC2 para asegurarse de que permite la entrada desde las subredes NLB.
D.
Verifique el grupo de seguridad para el servicio de registro que se ejecuta en instancias EC2 para asegurarse de que permite la entrada de los clientes.
E.
Verifique el grupo de seguridad para el NLB para asegurarse de que permite la entrada desde las subredes de punto final de la interfaz.
AnswerDiscussion
Correct Answer: B, E
Para resolver el problema, es esencial garantizar una comunicación adecuada entre las subredes de punto final de interfaz y las subredes de servicio de registro que se ejecutan en instancias EC2. Primero, las Listas de Control de Acceso a la Red (NACL) deben configurarse correctamente. Esto implica verificar que el NACL conectado a las subredes del servicio de registro permite las comunicaciones hacia y desde las subredes de punto final de la interfaz, y viceversa. Además, dado que los clientes no pueden enviar registros a través del punto final de la VPC, es crucial verificar que el grupo de seguridad para el balanceador de carga de red (NLB) permita la entrada desde las subredes de punto final de la interfaz. Al establecer estas configuraciones, se asegura de que el tráfico necesario pueda fluir entre los puntos finales y el servicio de registro.
Question 256 of 529
Una empresa tiene millones de objetos en un bucket de Amazon S3. Los objetos están en la clase de almacenamiento S3 Standard. Se accede frecuentemente a todos los objetos S3. El número de usuarios y aplicaciones que acceden a los objetos está aumentando rápidamente. Los objetos se cifran con cifrado del lado del servidor con claves de AWS KMS (SSE-KMS).
Un arquitecto de soluciones revisa la factura mensual de AWS de la compañía y advierte que los costos de AWS KMS están aumentando debido al alto número de solicitudes de Amazon S3. El arquitecto de soluciones necesita optimizar los costos con cambios mínimos en la aplicación.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un nuevo bucket S3 que tenga cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) como tipo de cifrado. Copie los objetos existentes en el nuevo bucket S3. Especifique SSE-C.
B.
Cree un nuevo bucket S3 que tenga cifrado del lado del servidor con claves administradas de Amazon S3 (SSE-S3) como tipo de cifrado. Utilice S3 Batch Operations para copiar los objetos existentes en el nuevo bucket S3. Especifique SSE-S3.
C.
Utilice AWS CloudHSM para almacenar las claves de cifrado. Crea un nuevo bucket S3. Utilice S3 Batch Operations para copiar los objetos existentes en el nuevo bucket S3. Cifrar los objetos usando las claves de CloudHSM.
D.
Utilice la clase de almacenamiento S3 Intelligent-Tiering para el bucket S3. Cree una configuración de archivo S3 Intelligent-Tiering para hacer la transición de los objetos a los que no se accede durante 90 días a S3 Glacier Deep Archive.
AnswerDiscussion
Correct Answer: B
La mejor solución para reducir los costos de AWS KMS implica pasar de SSE-KMS, que incurre en cargos por solicitud de API, a SSE-S3, que no tiene costos adicionales por solicitud. Al crear un nuevo bucket S3 con SSE-S3 y usar S3 Batch Operations para copiar los objetos existentes en este nuevo bucket, la compañía puede reducir significativamente los costos mientras mantiene el cifrado del lado del servidor administrado por Amazon S3. Este enfoque requiere cambios mínimos en la aplicación y tiene una sobrecarga operativa baja.
Question 257 of 529
Una aplicación de almacenamiento de medios carga fotos de usuario a Amazon S3 para su procesamiento por las funciones de AWS Lambda. El estado de la aplicación se almacena en tablas de Amazon DynamoDB. Los usuarios están informando que algunas fotos subidas no se están procesando correctamente. Los desarrolladores de aplicaciones rastrean los registros y descubren que Lambda está experimentando problemas de procesamiento de fotos cuando miles de usuarios suben fotos simultáneamente. Los problemas son el resultado de los límites de concurrencia de Lambda y el rendimiento de DynamoDB cuando se guardan los datos.
Qué combinación de acciones debe tomar un arquitecto de soluciones para aumentar el rendimiento y la confiabilidad de la aplicación? (Elija dos.)
A.
Evaluar y ajustar las RCUs para las tablas DynamoDB.
B.
Evaluar y ajustar las WCUs para las tablas de DynamoDB.
C.
Agregue una capa de Amazon ElastiCache para aumentar el rendimiento de las funciones de Lambda.
D.
Agregue una cola de Amazon Simple Queue Service (Amazon SQS) y una lógica de reprocesamiento entre Amazon S3 y las funciones Lambda.
E.
Utilice S3 Transfer Acceleration para proporcionar una latencia más baja a los usuarios.
AnswerDiscussion
Correct Answer: B, D
Para abordar los problemas relacionados con los límites de concurrencia de AWS Lambda y el rendimiento de DynamoDB cuando se guardan los datos, se deben tomar dos acciones. Primero, es necesario evaluar y ajustar las unidades de capacidad de escritura (WCUs) para las tablas DynamoDB para mejorar el rendimiento durante el guardado de datos, lo cual es crucial cuando miles de usuarios cargan fotos simultáneamente. En segundo lugar, agregar una cola de Amazon Simple Queue Service (Amazon SQS) e incorporar lógica de reprocesamiento entre Amazon S3 y las funciones Lambda ayudarán a desacoplar las etapas de carga y procesamiento. Esta configuración evita que las funciones de Lambda se vean abrumadas, lo que garantiza que las fotos se procesen de manera confiable y eficiente.
Question 258 of 529
Una empresa ejecuta una aplicación en un centro de datos local. La aplicación brinda a los usuarios la posibilidad de subir archivos multimedia. Los archivos persisten en un servidor de archivos. La aplicación web tiene muchos usuarios. El servidor de aplicaciones está sobreutilizado, lo que provoca que las cargas de datos fallen ocasionalmente. La compañía frecuentemente agrega nuevo almacenamiento al servidor de archivos. La compañía quiere resolver estos desafíos migrando la aplicación a AWS.
Usuarios de todo Estados Unidos y Canadá acceden a la aplicación. Solo los usuarios autenticados deben tener la capacidad de acceder a la aplicación para subir archivos. La compañía considerará una solución que refactorice la aplicación, y la compañía necesita acelerar el desarrollo de aplicaciones.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Utilice AWS Application Migration Service para migrar el servidor de aplicaciones a instancias de Amazon EC2. Cree un grupo de Auto Scaling para las instancias EC2. Utilice un balanceador de carga de aplicaciones para distribuir las solicitudes. Modifique la aplicación para usar Amazon S3 para persistir los archivos. Utilice Amazon Cognito para autenticar usuarios.
B.
Utilice AWS Application Migration Service para migrar el servidor de aplicaciones a instancias de Amazon EC2. Cree un grupo de Auto Scaling para las instancias EC2. Utilice un balanceador de carga de aplicaciones para distribuir las solicitudes. Configure AWS IAM Identity Center (AWS Single Sign-On) para que los usuarios puedan iniciar sesión en la aplicación. Modifique la aplicación para usar Amazon S3 para persistir los archivos.
C.
Crear un sitio web estático para subir archivos multimedia. Almacene los activos estáticos en Amazon S3. Utilice AWS AppSync para crear una API. Utilice los resolvers de AWS Lambda para cargar los archivos multimedia en Amazon S3. Utilice Amazon Cognito para autenticar usuarios.
D.
Utilice AWS Amplify para crear un sitio web estático para subir archivos multimedia. Utilice Amplify Hosting para servir el sitio web a través de Amazon CloudFront. Utilice Amazon S3 para almacenar los archivos multimedia cargados. Utilice Amazon Cognito para autenticar usuarios.
AnswerDiscussion
Correct Answer: D
La solución descrita en la opción D aprovecha AWS Amplify para crear una arquitectura escalable y sin servidor para cargas de archivos multimedia. AWS Amplify simplifica el proceso de desarrollo e implementación, lo que acelera el desarrollo de aplicaciones. Amplify Hosting, combinado con Amazon CloudFront, garantiza la entrega de contenido de baja latencia, lo cual es esencial para los usuarios de Estados Unidos y Canadá. Además, Amazon S3 proporciona almacenamiento escalable para archivos multimedia y Amazon Cognito se encarga de la autenticación de usuarios, lo que garantiza la seguridad. Esta solución integral minimiza la sobrecarga operativa, atendiendo los requerimientos de la compañía de manera eficiente.
Question 259 of 529
Una empresa tiene una aplicación que se implementa en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). Las instancias forman parte de un grupo de Auto Scaling. La aplicación tiene cargas de trabajo impredecibles y con frecuencia se escala hacia fuera y hacia adentro. El equipo de desarrollo de la compañía quiere analizar los registros de aplicaciones para encontrar formas de mejorar el rendimiento de la aplicación. Sin embargo, los registros ya no están disponibles después de que las instancias se escalen.
Qué solución le dará al equipo de desarrollo la capacidad de ver los registros de aplicaciones después de un evento de escalado?
A.
Habilite los registros de acceso para el ALB. Almacene los registros en un bucket de Amazon S3.
B.
Configure las instancias EC2 para publicar registros en Amazon CloudWatch Logs mediante el agente unificado de CloudWatch.
C.
Modifique el grupo Auto Scaling para usar una política de escalado por pasos.
D.
Instrumentar la aplicación con el trazado de rayos X de AWS.
AnswerDiscussion
Correct Answer: B
Para conservar los registros de aplicaciones incluso después de escalar las instancias EC2, debe configurar las instancias EC2 para que publiquen registros en Amazon CloudWatch Logs mediante el agente unificado de CloudWatch. Este enfoque garantiza que los registros se almacenen de forma centralizada y sean accesibles para su análisis independientemente del ciclo de vida de las instancias individuales. Ni habilitar los registros de acceso en el ALB, cambiar las políticas de Auto Scaling ni usar AWS X-Ray aborda específicamente el requisito de retener los registros de las aplicaciones después de que las instancias se escalen.
Question 260 of 529
Una empresa tiene un sitio web estático no autenticado (www.example.com) que incluye un formulario de registro para los usuarios. El sitio web utiliza Amazon S3 para el alojamiento y utiliza Amazon CloudFront como la red de entrega de contenido con AWS WAF configurado. Cuando se envía el formulario de registro, el sitio web llama a un punto de enlace API de Amazon API Gateway que invoca una función de AWS Lambda para procesar la carga útil y reenviar la carga útil a una llamada a la API externa.
Durante las pruebas, un arquitecto de soluciones encuentra un error de intercambio de recursos de origen cruzado (CORS). El arquitecto de soluciones confirma que el origen de distribución de CloudFront tiene el encabezado Access-Control-Allow-Origin establecido en www.example.com.
Qué debe hacer el arquitecto de soluciones para resolver el error?
A.
Cambie la configuración CORS en el bucket S3. Agregar reglas para CORS al elemento allowedOrigin para www.example.com.
B.
Habilite la configuración CORS en AWS WAF. Cree una regla ACL web en la que el encabezado Access-Control-Allow-Origin esté establecido en www.example.com.
C.
Habilite la configuración CORS en el punto final de API de puerta de enlace API. Asegúrese de que el punto final de la API esté configurado para devolver todas las respuestas que tengan el encabezado Access-Control-Allow-Origin establecido en www.example.com.
D.
Habilite la configuración CORS en la función Lambda. Asegúrese de que el código de retorno de la función tenga el encabezado Access-Control-Allow-Origin establecido en www.example.com.
AnswerDiscussion
Correct Answer: C
La acción correcta para resolver el error de uso compartido de recursos de origen cruzado (CORS) es habilitar la configuración CORS en el punto final de API de API Gateway. El error se produce porque a la respuesta de la API le falta el encabezado Access-Control-Allow-Origin, que especifica los dominios de origen permitidos. Al configurar la API Gateway para devolver respuestas con el encabezado Access-Control-Allow-Origin establecido en www.example.com, el navegador reconocerá la aprobación del servidor para las solicitudes de origen cruzado de este dominio, resolviendo así el problema CORS.
Question 261 of 529
Una empresa tiene muchas cuentas de AWS separadas y no utiliza facturación ni administración centralizada. Cada cuenta de AWS alberga servicios para diferentes departamentos de la compañía. La compañía cuenta con un Microsoft Azure Active Directory que está desplegado.
Un arquitecto de soluciones necesita centralizar la facturación y la administración de las cuentas de AWS de la compañía. La compañía quiere comenzar a usar la federación de identidades en lugar de la administración manual de usuarios. La compañía también quiere usar credenciales temporales en lugar de claves de acceso de larga duración.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Cree una nueva cuenta de AWS para que sirva como cuenta de administración. Implementar una organización en organizaciones de AWS. Invite a cada cuenta de AWS existente a unirse a la organización. Asegúrese de que cada cuenta acepte la invitación.
B.
Configure la dirección de correo electrónico de cada cuenta de AWS para que sea aws+ @example .com para que los mensajes de correo electrónico y las facturas de administración de cuentas se envíen al mismo lugar.
C.
Implementar AWS IAM Identity Center (AWS Single Sign-On) en la cuenta de administración. Conecte IAM Identity Center a Azure Active Directory. Configurar IAM Identity Center para la sincronización automática de usuarios y grupos.
D.
Implemente un directorio Microsoft AD administrado por AWS en la cuenta de administración. Comparta el directorio con todas las demás cuentas de la organización mediante AWS Resource Access Manager (AWS RAM).
E.
Cree conjuntos de permisos de AWS IAM Identity Center (AWS Single SignOn). Adjunte los conjuntos de permisos a los grupos de IAM Identity Center y cuentas de AWS correspondientes.
F.
Configure AWS Identity and Access Management (IAM) en cada cuenta de AWS para usar AWS Managed Microsoft AD para la autenticación y autorización.
AnswerDiscussion
Correct Answer: A, C, E
Para centralizar la facturación y administración de las cuentas de AWS de la compañía y comenzar a usar la federación de identidades con credenciales temporales, es necesario crear una nueva cuenta de administración e implementar una organización en AWS Organizations. Esto permite que todas las cuentas existentes se sometan a una gestión centralizada. La implementación de AWS IAM Identity Center (AWS Single Signe-On) en la cuenta de administración y la conexión a Azure Active Directory de la compañía permite el acceso federado mediante identidades existentes de Azure AD. Por último, crear conjuntos de permisos en AWS IAM Identity Center (AWS Single Signe-On) y adjuntarlos a grupos y cuentas de AWS adecuados garantiza controles de acceso y administración de permisos adecuados. El uso de estos pasos cumple con los requisitos de centralizar la facturación, la administración y la implementación de la federación de identidades con credenciales temporales.
Question 262 of 529
Una empresa quiere administrar los costos asociados a un grupo de 20 aplicaciones que se utilizan con poca frecuencia, pero que siguen siendo críticas para el negocio, migrando a AWS. Las aplicaciones son una mezcla de Java y Node.js repartidas en diferentes clústeres de instancias. La compañía quiere minimizar los costos a la vez que estandariza mediante el uso de una única metodología de implementación.
La mayoría de las aplicaciones forman parte de las rutinas de procesamiento de fin de mes con un pequeño número de usuarios simultáneos, pero ocasionalmente se ejecutan en otras ocasiones. El consumo promedio de memoria de las aplicaciones es inferior a 1 GB. aunque algunas aplicaciones utilizan tanto como 2.5 GB de memoria durante el pico de procesamiento. La aplicación más importante del grupo es un informe de facturación escrito en Java que accede a múltiples fuentes de datos y a menudo se ejecuta durante varias horas.
Cuál es la solución MÁS rentable?
A.
Implemente una función de AWS Lambda independiente para cada aplicación. Utilice los registros de AWS CloudTrail y las alarmas de Amazon CloudWatch para verificar la finalización de trabajos críticos.
B.
Implemente contenedores de Amazon ECS en Amazon EC2 con Auto Scaling configurado para una utilización de memoria del 75%. Implemente una tarea de ECS para cada aplicación que se migra con escalado de tareas de ECS. Supervise los servicios y los hosts mediante Amazon CloudWatch.
C.
Implemente AWS Elastic Beanstalk para cada aplicación con Auto Scaling para garantizar que todas las solicitudes tengan suficientes recursos. Supervise cada implementación de AWS Elastic Beanstalk mediante alarmas de CloudWatch.
D.
Implemente un nuevo clúster de instancias de Amazon EC2 que cohospede todas las aplicaciones mediante EC2 Auto Scaling y Application Load Balancers. Escale el tamaño del clúster en función de un conjunto de métricas personalizadas en la utilización de la memoria de instancias. Compra reservas de instancias reservadas de 3 años iguales al parámetro GroupMaxSize del grupo Auto Scaling.
AnswerDiscussion
Correct Answer: B
Para administrar los costos asociados con las aplicaciones críticas para el negocio que se usan con poca frecuencia, al tiempo que se minimizan los costos y se estandariza la implementación, implementar contenedores de Amazon ECS en Amazon EC2 con Auto Scaling configurado para una utilización de memoria del 75% es la solución más rentable. ECS permite una administración eficiente de contenedores, lo que reduce la sobrecarga y puede optimizar el uso de recursos. Auto Scaling garantizará que las aplicaciones tengan los recursos necesarios durante sus horas pico de uso sin sobreaprovisionamiento. Además, la contenerización es más granular y rentable en comparación con el aprovisionamiento de instancias dedicadas para cada aplicación.
Question 263 of 529
Un arquitecto de soluciones necesita revisar el diseño de un clúster de Amazon EMR que utiliza EMR File System (EMRFS). El clúster realiza tareas que son críticas para las necesidades del negocio. El clúster ejecuta instancias bajo demanda de Amazon EC2 en todo momento para todos los nodos principales, principales y de tareas. Las tareas de EMR se ejecutan cada mañana, a partir de la 1:00am. y tardan 6 horas en terminar de correr. La cantidad de tiempo para completar el procesamiento no es una prioridad porque no se hace referencia a los datos hasta tarde en el día.
El arquitecto de soluciones debe revisar la arquitectura y sugerir una solución para minimizar los costos de cómputos.
Qué solución debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Inicie todos los nodos principales, principales y de tareas en instancias puntuales en una flota de instancias. Terminar el clúster, incluidas todas las instancias, cuando se complete el procesamiento.
B.
Inicie los nodos principal y principal en instancias bajo demanda. Lanzar los nodos de tareas en instancias puntuales en una flota de instancias. Terminar el clúster, incluidas todas las instancias, cuando se complete el procesamiento. Compra planes de ahorro de cómputos para cubrir el uso de instancias bajo demanda.
C.
Continúe lanzando todos los nodos en instancias bajo demanda. Terminar el clúster, incluidas todas las instancias, cuando se complete el procesamiento. Compra planes de ahorro de cómputos para cubrir el uso de instancias bajo demanda.
D.
Inicie los nodos principal y principal en instancias bajo demanda. Lanzar los nodos de tareas en instancias puntuales en una flota de instancias. Termine solo las instancias del nodo de tarea cuando se complete el procesamiento. Compra planes de ahorro de cómputos para cubrir el uso de instancias bajo demanda.
AnswerDiscussion
Correct Answer: B
Para minimizar los costos de cómputos en un clúster de Amazon EMR, tiene más sentido utilizar una combinación de instancias bajo demanda y instancias puntuales. Las instancias bajo demanda deben usarse para los nodos principales y principales para garantizar la estabilidad y la disponibilidad, mientras que se pueden lanzar nodos de tareas menos críticos en instancias puntuales para ahorrar costos. Una vez que se completan las tareas de procesamiento, la terminación de todo el clúster puede maximizar el ahorro de costos, ya que los datos se almacenan en Amazon S3 y se puede acceder más tarde sin necesidad de mantener el clúster en ejecución. Además, la compra de planes de ahorro de cómputos puede reducir aún más los costos de las instancias bajo demanda. Este enfoque mantiene el equilibrio entre el ahorro de costos y la eficiencia operativa.
Question 264 of 529
Una empresa ha migrado una aplicación heredada a la nube de AWS. La aplicación se ejecuta en tres instancias de Amazon EC2 distribuidas en tres zonas de disponibilidad. Una instancia EC2 está en cada zona de disponibilidad. Las instancias EC2 se ejecutan en tres subredes privadas de la VPC y se configuran como destinos para un balanceador de carga de aplicaciones (ALB) asociado a tres subredes públicas.
La aplicación necesita comunicarse con los sistemas locales. Solo el tráfico de direcciones IP en el rango de direcciones IP de la compañía puede acceder a los sistemas locales. El equipo de seguridad de la compañía está trayendo solo una dirección IP de su rango interno de direcciones IP a la nube. La compañía ha agregado esta dirección IP a la lista de permisos para el firewall de la compañía. La compañía también ha creado una dirección IP elástica para esta dirección IP.
Un arquitecto de soluciones necesita crear una solución que brinde a la aplicación la capacidad de comunicarse con los sistemas locales. La solución también debe ser capaz de mitigar las fallas automáticamente.
Qué solución cumplirá con estos requisitos?
A.
Despliega tres puertas de enlace NAT, una en cada subred pública. Asigne la dirección IP elástica a las puertas de enlace NAT. Active las comprobaciones de estado de las puertas de enlace NAT. Si una puerta de enlace NAT falla una comprobación de estado, vuelva a crear la puerta de enlace NAT y asigne la dirección IP elástica a la nueva puerta de enlace NAT.
B.
Reemplace el ALB por un balanceador de carga de red (NLB). Asigne la dirección IP elástica al NLEncienda las comprobaciones de estado para el NEn el caso de una comprobación de estado fallida, vuelva a implementar el NLB en diferentes subredes.
C.
Implemente una única puerta de enlace NAT en una subred pública. Asigne la dirección IP elástica a la puerta de enlace NAT. Utilice Amazon CloudWatch con una métrica personalizada para supervisar la puerta de enlace NAT. Si la puerta de enlace NAT no es saludable, invoque una función de AWS Lambda para crear una nueva puerta de enlace NAT en una subred diferente. Asigne la dirección IP elástica a la nueva puerta de enlace NAT.
D.
Asigne la dirección IP elástica al ALB. Cree un registro simple de Amazon Route 53 con la dirección IP elástica como valor. Crea una comprobación de estado de Route 53. En el caso de una comprobación de estado fallida, recrear el ALB en diferentes subredes.
AnswerDiscussion
Correct Answer: C
Para habilitar la comunicación entre la aplicación que se ejecuta en instancias EC2 en subredes privadas y los sistemas locales, se debe implementar una única puerta de enlace NAT en una subred pública. La dirección IP elástica se asignará a la puerta de enlace NAT, permitiendo que todo el tráfico de las subredes privadas aparezca como proveniente de la dirección IP pública de la compañía. La supervisión del estado de esta puerta de enlace NAT mediante Amazon CloudWatch garantiza que, si se vuelve poco saludable, se puede activar un proceso de conmutación por error. Esto implica una función de AWS Lambda para crear una nueva puerta de enlace NAT en una subred diferente y reasignar la dirección IP elástica, asegurando así una comunicación continua y mitigando las fallas automáticamente. Esta solución cumple con los requisitos al proporcionar un único punto de salida con comprobaciones de estado automáticas y capacidad de conmutación por error.
Question 265 of 529
Una empresa utiliza AWS Organizations para administrar más de 1,000 cuentas de AWS. La compañía ha creado una nueva organización desarrolladora. Hay 540 cuentas de miembros desarrolladores que deben trasladarse a la nueva organización desarrolladora. Todas las cuentas se configuran con toda la información requerida para que cada cuenta pueda operarse como una cuenta independiente.
Qué combinación de pasos debe tomar un arquitecto de soluciones para trasladar todas las cuentas de desarrollador a la nueva organización de desarrolladores? (Elija tres.)
A.
Llame a la operación MoveAccount en la API de Organizaciones desde la cuenta de administración de la antigua organización para migrar las cuentas de desarrollador a la nueva organización desarrolladora.
B.
Desde la cuenta de administración, elimine cada cuenta de desarrollador de la organización anterior utilizando la operación RemoveAccountFromOrganization en la API de Organizaciones.
C.
De cada cuenta de desarrollador, elimine la cuenta de la organización anterior utilizando la operación RemoveAccountFromOrganization en la API de Organizaciones.
D.
Inicie sesión en la cuenta de administración de la nueva organización desarrolladora y cree una cuenta de miembro de marcador de posición que actúe como objetivo para la migración de la cuenta de desarrollador.
E.
Llame a la operación InviteAccountToOrganization en la API de Organizaciones desde la cuenta de administración de la nueva organización desarrolladora para enviar invitaciones a las cuentas de desarrollador.
F.
Haga que cada desarrollador inicie sesión en su cuenta y confirme para unirse a la nueva organización de desarrolladores.
ResponderDiscusión
Correct Answer: B, E, F
Para trasladar las cuentas de desarrollador a la nueva organización desarrolladora, los pasos deben ser los siguientes: Primero, de la cuenta de administración de la organización anterior, eliminar cada cuenta de desarrollador utilizando la operación RemoveAccountFromOrganization. A continuación, desde la cuenta de administración de la nueva organización desarrolladora, llame a la operación InviteAccountToOrganization para enviar invitaciones a las cuentas de desarrollador. Por último, haga que cada desarrollador inicie sesión en su cuenta y confirme la invitación para unirse a la nueva organización desarrolladora. Estas acciones garantizan colectivamente la transferencia de cuentas entre organizaciones. Las opciones que respaldan estas acciones son eliminar las cuentas, enviar invitaciones y confirmar las invitaciones, hacer que B, E y F sean las elecciones correctas.
Question 266 of 529
La aplicación web interactiva de una empresa utiliza una distribución de Amazon CloudFront para servir imágenes de un bucket de Amazon S3. Ocasionalmente, las herramientas de terceros ingieren imágenes corruptas en el bucket S3. Esta corrupción de imagen provoca una mala experiencia de usuario en la aplicación más adelante. La compañía ha implementado y probado con éxito la lógica Python para detectar imágenes corruptas.
Un arquitecto de soluciones debe recomendar una solución para integrar la lógica de detección con una latencia mínima entre la ingestión y el servicio.
Qué solución cumplirá con estos requisitos?
A.
Utilice una función Lambda @Edge que es invocada por un evento viewer-response.
B.
Utilice una función Lambda @Edge que sea invocada por un evento origin-response.
C.
Utilice una notificación de evento S3 que invoque una función de AWS Lambda.
D.
Utilice una notificación de evento S3 que invoque una máquina de estado de AWS Step Functions.
ResponderDiscusión
Correct Answer: C
Para garantizar una latencia mínima entre la ingestión y el servicio de imágenes mientras se detectan imágenes corruptas, la solución debería activar la lógica de detección tan pronto como se cargue una nueva imagen en el bucket S3. El uso de una notificación de eventos S3 para invocar una función de AWS Lambda integra efectivamente la lógica de detección justo en el punto de ingestión. Este enfoque permite la detección y manejo inmediato de imágenes corruptas, evitando que causen una mala experiencia de usuario posteriormente. Las opciones A y B, que involucran a Lambda @Edge invocada por eventos de respuesta del espectador o origin-respuesta, introducirían más latencia y detectarían el problema más adelante en el proceso. La opción D, que involucra AWS Step Functions, agregaría complejidad innecesaria para este caso de uso.
Question 267 of 529
Una empresa tiene una aplicación que se ejecuta en instancias de Amazon EC2 en un grupo de Amazon EC2 Auto Scaling. La compañía utiliza AWS CodePipeline para implementar la aplicación. Las instancias que se ejecutan en el grupo Auto Scaling cambian constantemente debido a los eventos de escalado.
Cuando la empresa implementa nuevas versiones de código de aplicación, la compañía instala el agente AWS CodeDeploy en cualquier instancia EC2 de destino nueva y asocia las instancias con el grupo de implementación CodeDeploy. La aplicación está programada para que entre en funcionamiento dentro de las próximas 24 horas.
Qué debería recomendar un arquitecto de soluciones para automatizar el proceso de implementación de aplicaciones con la MENOR cantidad de sobrecarga operativa?
A.
Configure Amazon EventBridge para invocar una función de AWS Lambda cuando se inicie una nueva instancia EC2 en el grupo Auto Scaling. Codifique la función Lambda para asociar las instancias EC2 con el grupo de implementación CodeDeploy.
B.
Escriba un script para suspender las operaciones de Amazon EC2 Auto Scaling antes de la implementación del nuevo código. Cuando se complete la implementación, cree una nueva AMI y configure la plantilla de lanzamiento del grupo Auto Scaling para usar la nueva AMI para nuevos lanzamientos. Reanude las operaciones de Auto Scaling de Amazon EC2.
C.
Cree un nuevo proyecto de AWS CodeBuild que cree una nueva AMI que contenga el nuevo código. Configure CodeBuild para actualizar la plantilla de lanzamiento del grupo Auto Scaling a la nueva AMI. Ejecute una operación de actualización de instancia de Amazon EC2 Auto Scaling.
D.
Cree una nueva AMI que tenga instalado el agente CodeDeploy. Configure la plantilla de lanzamiento del grupo Auto Scaling para usar la nueva AMI. Asocie el grupo de implementación CodeDeploy con el grupo Auto Scaling en lugar de las instancias EC2.
ResponderDiscusión
Correct Answer: D
Para automatizar el proceso de implementación de aplicaciones con la menor sobrecarga operativa, la mejor recomendación es crear una nueva Amazon Machine Image (AMI) que incluya el agente AWS CodeDeploy preinstalado. La plantilla de lanzamiento del grupo Auto Scaling debe actualizarse para usar esta nueva AMI. Al hacerlo, cualquier instancia nueva lanzada por el grupo Auto Scaling ya tendrá instalado el agente CodeDeploy y se puede asociar automáticamente con el grupo de implementación CodeDeploy. Esto elimina la necesidad de instalar manualmente el agente CodeDeploy en cada nueva instancia y garantiza un proceso de implementación sin fisuras y automatizado.
Question 268 of 529
Una empresa tiene un sitio web que se ejecuta en cuatro instancias de Amazon EC2 que están detrás de un balanceador de carga de aplicaciones (ALB). Cuando el ALB detecta que una instancia EC2 ya no está disponible, una alarma de Amazon CloudWatch entra en el estado ALARM. Un miembro del equipo de operaciones de la compañía luego agrega manualmente una nueva instancia EC2 detrás del ALB.
Un arquitecto de soluciones necesita diseñar una solución de alta disponibilidad que maneje automáticamente el reemplazo de instancias EC2. La compañía necesita minimizar el tiempo de inactividad durante el cambio a la nueva solución.
Qué conjunto de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Eliminar el ALB existente. Cree un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjunte una nueva plantilla de lanzamiento al grupo Auto Scaling. Crear un nuevo ALB. Adjunte el grupo Auto Scaling al nuevo ALB. Adjunte las instancias EC2 existentes al grupo Auto Scaling.
B.
Cree un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjunte una nueva plantilla de lanzamiento al grupo Auto Scaling. Adjunte el grupo Auto Scaling al ALAdjunte las instancias EC2 existentes al grupo Auto Scaling.
C.
Eliminar las instancias ALB y EC2 existentes. Cree un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjunte una nueva plantilla de lanzamiento al grupo Auto Scaling. Crear un nuevo ALB. Adjunte el grupo Auto Scaling al nuevo ALB. Espere a que el grupo Auto Scaling inicie el número mínimo de instancias EC2.
D.
Cree un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjunte una nueva plantilla de lanzamiento al grupo Auto Scaling. Adjunte el grupo Auto Scaling al ALB existente. Espere a que el ALB existente registre las instancias EC2 existentes con el grupo Auto Scaling.
ResponderDiscusión
Correct Answer: B
Para diseñar una solución de alta disponibilidad que maneje automáticamente el reemplazo de instancias EC2 mientras minimiza el tiempo de inactividad, el arquitecto de soluciones debe crear un grupo de Auto Scaling (ASG) configurado para manejar el tráfico de aplicaciones web. Adjunte una nueva plantilla de lanzamiento al ASG y luego adjunte el ASG al balanceador de carga de aplicaciones (ALB) existente. Las instancias EC2 existentes deben adjuntarse al ASG para garantizar que sean administradas por el ASG, que manejará automáticamente el reemplazo de cualquier instancia que falle en función de las comprobaciones de estado. Este enfoque aprovecha la infraestructura existente (el ALB y las instancias EC2 en ejecución) y la mejora con las capacidades del ASG, proporcionando una solución de escalado automatizada y fluida sin la necesidad de eliminar o recrear recursos, lo que garantiza un tiempo de inactividad mínimo.
Question 269 of 529
Una empresa quiere optimizar los costos de transferencia de datos de AWS y los costos de cómputos en todas las cuentas de desarrollador dentro de la organización de la compañía en AWS Organizations. Los desarrolladores pueden configurar VPC y lanzar instancias de Amazon EC2 en una sola región de AWS. Las instancias EC2 recuperan aproximadamente 1 TB de datos cada día de Amazon S3.
La actividad del desarrollador conlleva cargos mensuales excesivos de transferencia de datos y cargos de procesamiento de puerta de enlace NAT entre instancias EC2 y buckets S3, junto con altos costos de cómputos. La compañía quiere aplicar proactivamente patrones arquitectónicos aprobados para cualquier instancia EC2 e infraestructura de VPC que los desarrolladores implementen dentro de las cuentas de AWS. La compañía no quiere que esta aplicación afecte negativamente la velocidad a la que los desarrolladores pueden realizar sus tareas.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree SCP para evitar que los desarrolladores inicien tipos de instancias EC2 no aprobados. Proporcione a los desarrolladores una plantilla de AWS CloudFormation para implementar una configuración de VPC aprobada con puntos finales de interfaz S3. Alcance los permisos de IAM de los desarrolladores para que los desarrolladores puedan lanzar recursos de VPC solo con CloudFormation.
B.
Cree un presupuesto previsto diario con AWS Budget para monitorear los costos de computación de EC2 y los costos de transferencia de datos S3 en todas las cuentas de desarrollador. Cuando el costo previsto sea del 75% del costo real del presupuesto, envíe una alerta a los equipos de desarrolladores. Si el costo real del presupuesto es del 100%, cree una acción presupuestaria para terminar las instancias EC2 y la infraestructura de VPC de los desarrolladores.
C.
Cree una cartera de AWS Service Catalog que los usuarios puedan usar para crear una configuración de VPC aprobada con endpoints de puerta de enlace S3 e instancias EC2 aprobadas. Comparte la cartera con las cuentas de los desarrolladores. Configure una restricción de lanzamiento de AWS Service Catalog para usar un rol de IAM aprobado. Alcance los permisos de IAM de los desarrolladores para permitir el acceso solo a AWS Service Catalog.
D.
Cree e implemente reglas de AWS Config para monitorear el cumplimiento de los recursos de EC2 y VPC en las cuentas de AWS para desarrolladores. Si los desarrolladores lanzan instancias EC2 no aprobadas o si los desarrolladores crean VPC sin endpoints de puerta de enlace S3, realice una acción de corrección para terminar los recursos no aprobados.
ResponderDiscusión
Correct Answer: C
La mejor solución para cumplir con los requisitos de la compañía es crear una cartera de AWS Service Catalog. Esta cartera se puede configurar para permitir a los desarrolladores crear configuraciones de VPC que incluyan endpoints de puerta de enlace S3 e instancias EC2 aprobadas, lo que garantiza la rentabilidad y el cumplimiento de los patrones arquitectónicos de la empresa. Compartir la cartera con las cuentas de desarrollador y establecer restricciones de lanzamiento utilizando un rol de IAM aprobado permite la gobernanza mientras se mantiene la productividad del desarrollador. Al examinar los permisos de IAM de los desarrolladores para permitir el acceso solo a AWS Service Catalog, la compañía puede imponer el cumplimiento sin obstaculizar la velocidad a la que los desarrolladores pueden realizar sus tareas.
Question 270 of 529
Una empresa se está expandiendo. La compañía planea separar sus recursos en cientos de cuentas de AWS diferentes en varias regiones de AWS. Un arquitecto de soluciones debe recomendar una solución que niegue el acceso a cualquier operación fuera de las Regiones específicamente designadas.
Qué solución cumplirá con estos requisitos?
A.
Crear roles de IAM para cada cuenta. Cree políticas de IAM con permisos condicionales que incluyan solo Regiones aprobadas para las cuentas.
B.
Crear una organización en AWS Organizations. Crear usuarios de IAM para cada cuenta. Adjunte una política a cada usuario para bloquear el acceso a Regiones donde una cuenta no pueda implementar infraestructura.
C.
Lanzar una zona de aterrizaje de la torre de control de AWS. Cree unidades organizativas y adjunte SCP que nieguen el acceso para ejecutar servicios fuera de las Regiones aprobadas.
D.
Habilite AWS Security Hub en cada cuenta. Cree controles para especificar las regiones donde una cuenta puede implementar la infraestructura.
ResponderDiscusión
Correct Answer: C
La mejor solución para garantizar que las cuentas no puedan realizar operaciones fuera de las regiones designadas de AWS es utilizar AWS Control Tower junto con políticas de control de servicios (SCP). Al lanzar una zona de aterrizaje de la torre de control de AWS y crear unidades organizativas (OU), se pueden aplicar SCP a estas unidades organizativas para hacer cumplir restricciones en la ejecución de servicios fuera de las regiones aprobadas. Este método centraliza la gestión del control de acceso y escala de manera eficiente en múltiples cuentas, asegurando el cumplimiento constante de los requisitos de la compañía.
Question 271 of 529
Una empresa quiere refactorizar su aplicación web de pedidos minoristas que actualmente tiene una flota de instancias de Amazon EC2 con equilibrio de carga para alojamiento web, servicios API de bases de datos y lógica de negocios. La compañía necesita crear una arquitectura desacoplada y escalable con un mecanismo para retener las órdenes fallidas y minimizar los costos operativos.
Qué solución cumplirá con estos requisitos?
A.
Utilice Amazon S3 para alojamiento web con Amazon API Gateway para servicios API de base de datos. Utilice Amazon Simple Queue Service (Amazon SQS) para hacer cola de pedidos. Utilice Amazon Elastic Container Service (Amazon ECS) para la lógica de negocio con el sondeo largo de Amazon SQS para retener los pedidos fallidos.
B.
Utilice AWS Elastic Beanstalk para alojamiento web con Amazon API Gateway para servicios API de bases de datos. Usa Amazon MQ para hacer cola de pedidos. Utilice AWS Step Functions para la lógica empresarial con Amazon S3 Glacier Deep Archive para retener los pedidos fallidos.
C.
Utilice Amazon S3 para alojamiento web con AWS AppSync para servicios API de bases de datos. Utilice Amazon Simple Queue Service (Amazon SQS) para hacer cola de pedidos. Utilice AWS Lambda para la lógica empresarial con una cola de mensajes muertos de Amazon SQS para retener las órdenes fallidas.
D.
Utilice Amazon Lightail para alojamiento web con AWS AppSync para servicios API de bases de datos. Utilice Amazon Simple Email Service (Amazon SES) para hacer cola de pedidos. Utilice Amazon Elastic Kubernetes Service (Amazon EKS) para la lógica de negocio con Amazon OpenSearch Service para retener pedidos fallidos.
ResponderDiscusión
Correct Answer: C
Question 272 of 529
Una empresa aloja una aplicación web en AWS en la región us-east-1. Los servidores de aplicaciones se distribuyen en tres zonas de disponibilidad detrás de un balanceador de carga de aplicaciones. La base de datos está alojada en una base de datos MySQL en una instancia de Amazon EC2. Un arquitecto de soluciones necesita diseñar una solución de recuperación de datos entre regiones utilizando los servicios de AWS con un RTO de menos de 5 minutos y un RPO de menos de 1 minuto. El arquitecto de soluciones está implementando servidores de aplicaciones en us-west-2 y ha configurado las comprobaciones de estado de Amazon Route 53 y la conmutación por error de DNS a us-west-2.
Qué paso adicional debería dar el arquitecto de soluciones?
A.
Migre la base de datos a una instancia de Amazon RDS para MySQL con una réplica de lectura entre regiones en us-west-2.
B.
Migre la base de datos a una base de datos global de Amazon Aurora con la principal en us-east-1 y la secundaria en us-west-2.
C.
Migre la base de datos a una instancia de Amazon RDS para MySQL con una implementación Multi-AZ.
D.
Cree una base de datos MySQL en espera en una instancia de Amazon EC2 en us-west-2.
ResponderDiscusión
Correct Answer: B
Para lograr un RTO de menos de 5 minutos y un RPO de menos de 1 minuto, es esencial utilizar una solución de base de datos que permita una conmutación por error rápida y una pérdida mínima de datos. La migración de la base de datos a una base de datos global de Amazon Aurora con la principal en us-east-1 y la secundaria en us-west-2 aborda efectivamente estos requisitos. La función de base de datos global de Aurora permite un retraso de replicación de subsegundos y la capacidad de promover la región secundaria a primaria en menos de un minuto, cumpliendo así los requisitos de RTO y RPO.
Question 273 of 529
Una empresa utiliza AWS Organizations para administrar varias cuentas. Debido a los requisitos reglamentarios, la compañía quiere restringir cuentas de miembros específicas a ciertas regiones de AWS, donde se les permite implementar recursos. Los recursos en las cuentas deben ser etiquetados, aplicados en base a un estándar de grupo y administrados centralmente con una configuración mínima.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una regla de AWS Config en las cuentas de miembro específicas para limitar Regiones y aplicar una política de etiquetas.
B.
Desde la consola de AWS Billing and Cost Management, en la cuenta de administración, desactive Regions para las cuentas de miembro específicas y aplique una política de etiquetas en la raíz.
C.
Asociar las cuentas de miembro específicas con la raíz. Aplicar una política de etiquetas y un SCP usando condiciones para limitar Regiones.
D.
Asociar las cuentas de miembro específicas con una nueva unidad organizativa. Aplicar una política de etiquetas y un SCP usando condiciones para limitar Regiones.
ResponderDiscusión
Correct Answer: D
Para restringir cuentas de miembros específicas a ciertas regiones de AWS y aplicar políticas de etiquetado, asociar las cuentas de miembro con una nueva Unidad Organizativa (OU) y aplicar una Política de Control de Servicios (SCP) con condiciones para limitar Regiones es el enfoque más efectivo. Un SCP puede denegar o permitir acciones basadas en condiciones, y cuando se vincula a una unidad organizativa, puede aplicar políticas de manera consistente en todas las cuentas dentro de esa unidad organizativa. Además, se puede aplicar una política de etiquetas para garantizar que los recursos se etiqueten de acuerdo con los estándares del grupo. Este método permite una administración centralizada con una configuración mínima.
Question 274 of 529
Una empresa cuenta con una aplicación que genera informes y los almacena en un bucket de Amazon S3. Cuando un usuario accede a su informe, la aplicación genera una URL firmada para permitir al usuario descargar el informe. El equipo de seguridad de la compañía ha descubierto que los archivos son públicos y que cualquiera puede descargarlos sin autenticación. La compañía ha suspendido la generación de nuevos reportes hasta que se resuelva el problema.
Qué conjunto de acciones solucionará inmediatamente el problema de seguridad sin afectar el flujo de trabajo normal de la aplicación?
A.
Cree una función de AWS Lambda que aplique una política de denegar todo para los usuarios que no estén autenticados. Cree un evento programado para invocar la función Lambda.
B.
Revise la comprobación de permisos de bucket de AWS Trusted Advisor e implemente las acciones recomendadas.
C.
Ejecute un script que ponga una ACL privada en todos los objetos del bucket.
D.
Utilice la función Bloquear acceso público en Amazon S3 para establecer la opción IgnoRepublicacis en TRUE en el bucket.
ResponderDiscusión
Correct Answer: D
El uso de la función Bloquear acceso público en Amazon S3 para establecer la opción IgnoRepublicACLS en TRUE garantiza que se ignoran todas las ACL públicas, bloqueando de manera efectiva el acceso público a los archivos en el bucket S3. Este enfoque abordará inmediatamente el problema de seguridad al evitar descargas no autorizadas sin afectar el flujo de trabajo normal de la aplicación, ya que la aplicación aún puede generar URL firmadas para el acceso autenticado.
Question 275 of 529
Una compañía planea migrar una base de datos de Amazon RDS para Oracle a una instancia de base de datos RDS para PostgreSQL en otra cuenta de AWS. Un arquitecto de soluciones necesita diseñar una estrategia de migración que no requiera tiempo de inactividad y que minimice la cantidad de tiempo necesario para completar la migración. La estrategia de migración debe replicar todos los datos existentes y cualquier dato nuevo que se cree durante la migración. La base de datos de destino debe ser idéntica a la base de datos de origen al finalizar el proceso de migración.
Todas las aplicaciones utilizan actualmente un registro CNAME de Amazon Route 53 como punto final para la comunicación con la instancia de base de datos de RDS para Oracle. La instancia de base de datos RDS para Oracle se encuentra en una subred privada.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Cree una nueva instancia de base de datos RDS para PostgreSQL en la cuenta de destino. Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) para migrar el esquema de la base de datos de origen a la base de datos de destino.
B.
Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) para crear una nueva instancia de base de datos RDS para PostgreSQL en la cuenta de destino con el esquema y los datos iniciales de la base de datos de origen.
C.
Configure la interconexión de VPC entre las VPC en las dos cuentas de AWS para proporcionar conectividad a ambas instancias de base de datos desde la cuenta de destino. Configure los grupos de seguridad que se adjuntan a cada instancia de base de datos para permitir el tráfico en el puerto de base de datos desde la VPC en la cuenta de destino.
D.
Permitir temporalmente que la instancia de base de datos de origen sea accesible públicamente para proporcionar conectividad desde la VPC en la cuenta de destino. Configure los grupos de seguridad que se adjuntan a cada instancia de base de datos para permitir el tráfico en el puerto de base de datos desde la VPC en la cuenta de destino.
E.
Utilice AWS Database Migration Service (AWS DMS) en la cuenta de destino para realizar una migración de carga completa y captura de datos de cambio (CDC) de la base de datos de origen a la base de datos de destino. Cuando se complete la migración, cambie el registro CNAME para que apunte al punto final de la instancia de base de datos de destino.
F.
Utilice AWS Database Migration Service (AWS DMS) en la cuenta de destino para realizar una migración de captura de datos de cambio (CDC) de la base de datos de origen a la base de datos de destino. Cuando se complete la migración, cambie el registro CNAME para que apunte al punto final de la instancia de base de datos de destino.
ResponderDiscusión
Correct Answer: A, C, E
Para migrar una base de datos de Amazon RDS para Oracle a una instancia de base de datos de RDS para PostgreSQL sin tiempo de inactividad y un tiempo mínimo, el primer paso es crear una nueva instancia de base de datos RDS para PostgreSQL en la cuenta de destino. AWS Schema Conversion Tool (AWS SCT) se debe utilizar para migrar el esquema de la base de datos de origen a la base de datos de destino, asegurando la compatibilidad entre Oracle y PostgreSQL. A continuación, configure el peering de VPC entre las VPC en las dos cuentas de AWS para proporcionar conectividad entre ambas bases de datos. Esto garantiza una comunicación segura entre las cuentas. Por último, utilice AWS Database Migration Service (AWS DMS) para realizar una migración de carga completa y captura de datos de cambio (CDC) de la base de datos de origen a la base de datos de destino. Este proceso asegura que todos los datos existentes y cualquier dato nuevo durante la migración se repliquen. Una vez completada la migración, actualice el registro Route 53 CNAME para que apunte al nuevo punto final de instancia de base de datos PostgreSQL para redirigir las aplicaciones sin problemas a la nueva base de datos.
Question 276 of 529
Una compañía ha implementado un sistema de pedidos utilizando una arquitectura impulsada por eventos. Durante las pruebas iniciales, el sistema dejó de procesar órdenes. Un análisis adicional del registro reveló que un mensaje de pedido en una cola estándar de Amazon Simple Queue Service (Amazon SQS) estaba causando un error en el backend y bloqueaba todos los mensajes de pedido posteriores. El tiempo de espera de visibilidad de la cola se establece en 30 segundos y el tiempo de espera de procesamiento del backend se establece en 10 segundos. Un arquitecto de soluciones necesita analizar los mensajes de pedido defectuosos y asegurarse de que el sistema continúe procesando los mensajes posteriores.
Qué paso debe dar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Aumente el tiempo de espera de procesamiento del backend a 30 segundos para que coincida con el tiempo de espera de visibilidad.
B.
Reduzca el tiempo de espera de visibilidad de la cola para eliminar automáticamente el mensaje defectuoso.
C.
Configure una nueva cola FIFO de SQS como cola de letra muerta para aislar los mensajes defectuosos.
D.
Configure una nueva cola estándar SQS como cola de letra muerta para aislar los mensajes defectuosos.
ResponderDiscusión
Correct Answer: D
Para abordar el problema de un mensaje defectuoso que bloquea mensajes posteriores en una cola estándar de Amazon SQS, la mejor solución es configurar una nueva cola estándar SQS como cola de letra muerta. Este enfoque asegura que los mensajes defectuosos se aíslen en una cola separada, permitiendo que la cola principal continúe procesando los mensajes posteriores sin interrupción. El uso de una cola estándar de letra muerta es apropiado ya que la cola original también es una cola estándar, lo que garantiza la compatibilidad y el manejo adecuado de las fallas de los mensajes.
Question 277 of 529
Una empresa ha automatizado el reciclaje nocturno de sus modelos de aprendizaje automático mediante el uso de AWS Step Functions. El flujo de trabajo consta de varios pasos que utilizan AWS Lambda. Cada paso puede fallar por varias razones, y cualquier falla causa una falla en el flujo de trabajo general.
Una revisión revela que el reentrenamiento ha fracasado varias noches seguidas sin que la compañía se percatara del fracaso. Un arquitecto de soluciones necesita mejorar el flujo de trabajo para que se envíen notificaciones de todo tipo de fallas en el proceso de reentrenamiento.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Cree un tema de Amazon Simple Notification Service (Amazon SNS) con una suscripción de tipo “Correo electrónico” que se dirija a la lista de correo del equipo.
B.
Cree una tarea llamada “Correo electrónico” que reenvíe los argumentos de entrada al tema SNS.
C.
Agrega un campo Catch a todos los estados Tarea, Mapa y Paralelo que tengan una declaración de “ErrorRequals”: [“States.all”] y “Next”: “Email”.
D.
Agregar una nueva dirección de correo electrónico a Amazon Simple Email Service (Amazon SES). Verifica la dirección de correo electrónico.
E.
Cree una tarea llamada “Correo electrónico” que reenvíe los argumentos de entrada a la dirección de correo electrónico de SES.
F.
Agregue un campo Catch a todos los estados Task, Map y Parallel que tengan una declaración de “ErrorRequals”: [“States.Runtime”] y “Next”: “Email”.
ResponderDiscusión
Correct Answer: A, B, C
Para garantizar que se envíen notificaciones de todo tipo de fallas en el proceso de reciclaje, el arquitecto de soluciones debe crear un tema de Amazon Simple Notification Service (SNS) con una suscripción de tipo 'Email' que se dirija a la lista de correo del equipo. Esto permite notificaciones por correo electrónico cuando falla el proceso de reentrenamiento. Adicionalmente, se debe crear una tarea llamada 'Email' que reenvíe los argumentos de entrada al tema SNS, lo que asegura que estas notificaciones por correo electrónico se activen adecuadamente. Por último, incorporar un campo Catch a todos los estados Tarea, Mapa y Paralelo en el flujo de trabajo de AWS Step Functions con una declaración de 'erroRequals': ['States.all'] y 'Next': 'Email' manejará todo tipo de errores dirigiendo el flujo de trabajo a la tarea 'Email', asegurando un monitoreo integral y alertando de cualquier falla durante el proceso de reentrenamiento.
Question 278 of 529
Una compañía planea implementar un nuevo servicio de intranet privada en instancias de Amazon EC2 dentro de una VPC. Una VPN de sitio a sitio de AWS conecta la VPC a la red local de la compañía. El nuevo servicio debe comunicarse con los servicios locales existentes. Se puede acceder a los servicios locales mediante el uso de nombres de host que residen en la zona DNS de la empresa.ejemplo. Esta zona DNS está totalmente alojada en las instalaciones y solo está disponible en la red privada de la compañía.
Un arquitecto de soluciones debe asegurarse de que el nuevo servicio pueda resolver nombres de host en el dominio company.example para integrarse con los servicios existentes.
Qué solución cumple con estos requisitos?
A.
Crear una zona privada vacía en Amazon Route 53 para empresa.ejemplo. Agregue un registro NS adicional a la compañía local de la empresa.ejemplo de zona que apunta a los servidores de nombres autorizados para la nueva zona privada en Route 53.
B.
Active los nombres de host DNS para la VPC. Configure un nuevo punto final de salida con Amazon Route 53 Resolver. Cree una regla Resolver para reenviar solicitudes de empresa.example a los servidores de nombres locales.
C.
Active los nombres de host DNS para la VPConfigure un nuevo punto final de resolución entrante con Amazon Route 53 Resolver. Configurar&El servidor DNS local para reenviar solicitudes de empresa.ejemplo al nuevo solucionador.
D.
Utilice AWS Systems Manager para configurar un documento de ejecución que instalará un archivo de hosts que contenga los nombres de host requeridos. Utilice una regla de Amazon EventBridge para ejecutar el documento cuando una instancia esté entrando en el estado de ejecución.
ResponderDiscusión
Correct Answer: B
Para garantizar que el nuevo servicio pueda resolver nombres de host en el dominio company.example e integrarse con los servicios locales existentes, es necesario aprovechar Amazon Route 53 Resolver. Al activar los nombres de host DNS para la VPC, las instancias EC2 tendrán la capacidad de realizar la resolución DNS. La configuración de un nuevo punto final de salida con Route 53 Resolver permitirá a la VPC resolver consultas DNS para dominios alojados en la red local. La creación de una regla Resolver para reenviar solicitudes específicamente para el dominio company.example a los servidores de nombres locales garantiza que el nuevo servicio pueda acceder a los servicios locales existentes a través de sus nombres de host.
Question 279 of 529
Una empresa utiliza AWS CloudFormation para implementar aplicaciones dentro de varias VPC que están conectadas a una puerta de enlace de tránsito. Cada VPC que envíe tráfico a la Internet pública debe enviar el tráfico a través de una VPC de servicios compartidos. Cada subred dentro de una VPC utiliza la tabla de rutas de VPC predeterminada y el tráfico se enruta a la puerta de enlace de tránsito. La puerta de enlace de tránsito utiliza su tabla de rutas predeterminada para cualquier adjunto de VPC.
Una auditoría de seguridad revela que una instancia de Amazon EC2 que se implementa dentro de una VPC puede comunicarse con una instancia EC2 que se implementa en cualquiera de las otras VPC de la compañía. Un arquitecto de soluciones necesita limitar el tráfico entre las VPC. Cada VPC debe poder comunicarse únicamente con un conjunto limitado y predefinido de VPC autorizadas.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Actualice la ACL de red de cada subred dentro de una VPC para permitir el tráfico saliente solo a las VPC autorizadas. Elimina todas las reglas de denegar excepto la regla de denegar predeterminada.
B.
Actualice todos los grupos de seguridad que se utilizan dentro de una VPC para denegar el tráfico saliente a los grupos de seguridad que se utilizan dentro de las VPC no autorizadas.
C.
Cree una tabla de rutas de puerta de enlace de tránsito dedicada para cada adjunto de VPC. Enrutar el tráfico solo a los VPC autorizados.
D.
Actualice la tabla de rutas principal de cada VPC para enrutar el tráfico solo a las VPC autorizadas a través de la puerta de enlace de tránsito.
ResponderDiscusión
Correct Answer: C
Para garantizar que solo las VPC autorizadas puedan comunicarse entre sí, un arquitecto de soluciones debe crear una tabla de rutas de puerta de enlace de tránsito dedicada para cada adjunto de VPC. Este enfoque proporciona un control detallado sobre el enrutamiento del tráfico, lo que permite al arquitecto especificar rutas solo a las VPC predefinidas y autorizadas. Al configurar tablas de rutas separadas para cada adjunto de VPC, el tráfico se puede limitar adecuadamente, lo que impone restricciones de comunicación y mejora la seguridad de la red.
Question 280 of 529
Una compañía tiene una aplicación de escritorio basada en Windows que se empaqueta e implementa en las máquinas Windows de los usuarios. La compañía adquirió recientemente otra compañía que cuenta con empleados que utilizan principalmente máquinas con un sistema operativo Linux. La empresa adquirente ha decidido migrar y realojar la aplicación de escritorio basada en Windows a AWS.
Todos los empleados deben ser autenticados antes de usar la aplicación. La empresa adquirente utiliza Active Directory en las instalaciones pero quiere una forma simplificada de administrar el acceso a la aplicación en AWS para todos los empleados.
Qué solución realojará la aplicación en AWS con el MENOR esfuerzo de desarrollo?
A.
Configure y aprovisione un escritorio virtual de Amazon Workspaces para cada empleado. Implementar la autenticación mediante el uso de grupos de identidades de Amazon Cognito. Instruya a los empleados para que ejecuten la aplicación desde sus escritorios virtuales de Workspaces aprovisionados.
B.
Cree un grupo de Auto Scaling de instancias de Amazon EC2 basadas en Windows. Unir cada instancia EC2 al dominio de Active Directory de la compañía. Implementar la autenticación mediante el uso de Active Directory que se ejecuta en las instalaciones. Instruya a los empleados para que ejecuten la aplicación mediante un escritorio remoto de Windows.
C.
Utilice un generador de imágenes de Amazon AppStream 2.0 para crear una imagen que incluya la aplicación y las configuraciones necesarias. Aprovisione una flota AppStream 2.0 On-Demand con políticas dinámicas de Fleet Auto Scaling para ejecutar la imagen. Implementar la autenticación mediante el uso de grupos de usuarios de AppStream 2.0. Instruya a los empleados para que accedan a la aplicación iniciando sesiones de streaming de AppStream 2.0 basadas en navegador.
D.
Refactorizar y contenerizar la aplicación para que se ejecute como una aplicación basada en la web. Ejecute la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate con políticas de escalado por pasos. Implementar la autenticación mediante el uso de grupos de usuarios de Amazon Cognito. Instruir a los empleados para que ejecuten la aplicación desde sus navegadores.
ResponderDiscusión
Correct Answer: C
La solución más sencilla con el menor esfuerzo de desarrollo es usar Amazon AppStream 2.0. Este servicio permite crear una imagen que incluye la aplicación de escritorio basada en Windows y las configuraciones necesarias. AppStream 2.0 admite escalado dinámico y autenticación de usuarios a través de sus grupos de usuarios. Los empleados pueden acceder fácilmente a la aplicación a través de sesiones de streaming basadas en navegador, lo que la hace compatible multiplataforma sin refactorización significativa ni complejidad adicional. Esto efectivamente cierra la brecha entre los diferentes sistemas operativos utilizados por los empleados al tiempo que simplifica la gestión del acceso.
Question 281 of 529
Una empresa está recopilando una gran cantidad de datos de una flota de dispositivos IoT. Los datos se almacenan como archivos de columnas de fila optimizadas (ORC) en el sistema de archivos distribuido de Hadoop (HDFS) en un clúster persistente de Amazon EMR. El equipo de análisis de datos de la compañía consulta los datos usando SQL en Apache Presto implementado en el mismo clúster de EMR. Las consultas escanean grandes cantidades de datos, siempre se ejecutan por menos de 15 minutos y se ejecutan solo entre las 5 PM y las 10 PM.
A la compañía le preocupa el alto costo asociado a la solución actual. Un arquitecto de soluciones debe proponer la solución más rentable que permita realizar consultas de datos SQL.
Qué solución cumplirá con estos requisitos?
A.
Almacenar datos en Amazon S3. Utilice Amazon Redshift Spectrum para consultar datos.
B.
Almacenar datos en Amazon S3. Utilice el catálogo de datos de AWS Glue y Amazon Athena para consultar datos.
C.
Almacenar datos en Sistema de Archivos EMR (EMRFS). Use Presto en Amazon EMR para consultar datos.
D.
Almacenar datos en Amazon Redshift. Utilice Amazon Redshift para consultar datos.
ResponderDiscusión
Correct Answer: B
Almacenar datos en Amazon S3. Utilice el catálogo de datos de AWS Glue y Amazon Athena para consultar datos. Amazon S3 es una solución de almacenamiento altamente rentable en comparación con la ejecución de un clúster EMR persistente. El catálogo de datos de AWS Glue proporciona un repositorio centralizado para administrar metadatos, lo que facilita la organización de los datos y mejora el rendimiento de las consultas. Amazon Athena, un servicio de consultas sin servidor, le permite ejecutar consultas SQL directamente contra datos en S3 sin necesidad de infraestructura dedicada. Este enfoque se adapta bien a las necesidades de la compañía ya que las consultas se ejecutan solo por unas pocas horas diarias y solo pagan por las consultas ejecutadas, mejorando la rentabilidad.
Question 282 of 529
Una gran empresa experimentó recientemente un aumento inesperado en los costos de Amazon RDS y Amazon DynamoDB. La compañía necesita aumentar la visibilidad de los detalles de AWS Billing and Cost Management. Hay varias cuentas asociadas con las organizaciones de AWS, incluidas muchas cuentas de desarrollo y producción. No existe una estrategia de etiquetado consistente en toda la organización, pero existen pautas que requieren que toda la infraestructura se implemente con AWS CloudFormation con etiquetado consistente. La administración requiere números de centro de costos y números de ID de proyecto para todas las tablas de DynamoDB e instancias RDS existentes y futuras.
Qué estrategia debe proporcionar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice el Editor de etiquetas para etiquetar los recursos existentes. Cree etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto y permita 24 horas para que las etiquetas se propaguen a los recursos existentes.
B.
Utilice una regla de AWS Config para alertar al equipo financiero de los recursos sin etiquetar. Cree una solución centralizada basada en AWS Lambda para etiquetar bases de datos RDS sin etiquetar y recursos de DynamoDB cada hora utilizando un rol entre cuentas.
C.
Utilice el Editor de etiquetas para etiquetar los recursos existentes. Cree etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto. Utilice SCP para restringir la creación de recursos que no tengan el centro de costo y el ID del proyecto en el recurso.
D.
Cree etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto y permita 24 horas para que las etiquetas se propaguen a los recursos existentes. Actualice los roles federados existentes para restringir los privilegios para aprovisionar recursos que no incluyan el centro de costos y el ID del proyecto en el recurso.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de la compañía para los recursos existentes y futuros, la estrategia correcta es usar el Editor de etiquetas para etiquetar los recursos existentes y crear etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto. Además, el uso de políticas de control de servicios (SCP) puede imponer requisitos de etiquetado en la creación de nuevos recursos, asegurando que todas las tablas de DynamoDB e instancias de RDS futuras incluyan las etiquetas de centro de costo e ID de proyecto requeridas. Este enfoque proporciona una solución integral para gestionar el etiquetado tanto de manera retrospectiva como prospectiva.
Question 283 of 529
Una empresa quiere enviar datos desde sus sistemas locales a buckets de Amazon S3. La compañía creó los cubos S3 en tres cuentas diferentes. La empresa debe enviar los datos de forma privada sin que los datos viajen a través de Internet. La compañía no tiene conectividad dedicada a AWS.
Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. Configure una conexión AWS Direct Connect con un VIF privado entre el entorno local y la VPC privada.
B.
Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. Configure una conexión AWS Direct Connect con un VIF público entre el entorno local y la VPC privada.
C.
Cree un punto final de interfaz de Amazon S3 en la cuenta de red.
D.
Cree un endpoint de puerta de enlace de Amazon S3 en la cuenta de red.
E.
Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. VPC del mismo nivel de las cuentas que alojan los buckets S3 con la VPC en la cuenta de red.
ResponderDiscusión
Correct Answer: A, C
Para cumplir con los requisitos de enviar datos desde sistemas locales a buckets de Amazon S3 en diferentes cuentas sin que los datos viajen a través de Internet, la compañía debe establecer una cuenta de red en AWS y crear una VPC privada en esa cuenta. La configuración de una conexión AWS Direct Connect con una interfaz virtual privada (VIF) entre el entorno local y la VPC privada garantiza una conexión privada dedicada que no atraviesa la Internet pública. Además, la creación de un punto final de interfaz de Amazon S3 en la cuenta de red permite a los sistemas locales acceder a los buckets de S3 mediante direcciones IP privadas dentro de la VPC. Los puntos finales de puerta de enlace no permiten el acceso desde entornos locales, por lo tanto, aprovechar un punto final de interfaz es el enfoque adecuado para la transferencia segura y privada de datos.
Question 284 of 529
Una empresa opera restaurantes de servicio rápido. Los restaurantes siguen un modelo predecible con alto tráfico de ventas durante 4 horas diarias. El tráfico de ventas es menor fuera de esas horas pico.
La plataforma de punto de venta y administración se implementa en la nube de AWS y cuenta con un backend que se basa en Amazon DynamoDB. La tabla de la base de datos utiliza el modo de rendimiento aprovisionado con 100,000 RCU y 80.000 WCUs para hacer coincidir el consumo de recursos pico conocido.
La compañía quiere reducir su costo de DynamoDB y minimizar la sobrecarga operativa para el personal de TI.
Qué solución cumple con estos requisitos de manera más rentable?
A.
Reducir las RCUs y WCUs aprovisionadas.
B.
Cambie la tabla DynamoDB para utilizar la capacidad bajo demanda.
C.
Habilite el escalado automático de Dynamo DB para la tabla.
D.
Compra capacidad reservada de 1 año que sea suficiente para cubrir la carga máxima durante 4 horas cada día.
ResponderDiscusión
Correct Answer: C
El escenario declarado describe un restaurante con un alto tráfico de ventas predecible durante 4 horas cada día, mientras que las horas restantes tienen menor tráfico. La configuración actual de la tabla DynamoDB con modo de rendimiento aprovisionado se establece para manejar la carga máxima, lo que resulta en altos costos durante las horas no pico. Habilitar el escalado automático de DynamoDB es la solución más rentable para este patrón predecible. El escalado automático ajusta la capacidad de la mesa automáticamente en función del tráfico real, lo que reduce los costos durante las horas no pico al reducir los recursos y garantiza suficiente capacidad durante las horas pico al escalar según sea necesario. Este enfoque también minimiza la sobrecarga operativa al eliminar la necesidad de ajustes manuales, convirtiéndola en la opción más adecuada para patrones de tráfico predecibles.
Question 285 of 529
Una empresa aloja una aplicación de publicación de blog en AWS mediante Amazon API Gateway, Amazon DynamoDB y AWS Lambda. La aplicación actualmente no utiliza claves API para autorizar solicitudes. El modelo API es el siguiente:
OBTENER /publicaciones/ {POStiD}: para obtener los detalles de la publicación
GET /users/ {userId}: para obtener los datos del usuario
GET /comments/ {commentId}: para obtener los detalles de los comentarios
La compañía ha notado que los usuarios están discutiendo activamente temas en la sección de comentarios, y la compañía quiere aumentar la participación de los usuarios haciendo que los comentarios aparezcan en tiempo real.
Qué diseño se debe utilizar para reducir la latencia de comentarios y mejorar la experiencia del usuario?
A.
Utilice la API optimizada para bordes con Amazon CloudFront para almacenar en caché las respuestas de la API.
B.
Modifique el código de la aplicación del blog para solicitar Get/comments/ {commentID} cada 10 segundos.
C.
Utilice AWS AppSync y aproveche WebSockets para entregar comentarios.
D.
Cambie el límite de concurrencia de las funciones de Lambda para reducir el tiempo de respuesta de la API.
ResponderDiscusión
Correct Answer: C
Para lograr actualizaciones en tiempo real para los comentarios en la aplicación de publicación de blog, AWS AppSync with WebSockets proporciona la solución más efectiva. AWS AppSync es un servicio completamente administrado que facilita la sincronización de datos en tiempo real mediante GraphQL, y WebSockets son ideales para permitir la comunicación en tiempo real entre los clientes y el servidor. Esta configuración garantiza que los comentarios aparezcan instantáneamente a medida que se publican, lo que reduce la latencia y mejora la participación del usuario. Otras opciones proporcionadas o no admiten la comunicación en tiempo real o no abordan adecuadamente la necesidad de actualizaciones de comentarios en tiempo real.
Question 286 of 529
Una empresa administra cientos de cuentas de AWS de forma centralizada en una organización de AWS Organizations. La compañía recientemente comenzó a permitir que los equipos de producto crearan y administraran sus propios puntos de acceso S3 en sus cuentas. Solo se puede acceder a los puntos de acceso S3 dentro de las VPC, no en Internet.
Cuál es la manera más eficiente operacionalmente de hacer cumplir este requisito?
A.
Establezca la directiva de recursos del punto de acceso S3 para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetworkOrigin se evalúe como VPC.
B.
Cree un SCP en el nivel raíz en la organización para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetNetworkOrigin se evalúe como VPC.
C.
Utilice AWS CloudFormation StackSets para crear una nueva política de IAM en cada cuenta de AWS que permita la acción s3:createAccessPoint solo si la clave de condición s3:AccessPointNetworkOrigin se evalúa como VPC.
D.
Establezca la política de bucket de S3 para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetworkOrigin se evalúe como VPC.
ResponderDiscusión
Correct Answer: B
La forma más eficiente operacionalmente de hacer cumplir el requisito de que solo se pueda acceder a los puntos de acceso S3 dentro de las VPC en un entorno con cientos de cuentas de AWS administradas por organizaciones de AWS es crear una Política de control de servicios (SCP) a nivel raíz en la organización. Esto garantiza que la política se aplique de manera uniforme en todas las cuentas y evita la necesidad de configurar manualmente las políticas en cada cuenta individual. Los SCP están diseñados específicamente para controlar las acciones de servicio de AWS en múltiples cuentas dentro de una organización, lo que los hace ideales para este escenario.
Question 287 of 529
Un arquitecto de soluciones debe actualizar un entorno de aplicaciones dentro de AWS Elastic Beanstalk utilizando una metodología de implementación azul/verde. El arquitecto de soluciones crea un entorno que es idéntico al entorno de aplicación existente e implementa la aplicación en el nuevo entorno.
Qué se debe hacer a continuación para completar la actualización?
A.
Redirigir al nuevo entorno usando Amazon Route 53.
B.
Seleccione la opción Intercambiar URL de entorno.
C.
Reemplace la configuración de inicio de Auto Scaling.
D.
Actualizar los registros DNS para que apunten al entorno verde.
ResponderDiscusión
Correct Answer: B
Para completar la actualización en un entorno de AWS Elastic Beanstalk utilizando una metodología de implementación azul/verde, debe usar la opción Intercambiar URL de entorno. Esta opción intercambia sin problemas los registros CNAME de los dos entornos, redireccionando efectivamente el tráfico del entorno antiguo al nuevo con un tiempo de inactividad mínimo.
Question 288 of 529
Una empresa está construyendo un servicio de imágenes en la web que permitirá a los usuarios subir y buscar fotos aleatorias. En el pico de uso, hasta 10,000 usuarios en todo el mundo subirán sus imágenes. El entonces superpondrá texto en las imágenes subidas, que luego se publicarán en la página web de la compañía.
Qué diseño debe implementar un arquitecto de soluciones?
A.
Almacene las imágenes subidas en Amazon Elastic File System (Amazon EFS). Envíe información de registro de aplicaciones sobre cada imagen a Amazon CloudWatch Logs. Cree una flota de instancias de Amazon EC2 que utilicen CloudWatch Logs para determinar qué imágenes deben procesarse. Colocar las imágenes procesadas en otro directorio de Amazon EFS. Habilite Amazon CloudFront y configure el origen para que sea el de las instancias EC2 de la flota.
B.
Almacene las imágenes cargadas en un bucket de Amazon S3 y configure una notificación de evento de bucket S3 para enviar un mensaje a Amazon Simple Notification Service (Amazon SNS). Cree una flota de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB) para extraer mensajes de Amazon SNS para procesar las imágenes y colocarlas en Amazon Elastic File System (Amazon EFS). Utilice las métricas de Amazon CloudWatch para el volumen de mensajes SNS para escalar instancias EC2. Habilite Amazon CloudFront y configure el origen para que sea el ALB frente a las instancias EC2.
C.
Almacene las imágenes cargadas en un bucket de Amazon S3 y configure una notificación de evento de bucket S3 para enviar un mensaje a la cola de Amazon Simple Queue Service (Amazon SQS). Cree una flota de instancias de Amazon EC2 para obtener mensajes de la cola de SQS para procesar las imágenes y colocarlas en otro bucket S3. Utilice las métricas de Amazon CloudWatch para la profundidad de cola para escalar instancias EC2. Habilite Amazon CloudFront y configure el origen para que sea el bucket S3 que contiene las imágenes procesadas.
D.
Almacene las imágenes cargadas en un volumen compartido de Amazon Elastic Block Store (Amazon EBS) montado en una flota de instancias puntuales de Amazon EC2. Cree una tabla de Amazon DynamoDB que contenga información sobre cada imagen cargada y si se ha procesado. Utilice una regla de Amazon EventBridge para escalar instancias EC2. Habilite Amazon CloudFront y configure el origen para hacer referencia a un Elastic Load Balancer frente a la flota de instancias EC2.
ResponderDiscusión
Correct Answer: C
Para gestionar la carga y el procesamiento de imágenes de manera eficiente, almacenar las imágenes cargadas en un bucket de Amazon S3 proporciona un almacenamiento de objetos altamente escalable y duradero. La configuración de una notificación de eventos de bucket S3 para enviar un mensaje a una cola de Amazon Simple Queue Service (SQS) garantiza el desacoplamiento entre los pasos de carga y procesamiento. Una flota de instancias de Amazon EC2 puede extraer mensajes de la cola de SQS para procesar las imágenes, lo que garantiza que el sistema pueda escalar según la demanda mediante el uso de métricas de Amazon CloudWatch para monitorear la profundidad de la cola de SQS. Por último, colocar las imágenes procesadas en otro bucket S3 y habilitar Amazon CloudFront con el origen establecido en el bucket S3 que contiene las imágenes procesadas mejora la disponibilidad global y el rendimiento de la entrega de imágenes. Este diseño proporciona una solución escalable, desacoplada y eficiente para los requisitos dados.
Question 289 of 529
Una compañía ha implementado su base de datos en una instancia de base de datos de Amazon RDS para MySQL en la región us-east-1. La compañía necesita poner sus datos a disposición de los clientes en Europa. Los clientes en Europa deben tener acceso a los mismos datos que los clientes en Estados Unidos (EE. UU.) y no tolerarán una alta latencia de aplicación o datos obsoletos. Los clientes en Europa y los clientes en Estados Unidos necesitan escribir en la base de datos. Ambos grupos de clientes necesitan ver las actualizaciones del otro grupo en tiempo real.
Qué solución cumplirá con estos requisitos?
A.
Cree una réplica de Amazon Aurora MySQL de la instancia de base de datos de RDS para MySQL. Pausar las escrituras de aplicaciones en la instancia de base de datos de RDS. Promocione la réplica Aurora a un clúster de base de datos independiente. Reconfigure la aplicación para usar la base de datos Aurora y reanude las escrituras. Agregue eu-west-1 como región secundaria al clúster de base de datos. Habilite el reenvío de escritura en el clúster de base de datos. Desplegar la aplicación en eu-west-1. Configure la aplicación para usar el punto final Aurora MySQL en eu-west-1.
B.
Agregue una réplica entre regiones en eu-west-1 para la instancia de base de datos de RDS para MySQL. Configure la réplica para replicar consultas de escritura en la instancia de base de datos primaria. Desplegar la aplicación en eu-west-1. Configure la aplicación para usar el punto final RDS for MySQL en eu-west-1.
C.
Copie la instantánea más reciente de la instancia de base de datos RDS para MySQL a eu-west-1. Cree una nueva instancia de base de datos RDS para MySQL en eu-west-1 a partir de la instantánea. Configure la replicación lógica MySQL de us-east-1 a eu-west-1. Habilite el reenvío de escritura en el clúster de base de datos. Desplegar la aplicación en eu-wes&1. Configure la aplicación para usar el punto final RDS for MySQL en eu-west-1.
D.
Convierta la instancia de base de datos RDS para MySQL en un clúster de base de datos MySQL de Amazon Aurora. Agregue eu-west-1 como región secundaria al clúster de base de datos. Habilite el reenvío de escritura en el clúster de base de datos. Desplegar la aplicación en eu-west-1. Configure la aplicación para usar el punto final Aurora MySQL en eu-west-1.
ResponderDiscusión
Correct Answer: D
Para cumplir con los requisitos de proporcionar disponibilidad de datos en tiempo real y baja latencia tanto para clientes estadounidenses como europeos, la mejor solución es utilizar la base de datos global de Amazon Aurora con reenvío de escritura habilitado. Las bases de datos globales de Aurora permiten lecturas y escrituras globales de baja latencia, con sincronización en múltiples regiones. La conversión de la instancia de base de datos RDS para MySQL en un clúster de base de datos MySQL de Amazon Aurora y la adición de EU-West-1 como región secundaria garantiza que los clientes europeos puedan escribir en la base de datos y ver las actualizaciones de los clientes estadounidenses en tiempo real. Por lo tanto, convertir RDS a Aurora y habilitar el reenvío de escritura ofrece la solución más adecuada para el acceso global a datos de baja latencia y alta disponibilidad.
Question 290 of 529
Una empresa está sirviendo archivos a sus clientes a través de un servidor SFTP que es accesible a través de Internet. El servidor SFTP se ejecuta en una sola instancia de Amazon EC2 con una dirección IP elástica adjunta. Los clientes se conectan al servidor SFTP a través de su dirección IP elástica y utilizan SSH para la autenticación. La instancia EC2 también tiene un grupo de seguridad adjunto que permite el acceso desde todas las direcciones IP de los clientes.
Un arquitecto de soluciones debe implementar una solución para mejorar la disponibilidad, minimizar la complejidad de la administración de la infraestructura y minimizar la interrupción a los clientes que acceden a los archivos. La solución no debe cambiar la forma en que los clientes se conectan.
Qué solución cumplirá con estos requisitos?
A.
Desasociar la dirección IP elástica de la instancia EC2. Cree un bucket de Amazon S3 que se utilizará para el alojamiento de archivos SFTP. Cree un servidor de la familia AWS Transfer. Configure el servidor Transfer Family con un punto final de acceso público. Asocie la dirección IP elástica SFTP con el nuevo punto final. Apunte el servidor de la familia Transfer al bucket S3. Sincronizar todos los archivos del servidor SFTP al bucket S3.
B.
Desasociar la dirección IP elástica de la instancia EC2. Cree un bucket de Amazon S3 que se utilizará para el alojamiento de archivos SFTP. Cree un servidor de la familia AWS Transfer. Configure el servidor de la familia Transfer con un punto final orientado a Internet alojado en VPC. Asocie la dirección IP elástica SFTP con el nuevo punto final. Adjunte el grupo de seguridad con las direcciones IP del cliente al nuevo endpoint. Apunte el servidor de la familia Transfer al bucket S3. Sincronizar todos los archivos del servidor SFTP al bucket S3.
C.
Desasociar la dirección IP elástica de la instancia EC2. Cree un nuevo sistema de archivos Amazon Elastic File System (Amazon EFS) que se utilizará para el alojamiento de archivos SFTP. Cree una definición de tarea de AWS Fargate para ejecutar un servidor SFTP. Especifique el sistema de archivos EFS como montaje en la definición de tarea. Cree un servicio de Fargate mediante la definición de tarea y coloque un balanceador de carga de red (NLB) frente al servicio. Al configurar el servicio, conecte el grupo de seguridad con las direcciones IP del cliente a las tareas que ejecutan el servidor SFTP. Asocie la dirección IP elástica con el NLB. Sincronizar todos los archivos del servidor SFTP al bucket S3.
D.
Desasociar la dirección IP elástica de la instancia EC2. Cree un volumen de Amazon Elastic Block Store (Amazon EBS) de conexión múltiple que se utilizará para el alojamiento de archivos SFTP. Cree un balanceador de carga de red (NLB) con la dirección IP elástica adjunta. Cree un grupo de Auto Scaling con instancias EC2 que ejecuten un servidor SFTP. Defina en el grupo Auto Scaling que las instancias que se lanzan deben adjuntar el nuevo volumen de EBS de conexión múltiple. Configure el grupo Auto Scaling para agregar instancias automáticamente detrás del NLB. Configure el grupo Auto Scaling para usar el grupo de seguridad que permite las direcciones IP del cliente para las instancias EC2 que inicia el grupo Auto Scaling. Sincronizar todos los archivos del servidor SFTP al nuevo volumen EBS de conexión múltiple.
ResponderDiscusión
Correct Answer: B
La solución necesita mejorar la disponibilidad, minimizar la complejidad de la administración de la infraestructura y evitar interrumpir el acceso de los clientes, sin cambiar la forma en que los clientes se conectan al servidor SFTP. El mejor enfoque para lograr esto es usar la familia AWS Transfer con un bucket de Amazon S3 como backend para el alojamiento de archivos SFTP. Al crear un servidor Transfer Family con un punto final orientado a Internet alojado en VPC y asociar la dirección IP elástica existente a este punto final, la transición se vuelve perfecta para los clientes. Adicionalmente, adjuntar el grupo de seguridad existente que contiene las direcciones IP del cliente garantiza que solo los usuarios autorizados tengan acceso, manteniendo la seguridad sin alterar el método de conexión para los clientes. La sincronización de los archivos existentes con el bucket S3 logra la migración de datos necesaria sin interrupciones. Esta configuración cumple con todos los requisitos de manera efectiva.
Question 291 of 529
Una empresa ingiere y procesa datos de mercado en streaming. La velocidad de datos es constante. Un proceso nocturno que calcula estadísticas agregadas tarda 4 horas en completarse. El análisis estadístico no es crítico para el negocio, y los puntos de datos se procesan durante la siguiente iteración si falla una ejecución en particular.
La arquitectura actual utiliza un grupo de instancias reservadas de Amazon EC2 con reservas de 1 año. Estas instancias EC2 se ejecutan a tiempo completo para ingerir y almacenar los datos de streaming en volúmenes conectados de Amazon Elastic Block Store (Amazon EBS). Un script programado inicia instancias EC2 bajo demanda cada noche para realizar el procesamiento nocturno. Las instancias acceden a los datos almacenados de los recursos compartidos de NFS en los servidores de ingestión. El script termina las instancias cuando se completa el procesamiento.
Las reservas de Instancia Reservada están caducando. La compañía necesita determinar si comprar nuevas reservas o implementar un nuevo diseño.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Actualice el proceso de ingestión para usar Amazon Kinesis Data Firehose para guardar datos en Amazon S3. Utilice un script programado para lanzar una flota de instancias EC2 bajo demanda cada noche para realizar el procesamiento por lotes de los datos de S3. Configure el script para terminar las instancias cuando se complete el procesamiento.
B.
Actualice el proceso de ingestión para usar Amazon Kinesis Data Firehose para guardar datos en Amazon S3. Utilice AWS Batch with Spot Instancias para realizar el procesamiento nocturno con un precio máximo de spot que sea el 50% del precio bajo demanda.
C.
Actualice el proceso de ingestión para usar una flota de instancias reservadas EC2 con reservas de 3 años detrás de un Network LoadBalancer. Utilice AWS Batch with Spot Instancias para realizar el procesamiento nocturno con un precio máximo de spot que sea el 50% del precio bajo demanda.
D.
Actualice el proceso de ingestión para usar Amazon Kinesis Data Firehose para guardar datos en Amazon Redshift. Utilice Amazon EventBridge para programar una función de AWS Lambda para que se ejecute todas las noches para consultar a Amazon Redshift para generar las estadísticas diarias.
ResponderDiscusión
Correct Answer: B
El uso de Amazon Kinesis Data Firehose para guardar datos en Amazon S3 es una forma fiable y rentable de ingerir datos. AWS Batch with Spot Instancias proporciona un método altamente rentable para realizar el procesamiento por lotes, ya que las instancias puntuales pueden ser significativamente más económicas que las instancias bajo demanda. Dado que el análisis estadístico no es crítico y puede tolerar fallas ocasionales, el uso de Instancias puntuales, que pueden interrumpirse, es una opción adecuada y económica. Este enfoque se alinea bien con el requisito de minimizar los costos al tiempo que garantiza que el procesamiento nocturno se complete la mayor parte del tiempo.
Question 292 of 529
Una empresa necesita migrar un sitio SFTP local a AWS. El sitio SFTP actualmente se ejecuta en una máquina virtual Linux. Los archivos cargados se ponen a disposición de las aplicaciones descendentes a través de un recurso compartido NFS.
Como parte de la migración a AWS, un arquitecto de soluciones debe implementar alta disponibilidad. La solución debe proporcionar a los proveedores externos un conjunto de direcciones IP públicas estáticas que los proveedores puedan permitir. La compañía ha establecido una conexión AWS Direct Connect entre su centro de datos local y su VPC.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un servidor de la familia AWS Transfer. Configure un punto final de VPC orientado a Internet para el servidor de la familia Transfer. Especifique una dirección IP elástica para cada subred. Configure el servidor de la familia Transfer para colocar archivos en un sistema de archivos de Amazon Elastic File System (Amazon EFS) que se implementa en varias zonas de disponibilidad. Modifique la configuración en las aplicaciones descendentes que acceden al recurso compartido NFS existente para montar el punto final EFS en su lugar.
B.
Cree un servidor de la familia AWS Transfer. Configure un punto final de acceso público para el servidor Transfer Family. Configure el servidor de la familia Transfer para colocar archivos en un sistema de archivos de Amazon Elastic File System (Amazon EFS) que se implementa en varias zonas de disponibilidad. Modifique la configuración en las aplicaciones descendentes que acceden al recurso compartido NFS existente para montar el punto final EFS en su lugar.
C.
Utilice AWS Application Migration Service para migrar la máquina virtual Linux existente a una instancia de Amazon EC2. Asigne una dirección IP elástica a la instancia EC2. Monte un sistema de archivos de Amazon Elastic File System (Amazon EFS) en la instancia EC2. Configure el servidor SFTP para colocar archivos en el sistema de archivos EFS. Modifique la configuración en las aplicaciones descendentes que acceden al recurso compartido NFS existente para montar el punto final EFS en su lugar.
D.
Utilice AWS Application Migration Service para migrar la máquina virtual Linux existente a un servidor de la familia AWS Transfer. Configure un punto final de acceso público para el servidor Transfer Family. Configure el servidor de la familia Transfer para colocar archivos en un sistema de archivos Amazon FSx for Lustre que se implementa en varias zonas de disponibilidad. Modifique la configuración en las aplicaciones descendentes que acceden al recurso compartido NFS existente para montar el punto final FSx for Lustre en su lugar.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de la compañía de proporcionar direcciones IP públicas estáticas, la solución consiste en crear un servidor de la familia AWS Transfer y configurar un punto de enlace de VPC orientado a Internet para él. Al especificar una dirección IP elástica para cada subred, la compañía se asegura de que los proveedores externos tengan un conjunto consistente de IP estáticas para permitir. El servidor de la familia Transfer manejará las conexiones SFTP, mientras que Amazon EFS ofrece una solución de almacenamiento escalable y de alta disponibilidad, integrándose sin problemas con los sistemas basados en NFS existentes. Esta configuración minimiza la sobrecarga operativa al aprovechar los servicios administrados y garantiza una alta disponibilidad.
Question 293 of 529
Un arquitecto de soluciones tiene una carga de trabajo operativa implementada en instancias de Amazon EC2 en un grupo de Auto Scaling. La arquitectura de VPC abarca dos zonas de disponibilidad (AZ) con una subred en cada una a la que se dirige el grupo Auto Scaling. La VPC está conectada a un entorno local y la conectividad no se puede interrumpir. El tamaño máximo del grupo Auto Scaling es de 20 instancias en servicio. El direccionamiento IPv4 de VPC es el siguiente:
VPC CIDR: 10.0.0.0/23 -
CIDR de subred AZ1:10.0.0.0/24 -
CIDR de subred AZ2:10.0.1.0/24 -
Desde su implementación, una tercera AZ ha estado disponible en la Región. El arquitecto de soluciones quiere adoptar la nueva AZ sin agregar espacio de direcciones IPv4 adicional y sin tiempo de inactividad del servicio. Qué solución cumplirá con estos requisitos?
A.
Actualice el grupo Auto Scaling para usar únicamente la subred AZ2. Elimine y vuelva a crear la subred AZ1 usando la mitad del espacio de direcciones anterior. Ajuste el grupo Auto Scaling para usar también la nueva subred AZ1. Cuando las instancias estén en buen estado, ajuste el grupo Auto Scaling para usar solo la subred AZ1. Eliminar la subred AZ2 actual. Cree una nueva subred AZ2 utilizando la segunda mitad del espacio de direcciones de la subred AZ1 original. Cree una nueva subred AZ3 usando la mitad del espacio de direcciones de subred AZ2 original, luego actualice el grupo Auto Scaling para apuntar a las tres subredes nuevas.
B.
Termine las instancias EC2 en la subred AZ1. Elimine y vuelva a crear la subred AZ1 usando la mitad del espacio de direcciones. Actualice el grupo Auto Scaling para usar esta nueva subred. Repita esto para el segundo AZ. Defina una nueva subred en AZ3 y, a continuación, actualice el grupo Auto Scaling para apuntar a las tres subredes nuevas.
C.
Cree una nueva VPC con el mismo espacio de direcciones IPv4 y defina tres subredes, con una para cada AZ. Actualice el grupo de Auto Scaling existente para apuntar a las nuevas subredes en la nueva VPC.
D.
Actualice el grupo Auto Scaling para usar únicamente la subred AZ2. Actualice la subred AZ1 para que tenga la mitad del espacio de direcciones anterior. Ajuste el grupo Auto Scaling para usar también la subred AZ1 nuevamente. Cuando las instancias estén en buen estado, ajuste el grupo Auto Scaling para usar solo la subred AZ1. Actualice la subred AZ2 actual y asigne la segunda mitad del espacio de direcciones de la subred AZ1 original. Cree una nueva subred AZ3 usando la mitad del espacio de direcciones de subred AZ2 original, luego actualice el grupo Auto Scaling para apuntar a las tres subredes nuevas.
ResponderDiscusión
Correct Answer: A
El enfoque correcto para agregar una nueva AZ sin tiempo de inactividad del servicio, mientras se trabaja dentro del espacio de direcciones IPv4 existente, implica la transición progresiva a nuevas subredes. Esto garantiza una alta disponibilidad y una interrupción mínima. He aquí por qué: Primero actualiza el grupo Auto Scaling para usar solo la subred AZ2 existente, asegurando la continuidad. Luego, eliminando y recreando la subred AZ1 con un espacio de direcciones más pequeño y cambiando gradualmente el grupo Auto Scaling a esta nueva subred, se mantienen instancias sanas. Una vez hecho esto, elimina la antigua subred AZ2, recórala con un espacio de direcciones más pequeño y finalmente crea una nueva subred en AZ3. Este método asegura que las instancias estén siempre dentro de una subred, manteniendo la disponibilidad del servicio. Por lo tanto, la opción A es la opción más adecuada.
Question 294 of 529
Una empresa utiliza una organización en AWS Organizations para administrar las cuentas de AWS de la compañía. La compañía utiliza AWS CloudFormation para implementar toda la infraestructura. Un equipo de finanzas quiere construir un modelo de contracargo. El equipo de finanzas pidió a cada unidad de negocio etiquetar los recursos usando una lista predefinida de valores del proyecto.
Cuando el equipo de finanzas utilizó el informe de costos y uso de AWS en AWS Cost Explorer y se filtró según el proyecto, el equipo notó valores de proyecto que no cumplían con los requisitos. La compañía quiere hacer cumplir el uso de etiquetas de proyecto para nuevos recursos.
Qué solución cumplirá estos requisitos con el MENOR esfuerzo?
A.
Cree una política de etiquetas que contenga los valores de etiqueta de proyecto permitidos en la cuenta de administración de la organización. Cree un SCP que deniegue la operación de la API CloudFormation:CreateStack a menos que se agregue una etiqueta de proyecto. Adjuntar el SCP a cada unidad organizativa.
B.
Cree una política de etiquetas que contenga los valores de etiqueta de proyecto permitidos en cada unidad OU. Cree un SCP que deniegue la operación de la API CloudFormation:CreateStack a menos que se agregue una etiqueta de proyecto. Adjuntar el SCP a cada unidad organizativa.
C.
Cree una política de etiquetas que contenga los valores de etiqueta de proyecto permitidos en la cuenta de administración de AWS. Cree una política de IAM que deniegue la operación de la API CloudFormation:CreateStack a menos que se agregue una etiqueta de proyecto. Asignar la política a cada usuario.
D.
Utilice AWS Service Catalog para administrar las pilas de CloudFormation como productos. Utilice una biblioteca TagOptions para controlar los valores de etiqueta del proyecto. Compartir la cartera con todas las unidades organizativas que se encuentren en la organización.
ResponderDiscusión
Correct Answer: A
La compañía debe crear una política de etiquetas en la cuenta de administración de la organización con los valores de etiqueta de proyecto permitidos. Esto asegura la consistencia en toda la organización. Adicionalmente, deben crear una Política de Control de Servicios (SCP) que deniegue la operación de la API CloudFormation:CreateStack a menos que se agregue una etiqueta de proyecto y adjunte este SCP a cada Unidad Organizacional (OU). Este enfoque aplica las etiquetas correctas con el mínimo esfuerzo, ya que la política de etiquetas en la cuenta de administración es heredada por todas las unidades organizativas secundarias. El uso de políticas de IAM para usuarios individuales o la administración de políticas en el nivel de unidad organizativa crearía una sobrecarga innecesaria. AWS Service Catalog es una complicación excesiva y no aplica etiquetas directamente para todos los recursos.
Question 295 of 529
Se implementa una aplicación en instancias de Amazon EC2 que se ejecutan en un grupo de Auto Scaling. La configuración del grupo Auto Scaling utiliza solo un tipo de instancia.
Las métricas de utilización de CPU y memoria muestran que las instancias están infrautilizadas. Un arquitecto de soluciones necesita implementar una solución para reducir permanentemente el costo de EC2 y aumentar la utilización.
Qué solución cumplirá estos requisitos con la MENOR cantidad de cambios de configuración en el futuro?
A.
Enumere los tipos de instancias que tienen propiedades similares a las propiedades que tienen las instancias actuales. Modifique la configuración de la plantilla de lanzamiento del grupo Auto Scaling para usar varios tipos de instancias de la lista.
B.
Utilice la información sobre la utilización de la CPU y la memoria de la aplicación para seleccionar un tipo de instancia que coincida con los requisitos. Modifique la configuración del grupo Auto Scaling agregando el nuevo tipo de instancia. Elimine el tipo de instancia actual de la configuración.
C.
Utilice la información sobre la utilización de la CPU y la memoria de la aplicación para especificar los requisitos de CPU y memoria en una nueva revisión de la plantilla de lanzamiento del grupo Auto Scaling. Elimine el tipo de instancia actual de la configuración.
D.
Cree un script que seleccione los tipos de instancia adecuados de la API masiva de lista de precios de AWS. Utilice los tipos de instancia seleccionados para crear una nueva revisión de la plantilla de lanzamiento del grupo Auto Scaling.
ResponderDiscusión
Correct Answer: B
Para reducir permanentemente los costos de EC2 y aumentar la utilización, es efectivo seleccionar un tipo de instancia en función de los requisitos de utilización de la CPU y la memoria de la aplicación. Esto asegura que el tipo de instancia se alinee con las necesidades de uso, optimizando tanto el rendimiento como el costo. Al modificar la configuración del grupo Auto Scaling para usar el nuevo tipo de instancia y eliminar la anterior, se mantiene una configuración única que se adapta a las necesidades de la aplicación. Este enfoque minimiza la necesidad de ajustes futuros, ya que aborda directamente el tema de la sobreasignación seleccionando un tamaño de instancia apropiado desde el inicio.
Question 296 of 529
Una empresa implementa una aplicación contenerizada mediante el uso de Amazon Elastic Container Service (Amazon ECS) y Amazon API Gateway Los datos de la aplicación se almacenan en bases de datos de Amazon Aurora y bases de datos de Amazon DynamoDB. La compañía automatiza el aprovisionamiento de infraestructura mediante el uso de AWS CloudFormation. La compañía automatiza la implementación de aplicaciones mediante AWS CodePipeline.
Un arquitecto de soluciones necesita implementar una estrategia de recuperación ante desastres (DR) que cumpla con un RPO de 2 horas y un RTO de 4 horas.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Configure una base de datos global Aurora y tablas globales de DynamoDB para replicar las bases de datos en una región secundaria de AWS. En la Región primaria y en la Región secundaria, configure una API API Gateway con un punto final Regional. Implemente Amazon CloudFront con failover de origen para enrutar el tráfico a la región secundaria durante un escenario de recuperación ante desastres.
B.
Utilice AWS Database Migration Service (AWS DMS), Amazon EventBridge y AWS Lambda para replicar las bases de datos Aurora en una región secundaria de AWS. Utilice DynamoDB Streams, EventBridge. y Lambda para replicar las bases de datos de DynamoDB en la región secundaria. En la Región primaria y en la Región secundaria, configure una API API Gateway con un punto final Regional. Implemente el enrutamiento de conmutación por error de Amazon Route 53 para cambiar el tráfico de la región principal a la región secundaria.
C.
Utilice AWS Backup para crear copias de seguridad de las bases de datos Aurora y las bases de datos de DynamoDB en una región secundaria de AWS. En la Región primaria y en la Región secundaria, configure una API API Gateway con un punto final Regional. Implemente el enrutamiento de conmutación por error de Amazon Route 53 para cambiar el tráfico de la región principal a la región secundaria.
D.
Configure una base de datos global Aurora y tablas globales de DynamoDB para replicar las bases de datos en una región secundaria de AWS. En la Región primaria y en la Región secundaria, configure una API API Gateway con un punto final Regional. Implemente el enrutamiento de conmutación por error de Amazon Route 53 para cambiar el tráfico de la región principal a la región secundaria.
ResponderDiscusión
Correct Answer: D
Para garantizar un RPO de 2 horas y un RTO de 4 horas, la mejor opción implica una complejidad mínima sin dejar de cumplir con los requisitos de recuperación. La configuración de una base de datos global Aurora y el uso de tablas globales de DynamoDB para la replicación garantizan que los datos se sincronicen continuamente entre las regiones primaria y secundaria, cumpliendo efectivamente con el RPO. La configuración de API Gateway con endpoints regionales en ambas regiones permite un cambio rápido en caso de desastre, lo que contribuye a cumplir con el RTO. El uso del enrutamiento de conmutación por error de Amazon Route 53 proporciona una manera confiable y rentable de redirigir automáticamente el tráfico a la región secundaria durante un escenario de recuperación ante desastres, lo que garantiza que la transición se realice sin problemas sin configuraciones complejas adicionales o altos costos asociados con servicios como CloudFront.
Question 297 of 529
Una empresa cuenta con una aplicación web compleja que aprovecha Amazon CloudFront para lograr escalabilidad y rendimiento globales. Con el tiempo, los usuarios informan que la aplicación web se está desacelerando.
El equipo de operaciones de la compañía informa que la relación de aciertos de caché de CloudFront ha ido disminuyendo constantemente. El informe de métricas de caché indica que las cadenas de consulta en algunas URL están ordenadas de manera inconsistente y a veces se especifican en letras mixtas y a veces en letras minúsculas.
Qué conjunto de acciones debería tomar el arquitecto de soluciones para aumentar la relación de aciertos de caché lo más rápido posible?
A.
Despliega una función Lambda @Edge para ordenar los parámetros por nombre y obligarlos a ser minúsculas. Seleccione el activador de solicitud del visor de CloudFront para invocar la función.
B.
Actualice la distribución de CloudFront para deshabilitar el almacenamiento en caché según los parámetros de cadena de consulta.
C.
Implemente un proxy inverso después del equilibrador de carga para postprocesar las URL emitidas en la aplicación para forzar que las cadenas de URL estén en minúsculas.
D.
Actualice la distribución de CloudFront para especificar el procesamiento de cadena de consulta insensible a la carcasa.
ResponderDiscusión
Correct Answer: A
Usar una función Lambda @Edge para ordenar los parámetros por nombre y obligarlos a ser minúsculas es la solución más efectiva. Este método aborda el problema de las cadenas de consulta inconsistentes y de casos mixtos, que están causando errores de caché. Al normalizar estos parámetros en el borde de CloudFront, la relación de aciertos de caché mejorará ya que las solicitudes de los mismos recursos pueden coincidir correctamente.
Question 298 of 529
Una empresa ejecuta una aplicación de comercio electrónico en una sola región de AWS. La aplicación utiliza un clúster de base de datos Amazon Aurora MySQL de cinco nodos para almacenar información sobre los clientes y sus pedidos recientes. El clúster de base de datos experimenta una gran cantidad de transacciones de escritura a lo largo del día.
La compañía necesita replicar los datos de la base de datos Aurora a otra región para cumplir con los requisitos de recuperación ante desastres. La empresa cuenta con un RPO de 1 hora.
Qué solución cumplirá estos requisitos con el menor costo?
A.
Modificar la base de datos Aurora para que sea una base de datos global de Aurora. Crear una segunda base de datos Aurora en otra Región.
B.
Habilite la función Retroceso para la base de datos Aurora. Cree una función de AWS Lambda que se ejecute diariamente para copiar las instantáneas de la base de datos en una región de respaldo.
C.
Utilice AWS Database Migration Service (AWS DMS). Cree una tarea de captura de datos de cambio (CDC) de DMS que replique los cambios en curso de la base de datos Aurora a un bucket de Amazon S3 en otra región.
D.
Desactive las copias de seguridad automáticas de Aurora. Configure las copias de seguridad Aurora con una frecuencia de backup de 1 hora. Especifique otra Región como Región de destino. Seleccione la base de datos Aurora como asignación de recursos.
ResponderDiscusión
Correct Answer: A
La compañía necesita replicar los datos de la base de datos Aurora a otra región para cumplir con los requisitos de recuperación ante desastres. La solución debe proporcionar un objetivo de punto de recuperación bajo (RPO) de 1 hora y ser rentable. La modificación de la base de datos Aurora para que sea una base de datos global Aurora y la creación de una segunda base de datos Aurora en otra región aprovecha la función de base de datos global integrada de Aurora, que permite la replicación continua con baja latencia y costos mínimos de transferencia de datos. Este método aborda directamente las necesidades de recuperación ante desastres y asegura el cumplimiento del requisito de RPO.
Question 299 of 529
El arquitecto de soluciones de una compañía está evaluando una carga de trabajo de AWS que se implementó hace varios años. El nivel de aplicación no tiene estado y se ejecuta en una sola instancia grande de Amazon EC2 que se lanzó desde una AMI. La aplicación almacena datos en una base de datos MySQL que se ejecuta en una sola instancia EC2.
La utilización de la CPU en la instancia EC2 del servidor de aplicaciones a menudo alcanza el 100% y hace que la aplicación deje de responder. La compañía instala manualmente parches en las instancias. La aplicación de parches ha causado tiempo de inactividad en el pasado. La empresa necesita que la aplicación esté altamente disponible.
Qué solución cumplirá estos requisitos con el MENOR desarrollo me?
A.
Mueva el nivel de aplicación a las funciones de AWS Lambda en la VPC existente. Cree un balanceador de carga de aplicaciones para distribuir el tráfico a través de las funciones de Lambda. Utilice Amazon GuardDuty para escanear las funciones de Lambda. Migre la base de datos a Amazon DocumentDB (con compatibilidad con MongoDB.
B.
Cambie el tipo de instancia EC2 a un tipo de instancia alimentado por Graviton más pequeño. Utilice la AMI existente para crear una plantilla de lanzamiento para un grupo de Auto Scaling. Cree un balanceador de carga de aplicaciones para distribuir el tráfico entre las instancias del grupo Auto Scaling. Establezca el grupo Auto Scaling para escalar según la utilización de la CPU. Migre la base de datos a Amazon DynamoDB.
C.
Mueva el nivel de aplicación a contenedores mediante Docker. Ejecute los contenedores en Amazon Elastic Container Service (Amazon ECS) con instancias EC2. Cree un balanceador de carga de aplicaciones para distribuir el tráfico a través del clúster ECS. Configure el clúster ECS para escalar según la utilización de la CPU. Migre la base de datos a Amazon Neptune.
D.
Cree una AMI ahora configurada con AWS Systems Manager Agent (agente SSM). Utilice la nueva AMI para crear una plantilla de lanzamiento para un grupo de Auto Scaling. Utilice instancias más pequeñas en el grupo Auto Scaling. Cree un balanceador de carga de aplicaciones para distribuir el tráfico entre las instancias del grupo Auto Scaling. Establezca el grupo Auto Scaling para escalar según la utilización de la CPU. Migre la base de datos a Amazon Aurora MySQL.
ResponderDiscusión
Correct Answer: D
El mejor enfoque para que la aplicación esté altamente disponible con el menor esfuerzo de desarrollo implica mantener la compatibilidad con la arquitectura existente. La creación de una nueva AMI configurada con AWS Systems Manager Agent (agente SSM) y su uso para crear una plantilla de lanzamiento para un grupo de Auto Scaling garantiza el escalado basado en la utilización de la CPU. Las instancias más pequeñas del grupo Auto Scaling mejorarían la eficiencia de la asignación de recursos y un balanceador de carga de aplicaciones distribuye el tráfico de manera efectiva. La migración de la base de datos MySQL a Amazon Aurora MySQL minimiza los cambios necesarios al tiempo que aprovecha los beneficios de un servicio administrado que es compatible con la base de datos MySQL existente.
Question 300 of 529
Una empresa planea migrar varias aplicaciones a AWS. La compañía no tiene una buena comprensión de todo su estado de aplicación. El estado consiste en una mezcla de máquinas físicas y VMs.
Una aplicación que la empresa migrará tiene muchas dependencias que son sensibles a la latencia. La empresa no está segura de cuáles son todas las dependencias. Sin embargo, la compañía sabe que las comunicaciones de baja latencia utilizan un protocolo personalizado basado en IP que se ejecuta en el puerto 1000. La compañía quiere migrar la aplicación y estas dependencias juntas para mover todas las interfaces de baja latencia a AWS al mismo tiempo.
La compañía ha instalado AWS Application Discovery Agent y lleva varios meses recopilando datos.
Qué debe hacer la empresa para identificar las dependencias que necesitan migrarse en la misma fase que la aplicación?
A.
Utilice AWS Migration Hub y seleccione los servidores que alojan la aplicación. Visualice el gráfico de red para encontrar servidores que interactúen con la aplicación. Activar exploración de datos en Amazon Atenea. Consulta los datos que se transfieren entre los servidores para identificar los servidores que se comunican en el puerto 1000. Regresar a Migration Hub. Crear un grupo de movimientos que se base en los hallazgos de las consultas de Athena.
B.
Utilice AWS Application Migration Service y seleccione los servidores que alojan la aplicación. Visualice el gráfico de red para encontrar servidores que interactúen con la aplicación. Configure Application Migration Service para lanzar instancias de prueba para todos los servidores que interactúan con la aplicación. Realizar pruebas de aceptación en las instancias de prueba. Si no se identifican problemas, cree un grupo de movimiento basado en los servidores probados.
C.
Utilice AWS Migration Hub y seleccione los servidores que alojan la aplicación. Active la exploración de datos en Network Access Analyzer. Utilice la consola de Network Access Analyzer para seleccionar los servidores que alojan la aplicación. Seleccione un alcance de acceso a la red del puerto 1000 y anote los servidores coincidentes. Regresar a Migration Hub. Cree un grupo de movimiento basado en los hallazgos de Network Access Analyzer.
D.
Utilice AWS Migration Hub y seleccione los servidores que alojan la aplicación. Empuje el agente de Amazon CloudWalch a los servidores identificados mediante AWS Application Discovery Agent. Exporte los registros de CloudWatch que recopilan los agentes a Amazon S3. Utilice Amazon Athena para consultar los registros para encontrar servidores que se comuniquen en el puerto 1000. Regresar a Migration Hub Crear un grupo de movimientos que se base en los hallazgos de las consultas de Athena.
ResponderDiscusión
Correct Answer: A
Para identificar dependencias sensibles a la latencia que se comunican mediante un protocolo personalizado basado en IP en el puerto 1000, la empresa debe usar AWS Migration Hub para visualizar el gráfico de red. Esto permite la identificación de servidores que interactúan con la aplicación. Activar la exploración de datos en Amazon Athena y consultar datos del servidor específicamente para la comunicación del puerto 1000 resaltará las dependencias necesarias. En base a estos hallazgos, se puede crear un grupo de movimiento en Migration Hub, asegurando que todas las dependencias se migren juntas, manteniendo la comunicación de baja latencia.
Question 301 of 529
Una empresa está construyendo una aplicación que se ejecutará en una función de AWS Lambda. Cientos de clientes utilizarán la aplicación. La empresa quiere darle a cada cliente una cuota de solicitudes por un periodo de tiempo específico. Las cuotas deben coincidir con los patrones de uso del cliente. Algunos clientes deben recibir una cuota más alta por un período de tiempo más corto.
Qué solución cumplirá con estos requisitos?
A.
Cree una API REST de Amazon API Gateway con una integración de proxy para invocar la función Lambda. Para cada cliente, configure un plan de uso de API Gateway que incluya una cuota de solicitud adecuada. Cree una clave API a partir del plan de uso para cada usuario que el cliente necesite.
B.
Cree una API HTTP de Amazon API Gateway con una integración de proxy para invocar la función Lambda. Para cada cliente, configure un plan de uso de API Gateway que incluya una cuota de solicitud adecuada Configurar la regulación a nivel de ruta para cada plan de uso. Crear una Clave API a partir del plan de uso para cada usuario que el cliente necesite.
C.
Cree un alias de función Lambda para cada cliente. Incluir un límite de concurrencia con una cuota de solicitud adecuada. Cree una URL de función Lambda para cada alias de función. Comparta la URL de la función Lambda para cada alias con el cliente relevante.
D.
Cree un balanceador de carga de aplicaciones (ALB) en una VPC. Configure la función Lambda como objetivo para el ALB. Configure una ACL web de AWS WAF para el ALB. Para cada cliente, configure una regla basada en raleo que incluya una cuota de solicitud adecuada.
AnswerDiscussion
Correct Answer: A
La mejor solución para crear cuotas de solicitud para cada cliente en una aplicación de AWS Lambda es usar la API REST API de Amazon API Gateway con una integración de proxy para invocar la función Lambda. Al configurar un plan de uso de API Gateway para cada cliente, puede administrar cuotas de solicitud específicas, adaptándose a diferentes patrones de uso del cliente. Este enfoque permite la creación de una clave API a partir del plan de uso para cada usuario que el cliente necesite, ayudando a limitar y rastrear efectivamente el uso en función de las cuotas predefinidas.
Question 302 of 529
Una compañía planea migrar su clúster de VMware local de 120 máquinas virtuales a AWS. Las máquinas virtuales tienen muchos sistemas operativos diferentes y muchos paquetes de software personalizados instalados. La compañía también cuenta con un servidor NFS local que tiene un tamaño de 10 TB. La compañía ha establecido una conexión AWS Direct Connect de 10 Gbps a AWS para la migración.
Qué solución completará la migración a AWS en la MENOR cantidad de tiempo?
A.
Exporte las máquinas virtuales locales y cópielas en un bucket de Amazon S3. Utilice VM Import/Export para crear AMI a partir de las imágenes de VM almacenadas en Amazon S3. Ordene un dispositivo AWS Snowball Edge. Copie los datos del servidor NFS en el dispositivo. Restaure los datos del servidor NFS en una instancia de Amazon EC2 que tenga configurado NFS.
B.
Configure AWS Application Migration Service con una conexión al clúster de VMware. Cree un trabajo de replicación para el VMS. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Configure AWS DataSync para copiar los datos del servidor NFS en el sistema de archivos EFS a través de la conexión Direct Connect.
C.
Recrea las máquinas virtuales en AWS como instancias de Amazon EC2. Instale todos los paquetes de software requeridos. Cree un sistema de archivos Amazon FSx for Lustre. Configure AWS DataSync para copiar los datos del servidor NFS en el sistema de archivos FSx for Lustre a través de la conexión Direct Connect.
D.
Ordene dos dispositivos AWS Snowball Edge. Copie las máquinas virtuales y los datos del servidor NFS en los dispositivos. Ejecute VM Import/Export después de cargar los datos de los dispositivos en un bucket de Amazon S3. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Copie los datos del servidor NFS de Amazon S3 al sistema de archivos EFS.
AnswerDiscussion
Correct Answer: B
El enfoque más eficiente para minimizar el tiempo de migración del clúster VMware local y los datos del servidor NFS a AWS es utilizar AWS Application Migration Service para las máquinas virtuales y AWS DataSync para transferir los datos NFS mediante la conexión AWS Direct Connect existente de 10 Gbps. AWS Application Migration Service está diseñado para manejar la migración de máquinas virtuales de manera eficiente, y AWS DataSync puede mover grandes cantidades de datos rápidamente. Este método aprovecha la conexión Direct Connect de alta velocidad, lo que garantiza una rápida transferencia de datos sin la necesidad de dispositivos físicos como AWS Snowball. La creación de Amazon Elastic File System (EFS) permite un almacenamiento escalable compatible con NFS, lo que proporciona una transición perfecta para los datos del servidor NFS.
Question 303 of 529
Una empresa de encuestas en línea ejecuta su aplicación en la nube de AWS. La aplicación se distribuye y consta de microservicios que se ejecutan en un clúster de Amazon Elastic Container Service (Amazon ECS) escalado automáticamente. El clúster ECS es un destino para un balanceador de carga de aplicaciones (ALB). El ALB es un origen personalizado para una distribución de Amazon CloudFront.
La empresa cuenta con una encuesta que contiene datos sensibles. Los datos sensibles deben estar encriptados cuando se mueven por la aplicación. El microservicio de manejo de datos de la aplicación es el único microservicio que debería poder descifrar los datos
Qué solución cumplirá con estos requisitos?
A.
Cree una clave simétrica de AWS Key Management Service (AWS KMS) dedicada al microservicio de manejo de datos. Cree un perfil de cifrado a nivel de campo y una configuración. Asocie la clave KMS y la configuración con el comportamiento de caché de CloudFront.
B.
Cree un par de claves RSA dedicado al microservicio de entrega de datos. Cargue la clave pública a la distribución de CloudFront. Cree un perfil de cifrado a nivel de campo y una configuración. Agregue la configuración al comportamiento de caché de CloudFront.
C.
Cree una clave simétrica de AWS Key Management Service (AWS KMS) dedicada al microservicio de manejo de datos. Crea una función Lambda @Edge. Programe la función para usar la clave KMS para cifrar los datos confidenciales.
D.
Cree un par de claves RSA dedicado al microservicio de manejo de datos. Crea una función Lambda @Edge. Programe la función para usar la clave privada del par de claves RSA para cifrar los datos confidenciales.
AnswerDiscussion
Correct Answer: B
Para cumplir con el requisito de encriptar datos confidenciales mientras se mueven a través de la aplicación y garantizar que solo el microservicio de manejo de datos pueda descifrarlos, usar un par de claves RSA para el cifrado a nivel de campo en Amazon CloudFront es la solución correcta. El cifrado a nivel de campo en CloudFront requiere cifrado asimétrico, específicamente utilizando un par de claves público-privadas RSA. Al cargar la clave pública a la distribución de CloudFront y crear un perfil y configuración de cifrado a nivel de campo, puede asegurarse de que los datos estén cifrados antes de que lleguen al backend y solo el microservicio de manejo de datos, que contiene la clave privada, puede descifrarlos.
Question 304 of 529
Un arquitecto de soluciones está determinando la estrategia de DNS para una VPC existente. La VPC se aprovisiona para usar el bloque CIDR 10.24.34.0/24. La VPC también utiliza Amazon Route 53 Resolver para DNS. Los nuevos requisitos exigen que las consultas DNS deben usar zonas alojadas privadas. Adicionalmente, las instancias que tienen direcciones IP públicas deben recibir los nombres de host públicos correspondientes
Qué solución cumplirá con estos requisitos para garantizar que los nombres de dominio se resuelven correctamente dentro de la VPC?
A.
Crear una zona privada alojada. Active el atributo enableDNSSupport y el atributo enableDNShostNames para la VPC. Actualice las opciones DHCP de VPC establecidas para incluir servidores de nombres de dominio = 10.24.34.2.
B.
Crear una zona alojada privada Asociar la zona alojada privada con la VPC. Active el atributo enableDNSSupport y el atributo enableDNShostNames para la VPC. Cree un nuevo conjunto de opciones DHCP de VPC y configure Domain-name-servers=AmazonProvideDDNS. Asocie el nuevo conjunto de opciones DHCP con la VPC.
C.
Desactive el atributo enableDNSSupport para VPActive el atributo enableDNShostNames para VPCrear un nuevo conjunto de opciones DHCP de VPC y configure doman-name-servers=10.24.34.2. Asocie el nuevo conjunto de opciones DHCP con la VPC.
D.
Crear una zona privada alojada. Asociar la zona privada alojada con la VPC. Active el atributo enableDNSSupport para la VPC. Desactive el atributo enableDNShostNames para la VPC. Actualice las opciones DHCP de VPC establecidas para incluir Domain-name-servers=AmazonProvideDDNS.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos de que las consultas DNS deben usar zonas alojadas privadas y que las instancias con direcciones IP públicas deben recibir los nombres de host públicos correspondientes, necesitamos crear una zona alojada privada y asociarla con la VPC. Además, Amazon Route 53 Resolver requerirá que se activen los atributos EnableDNSSupport y EnableDNShostNames. El conjunto de opciones DHCP de VPC debe configurarse para usar AmazonProvideDDNS para garantizar una resolución adecuada de los nombres de dominio dentro de la VPC.
Question 305 of 529
Una empresa de análisis de datos tiene un clúster de Amazon Redshift que consta de varios nodos reservados. El clúster está experimentando ráfagas inesperadas de uso porque un equipo de empleados está compilando un informe de análisis de auditoría profundo. Las consultas para generar el informe son consultas de lectura complejas y requieren un uso intensivo de CPU.
Los requisitos del negocio dictan que el clúster debe ser capaz de atender consultas de lectura y escritura en todo momento. Un arquitecto de soluciones debe idear una solución que se adapte a las ráfagas de uso.
Qué solución cumple con estos requisitos de manera más rentable?
A.
Aprovisionar un clúster de Amazon EMR Descargue las tareas complejas de procesamiento de datos.
B.
Implemente una función de AWS Lambda para agregar capacidad al clúster de Amazon Redshift mediante una operación clásica de cambio de tamaño cuando las métricas de CPU del clúster en Amazon CloudWatch alcanzan el 80%.
C.
Implemente una función de AWS Lambda para agregar capacidad al clúster de Amazon Redshift mediante una operación elástica de cambio de tamaño cuando las métricas de CPU del clúster en Amazon CloudWatch alcancen el 80%.
D.
Active la función de escalado de concurrencia para el clúster de Amazon Redshift.
AnswerDiscussion
Correct Answer: D
Al activar la función de escalado de concurrencia para el clúster de Amazon Redshift, el sistema puede agregar automáticamente capacidad adicional para manejar consultas de lectura y escritura incrementadas durante ráfagas inesperadas de uso. Garantiza que la carga de trabajo se administre dinámicamente sin intervención manual y es la solución más rentable para mantener el rendimiento tanto para las operaciones de lectura como de escritura.
Question 306 of 529
Un centro de investigación está migrando a la nube de AWS y ha trasladado su almacenamiento local de objetos de 1 PB a un bucket de Amazon S3. Cien científicos están utilizando este almacenamiento de objetos para almacenar sus documentos relacionados con el trabajo. Cada científico tiene una carpeta personal en el almacén de objetos. Todos los científicos son miembros de un solo grupo de usuarios de IAM.
Al oficial de cumplimiento del centro de investigación le preocupa que los científicos puedan acceder al trabajo de los demás. El centro de investigación tiene la obligación estricta de informar sobre qué científico accede a qué documentos. El equipo responsable de estos informes tiene poca experiencia en AWS y quiere una solución lista para usar que minimice la sobrecarga operativa.
Qué combinación de acciones debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Crear una política de identidad que otorgue al usuario acceso de lectura y escritura. Agregue una condición que especifique que las rutas S3 deben tener el prefijo $ (aws:username). Aplicar la política en el grupo de usuarios del IAM de los científicos.
B.
Configure una ruta con AWS CloudTrail para capturar todos los eventos a nivel de objeto en el bucket S3. Almacene la salida del sendero en otro cubo S3. Utilice Amazon Athena para consultar los registros y generar informes.
C.
Habilite el registro de acceso al servidor S3. Configure otro bucket S3 como destino para la entrega de registros. Utilice Amazon Athena para consultar los registros y generar informes.
D.
Crear una política de bucket S3 que otorgue acceso de lectura y escritura a los usuarios del grupo de usuarios de IAM de los científicos.
E.
Configure una ruta con AWS CloudTrail para capturar todos los eventos a nivel de objeto en el bucket S3 y escribir los eventos en Amazon CloudWatch. Utilice el conector Amazon Athena CloudWatch para consultar los registros y generar informes.
AnswerDiscussion
Correct Answer: A, B
Para garantizar que cada científico solo pueda acceder a sus propios documentos relacionados con el trabajo y cumplir con los estrictos requisitos de informes de cumplimiento, es necesaria una estrategia de dos partes. Primero, cree una política de identidad que otorgue a los usuarios acceso de lectura y escritura específicamente a rutas prefijadas con su nombre de usuario. Esto asegurará que los científicos no puedan acceder a las carpetas de los demás y mantener sus datos aislados de acuerdo con las preocupaciones del oficial de cumplimiento. En segundo lugar, configure un rastro con AWS CloudTrail para capturar todos los eventos a nivel de objeto en el bucket S3 y almacenar los registros en otro bucket S3. Esto proporcionará un registro detallado y preciso de qué científico accede a qué documentos, los cuales pueden consultarse utilizando Amazon Athena para generar los informes de cumplimiento necesarios con una sobrecarga operativa mínima. Esta combinación aborda de manera efectiva tanto el control de acceso como los requisitos de auditoría.
Question 307 of 529
Una empresa utiliza AWS Organizations para administrar una estructura multicuenta. La compañía tiene cientos de cuentas de AWS y espera que aumente el número de cuentas. La compañía está construyendo una nueva aplicación que utiliza imágenes Docker. La compañía empujará las imágenes de Docker a Amazon Elastic Container Registry (Amazon ECR). Solo las cuentas que estén dentro de la organización de la empresa deben tener acceso a las imágenes.
La compañía cuenta con un proceso de CI/CD que se ejecuta con frecuencia. La compañía quiere conservar todas las imágenes etiquetadas. No obstante, la compañía quiere retener solo las cinco imágenes sin etiquetar más recientes.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Crear un repositorio privado en Amazon ECR. Cree una política de permisos para el repositorio que permita únicamente las operaciones ECR requeridas. Incluir una condición para permitir las operaciones ECR si el valor de la clave de condición AWS:PrincipalORGLD es igual al ID de la organización de la compañía. Agregar una regla de ciclo de vida al repositorio ECR que elimina todas las imágenes sin etiquetar en el recuento de cinco
B.
Crear un repositorio público en Amazon ECR. Crear un rol de IAM en la cuenta ECR. Establezca permisos para que cualquier cuenta pueda asumir el rol si el valor de la clave de condición AWS:PrincipalOrGld es igual al ID de la organización de la compañía. Agregue una regla de ciclo de vida al repositorio ECR que borre todas las imágenes sin etiquetar en el recuento de cinco.
C.
Crear un repositorio privado en Amazon ECR. Cree una política de permisos para el repositorio que incluya solo las operaciones ECR requeridas. Incluir una condición para permitir las operaciones ECR para todos los ID de cuenta en la organización Programe una regla diaria de Amazon EventBridge para invocar una función de AWS Lambda que elimine todas las imágenes sin etiquetar en un recuento de cinco.
D.
Crear un repositorio público en Amazon ECR. Configure Amazon ECR para utilizar un punto final de VPC de interfaz con una política de punto final que incluya los permisos necesarios para las imágenes que la empresa necesita obtener. Incluir una condición para permitir las operaciones ECR para todos los ID de cuenta en la organización de la compañía. Programe una regla diaria de Amazon EventBridge para invocar una función de AWS Lambda que elimine todas las imágenes sin etiquetar a lo largo de cinco.
AnswerDiscussion
Correct Answer: A
La creación de un repositorio privado en Amazon ECR permite el acceso controlado y garantiza que solo las cuentas dentro de la organización de la compañía puedan acceder a las imágenes de Docker. Al establecer una política de permisos que incluya una condición basada en la clave de condición AWS:PrincipalOrGld, el acceso está restringido a las cuentas de la organización. Agregar una regla de ciclo de vida al repositorio ECR para eliminar imágenes sin etiquetar a lo largo del recuento de cinco automatiza el proceso de limpieza, reduciendo la sobrecarga operativa. Esta solución cumple con los requisitos de escalabilidad, seguridad y eficiencia operativa.
Question 308 of 529
Un arquitecto de soluciones está revisando el proceso de una empresa para tomar instantáneas de instancias de base de datos de Amazon RDS. La compañía toma instantáneas automáticas todos los días y las conserva durante 7 días.
El arquitecto de soluciones necesita recomendar una solución que tome instantáneas cada 6 horas y las conserve durante 30 días. La compañía utiliza AWS Organizations para administrar todas sus cuentas de AWS. La compañía necesita una visión consolidada del estado de las instantáneas de RDS.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Activa la función de administración entre cuentas en AWS Backup. Cree un plan de respaldo que especifique los requisitos de frecuencia y retención. Agregue una etiqueta a las instancias de base de datos. Aplicar el plan de respaldo mediante etiquetas. Utilice AWS Backup para monitorear el estado de las copias de seguridad.
B.
Activa la función de administración entre cuentas en Amazon RDS. Cree una política global de instantáneas que especifique los requisitos de frecuencia y retención. Utilice la consola RDS en la cuenta de administración para monitorear el estado de las copias de seguridad.
C.
Activa la función de administración entre cuentas en AWS CloudFormation. Desde la cuenta de administración, implemente un conjunto de pila de CloudFormation que contenga un plan de copia de seguridad de AWS Backup que especifique los requisitos de frecuencia y retención. Cree una función de AWS Lambda en la cuenta de administración para monitorear el estado de las copias de seguridad. Cree una regla de Amazon EventBridge en cada cuenta para ejecutar la función Lambda según un horario.
D.
Configure AWS Backup en cada cuenta. Cree una política de ciclo de vida de Amazon Data Lifecycle Manager que especifique los requisitos de frecuencia y retención. Especifique las instancias de base de datos como recurso de destino Utilice la consola de Amazon Data Lifecycle Manager en cada cuenta de miembro para supervisar el estado de las copias de seguridad.
AnswerDiscussion
Correct Answer: A
La solución óptima para manejar instantáneas cada 6 horas y conservarlas durante 30 días, con monitoreo de estado consolidado y una sobrecarga operativa mínima, es usar AWS Backup. Al activar la función de administración entre cuentas en AWS Backup, crear un plan de copia de seguridad que especifique la frecuencia y retención requeridas, y aplicando el plan de copia de seguridad mediante etiquetas, la compañía puede administrar y monitorear de manera eficiente el estado de las copias de seguridad en todas las cuentas. Este enfoque aprovecha las características integradas de AWS Backup para la administración de cuentas cruzadas y el monitoreo del estado, cumpliendo los requisitos con la menor sobrecarga operativa.
Question 309 of 529
Una empresa utiliza AWS Organizations con una arquitectura multicuenta. La configuración de seguridad actual de la compañía para la arquitectura de la cuenta incluye SCP, políticas basadas en recursos, políticas basadas en identidad, políticas de confianza y políticas de sesión.
Un arquitecto de soluciones necesita permitir que un usuario de IAM en la Cuenta A asuma un rol en la Cuenta B.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con este requisito? (Elija tres.)
A.
Configure el SCP para la Cuenta A para permitir la acción.
B.
Configure las políticas basadas en recursos para permitir la acción.
C.
Configure la política basada en identidad del usuario en la Cuenta A para permitir la acción.
D.
Configure la política basada en identidad del usuario en la Cuenta B para permitir la acción.
E.
Configure la política de confianza sobre el rol objetivo en la Cuenta B para permitir la acción.
F.
Configure la política de sesión para permitir la acción y que sea pasada programáticamente por la operación de la API GetSessionToken.
AnswerDiscussion
Correct Answer: A, C, E
Para permitir que un usuario de IAM en la Cuenta A asuma un rol en la Cuenta B, son necesarios varios pasos: Primero, se debe configurar la política basada en la identidad del usuario en la Cuenta A para permitir la acción, ya que esta política controla lo que pueden hacer los usuarios de la Cuenta A. En segundo lugar, la política de confianza sobre el rol en la Cuenta B debe configurarse para confiar en el usuario de IAM desde la Cuenta A para que asuma el rol. Esta configuración establece la relación que permite al usuario asumir el rol. Por último, como la compañía utiliza AWS Organizations con SCP, el SCP para la cuenta A debe configurarse para permitir esta acción. Los SCP actúan a nivel de unidad organizativa y cuenta para garantizar que nada en la jerarquía niegue explícitamente la acción requerida.
Question 310 of 529
Una empresa quiere utilizar Amazon S3 para realizar copias de seguridad de su solución de almacenamiento de archivos local. La solución de almacenamiento de archivos on-premise de la compañía es compatible con NFS, y la compañía quiere que su nueva solución sea compatible con NFS. La compañía quiere archivar los archivos de respaldo después de 5 días. Si la empresa necesita archivos archivados para la recuperación ante desastres, la compañía está dispuesta a esperar unos días para la recuperación de esos archivos.
Qué solución cumple con estos requisitos de manera más rentable?
A.
Implemente una puerta de enlace de archivos de AWS Storage Gateway asociada a un bucket S3. Mueva los archivos de la solución de almacenamiento de archivos local a la puerta de enlace de archivos. Cree una regla de ciclo de vida de S3 para mover los archivos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 5 días.
B.
Implemente una puerta de enlace de volumen de AWS Storage Gateway asociada a un bucket S3. Mueva los archivos de la solución de almacenamiento de archivos local a la puerta de enlace de volumen. Cree una regla de ciclo de vida de S3 para mover los archivos a S3 Glacier Deep Archive después de 5 días.
C.
Implemente una puerta de enlace de cinta de AWS Storage Gateway asociada a un bucket S3. Mueva los archivos de la solución de almacenamiento de archivos local a la puerta de enlace en cinta. Cree una regla de ciclo de vida de S3 para mover los archivos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 5 días.
D.
Implemente una puerta de enlace de archivos de AWS Storage Gateway asociada a un bucket S3. Mueva los archivos de la solución de almacenamiento de archivos local a la puerta de enlace de archivos. Cree una regla de ciclo de vida de S3 para mover los archivos a S3 Glacier Deep Archive después de 5 días.
AnswerDiscussion
Correct Answer: D
Para realizar copias de seguridad de la solución de almacenamiento de archivos local que admite NFS y archivar archivos después de 5 días, la solución más rentable es usar una puerta de enlace de archivos AWS Storage Gateway asociada con un bucket S3. La regla del ciclo de vida de S3 debería mover los archivos a S3 Glacier Deep Archive después de 5 días, ya que esta clase de almacenamiento es la más rentable para el almacenamiento a largo plazo a pesar de su mayor tiempo de recuperación, que la compañía está dispuesta a acomodar para fines de recuperación ante desastres.
Question 311 of 529
Una empresa ejecuta su aplicación en instancias de Amazon EC2 y funciones de AWS Lambda. Las instancias EC2 experimentan una carga continua y estable. Las funciones Lambda experimentan una carga variada e impredecible. La aplicación incluye una capa de almacenamiento en caché que utiliza un clúster de Amazon MemoryDB para Redis.
Un arquitecto de soluciones debe recomendar una solución para minimizar los costos mensuales generales de la compañía.
Qué solución cumplirá con estos requisitos?
A.
Adquiera un plan de ahorro de instancias EC2 para cubrir las instancias EC2. Adquirir un Plan de Ahorro de Computación para Lambda para cubrir el consumo mínimo esperado de las funciones de Lambda. Compra nodos reservados para cubrir los nodos de caché de MemoryDB.
B.
Adquiera un plan de ahorro de cómputos para cubrir las instancias EC2. Compra simultaneidad reservada de Lambda para cubrir el uso esperado de Lambda. Compra nodos reservados para cubrir los nodos de caché de MemoryDB.
C.
Adquiera un plan de ahorro de cómputos para cubrir todo el costo esperado de las instancias EC2, las funciones Lambda y los nodos de caché MemoryDB.
D.
Adquiera un plan de ahorro de cómputos para cubrir las instancias EC2 y los nodos de caché de MemoryDB. Compra simultaneidad reservada de Lambda para cubrir el uso esperado de Lambda.
AnswerDiscussion
Correct Answer: A
Para minimizar los costos mensuales generales de la compañía mientras se abordan las características específicas de la carga de la aplicación, la mejor solución es comprar un Plan de Ahorro de instancias EC2 para cubrir la carga continua y estable de las instancias EC2. Para la carga variada e impredecible que experimentan las funciones Lambda, es apropiado un Plan de Ahorro de Computación para cubrir el consumo mínimo esperado. Además, la compra de nodos reservados para los nodos de caché de MemoryDB proporcionará ahorros de costos para la capa de almacenamiento en caché. Este enfoque garantiza que el mecanismo de ahorro de costos de cada componente se alinee con su patrón de uso.
Question 312 of 529
Una compañía está lanzando un nuevo juego en línea en instancias de Amazon EC2. El juego debe estar disponible a nivel mundial. La compañía planea ejecutar el juego en tres regiones de AWS us-east-1, eu-west-1 y ap-southeast-1. Las tablas de clasificación del juego, el inventario de jugadores y el estado del evento deben estar disponibles en todas las regiones.
Un arquitecto de soluciones debe diseñar una solución que le dé a cualquier Región la capacidad de escalar para manejar la carga de todas las Regiones. Adicionalmente, los usuarios deben conectarse automáticamente a la Región que proporcione la menor latencia.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una Flota de Spot EC2. Adjunte la flota de spot a un balanceador de carga de red (NLB) en cada región. Cree una dirección IP de AWS Global Accelerator que apunte a la NLB. Cree una entrada de enrutamiento basada en latencia de Amazon Route 53 para la dirección IP de Global Accelerator. Guarde los metadatos del juego en una instancia de base de datos de Amazon RDS para MySQL en cada región. Configura una réplica de lectura en las otras regiones.
B.
Crear un grupo de Auto Scaling para las instancias EC2 Adjuntar el grupo Auto Scaling a un balanceador de carga de red (NLB) en cada región. Para cada región, cree una entrada Amazon Route 53 que utilice enrutamiento de geoproximidad y apunte a la NLB en esa región. Guarde los metadatos del juego en bases de datos MySQL en instancias EC2 en cada región. Configure la replicación entre las instancias EC2 de la base de datos en cada región.
C.
Cree un grupo de Auto Scaling para las instancias EC2. Adjunte el grupo Auto Scaling a un balanceador de carga de red (NLB) en cada región. Para cada región, cree una entrada Amazon Route 53 que utilice enrutamiento basado en latencia y apunte a la NLB en esa región. Guarde los metadatos del juego en una tabla global de Amazon DynamoDB.
D.
Utilice EC2 Global View. Implemente las instancias EC2 en cada región. Adjunte las instancias a un balanceador de carga de red (NLB). Implemente un servidor DNS en una instancia EC2 en cada región. Configure la lógica personalizada en cada servidor DNS para redirigir al usuario a la región que proporcione la latencia más baja. Guarde los metadatos del juego en una base de datos global de Amazon Aurora.
AnswerDiscussion
Correct Answer: C
La mejor solución para satisfacer los requisitos con la menor sobrecarga operativa implica crear un grupo de Auto Scaling para las instancias EC2 y conectarlo a un balanceador de carga de red (NLB) en cada región. El uso del enrutamiento basado en latencia en Amazon Route 53 garantiza que los usuarios se conecten automáticamente a la región con la menor latencia. Almacenar los metadatos del juego en una tabla global de Amazon DynamoDB permite una replicación fluida y multiregional de las tablas de clasificación del juego, el inventario de jugadores y el estado del evento. Esta configuración proporciona alta disponibilidad y escalabilidad al tiempo que minimiza la complejidad operativa.
Question 313 of 529
Una empresa está implementando una solución de dispositivo de firewall de terceros de AWS Marketplace para monitorear y proteger el tráfico que sale de los entornos de AWS de la compañía. La compañía quiere implementar este dispositivo en una VPC de servicios compartidos y enrutar todo el tráfico saliente de Internet a través de los dispositivos.
Un arquitecto de soluciones necesita recomendar un método de implementación que priorice la confiabilidad y minimice el tiempo de conmutación por error entre dispositivos de firewall dentro de una sola región de AWS. La compañía ha configurado el enrutamiento desde la VPC de servicios compartidos a otras VPC.
Qué pasos debería recomendar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Implemente dos dispositivos de firewall en la VPC de servicios compartidos, cada uno en una zona de disponibilidad separada.
B.
Cree un nuevo balanceador de carga de red en la VPC de servicios compartidos. Cree un nuevo grupo objetivo y conéctelo al nuevo balanceador de carga de red. Agregue cada una de las instancias del dispositivo de firewall al grupo de destino.
C.
Crear un nuevo balanceador de carga de puerta de enlace en los servicios compartidos VPCrear un nuevo grupo de destino y adjuntarlo al nuevo Balanceador de carga de puerta de enlace Agregue cada una de las instancias del dispositivo de firewall al grupo de destino.
D.
Cree un punto final de interfaz de VPC. Agregue una ruta a la tabla de rutas en la VPC de servicios compartidos. Designe el nuevo punto final como el siguiente salto para el tráfico que ingresa a la VPC de servicios compartidos desde otras VPC.
E.
Implemente dos dispositivos de firewall en la VPC de servicios compartidos, cada uno en la misma zona de disponibilidad.
F.
Cree un punto final de equilibrador de carga de puerta de enlace de VPC. Agregue una ruta a la tabla de rutas en la VPC de servicios compartidos. Designe el nuevo punto final como el siguiente salto para el tráfico que ingresa a la VPC de servicios compartidos desde otras VPC.
AnswerDiscussion
Correct Answer: A, C, F
Para garantizar una alta disponibilidad y confiabilidad al tiempo que se minimizan los tiempos de conmutación por error, la implementación debe involucrar varias zonas de disponibilidad y utilizar servicios especializados de AWS. La implementación de dos dispositivos de firewall en zonas de disponibilidad separadas aumenta la redundancia y la tolerancia a fallas. Un balanceador de carga de puerta de enlace (GWLB) está diseñado para manejar el enrutamiento y balanceo de tráfico para dispositivos virtuales como firewalls. Un punto final GWLB garantiza que el tráfico de otras VPC se pueda enrutar a los dispositivos de firewall de manera efectiva. Estos pasos garantizan que los tiempos de conmutación por error se minimizan y se prioriza la confiabilidad.
Question 314 of 529
Un arquitecto de soluciones necesita migrar una aplicación heredada local a AWS. La aplicación se ejecuta en dos servidores detrás de un equilibrador de carga. La aplicación requiere un archivo de licencia que esté asociado a la dirección MAC del adaptador de red del servidor. El proveedor de software tarda 12 horas en enviar nuevos archivos de licencia. La aplicación también utiliza archivos de configuración con una dirección IP estática para acceder a un servidor de base de datos, los nombres de host no son compatibles.
Dados estos requisitos, qué combinación de pasos se deben tomar para implementar una arquitectura de alta disponibilidad para los servidores de aplicaciones en AWS? (Elija dos.)
A.
Crear un grupo de ENI. Solicite archivos de licencia al proveedor para el grupo y almacene los archivos de licencia en Amazon S3. Cree un script de automatización de arranque para descargar un archivo de licencia y adjuntar el ENI correspondiente a una instancia de Amazon EC2.
B.
Crear un grupo de ENI. Solicite archivos de licencia al proveedor para el grupo, almacene los archivos de licencia en una instancia de Amazon EC2. Cree una AMI a partir de la instancia y utilice esta AMI para todas las instancias EC2 futuras.
C.
Cree un script de automatización de arranque para solicitar un nuevo archivo de licencia al proveedor. Cuando se reciba la respuesta, aplique el archivo de licencia a una instancia de Amazon EC2.
D.
Edite el script de automatización de arranque para leer la dirección IP del servidor de base de datos del almacén de parámetros de AWS Systems Manager e inyecte el valor en los archivos de configuración locales.
E.
Edite una instancia de Amazon EC2 para incluir la dirección IP del servidor de base de datos en los archivos de configuración y vuelva a crear la AMI para usar en todas las futuras posturas de EC2.
AnswerDiscussion
Correct Answer: A, D
Para implementar una arquitectura de alta disponibilidad para los servidores de aplicaciones en AWS dados los requisitos de licencia y de IP estática de la aplicación, se deben tomar dos pasos. Primero, cree un grupo de Elastic Network Interfaces (ENI). Solicite archivos de licencia al proveedor para cada ENI del grupo y almacene estos archivos de licencia en Amazon S3. Luego, cree un script de automatización de arranque para descargar un archivo de licencia de S3 y adjuntar el ENI correspondiente a una instancia de Amazon EC2 al inicio de la instancia. Este enfoque garantiza que el archivo de licencia asociado a la dirección MAC se administre de manera efectiva. En segundo lugar, edite el script de automatización de arranque para leer la dirección IP estática del servidor de base de datos desde AWS Systems Manager Parameter Store e inyectar esta dirección IP en los archivos de configuración locales de la aplicación. Esto asegura que los archivos de configuración siempre tengan la dirección IP correcta y actualizada para el servidor de base de datos, manteniendo la capacidad de la aplicación para conectarse a su base de datos.
Question 315 of 529
Una compañía ejecuta su aplicación de informes de ventas en una región de AWS en los Estados Unidos. La aplicación utiliza una API regional de Amazon API Gateway y funciones de AWS Lambda para generar informes bajo demanda a partir de datos en una base de datos de Amazon RDS para MySQL. La interfaz de la aplicación está alojada en Amazon S3 y los usuarios acceden a ella a través de una distribución de Amazon CloudFront. La compañía está utilizando Amazon Route 53 como el servicio DNS para el dominio. Route 53 se configura con una política de enrutamiento simple para enrutar el tráfico a la API de API Gateway.
En los próximos 6 meses, la compañía planea expandir sus operaciones a Europa. Más del 90% del tráfico de la base de datos es tráfico de solo lectura. La compañía ya ha implementado una API Gateway API y funciones Lambda en la nueva Región.
Un arquitecto de soluciones debe diseñar una solución que minimice la latencia para los usuarios que descargan informes.
Qué solución cumplirá con estos requisitos?
A.
Utilice una tarea de AWS Database Migration Service (AWS DMS) con carga completa para replicar la base de datos principal de la región original en la base de datos de la nueva región. Cambie el registro Route 53 a enrutamiento basado en latencia para conectarse a la API de API Gateway.
B.
Utilice una tarea de AWS Database Migration Service (AWS DMS) con carga completa más captura de datos de cambio (CDC) para replicar la base de datos principal de la región original a la base de datos de la nueva región. Cambie el registro Route 53 a enrutamiento de geolocalización para conectarse a la API de API Gateway.
C.
Configure una réplica de lectura entre regiones para la base de datos RDS en la nueva región Cambiar el registro Route 53 a enrutamiento basado en latencia para conectarse a la API de API Gateway.
D.
Configure una réplica de lectura entre regiones para la base de datos RDS en la nueva región. Cambie el registro Route 53 a enrutamiento de geolocalización para conectarse a la API de API Gateway.
AnswerDiscussion
Correct Answer: C
Para minimizar la latencia de los usuarios que descargan informes, la solución óptima debe garantizar que los datos sean fácilmente accesibles desde la región más cercana. La configuración de una réplica de lectura entre regiones para la base de datos RDS en la nueva región garantiza que el tráfico de solo lectura se pueda manejar localmente, lo que reduce la latencia. Además, el uso de enrutamiento basado en latencia para el registro de Route 53 dirigirá a los usuarios a la API de puerta de enlace API más cercana, minimizando aún más la latencia. Por lo tanto, configurar una réplica de lectura entre regiones y utilizar el enrutamiento basado en latencia cumple mejor con los requisitos.
Question 316 of 529
Una empresa de software necesita crear entornos de prueba de corta duración para probar las solicitudes de extracción como parte de su proceso de desarrollo. Cada entorno de prueba consta de una única instancia de Amazon EC2 que se encuentra en un grupo de Auto Scaling.
Los entornos de prueba deben poder comunicarse con un servidor central para reportar los resultados de las pruebas. El servidor central se encuentra en un centro de datos local. Un arquitecto de soluciones debe implementar una solución para que la empresa pueda crear y eliminar entornos de prueba sin ninguna intervención manual. La compañía ha creado una puerta de enlace de tránsito con una conexión VPN a la red local.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una plantilla de AWS CloudFormation que contenga un adjunto de puerta de enlace de tránsito y configuraciones de enrutamiento relacionadas. Cree un conjunto de pila de CloudFormation que incluya esta plantilla. Utilice CloudFormation StackSets para implementar una nueva pila para cada VPC de la cuenta. Implemente una nueva VPC para cada entorno de prueba.
B.
Cree una única VPC para los entornos de prueba. Incluya un accesorio de puerta de enlace de tránsito y configuraciones de enrutamiento relacionadas. Utilice AWS CloudFormation para implementar todos los entornos de prueba en la VPC.
C.
Cree una nueva unidad organizativa en las organizaciones de AWS para realizar pruebas. Cree una plantilla de AWS CioudFormation que contenga una VPC, los recursos de red necesarios, un adjunto de puerta de enlace de tránsito y configuraciones de enrutamiento relacionadas. Cree un conjunto de pila de CloudFormation que incluya esta plantilla. Utilice CloudFormation StackSets para implementaciones en cada cuenta bajo la unidad organizativa de prueba. Crear una nueva cuenta para cada entorno de prueba.
D.
Convierta las instancias EC2 del entorno de prueba en imágenes Docker. Utilice AWS CloudFormation para configurar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en una nueva VPC, crear un adjunto de puerta de enlace de tránsito y crear configuraciones de enrutamiento relacionadas. Utilice Kubernetes para administrar la implementación y el ciclo de vida de los entornos de prueba.
AnswerDiscussion
Correct Answer: B
La solución que implica la creación de una única VPC para los entornos de prueba, incluido un adjunto de puerta de enlace de tránsito y configuraciones de enrutamiento relacionadas, y el uso de AWS CloudFormation para implementar todos los entornos de prueba en la VPC, es la que cumple con los requisitos con la menor sobrecarga operativa. Este enfoque evita la complejidad de administrar varias cuentas de VPC o AWS Organizations y garantiza que los nuevos entornos de prueba puedan comunicarse con el servidor central local de manera eficiente. Además, el uso de una única VPC simplifica la administración de la red y reduce la sobrecarga asociada con la creación y eliminación de entornos de prueba.
Question 317 of 529
Una empresa está implementando una nueva API en AWS. La API utiliza Amazon API Gateway con un punto de enlace de API regional y una función de AWS Lambda para el alojamiento. La API recupera datos de una API de proveedor externa, almacena datos en una tabla global de Amazon DynamoDB y recupera datos de la tabla global de DynamoDB La clave de API para la API del proveedor se almacena en AWS Secrets Manager y se cifra con una clave administrada por el cliente en AWS Key Management Service (AWS KMS). La compañía ha implementado su propia API en una sola región de AWS.
Un arquitecto de soluciones necesita cambiar los componentes de API de la API de la compañía para garantizar que los componentes puedan ejecutarse en varias regiones en una configuración activa-activa.
Qué combinación de cambios cumplirá con este requisito con la menor sobrecarga operativa? (Elija tres.)
A.
Implementar la API en varias regiones. Configure Amazon Route 53 con nombres de dominio personalizados que dirijan el tráfico a cada punto final de la API regional. Implementar una política de enrutamiento de respuesta multivalue Route 53.
B.
Cree una nueva clave administrada por el cliente de KMS Multi-región. Cree una nueva clave de réplica administrada por el cliente de KMS en cada región dentro del alcance.
C.
Replique el secreto existente de Secrets Manager a otras Regiones. Para el secreto replicado de cada región dentro del alcance, seleccione la clave KMS apropiada.
D.
Cree una nueva clave KMS administrada por AWS en cada región dentro del alcance. Convierta una clave existente en una clave MultiRegion. Utilice la clave Multi-región en otras regiones.
E.
Cree un nuevo secreto de Secrets Manager en cada región dentro del alcance. Copia el valor secreto de la región existente al nuevo secreto en cada región dentro del alcance.
F.
Modifique el proceso de implementación de la función Lambda para repetir la implementación en las regiones dentro del alcance. Active la opción Multi-región para la API existente. Seleccione la función Lambda que se despliega en cada región como backend para la API de varias regiones.
AnswerDiscussion
Correct Answer: A, B, F
Para lograr una configuración multiregión activa-activa para la API con la menor sobrecarga operativa, son necesarios los siguientes pasos. En primer lugar, la API debe implementarse en varias regiones y Amazon Route 53 debe configurarse con nombres de dominio personalizados que enruten el tráfico a cada punto final de la API regional mediante una política de enrutamiento de respuestas multivalue. En segundo lugar, se debe crear una nueva clave administrada por el cliente de varias regiones de KMS, junto con una clave de réplica administrada por el cliente en cada región dentro del alcance, para manejar las necesidades de cifrado en todas las regiones de manera eficiente. Finalmente, el proceso de implementación de la función Lambda debe modificarse para repetir la implementación en todas las regiones dentro del alcance, y la opción multi-región debe activarse para la API existente, seleccionando la función Lambda respectiva implementada en cada región como backend. Esta combinación garantiza redundancia regional y tolerancia a fallas mientras mantiene una baja complejidad operativa.
Question 318 of 529
Una empresa minorista en línea aloja su aplicación basada en la web con estado y la base de datos MySQL en un centro de datos local en un solo servidor. La compañía quiere aumentar su base de clientes mediante la realización de más campañas de marketing y promociones. En preparación, la compañía quiere migrar su aplicación y base de datos a AWS para aumentar la confiabilidad de su arquitectura.
Qué solución debería proporcionar el nivel MÁS ALTO de confiabilidad?
A.
Migre la base de datos a una instancia de base de datos Multi-AZ de Amazon RDS MySQL. Implemente la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. Sesiones de tienda en Amazon Neptune
B.
Migre la base de datos a Amazon Aurora MySQL. Implemente la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. Almacene sesiones en un grupo de replicación de Amazon ElastiCache para Redis.
C.
Migre la base de datos a Amazon DocumentDB (con compatibilidad con MongoDB). Implemente la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de sesiones de Network Load Balancer Store en Amazon Kinesis Data Firehose.
D.
Migre la base de datos a una instancia de base de datos Multi-AZ de MariaDB de Amazon RDS. Implemente la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. Almacenar sesiones en Amazon ElastiCache para Memcached.
AnswerDiscussion
Correct Answer: B
La migración de la base de datos a Amazon Aurora MySQL y la implementación de la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones es una solución sólida. Amazon Aurora es altamente confiable debido a su seguridad integrada, backups continuos, acceso a réplicas de lectura y capacidades de replicación automatizada en varias regiones. El uso de Amazon ElastiCache para Redis para almacenar sesiones mejora adicionalmente la confiabilidad de la arquitectura, ya que Redis admite la replicación y proporciona alta disponibilidad y tolerancia a fallas.
Question 319 of 529
El arquitecto de soluciones de una empresa necesita proporcionar conectividad segura de Escritorio remoto a los usuarios para las instancias de Windows de Amazon EC2 alojadas en una VPC. La solución debe integrar la administración centralizada de usuarios con el Active Directory local de la compañía. La conectividad a la VPC es a través de Internet. La compañía cuenta con hardware que se puede utilizar para establecer una conexión VPN de sitio a sitio de AWS.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Implemente un Active Directory administrado mediante AWS Directory Service para Microsoft Active Directory. Establezca una confianza con el Active Directory local. Implemente una instancia EC2 como host bastión en la VPC. Asegúrese de que la instancia EC2 esté unida al dominio. Utilice el host bastión para acceder a las instancias de destino a través de RDP.
B.
Configure AWS IAM Identity Center (AWS Single Signa-On) para que se integre con el Active Directory local mediante AWS Directory Service para Microsoft Active Directory AD Connector. Configure conjuntos de permisos contra grupos de usuarios para acceder a AWS Systems Manager. Utilice Systems Manager Fleet Manager para acceder a las instancias de destino a través de RDP.
C.
Implemente una VPN entre el entorno local y la VPN de destino Asegúrese de que las instancias de destino se unan al dominio local de Active Directory a través de la conexión VPN. Configure el acceso RDP a través de la VPN. Conéctese desde la red de la compañía a las instancias objetivo.
D.
Implemente un Active Directory administrado mediante AWS Directory Service para Microsoft Active Directory. Establezca una confianza con el Active Directory local. Implemente una puerta de enlace de escritorio remoto en AWS mediante AWS Quick Start. Asegúrese de que la puerta de enlace de escritorio remoto esté unida al dominio. Utilice la puerta de enlace de escritorio remoto para acceder a las instancias de destino a través de RDP.
AnswerDiscussion
Correct Answer: B
La solución más rentable es configurar AWS IAM Identity Center (AWS Single Sign-On) para que se integre con Active Directory local mediante el uso de AWS Directory Service para Microsoft Active Directory AD Connector. Este enfoque aprovecha la administración centralizada de usuarios integrada con el Active Directory local de la compañía y proporciona conectividad de escritorio remoto segura a través de AWS Systems Manager Fleet Manager, evitando la necesidad de infraestructura adicional como hosts bastión o conexiones administradas por VPN.
Question 320 of 529
La auditoría de cumplimiento de una empresa revela que algunos volúmenes de Amazon Elastic Block Store (Amazon EBS) que se crearon en una cuenta de AWS no estaban cifrados. Un arquitecto de soluciones debe implementar una solución para cifrar todos los nuevos volúmenes de EBS en reposo.
Cuál solución cumplirá con este requisito con el MENOR esfuerzo?
A.
Cree una regla de Amazon EventBridge para detectar la creación de volúmenes de EBS sin cifrar. Invoque una función de AWS Lambda para eliminar volúmenes no conformes.
B.
Utilice AWS Audit Manager con cifrado de datos.
C.
Cree una regla de AWS Config para detectar la creación de un nuevo volumen de EBS. Cifrar el volumen mediante AWS Systems Manager Automation.
D.
Active el cifrado EBS de forma predeterminada en todas las regiones de AWS.
AnswerDiscussion
Correct Answer: D
Activar el cifrado de EBS de forma predeterminada en todas las regiones de AWS garantizará que todos los nuevos volúmenes de EBS se cifren automáticamente en reposo, proporcionando una solución que requiere el menor esfuerzo para administrar e implementar. Este enfoque elimina la necesidad de monitoreo continuo y corrección de volúmenes no conformes, simplificando así la gestión del cumplimiento.
Question 321 of 529
Una empresa de investigación realiza simulaciones diarias en la nube de AWS para satisfacer la alta demanda. Las simulaciones se ejecutan en varios cientos de instancias de Amazon EC2 basadas en Amazon Linux 2. Ocasionalmente, una simulación se atasca y requiere un ingeniero de operaciones en la nube para resolver el problema conectándose a una instancia EC2 a través de SSH.
La política de la compañía establece que ninguna instancia EC2 puede usar la misma clave SSH y que todas las conexiones deben registrarse en AWS CloudTrail.
Cómo puede un arquitecto de soluciones cumplir con estos requisitos?
A.
Inicie nuevas instancias EC2 y genere una clave SSH individual para cada instancia. Almacene la clave SSH en AWS Secrets Manager. Cree una nueva política de IAM y adjúntela al rol de IAM de los ingenieros con una instrucción Alt para la acción GetSecretValue. Indique a los ingenieros que obtengan la clave SSH de Secrets Manager cuando se conecten a través de cualquier cliente SSH.
B.
Cree un documento de AWS Systems Manager para ejecutar comandos en instancias EC2 y establecer una nueva clave SSH única. Cree una nueva política de IAM y adjúntela al rol de IAM de los ingenieros con una declaración Permitir para ejecutar documentos de Systems Manager. Indique a los ingenieros que ejecuten el documento para establecer una clave SSH y conectarse a través de cualquier cliente SSH.
C.
Inicie nuevas instancias EC2 sin configurar ninguna clave SSH para las instancias. Configure EC2 Instance Connect en cada instancia. Cree una nueva política de IAM y adjúntela al rol de IAM de los ingenieros con una declaración Permitir para la acción SendsShPublicKey. Indique a los ingenieros que se conecten a la instancia mediante un cliente SSH basado en navegador desde la consola EC2.
D.
Configure AWS Secrets Manager para almacenar la clave SSH EC2. Cree una nueva función de AWS Lambda para crear una nueva clave SSH y llamar a AWS Systems Manager Session Manager para establecer la clave SSH en la instancia EC2. Configure Secrets Manager para usar la función Lambda para la rotación automática una vez al día. Indique a los ingenieros que obtengan la clave SSH de Secrets Manager cuando se conecten a través de cualquier cliente SSH.
AnswerDiscussion
Correct Answer: C
Para cumplir con los requisitos, lance nuevas instancias EC2 sin configurar ninguna clave SSH para las instancias. Configure EC2 Instance Connect en cada instancia, lo que facilita el uso de claves SSH temporales únicas para cada conexión. Al crear una nueva política de IAM y adjuntarla al rol de IAM de los ingenieros con una declaración Allow para la acción SendsShPublicKey, los ingenieros pueden conectarse a las instancias usando un cliente SSH basado en navegador desde la consola EC2. Esto garantiza el cumplimiento de la política de no reutilizar claves SSH y permite que todas las conexiones se registren en AWS CloudTrail.
Question 322 of 529
Una empresa está migrando aplicaciones de banca móvil para que se ejecuten en instancias de Amazon EC2 en una VPC. Las aplicaciones de servicio backend se ejecutan en un centro de datos local. El centro de datos tiene una conexión AWS Direct Connect en AWS. Las aplicaciones que se ejecutan en la VPC necesitan resolver las solicitudes DNS a un dominio de Active Directory local que se ejecute en el centro de datos.
Qué solución cumplirá estos requisitos con la menor sobrecarga administrativa?
A.
Aprovisione un conjunto de instancias EC2 en dos zonas de disponibilidad en la VPC como servidores DNS de almacenamiento en caché para resolver las consultas DNS de los servidores de aplicaciones dentro de la VPC.
B.
Aprovisione una zona hospedada privada Amazon Route 53. Configure registros NS que apunten a servidores DNS locales.
C.
Cree endpoints DNS mediante Amazon Route 53 Resolver. Agregue reglas de reenvío condicional para resolver los espacios de nombres DNS entre el centro de datos local y la VPC.
D.
Aprovisione un nuevo controlador de dominio de Active Directory en la VPC con una confianza bidireccional entre este nuevo dominio y el dominio de Active Directory local.
AnswerDiscussion
Correct Answer: C
La solución que cumple los requisitos con la menor sobrecarga administrativa es crear endpoints DNS mediante Amazon Route 53 Resolver y agregar reglas de reenvío condicional para resolver los espacios de nombres DNS entre el centro de datos local y la VPC. Este método aprovecha los servicios administrados por AWS, lo que reduce la necesidad de administración manual de infraestructura y configuraciones complejas. Permite el reenvío continuo de consultas DNS entre el dominio de Active Directory local y las aplicaciones de VPC, minimizando la sobrecarga administrativa en comparación con otras opciones como aprovisionar instancias EC2 o un nuevo controlador de dominio de Active Directory.
Question 323 of 529
Una empresa procesa datos ambientales. La compañía ha configurado sensores para proporcionar un flujo continuo de datos desde diferentes áreas de una ciudad. Los datos están disponibles en formato JSON.
La compañía quiere utilizar una solución de AWS para enviar los datos a una base de datos que no requiera esquemas fijos para su almacenamiento. Los datos deben ser enviados en tiempo real.
Qué solución cumplirá con estos requisitos?
A.
Utilice Amazon Kinesis Data Firehose para enviar los datos a Amazon Redshift.
B.
Utilice Amazon Kinesis Data Flujos para enviar los datos a Amazon DynamoDB.
C.
Utilice Amazon Managed Streaming para Apache Kafka (Amazon MSK) para enviar los datos a Amazon Aurora.
D.
Utilice Amazon Kinesis Data Firehose para enviar los datos a Amazon Keyspaces (para Apache Cassandra).
AnswerDiscussion
Correct Answer: B
Para cumplir con el requisito de enviar datos ambientales en tiempo real a una base de datos que no requiera esquemas fijos, la mejor solución es utilizar Amazon Kinesis Data Flow para enviar los datos a Amazon DynamoDB. Amazon Kinesis Data Flujos está diseñado para capturar y procesar datos en tiempo real, y Amazon DynamoDB es una base de datos NoSQL que permite flexibilidad en el esquema de datos, por lo que es ideal para almacenar datos en formato JSON sin esquemas fijos.
Question 324 of 529
Una empresa está migrando una aplicación heredada de un centro de datos local a AWS. La aplicación utiliza MongoDB como base de datos clave-valor. De acuerdo con las directrices técnicas de la compañía, todas las instancias de Amazon EC2 deben estar alojadas en una subred privada sin conexión a Internet. Además, toda la conectividad entre aplicaciones y bases de datos debe estar encriptada. La base de datos debe poder escalar en función de la demanda.
Qué solución cumplirá con estos requisitos?
A.
Cree nuevas tablas de Amazon DocumentDB (con compatibilidad con MongoDB) para la aplicación con volúmenes de IOPS aprovisionadas. Utilice el punto final de la instancia para conectarse a Amazon DocumentDB.
B.
Cree nuevas tablas de Amazon DynamoDB para la aplicación con capacidad bajo demanda. Utilice un punto final de VPC de puerta de enlace para DynamoDB para conectarse a las tablas de DynamoDB.
C.
Cree nuevas tablas de Amazon DynamoDB para la aplicación con capacidad bajo demanda. Utilice un punto de enlace de VPC de interfaz para DynamoDB para conectarse a las tablas de DynamoDB.
D.
Cree nuevas tablas de Amazon DocumentDB (con compatibilidad con MongoDB) para la aplicación con volúmenes de IOPS aprovisionadas. Utilice el punto final del clúster para conectarse a Amazon DocumentDB.
AnswerDiscussion
Correct Answer: B
La solución necesita involucrar una base de datos que pueda escalar según la demanda y garantizar que toda la conectividad entre aplicaciones y bases de datos esté encriptada mientras sea accesible sin una conexión a Internet. Amazon DynamoDB es una base de datos escalable de clave-valor adecuada para este uso y ofrece un modo de capacidad bajo demanda, que se ajusta automáticamente para adaptarse a las fluctuaciones de la carga de trabajo. Mediante el uso de un punto de enlace VPC para DynamoDB, podemos garantizar que las instancias EC2 en una subred privada puedan conectarse de forma segura a las tablas de DynamoDB sin necesidad de acceso a Internet. Esta configuración se alinea bien con las pautas técnicas de la compañía.
Question 325 of 529
Una empresa está ejecutando una aplicación en instancias de Amazon EC2 en la nube de AWS. La aplicación está utilizando una base de datos MongoDB con un conjunto de réplicas como su nivel de datos. La base de datos MongoDB está instalada en sistemas del centro de datos local de la compañía y es accesible a través de una conexión AWS Direct Connect al entorno del centro de datos.
Un arquitecto de soluciones debe migrar la base de datos MongoDB local a Amazon DocumentDB (con compatibilidad con MongoDB).
Qué estrategia debe elegir el arquitecto de soluciones para realizar esta migración?
A.
Cree una flota de instancias EC2. Instale MongoDB Community Edition en las instancias EC2 y cree una base de datos. Configure la replicación sincrónica continua con la base de datos que se está ejecutando en el centro de datos local.
B.
Cree una instancia de replicación de AWS Database Migration Service (AWS DMS). Cree un punto final de origen para la base de datos MongoDB local mediante la captura de datos de cambio (CDC). Cree un punto final de destino para la base de datos de Amazon DocumentDB. Crear y ejecutar una tarea de migración DMS.
C.
Cree una canalización de migración de datos mediante AWS Data Pipeline. Defina nodos de datos para la base de datos MongoDB local y la base de datos de Amazon DocumentDB. Cree una tarea programada para ejecutar la canalización de datos.
D.
Cree un punto final de origen para la base de datos MongoDB local mediante los rastreadores de AWS Glue. Configure la replicación asincrónica continua entre la base de datos MongoDB y la base de datos de Amazon DocumentDB.
AnswerDiscussion
Correct Answer: B
La estrategia más adecuada para migrar una base de datos MongoDB local a Amazon DocumentDB (con compatibilidad con MongoDB) es utilizar AWS Database Migration Service (AWS DMS). Al crear una instancia de replicación DMS y utilizar la tecnología de captura de datos de cambio (CDC), se pueden capturar y replicar con precisión los cambios en curso de la base de datos MongoDB de origen a la base de datos de Amazon DocumentDB de destino. Este enfoque garantiza una transición sin problemas con un tiempo de inactividad mínimo e integridad de los datos durante el proceso de migración.
Question 326 of 529
Una empresa está rediseñando sus aplicaciones para que se ejecuten en AWS. La infraestructura de la compañía incluye múltiples instancias de Amazon EC2. El equipo de desarrollo de la compañía necesita diferentes niveles de acceso. La compañía quiere implementar una política que requiera que todas las instancias de EC2 de Windows se unan a un dominio de Active Directory en AWS. La compañía también quiere implementar procesos de seguridad mejorados como la autenticación multifactor (MFA). La compañía quiere utilizar los servicios administrados de AWS siempre que sea posible.
Qué solución cumplirá con estos requisitos?
A.
Cree un servicio de directorio de AWS para la implementación de Microsoft Active Directory. Lanzar un espacio de trabajo de Amazon. Conéctese y use Workspace para tareas de configuración de seguridad de dominio.
B.
Cree un servicio de directorio de AWS para la implementación de Microsoft Active Directory. Lanzar una instancia EC2. Conéctese y utilice la instancia EC2 para las tareas de configuración de seguridad del dominio.
C.
Crear una implementación de AWS Directory Service Simple AD. Lanzar una instancia EC2. Conéctese y utilice la instancia EC2 para las tareas de configuración de seguridad del dominio.
D.
Crear una implementación de AWS Directory Service Simple AD. Lanzar un espacio de trabajo de Amazon. Conéctese y use Workspace para tareas de configuración de seguridad de dominio.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de tener todas las instancias EC2 de Windows unidas a un dominio de Active Directory en AWS, así como implementar la autenticación multifactor y utilizar los servicios administrados de AWS siempre que sea posible, la mejor solución es crear un servicio de directorio de AWS para la implementación de Microsoft Active Directory. El uso de Amazon WorkSpaces para tareas de configuración de seguridad de dominio es un servicio completamente administrado que proporciona un entorno de escritorio Windows en la nube de AWS, lo que facilita la administración y la seguridad en comparación con la configuración y configuración manual de una instancia EC2.
Question 327 of 529
Una empresa quiere migrar su aplicación local a AWS. La base de datos para la aplicación almacena datos estructurados de productos y datos temporales de sesión de usuario. La empresa necesita desacoplar los datos del producto de los datos de sesión del usuario. La compañía también necesita implementar replicación en otra región de AWS para la recuperación ante desastres.
Qué solución cumplirá estos requisitos con el MÁS ALTO rendimiento?
A.
Cree una instancia de base de datos de Amazon RDS con esquemas independientes para alojar los datos del producto y los datos de sesión del usuario. Configure una réplica de lectura para la instancia de base de datos en otra región.
B.
Cree una instancia de base de datos de Amazon RDS para alojar los datos del producto. Configure una réplica de lectura para la instancia de base de datos en otra región. Cree un almacén de datos global en Amazon ElastiCache para Memcached para alojar los datos de sesión del usuario.
C.
Cree dos tablas globales de Amazon DynamoDB. Utilice una tabla global para alojar los datos del producto. Utilice la otra tabla global para alojar los datos de sesión del usuario. Utilice DynamoDB Accelerator (DAX) para el almacenamiento en caché.
D.
Cree una instancia de base de datos de Amazon RDS para alojar los datos del producto. Configure una réplica de lectura para la instancia de base de datos en otra región. Cree una tabla global de Amazon DynamoDB para alojar los datos de sesión del usuario.
AnswerDiscussion
Correct Answer: B
Para lograr un alto rendimiento y satisfacer la necesidad de desacoplar los datos del producto de los datos de sesión del usuario, Amazon RDS para los datos de productos estructurados combinados con Amazon ElastiCache para Memcached para los datos de sesión de usuario proporciona una solución convincente. RDS es adecuado para datos estructurados debido a sus capacidades de modelo relacional, y ElastiCache se destaca en la administración de datos de sesión temporales con acceso de alta velocidad. Además, la configuración de RDS con una réplica de lectura en otra región garantiza la replicación entre regiones y, por lo tanto, la recuperación ante desastres. Esta configuración garantiza un alto rendimiento y tolerancia a fallas. Aunque la opción D proporciona una configuración similar, no aprovecha el almacenamiento en caché de alto rendimiento que ElastiCache ofrece para los datos de sesión. Por lo tanto, la opción B satisface mejor los requisitos. Si bien hay afirmaciones sobre el almacén de datos global en ElastiCache, debe tratarse con precaución, pero generalmente, ElastiCache sigue siendo eficiente para fines de almacenamiento en caché.
Question 328 of 529
Una empresa organiza una estructura multicuenta en AWS mediante el uso de AWS Control Tower. La compañía utiliza AWS Organizations, AWS Config y AWS Trusted Advisor. La compañía tiene una unidad organizativa específica para cuentas de desarrollo que los desarrolladores utilizan para experimentar en AWS. La compañía tiene cientos de desarrolladores, y cada desarrollador tiene una cuenta de desarrollo individual.
La compañía quiere optimizar costos en estas cuentas de desarrollo. Las instancias de Amazon EC2 y las instancias de Amazon RDS en estas cuentas deben ser de ráfagas. La empresa quiere no permitir el uso de otros servicios que no sean relevantes.
Qué debería recomendar un arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree un SCP personalizado en las organizaciones de AWS para permitir la implementación de solo instancias con ráfagas y para no permitir servicios que no sean relevantes. Aplicar el SCP a la OU de desarrollo.
B.
Cree un control de detective personalizado (barandilla) en AWS Control Tower. Configure el control (guardrail) para permitir el despliegue de solo instancias con ráfagas y para no permitir servicios que no sean relevantes. Aplicar el control (baranda) a la unidad organizativa de desarrollo.
C.
Cree un control preventivo personalizado (barandilla) en AWS Control Tower. Configure el control (guardrail) para permitir el despliegue de solo instancias con ráfagas y para no permitir servicios que no sean relevantes. Aplicar el control (baranda) a la unidad organizativa de desarrollo.
D.
Cree una regla de AWS Config en la cuenta de AWS Control Tower. Configure la regla de AWS Config para permitir la implementación de solo instancias con ráfagas y para no permitir servicios que no sean relevantes. Implemente la regla de AWS Config en la unidad organizativa de desarrollo mediante AWS CloudFormation StackSets.
AnswerDiscussion
Correct Answer: C
Para cumplir con el requisito de permitir solo instancias EC2 y RDS con ráfagas mientras no se permiten servicios irrelevantes en cuentas de desarrollo, un control preventivo personalizado (guardrail) en AWS Control Tower es la mejor opción. Los controles preventivos están destinados a hacer cumplir el cumplimiento mediante la prevención de acciones que no cumplan con los criterios especificados. Al configurar este control para permitir solo instancias burestables y aplicarlo a la unidad organizativa de desarrollo, la compañía puede garantizar que las restricciones deseadas se apliquen en todas las cuentas de desarrollo.
Question 329 of 529
Una compañía de servicios financieros ejecuta una aplicación compleja de varios niveles en instancias de Amazon EC2 y funciones de AWS Lambda. La aplicación almacena datos temporales en Amazon S3. Los objetos S3 son válidos por solo 45 minutos y se eliminan después de 24 horas.
La compañía implementa cada versión de la aplicación mediante el lanzamiento de una pila de AWS CloudFormation. La pila crea todos los recursos necesarios para ejecutar la aplicación. Cuando la compañía despliega y valida una nueva versión de la aplicación, la compañía elimina la pila de CloudFormation de la versión anterior.
La compañía intentó recientemente eliminar la pila de CloudFormation de una versión antigua de la aplicación, pero la operación falló. Un análisis muestra que CloudFormation no pudo eliminar un bucket S3 existente. Un arquitecto de soluciones necesita resolver este problema sin realizar cambios importantes en la arquitectura de la aplicación.
Qué solución cumple con estos requisitos?
A.
Implementar una función Lambda que elimine todos los archivos de un bucket S3 dado. Integre esta función Lambda como un recurso personalizado en la pila de CloudFormation. Asegúrese de que el recurso personalizado tenga un atributo DependSON que apunte al recurso del bucket S3.
B.
Modifique la plantilla de CloudFormation para aprovisionar un sistema de archivos de Amazon Elastic File System (Amazon EFS) para almacenar los archivos temporales allí en lugar de en Amazon S3. Configure las funciones de Lambda para que se ejecuten en la misma VPC que el sistema de archivos. Monte el sistema de archivos en las instancias EC2 y las funciones Lambda.
C.
Modifique la pila de ormación de CloudF para crear una regla de ciclo de vida de S3 que caduque todos los objetos 45 minutos después de la creación. Agregue un atributo DependSON que apunte al recurso del bucket S3.
D.
Modifique la pila de CloudFormation para adjuntar un atributo DeletionPolicy con el valor Delete al bucket S3.
AnswerDiscussion
Correct Answer: A
Para eliminar un bucket S3 correctamente en una pila de CloudFormation, el bucket debe estar vacío. La solución más efectiva es usar una función Lambda que limpie el contenido del bucket antes de su eliminación. Este enfoque garantiza que el bucket S3 se pueda eliminar sin realizar cambios significativos en la arquitectura de la aplicación. Integrar esta función Lambda como un recurso personalizado en la pila de CloudFormation y establecer el atributo DependSON para que apunte al recurso del bucket S3 garantiza la secuenciación adecuada de los pasos de eliminación, permitiendo que la función borre el bucket antes de que la pila intente eliminarlo.
Question 330 of 529
Una empresa ha desarrollado un juego para móviles. El backend del juego se ejecuta en varias máquinas virtuales ubicadas en un centro de datos local. La lógica de negocio se expone usando una API REST con múltiples funciones. Los datos de la sesión del jugador se almacenan en el almacenamiento central de archivos. Los servicios backend utilizan diferentes claves API para limitar y distinguir entre el tráfico en vivo y el de prueba.
La carga en el backend del juego varía a lo largo del día. Durante las horas pico, la capacidad del servidor no es suficiente. También hay problemas de latencia al obtener datos de sesión del jugador. La administración ha pedido a un arquitecto de soluciones que presente una arquitectura en la nube que pueda manejar la carga variable del juego y proporcionar acceso a datos de baja latencia. No se debe cambiar el modelo de API.
Qué solución cumple con estos requisitos?
A.
Implemente la API REST usando un balanceador de carga de red (NLB). Ejecute la lógica de negocio en una instancia de Amazon EC2 detrás del NLB. Almacene los datos de la sesión del reproductor en Amazon Aurora Serverless.
B.
Implemente la API REST usando un balanceador de carga de aplicaciones (ALB). Ejecute la lógica de negocio en AWS Lambda. Almacene los datos de la sesión del reproductor en Amazon DynamoDB con capacidad bajo demanda.
C.
Implemente la API REST mediante Amazon API Gateway. Ejecute la lógica de negocio en AWS Lambda. Almacene los datos de la sesión del reproductor en Amazon DynamoDB con capacidad bajo demanda.
D.
Implemente la API REST mediante AWS AppSync. Ejecute la lógica de negocio en AWS Lambda. Almacene los datos de la sesión del reproductor en Amazon Aurora Serverless.
AnswerDiscussion
Correct Answer: C
Para manejar la carga variable del juego y garantizar el acceso a los datos de baja latencia, usar Amazon API Gateway para implementar la API REST es una opción óptima, ya que puede administrar de manera eficiente las cargas fluctuantes y escalar automáticamente. Ejecutar la lógica de negocio en AWS Lambda es adecuado porque Lambda escala automáticamente con la carga y elimina la necesidad de administración de servidores. El almacenamiento de datos de sesión del reproductor en Amazon DynamoDB con capacidad bajo demanda garantiza un acceso de baja latencia y puede manejar altas tasas de solicitud sin intervención manual, lo que hace que la arquitectura sea más resistente y responda a los picos de tráfico.
Question 331 of 529
Una empresa está migrando una aplicación a la nube de AWS. La aplicación se ejecuta en un centro de datos local y escribe miles de imágenes en un sistema de archivos NFS montado cada noche. Después de que la compañía migre la aplicación, la compañía alojará la aplicación en una instancia de Amazon EC2 con un sistema de archivos Amazon Elastic File System (Amazon EFS) montado.
La compañía ha establecido una conexión AWS Direct Connect con AWS. Antes del cambio de transición de migración, un arquitecto de soluciones debe crear un proceso que replique las imágenes locales recién creadas en el sistema de archivos EFS.
Cuál es la manera más eficiente operacionalmente de replicar las imágenes?
A.
Configure un proceso periódico para ejecutar el comando aws s3 sync desde el sistema de archivos local a Amazon S3. Configure una función de AWS Lambda para procesar notificaciones de eventos de Amazon S3 y copiar las imágenes de Amazon S3 al sistema de archivos EFS.
B.
Implemente una puerta de enlace de archivos de AWS Storage Gateway con un punto de montaje NFS. Monte el sistema de archivos de puerta de enlace de archivos en el servidor local. Configure un proceso para copiar periódicamente las imágenes al punto de montaje.
C.
Implemente un agente AWS DataSync en un servidor local que tenga acceso al sistema de archivos NFS. Envíe datos a través de la conexión Direct Connect a un bucket S3 mediante un VIF público. Configure una función de AWS Lambda para procesar notificaciones de eventos de Amazon S3 y copiar las imágenes de Amazon S3 al sistema de archivos EFS.
D.
Implemente un agente AWS DataSync en un servidor local que tenga acceso al sistema de archivos NFS. Envíe datos a través de la conexión Direct Connect a un punto de enlace de VPC de la interfaz AWS PrivateLink para Amazon EFS mediante un VIF privado. Configure una tarea programada de DataSync para enviar las imágenes al sistema de archivos EFS cada 24 horas.
AnswerDiscussion
Correct Answer: D
La forma más eficiente desde el punto de vista operativo de replicar imágenes desde un sistema de archivos NFS local a un sistema de archivos de Amazon EFS es implementar un agente AWS DataSync en un servidor local que tenga acceso al sistema de archivos NFS. DataSync está diseñado específicamente para automatizar la transferencia de grandes cantidades de datos entre el almacenamiento local y los servicios de almacenamiento de AWS, como EFS. Al utilizar DataSync a través de la conexión AWS Direct Connect, puede aprovechar un enlace de red privado y de gran ancho de banda, lo que garantiza una transferencia de datos segura y eficiente. La configuración de una tarea programada de DataSync para enviar las imágenes directamente al sistema de archivos EFS cada 24 horas simplifica el proceso y reduce la necesidad de almacenamiento intermedio o pasos de procesamiento adicionales. Este método proporciona una solución sencilla, eficiente y confiable para la tarea de replicación de datos.
Question 332 of 529
Una empresa migró recientemente una aplicación web de un centro de datos local a la nube de AWS. La infraestructura de aplicaciones web consiste en una distribución de Amazon CloudFront que se dirige a un balanceador de carga de aplicaciones (ALB), con Amazon Elastic Container Service (Amazon ECS) para procesar solicitudes. Una auditoría de seguridad reciente reveló que la aplicación web es accesible mediante el uso de puntos finales de CloudFront y ALB. Sin embargo, la compañía requiere que la aplicación web sea accesible solo mediante el uso del punto final de CloudFront.
Qué solución cumplirá con este requisito con la MENOR cantidad de esfuerzo?
A.
Cree un nuevo grupo de seguridad y adjúntelo a la distribución de CloudFront. Actualice la entrada del grupo de seguridad ALB para permitir el acceso solo desde el grupo de seguridad de CloudFront.
B.
Actualice la entrada del grupo de seguridad ALB para permitir el acceso solo desde la lista de prefijos administrados de CloudFront com.amazonaws.global.cloudfront.origin-facing.
C.
Cree un punto final de interfaz de VPC com.amazonaws.region.elasticloadbalancing para Elastic Load Balancing. Actualizar el esquema ALB de internet a interno.
D.
Extraiga las IPs de CloudFront del documento ip-ranges.json proporcionado por AWS. Actualice la entrada de grupos de seguridad ALB para permitir el acceso solo desde las IPs de CloudFront.
AnswerDiscussion
Correct Answer: B
Para restringir el acceso a la aplicación web de manera que solo sea accesible a través del endpoint de CloudFront, la solución más simple y efectiva consiste en actualizar las reglas de ingreso del grupo de seguridad ALB. Al permitir el acceso solo desde la lista de prefijos administrados de CloudFront (com.amazonaws.global.cloudfront.origin-facing), puede asegurarse de que las solicitudes que llegan al ALB sean exclusivamente aquellas reenviadas desde CloudFront. Este método es sencillo y requiere un mínimo esfuerzo en comparación con otras opciones, que implican configuraciones más complejas o actualizaciones manuales.
Question 333 of 529
Una empresa aloja un sitio de foro de la comunidad mediante un balanceador de carga de aplicaciones (ALB) y una aplicación Docker alojada en un clúster de Amazon ECS. Los datos del sitio se almacenan en Amazon RDS para MySQL y la imagen del contenedor se almacena en ECR. La compañía necesita proporcionar a sus clientes un SLA de recuperación ante desastres con un RTO de no más de 24 horas y RPO de no más de 8 horas.
Cuál de las siguientes soluciones es la forma MÁS rentable de cumplir con los requisitos?
A.
Utilice AWS CloudFormation para implementar recursos idénticos de ALB, EC2, ECS y RDS en dos regiones. Programe instantáneas de RDS cada 8 horas. Utilice la replicación multirregional de RDS para actualizar la copia de la base de datos de la región secundaria. En caso de falla, restaure desde la última instantánea y use una política de conmutación por error de DNS de Amazon Route 53 para redirigir automáticamente a los clientes al ALB en la región secundaria.
B.
Almacene la imagen Docker en ECR en dos regiones. Programe instantáneas de RDS cada 8 horas con instantáneas copiadas en la región secundaria. En caso de falla, use AWS CloudFormation para implementar los recursos ALB, EC2, ECS y RDS en la región secundaria, restaure desde la última instantánea y actualice el registro DNS para que apunte al ALB en la región secundaria.
C.
Utilice AWS CloudFormation para implementar recursos idénticos de ALB, EC2, ECS y RDS en una región secundaria. Programe backups de RDS MySQL por hora en Amazon S3 y utilice la replicación entre regiones para replicar datos en un bucket en la región secundaria. En caso de que se produzca un error, importe la última imagen de Docker a Amazon ECR en la región secundaria, implemente en la instancia EC2, restaure la última copia de seguridad de MySQL y actualice el registro DNS para que apunte al ALB en la región secundaria.
D.
Implemente un entorno piloto ligero en una región secundaria con un ALB y una implementación mínima de EC2 de recursos para Docker en un grupo de AWS Auto Scaling con una política de escalado para aumentar el tamaño de la instancia y el número de nodos. Cree una réplica de lectura entre regiones de los datos RDS. En caso de falla, promueva la réplica a primaria y actualice el registro DNS para que apunte al ALB en la región secundaria.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos de un RTO de 24 horas y un RPO de 8 horas de la manera más rentable, implementar un entorno de luz piloto es ideal. Esto implica mantener los recursos mínimos funcionando en todo momento en una región secundaria, lo que mantiene bajos los costos al tiempo que garantiza una recuperación rápida. El entorno de luz piloto incluye un ALB y una configuración mínima de EC2 que se puede escalar rápidamente. El uso de una réplica de lectura entre regiones para los datos RDS garantiza que los datos se mantengan actualizados dentro del RPO de 8 horas. En caso de falla, la réplica de lectura puede promoverse a primaria, y el registro DNS se puede actualizar para que apunte al ALB en la región secundaria, asegurando que la recuperación se pueda completar dentro del RTO de 24 horas.
Question 334 of 529
Una empresa está migrando su infraestructura a la nube de AWS. La compañía debe cumplir con una variedad de estándares regulatorios para diferentes proyectos. La empresa necesita un entorno multicuenta.
Un arquitecto de soluciones necesita preparar la infraestructura de línea base. La solución debe proporcionar una línea de base consistente de administración y seguridad, pero debe permitir flexibilidad para diferentes requisitos de cumplimiento dentro de varias cuentas de AWS. La solución también necesita integrarse con el servidor local existente de Active Directory Federation Services (AD FS).
Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Crear una organización en AWS Organizations. Cree un SCP único para el acceso mínimo de privilegios en todas las cuentas. Cree una unidad organizativa única para todas las cuentas. Configure un proveedor de identidades de IAM para la federación con el servidor local de AD FS. Configure una cuenta de registro central con un proceso definido para los servicios de generación de registros para enviar eventos de registro a la cuenta central. Habilite AWS Config en la cuenta central con paquetes de conformidad para todas las cuentas.
B.
Crear una organización en AWS Organizations. Habilite AWS Control Tower en la organización. Revisar los controles incluidos (barandas) para SCP. Consulte AWS Config para ver las áreas que requieren adiciones. Agregue las OU según sea necesario. Conecte AWS IAM Identity Center (AWS Single Sign-On) al servidor local de AD FS.
C.
Crear una organización en AWS Organizations. Cree SCP para el acceso de menor privilegio. Cree una estructura de unidad organizativa y utilícela para agrupar cuentas de AWS. Conecte AWS IAM Identity Center (AWS Single Sign-On) al servidor local de AD FS. Configure una cuenta de registro central con un proceso definido para los servicios de generación de registros para enviar eventos de registro a la cuenta central. Habilite AWS Config en la cuenta central con agregadores y paquetes de conformidad.
D.
Crear una organización en AWS Organizations. Habilite AWS Control Tower en la organización. Revisar los controles incluidos (barandas) para SCP. Consulte AWS Config para ver las áreas que requieren adiciones. Configure un proveedor de identidades de IAM para la federación con el servidor local de AD FS.
AnswerDiscussion
Correct Answer: B
La solución que proporciona la menor cantidad de gastos operativos mientras cumple con los requisitos de la compañía es crear una organización en AWS Organizations, habilitar AWS Control Tower y conectar AWS IAM Identity Center al servidor local de AD FS. AWS Control Tower automatiza la configuración de un entorno multicuenta e incluye planes de mejores prácticas para la gobernanza, lo que reduce la configuración manual y garantiza la coherencia. IAM Identity Center proporciona una integración perfecta para la autenticación y autorización de la fuerza de trabajo con el AD FS existente. Este enfoque garantiza una línea de base consistente de administración y seguridad, al tiempo que permite la flexibilidad necesaria en varias cuentas de AWS.
Question 335 of 529
Una revista en línea lanzará su última edición este mes. Esta edición será la primera que se distribuirá globalmente. El sitio web dinámico de la revista utiliza actualmente un balanceador de carga de aplicaciones frente al nivel web, una flota de instancias de Amazon EC2 para servidores web y de aplicaciones y Amazon Aurora MySQL. Algunas partes del sitio web incluyen contenido estático y casi todo el tráfico es de solo lectura.
La revista espera un repunte significativo en el tráfico de internet cuando se lance la nueva edición. El rendimiento óptimo es una prioridad máxima para la semana siguiente al lanzamiento.
Qué combinación de pasos debe tomar un arquitecto de soluciones para reducir los tiempos de respuesta del sistema para una audiencia global? (Elija dos.)
A.
Utilice la replicación lógica entre regiones para replicar la base de datos Aurora MySQL en una región secundaria. Reemplace los servidores web por Amazon S3. Implemente buckets S3 en modo de replicación entre regiones.
B.
Asegúrese de que los niveles web y de aplicaciones estén en grupos de Auto Scaling. Introducir una conexión AWS Direct Connect. Despliegue los niveles web y de aplicaciones en Regions de todo el mundo.
C.
Migre la base de datos de Amazon Aurora a Amazon RDS para MySQL. Asegúrese de que los tres niveles de aplicación (web, aplicación y base de datos) estén en subredes privadas.
D.
Utilice una base de datos global de Aurora para la replicación física entre regiones. Utilice Amazon S3 con replicación entre regiones para contenido estático y recursos. Despliegue los niveles web y de aplicaciones en Regions de todo el mundo.
E.
Presente Amazon Route 53 con enrutamiento basado en latencia y distribuciones de Amazon CloudFront. Asegúrese de que los niveles web y de aplicaciones estén en grupos de Auto Scaling.
AnswerDiscussion
Correct Answer: D, E
Para reducir los tiempos de respuesta del sistema para una audiencia global y garantizar un rendimiento óptimo durante el lanzamiento, el uso de una base de datos global Aurora para la replicación física entre regiones permite un acceso más rápido a los datos en diferentes regiones. Además, la implementación de Amazon S3 con replicación entre regiones garantiza que el contenido estático se entregue rápidamente independientemente de la ubicación geográfica del usuario. La introducción de Amazon Route 53 con enrutamiento basado en latencia ayuda a dirigir a los usuarios a la implementación más cercana, reduciendo la latencia, mientras que las distribuciones de Amazon CloudFront proporcionan una entrega más rápida de contenido estático y dinámico a través de ubicaciones de borde. Asegurar que los niveles web y de aplicaciones estén cada uno en los grupos de Auto Scaling permite a la infraestructura manejar diferentes niveles de carga de manera eficiente.
Question 336 of 529
Una compañía de juegos en línea necesita optimizar el costo de sus cargas de trabajo en AWS. La compañía utiliza una cuenta dedicada para alojar el entorno de producción para su aplicación de juegos en línea y una aplicación de análisis.
Las instancias de Amazon EC2 alojan la aplicación de juegos y siempre deben estar disponibles. Las instancias EC2 se ejecutan todo el año. La aplicación de análisis utiliza datos que se almacenan en Amazon S3. La aplicación de análisis puede interrumpirse y reanudarse sin problemas.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Adquiera un plan de ahorro de instancias EC2 para las instancias de aplicaciones de juegos en línea. Utilice Instancias bajo demanda para la aplicación de análisis.
B.
Adquiera un plan de ahorro de instancias EC2 para las instancias de aplicaciones de juegos en línea. Utilice Instancias puntuales para la aplicación de análisis.
C.
Use instancias puntuales para la aplicación de juegos en línea y la aplicación de análisis. Configure un catálogo en AWS Service Catalog para proporcionar servicios con descuento.
D.
Use Instancias bajo demanda para la aplicación de juegos en línea. Utilice Instancias puntuales para la aplicación de análisis. Configure un catálogo en AWS Service Catalog para proporcionar servicios con descuento.
AnswerDiscussion
Correct Answer: B
Para optimizar los costos y garantizar la confiabilidad para el entorno de producción de la aplicación de juegos en línea, se debe usar un Plan de Ahorro de Instancia EC2 para las instancias de aplicaciones de juego. Esto garantiza que estas instancias, que deben ejecutarse todo el año y estar disponibles continuamente, estén cubiertas a un costo reducido en comparación con los precios bajo demanda. Para la aplicación de análisis, que puede interrumpirse y reanudarse sin problemas, las instancias puntuales son la solución más rentable. Las instancias puntuales le permiten aprovechar la capacidad EC2 no utilizada a precios significativamente reducidos. Esta combinación satisface los requisitos de manera más rentable.
Question 337 of 529
Una empresa ejecuta aplicaciones en cientos de cuentas de producción de AWS. La compañía utiliza AWS Organizations con todas las funciones habilitadas y tiene una operación de backup centralizada que utiliza AWS Backup.
A la compañía le preocupan los ataques de ransomware. Para abordar esta preocupación, la compañía ha creado una nueva política de que todas las copias de seguridad deben ser resistentes a las violaciones de credenciales de usuario privilegiado en cualquier cuenta de producción.
Qué combinación de pasos cumplirá con este nuevo requisito? (Elija tres.)
A.
Implemente copias de seguridad entre cuentas con bóvedas de AWS Backup en cuentas designadas que no sean de producción.
B.
Agregue un SCP que restrinja la modificación de las bóvedas de AWS Backup.
C.
Implemente AWS Backup Vault Lock en modo de cumplimiento.
C. Implementar el acceso con privilegios mínimos para la función de servicio de IAM asignada a AWS Backup.
D.
Configure la frecuencia, el ciclo de vida y el período de retención del backup para garantizar que siempre exista al menos una copia de seguridad en el nivel frío.
E.
Configure AWS Backup para escribir todas las copias de seguridad en un bucket de Amazon S3 en una cuenta de no producción designada. Asegúrese de que el bucket S3 tenga activado el bloqueo de objetos S3.
AnswerDiscussion
Correct Answer: A, B, C
Para garantizar que los backups sean resistentes a las violaciones de credenciales de usuario privilegiado, implemente backups entre cuentas con bóvedas de AWS Backup en cuentas designadas que no sean de producción para aislar los backups de posibles brechas. Agregar una política de control de servicios (SCP) que restringe la modificación de las bóvedas de AWS Backup mejora la seguridad al evitar cambios no autorizados. La implementación de AWS Backup Vault Lock en modo de cumplimiento garantiza que las copias de seguridad no se puedan modificar o eliminar durante su período de retención, lo que proporciona protección adicional contra credenciales comprometidas.
Question 338 of 529
Una empresa necesita agregar los registros de Amazon CloudWatch de sus cuentas de AWS en una cuenta central de registro. Los registros recopilados deben permanecer en la región de creación de AWS. La cuenta central de registro procesará los registros, normalizará los registros en formato de salida estándar y transmitirá los registros de salida a una herramienta de seguridad para un mayor procesamiento.
Un arquitecto de soluciones debe diseñar una solución que pueda manejar un gran volumen de datos de registro que necesitan ser ingeridos. Se producirá menos tala fuera del horario comercial normal que durante el horario comercial normal. La solución de registro debe escalar con la carga anticipada. El arquitecto de soluciones ha decidido utilizar un diseño de la torre de control de AWS para manejar el proceso de registro multicuenta.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con los requisitos? (Elija tres.)
A.
Cree un flujo de datos de Amazon Kinesis de destino en la cuenta de registro central.
B.
Cree una cola de Amazon Simple Queue Service (Amazon SQS) de destino en la cuenta de registro central.
C.
Cree una función de IAM que otorgue a Amazon CloudWatch Logs el permiso para agregar datos a la transmisión de datos de Amazon Kinesis. Crear una política de confianza. Especifique la política de confianza en el rol de IAM. En cada cuenta de miembro, cree un filtro de suscripción para cada grupo de registro para enviar datos al flujo de datos de Kinesis.
D.
Cree una función de IAM que otorgue a Amazon CloudWatch Logs el permiso para agregar datos a la cola de Amazon Simple Queue Service (Amazon SQS). Crear una política de confianza. Especifique la política de confianza en el rol de IAM. En cada cuenta de miembro, cree un único filtro de suscripción para que todos los grupos de registro envíen datos a la cola SQS.
E.
Cree una función de AWS Lambda. Programe la función Lambda para normalizar los registros en la cuenta de registro central y escribir los registros en la herramienta de seguridad.
F.
Cree una función de AWS Lambda. Programe la función Lambda para normalizar los registros en las cuentas de los miembros y escribir los registros en la herramienta de seguridad.
AnswerDiscussion
Correct Answer: A, C, E
Para agregar registros de Amazon CloudWatch desde varias cuentas de AWS, es eficiente usar Amazon Kinesis Data streams como destino en la cuenta de registro central porque puede manejar grandes volúmenes de datos y permite el procesamiento en tiempo real. La creación de un rol de IAM que otorgue permiso a CloudWatch Logs para agregar datos al flujo de datos de Kinesis con el filtro de suscripción adecuado garantiza que los registros se enruten correctamente desde las cuentas de miembro. Una función de AWS Lambda programada dentro de la cuenta de registro central normalizará estos registros y los reenviará a la herramienta de seguridad, cumpliendo con los requisitos de procesamiento y transmisión de datos.
Question 339 of 529
Una empresa está migrando una aplicación heredada de un centro de datos local a AWS. La aplicación consiste en un único servidor de aplicaciones y un servidor de base de datos Microsoft SQL Server. Cada servidor se implementa en una máquina virtual VMware que consume 500 TB de datos en múltiples volúmenes conectados.
La compañía ha establecido una conexión AWS Direct Connect de 10 Gbps desde la región de AWS más cercana a su centro de datos local. La conexión Direct Connect no está siendo utilizada actualmente por otros servicios.
Qué combinación de pasos debe tomar un arquitecto de soluciones para migrar la aplicación con la MENOR cantidad de tiempo de inactividad? (Elija dos.)
A.
Utilice un trabajo de replicación de AWS Server Migration Service (AWS SMS) para migrar la máquina virtual del servidor de base de datos a AWS.
B.
Utilice VM Import/Export para importar la VM del servidor de aplicaciones.
C.
Exporte las imágenes de VM a un dispositivo AWS Snowball Edge Storage Optimized.
D.
Utilice un trabajo de replicación de AWS Server Migration Service (AWS SMS) para migrar la máquina virtual del servidor de aplicaciones a AWS.
E.
Utilice una instancia de replicación de AWS Database Migration Service (AWS DMS) para migrar la base de datos a una instancia de base de datos de Amazon RDS.
AnswerDiscussion
Correct Answer: D, E
Para migrar la aplicación con la menor cantidad de tiempo de inactividad, el arquitecto de la solución debe usar AWS Server Migration Service (AWS SMS) para migrar la máquina virtual del servidor de aplicaciones y AWS Database Migration Service (AWS DMS) para migrar la base de datos a una instancia de base de datos de Amazon RDS. AWS SMS permite la replicación automatizada e incremental de las máquinas virtuales en la nube, minimizando el tiempo de inactividad durante el proceso de transición. AWS DMS proporciona replicación continua y está diseñado específicamente para migrar bases de datos con un tiempo de inactividad mínimo. Esta combinación garantiza que tanto el servidor de aplicaciones como el servidor de base de datos se migren de manera eficiente y oportuna, lo que reduce la cantidad de tiempo de inactividad experimentado durante la migración.
Question 340 of 529
Una compañía opera una flota de servidores en las instalaciones y opera una flota de instancias de Amazon EC2 en su organización en organizaciones de AWS. Las cuentas de AWS de la compañía contienen cientos de VPC. La compañía quiere conectar sus cuentas de AWS a su red local. Las conexiones VPN de sitio a sitio de AWS ya están establecidas en una sola cuenta de AWS. La compañía quiere controlar qué VPC pueden comunicarse con otras VPC.
Qué combinación de pasos logrará este nivel de control con el MENOR esfuerzo operativo? (Elija tres.)
A.
Cree una puerta de enlace de tránsito en una cuenta de AWS. Comparta la puerta de enlace de tránsito entre cuentas mediante AWS Resource Access Manager (AWS RAM).
B.
Configure los archivos adjuntos a todas las VPC y VPNs.
C.
Configurar tablas de rutas de puerta de enlace de tránsito. Asocie las VPC y VPNs con las tablas de ruta.
D.
Configure la vinculación de VPC entre las VPC.
E.
Configure los archivos adjuntos entre las VPC y las VPN.
F.
Configurar tablas de ruta en las VPC y VPNs.
AnswerDiscussion
Correct Answer: A, B, C
Para lograr el control sobre la comunicación de VPC con el menor esfuerzo operativo, es necesaria la siguiente combinación de pasos: Primero, cree una puerta de enlace de tránsito en una cuenta de AWS y compártala entre cuentas usando AWS Resource Access Manager (AWS RAM). Esto permite un control centralizado sobre la conectividad de red. En segundo lugar, configure los adjuntos a todas las VPC y VPN, lo que implica conectar cada VPC y VPN a la puerta de enlace de tránsito, permitiendo así la conectividad a través de la puerta de enlace. Por último, configure tablas de rutas de puerta de enlace de tránsito y asocie las VPC y VPN con las tablas de ruta, lo que permitirá un control detallado sobre el enrutamiento entre diferentes VPC y la red local. Esta configuración evita la necesidad de arreglos complejos de interconexión de VPC y actualizaciones manuales de tablas de rutas en VPC individuales.
Question 341 of 529
Una empresa necesita optimizar el costo de su aplicación en AWS. La aplicación utiliza funciones de AWS Lambda y contenedores de Amazon Elastic Container Service (Amazon ECS) que se ejecutan en AWS Fargate. La aplicación es de escritura pesada y almacena datos en una base de datos MySQL de Amazon Aurora.
La carga en la aplicación no es consistente. La aplicación experimenta largos periodos sin uso, seguidos de aumentos y disminuciones repentinos y significativos en el tráfico. La base de datos se ejecuta en una instancia de base de datos optimizada para memoria que no puede manejar la carga.
Un arquitecto de soluciones debe diseñar una solución que pueda escalar para manejar los cambios en el tráfico.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Agregar réplicas de lectura adicionales a la base de datos. Compra de Planes de Ahorro de Instancias e Instancias Reservadas RDS.
B.
Migre la base de datos a un clúster de base de datos Aurora que tenga varias instancias de escritor. Planes de Ahorro de Instancias de Compra.
C.
Migrar la base de datos a una base de datos global Aurora. Compra Planes de Ahorro de Computación e instancias reservadas RDS.
D.
Migrar la base de datos a Aurora Serverless v1. Compra Planes de Ahorro de Cómputos.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos de manejar aumentos y disminuciones repentinos y significativos en el tráfico de manera rentable, migrar la base de datos a Aurora Serverless v1 es la mejor solución. Aurora Serverless v1 está diseñado para escalar automáticamente los recursos de la base de datos hacia arriba o hacia abajo según la demanda de la aplicación, eliminando la necesidad de administrar manualmente la capacidad de la base de datos. Esto lo convierte en una opción rentable para cargas de trabajo con patrones de tráfico variables, lo que garantiza que solo pague por los recursos que usa. Además, la compra de planes de ahorro de cómputos optimiza aún más los costos al ofrecer ahorros en una cantidad consistente de uso de cómputos, incluso si cambian las instancias específicas.
Question 342 of 529
Una empresa migró una aplicación a la nube de AWS. La aplicación se ejecuta en dos instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB).
Los datos de la aplicación se almacenan en una base de datos MySQL que se ejecuta en una instancia EC2 adicional. El uso de la base de datos por parte de la aplicación es de lectura pesada.
La aplicación carga contenido estático de los volúmenes de Amazon Elastic Block Store (Amazon EBS) que se adjuntan a cada instancia EC2. El contenido estático se actualiza con frecuencia y debe copiarse en cada volumen de EBS.
La carga en la aplicación cambia a lo largo del día. Durante las horas pico, la aplicación no puede manejar todas las solicitudes entrantes. Los datos de rastreo muestran que la base de datos no puede manejar la carga de lectura durante las horas pico.
Qué solución mejorará la confiabilidad de la aplicación?
A.
Migre la aplicación a un conjunto de funciones de AWS Lambda. Establezca las funciones Lambda como objetivos para el ALB. Cree un nuevo volumen único de EBS para el contenido estático. Configure las funciones de Lambda para leer del nuevo volumen de EBS. Migre la base de datos a un clúster de base de datos Multi-AZ de Amazon RDS para MySQL.
B.
Migre la aplicación a un conjunto de máquinas de estado de AWS Step Functions. Establezca las máquinas de estado como destinos para el sistema de archivos ALCrear un sistema de archivos Amazon Elastic File System (Amazon EFS) para el contenido estático. Configure las máquinas de estado para leer desde el sistema de archivos EFS. Migre la base de datos a Amazon Aurora MySQL Serverless v2 con una instancia de base de datos lectora.
C.
Contenerizar la aplicación. Migre la aplicación a un clúster de Amazon Elastic Container Service (Amazon ECS). Utilice el tipo de lanzamiento de AWS Fargate para las tareas que alojan la aplicación. Cree un nuevo volumen único de EBS para el contenido estático. Monte el nuevo volumen EBS en el clúster ECS. Configure el Auto Scaling de aplicaciones de AWS en el clúster de ECS. Establezca el servicio ECS como objetivo para el ALB. Migre la base de datos a un clúster de base de datos Multi-AZ de Amazon RDS para MySQL.
D.
Contenerizar la aplicación. Migre la aplicación a un clúster de Amazon Elastic Container Service (Amazon ECS). Utilice el tipo de lanzamiento de AWS Fargate para las tareas que alojan la aplicación. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS) para el contenido estático. Monte el sistema de archivos EFS en cada contenedor. Configure el Auto Scaling de aplicaciones de AWS en el clúster de ECS. Establezca el servicio ECS como objetivo para el ALB. Migre la base de datos a Amazon Aurora MySQL Serverless v2 con una instancia de base de datos lectora.
AnswerDiscussion
Correct Answer: D
Para mejorar la confiabilidad de la aplicación, colocarla en contenedores en Amazon Elastic Container Service (ECS) con el tipo de lanzamiento de AWS Fargate es un enfoque efectivo. El uso de Amazon EFS para contenido estático permite un uso compartido y escalabilidad más fáciles, ya que EFS se puede montar en varios contenedores. Además, la habilitación de AWS Application Auto Scaling garantiza que el clúster de ECS pueda manejar cargas variables ajustando los recursos automáticamente. La migración de la base de datos a Amazon Aurora MySQL Serverless v2 con una instancia de base de datos de lector aborda el requisito de gran cantidad de lectura y garantiza que la base de datos pueda escalar para manejar la carga máxima sin intervención manual. Esta combinación proporciona una solución escalable, altamente disponible y confiable para la aplicación.
Question 343 of 529
Un arquitecto de soluciones quiere asegurarse de que solo los usuarios o roles de AWS con permisos adecuados puedan acceder a un nuevo endpoint de Amazon API Gateway. El arquitecto de soluciones quiere una vista de extremo a extremo de cada solicitud para analizar la latencia de la solicitud y crear mapas de servicio.
Cómo puede el arquitecto de soluciones diseñar el control de acceso API Gateway y realizar inspecciones de solicitudes?
A.
Para el método API Gateway, establezca la autorización en AWS_IAM. Luego, otorgue al usuario o rol de IAM el permiso Execute-API:Invoke en el recurso REST API. Habilite a la persona que llama a la API para que firme solicitudes con AWS Signature cuando acceda al endpoint. Utilice AWS X-Ray para rastrear y analizar las solicitudes de los usuarios a API Gateway.
B.
Para el recurso API Gateway, establezca CORS en habilitado y solo devuelva el dominio de la compañía en los encabezados Access-Control-Allow-Origin. Luego, otorgue al usuario o rol de IAM el permiso Execute-API:Invoke en el recurso REST API. Utilice Amazon CloudWatch para rastrear y analizar las solicitudes de los usuarios a API Gateway.
C.
Cree una función de AWS Lambda como autorizador personalizado, solicite al cliente API que pase la clave y el secreto al realizar la llamada y luego use Lambda para validar el par clave/secreto contra el sistema IAM. Utilice AWS X-Ray para rastrear y analizar las solicitudes de los usuarios a API Gateway.
D.
Crear un certificado de cliente para API Gateway. Distribuya el certificado a los usuarios y roles de AWS que necesitan acceder al endpoint. Habilite a la persona que llama API para que pase el certificado de cliente al acceder al punto final. Utilice Amazon CloudWatch para rastrear y analizar las solicitudes de los usuarios a API Gateway.
AnswerDiscussion
Correct Answer: A
Para garantizar que solo los usuarios o roles de AWS con los permisos adecuados puedan acceder al nuevo endpoint de Amazon API Gateway, el método API Gateway debe tener su autorización establecida en AWS_IAM. Esto le permite definir el usuario o rol de IAM con el permiso Execute-API:Invoke en el recurso REST API. A continuación, la persona que llama a la API firma las solicitudes mediante AWS Signature cuando accede al punto final para garantizar un acceso seguro. Para analizar la latencia y crear mapas de servicio desde una perspectiva de extremo a extremo, AWS X-Ray se puede utilizar para rastrear y analizar las solicitudes de los usuarios a la API Gateway. Este enfoque cumple con los requisitos tanto para el control de acceso como para la inspección detallada de solicitudes.
Question 344 of 529
Una empresa está utilizando AWS CodePipeline para el CI/CD de una aplicación a un grupo de Amazon EC2 Auto Scaling. Todos los recursos de AWS se definen en las plantillas de AWS CloudFormation. Los artefactos de la aplicación se almacenan en un bucket de Amazon S3 y se implementan en el grupo Auto Scaling mediante scripts de datos de usuario de instancia. A medida que la aplicación se ha vuelto más compleja, los cambios recientes de recursos en las plantillas de CloudFormation han causado un tiempo de inactividad no planificado.
Cómo debería un arquitecto de soluciones mejorar la canalización de CI/CD para reducir la probabilidad de que los cambios en las plantillas causen tiempo de inactividad?
A.
Adapte los scripts de implementación para detectar e informar las condiciones de error de CloudFormation al realizar implementaciones. Escriba planes de prueba para que un equipo de pruebas funcione en un entorno que no sea de producción antes de aprobar el cambio para producción.
B.
Implemente pruebas automatizadas con AWS CodeBuild en un entorno de prueba. Utilice los conjuntos de cambios de CloudFormation para evaluar los cambios antes de la implementación. Utilice AWS CodeDeploy para aprovechar los patrones de implementación azules/verdes para permitir evaluaciones y la capacidad de revertir los cambios, si es necesario.
C.
Use complementos para el entorno de desarrollo integrado (IDE) para verificar las plantillas en busca de errores y use la CLI de AWS para validar que las plantillas son correctas. Adapte el código de implementación para verificar las condiciones de error y generar notificaciones sobre errores. Implemente en un entorno de prueba y ejecute un plan de pruebas manual antes de aprobar el cambio para producción.
D.
Utilice AWS CodeDeploy y un patrón de implementación azul/verde con CloudFormation para reemplazar los scripts de implementación de datos de usuario. Hacer que los operadores inicien sesión en las instancias en ejecución y pasen por un plan de pruebas manual para verificar que la aplicación se esté ejecutando como se esperaba.
AnswerDiscussion
Correct Answer: B
Para reducir la probabilidad de que los cambios en las plantillas de CloudFormation causen tiempo de inactividad, un arquitecto de soluciones debe implementar pruebas automatizadas para detectar problemas temprano y usar estrategias de implementación que minimicen el impacto de los cambios. Las pruebas automatizadas con AWS CodeBuild pueden validar los cambios en un entorno de prueba, reduciendo los errores humanos y asegurando que los cambios no rompan la aplicación. La implementación de conjuntos de cambios de CloudFormation permite una evaluación precisa de los cambios antes de implementarlos. El uso de AWS CodeDeploy con patrones de implementación azul/verde permite una transición fluida entre las versiones actuales y nuevas, minimizando el tiempo de inactividad y permitiendo una fácil reversión si se detectan problemas.
Question 345 of 529
Una compañía norteamericana con sede en la costa este está implementando una nueva aplicación web que se ejecuta en Amazon EC2 en la región us-east-1. La aplicación debe escalar dinámicamente para satisfacer la demanda de los usuarios y mantener la resiliencia. Adicionalmente, la aplicación debe tener capacidades de recuperación ante desastres en una configuración activo-pasiva con la región us-west-1.
Qué pasos debe tomar un arquitecto de soluciones después de crear una VPC en la región us-east-1?
A.
Crear una VPC en la región us-west-1. Utilice la interconexión de VPC entre regiones para conectar ambas VPC. Implemente un balanceador de carga de aplicaciones (ALB) que abarque varias zonas de disponibilidad (AZ) en la VPC en la región us-east-1. Implemente instancias EC2 en varias AZ en cada región como parte de un grupo de Auto Scaling que abarca ambas VPC y servido por el ALB.
B.
Implemente un balanceador de carga de aplicaciones (ALB) que abarque varias zonas de disponibilidad (AZ) en la VPC en la región us-east-1. Implemente instancias EC2 en múltiples AZ como parte de un grupo de Auto Scaling al que presta servicio AldePloy, la misma solución en la región us-west-1. Cree un conjunto de registros de Amazon Route 53 con una política de enrutamiento de conmutación por error y comprobaciones de estado habilitadas para proporcionar alta disponibilidad en ambas regiones.
C.
Crear una VPC en la región us-west-1. Utilice la interconexión de VPC entre regiones para conectar ambas VPC. Implemente un balanceador de carga de aplicaciones (ALB) que abarque ambas VPC. Implemente instancias EC2 en varias zonas de disponibilidad como parte de un grupo de Auto Scaling en cada VPC servida por el ALB. Crear un registro Amazon Route 53 que apunte a la ALB.
D.
Implemente un balanceador de carga de aplicaciones (ALB) que abarque varias zonas de disponibilidad (AZ) en la VPC en la región us-east-1. Implemente instancias EC2 en varias AZ como parte de un grupo de Auto Scaling atendido por ALB. Implemente la misma solución en la región us-west-1. Crear registros separados de la Ruta Amazónica 53 en cada Región que apunten al ALB en la Región. Utilice las comprobaciones de estado de Route 53 para proporcionar alta disponibilidad en ambas regiones.
AnswerDiscussion
Correct Answer: B
Después de crear una VPC en la región us-east-1, debe implementar un balanceador de carga de aplicaciones (ALB) que abarque varias zonas de disponibilidad (AZ) en esa VPC. Luego, debe implementar instancias EC2 en esas múltiples AZ como parte de un grupo de Auto Scaling servido por el ALB. Para garantizar la recuperación ante desastres y la resiliencia, implemente la misma solución en la región us-west-1. Por último, cree un conjunto de registros de Amazon Route 53 con una política de enrutamiento de conmutación por error y comprobaciones de estado habilitadas para proporcionar alta disponibilidad en ambas regiones. Esta configuración garantiza que la aplicación pueda escalar dinámicamente, mantener la resiliencia y lograr la recuperación ante desastres en una configuración activo-pasiva.
Question 346 of 529
Una empresa tiene una aplicación heredada que se ejecuta en múltiples componentes de NET Framework. Los componentes comparten la misma base de datos Microsoft SQL Server y se comunican entre sí de forma asincrónica mediante Microsoft Message Queueing (MSMQ).
La compañía está iniciando una migración a componentes principales.NET contenerizados y quiere refactorizar la aplicación para que se ejecute en AWS. Los componentes de.NET Core requieren una orquestación compleja. La compañía debe tener control total sobre las redes y la configuración del host. El modelo de base de datos de la aplicación es fuertemente relacional.
Qué solución cumplirá con estos requisitos?
A.
Aloje los componentes principales de INET en AWS App Runner. Aloje la base de datos en Amazon RDS para SQL Server. Utilice Amazon EventBiridge para la mensajería asincrónica.
B.
Aloje los componentes principales de.NET en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento de AWS Fargate. Aloje la base de datos en Amazon DynamoDuse Amazon Simple Notification Service (Amazon SNS) para mensajería asincrónica.
C.
Aloje los componentes principales de.NET en AWS Elastic Beanstalk. Alojar la base de datos en Amazon Aurora PostgreSQL Serverless v2. Utilice Amazon Managed Streaming para Apache Kafka (Amazon MSK) para mensajería asincrónica.
D.
Aloje los componentes NET Core en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento de Amazon EC2. Aloje la base de datos en Amazon Aurora MySQL Serverless v2. Utilice Amazon Simple Queue Service (Amazon SQS) para la mensajería asincrónica.
AnswerDiscussion
Correct Answer: D
El alojamiento de los componentes principales de .NET en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento de Amazon EC2 proporciona el control necesario sobre la configuración de redes y host, lo cual es crucial para las complejas necesidades de orquestación de la aplicación. Amazon Aurora MySQL Serverless v2 admite un modelo de base de datos fuertemente relacional, que se alinea con los requisitos de la aplicación. Por último, Amazon Simple Queue Service (Amazon SQS) es un reemplazo adecuado para MSMQ para mensajería asíncrona, lo que garantiza una comunicación fluida entre los componentes.
Question 347 of 529
Un arquitecto de soluciones ha lanzado varias instancias de Amazon EC2 en un grupo de ubicación dentro de una sola zona de disponibilidad. Debido a la carga adicional en el sistema, el arquitecto de soluciones intenta agregar nuevas instancias al grupo de ubicación. Sin embargo, el arquitecto de soluciones recibe un error de capacidad insuficiente.
Qué debe hacer el arquitecto de soluciones para solucionar este problema?
A.
Utilice un grupo de colocación de spread. Establezca un mínimo de ocho instancias para cada Zona de Disponibilidad.
B.
Detener e iniciar todas las instancias en el grupo de colocación. Intente de nuevo el lanzamiento.
C.
Crear un nuevo grupo de ubicación. Fusionar el nuevo grupo de ubicación con el grupo de ubicación original.
D.
Inicie las instancias adicionales como Hosts Dedicados en los grupos de ubicación.
AnswerDiscussion
Correct Answer: B
Para solucionar un error de capacidad insuficiente al agregar nuevas instancias a un grupo de ubicación existente, el mejor enfoque es detener e iniciar todas las instancias en el grupo de ubicación. Esta acción puede migrar potencialmente las instancias a hardware con capacidad suficiente para satisfacer la solicitud de instancias adicionales.
Question 348 of 529
Una compañía ha utilizado la infraestructura como código (IAC) para aprovisionar un conjunto de dos instancias de Amazon EC2. Las instancias han permanecido igual desde hace varios años.
El negocio de la compañía ha crecido rápidamente en los últimos meses. En respuesta, el equipo de operaciones de la compañía ha implementado un grupo Auto Scaling para gestionar los aumentos repentinos en el tráfico. La política de la compañía requiere una instalación mensual de actualizaciones de seguridad en todos los sistemas operativos que se estén ejecutando.
La actualización de seguridad más reciente requirió un reinicio. Como resultado, el grupo Auto Scaling terminó las instancias y las reemplazó por instancias nuevas sin parches.
Qué combinación de pasos debería recomendar un arquitecto de soluciones para evitar una recurrencia de este problema? (Elija dos.)
A.
Modifique el grupo Auto Scaling configurando la directiva Actualizar para que se dirija a la configuración de lanzamiento más antigua para su sustitución.
B.
Cree un nuevo grupo de Auto Scaling antes del siguiente mantenimiento del parche. Durante la ventana de mantenimiento, parchee ambos grupos y reinicie las instancias.
C.
Cree un balanceador de carga elástico frente al grupo Auto Scaling. Configure la supervisión para garantizar que las comprobaciones de estado del grupo de destino vuelvan en buen estado después de que el grupo Auto Scaling sustituya las instancias terminadas.
D.
Cree scripts de automatización para parchear una AMI, actualizar la configuración de lanzamiento e invocar una actualización de instancia de Auto Scaling.
E.
Cree un balanceador de carga elástico frente al grupo Auto Scaling. Configure la protección de terminación en las instancias.
AnswerDiscussion
Correct Answer: A, D
El problema surge porque el grupo Auto Scaling reemplaza las instancias después de una actualización de seguridad que requiere un reinicio, lo que da como resultado la creación de instancias nuevas sin parches. Para evitar esto, las acciones deben garantizar que las instancias estén actualizadas y no sean reemplazadas innecesariamente. La modificación del grupo Auto Scaling para apuntar a la configuración de lanzamiento más antigua para su reemplazo garantiza que las instancias más antiguas y potencialmente menos seguras se reemplazen primero, lo que puede ayudar a mantener un entorno más actualizado y seguro. La creación de scripts de automatización para parchear una AMI, actualizar la configuración de lanzamiento e invocar una actualización de instancia de Auto Scaling garantiza que las nuevas instancias lanzadas por el grupo Auto Scaling estarán actualizadas con los últimos parches de seguridad, resolviendo así la causa raíz del problema. Este enfoque se alinea con el mantenimiento del cumplimiento de la seguridad y la eficiencia operativa.
Question 349 of 529
Un equipo de científicos de datos está utilizando instancias de Amazon SaeMaker y API de SAGeMaker para entrenar modelos de aprendizaje automático (ML). Las instancias de SageMaker se implementan en una VPC que no tiene acceso a o desde Internet. Los conjuntos de datos para la capacitación del modelo ML se almacenan en un bucket de Amazon S3. Los endpoints de interfaz de VPC proporcionan acceso a Amazon S3 y a las API de SAGeMaker.
Ocasionalmente, los científicos de datos requieren acceso al repositorio Python Package Index (PyPI) para actualizar los paquetes de Python que utilizan como parte de su flujo de trabajo. Un arquitecto de soluciones debe proporcionar acceso al repositorio PyPI mientras se asegura de que las instancias de SAGeMaker permanezcan aisladas de Internet.
Qué solución cumplirá con estos requisitos?
A.
Cree un repositorio de AWS CodeCommit para cada paquete al que los científicos de datos necesiten acceder. Configure la sincronización de código entre el repositorio PyPI y el repositorio CodeCommit. Cree un punto final de VPC para CodeCommit.
B.
Cree una puerta de enlace NAT en la VPC. Configure rutas de VPC para permitir el acceso a Internet con una ACL de red que permita el acceso solo al punto final del repositorio PyPI.
C.
Cree una instancia NAT en la VPConfigurar rutas de VPC para permitir el acceso a Internet. Configure reglas de firewall de instancia de notebook de SageMaker que permitan el acceso solo al punto final del repositorio PyPI.
D.
Cree un dominio y un repositorio de AWS CodeArtifact. Agregar una conexión externa para public:pypi al repositorio CodeArtifact. Configure el cliente Python para usar el repositorio CodeArtifact. Cree un punto final de VPC para CodeArtifact.
AnswerDiscussion
Correct Answer: D
Para cumplir con el requisito de proporcionar acceso al repositorio PyPI mientras se garantiza que las instancias de SageMaker permanezcan aisladas de Internet, la mejor solución es crear un dominio y un repositorio de AWS CodeArtifact. Al agregar una conexión externa para public:pypi al repositorio CodeArtifact y configurar el cliente Python para usar este repositorio, se habilita el acceso necesario a los paquetes de Python requeridos. Además, la creación de un punto final de VPC para CodeArtifact garantiza que las instancias de SAGeMaker puedan acceder a CodeArtifact sin necesidad de acceso directo a Internet, manteniendo así su aislamiento. Este enfoque garantiza la seguridad y la eficiencia.
Question 350 of 529
Un arquitecto de soluciones trabaja para una agencia gubernamental que tiene estrictos requisitos de recuperación ante desastres. Todas las instantáneas de Amazon Elastic Block Store (Amazon EBS) deben guardarse en al menos dos regiones de AWS adicionales. También se requiere que el organismo mantenga los gastos generales operativos más bajos posibles.
Qué solución cumple con estos requisitos?
A.
Configure una política en Amazon Data Lifecycle Manager (Amazon DLM) para que se ejecute una vez al día y copie las instantáneas de EBS en las regiones adicionales.
B.
Utilice Amazon EventBridge para programar una función de AWS Lambda para copiar las instantáneas de EBS en las regiones adicionales.
C.
Configure AWS Backup para crear las instantáneas de EBS. Configure la replicación entre regiones de Amazon S3 para copiar las instantáneas de EBS en las regiones adicionales.
D.
Programe que Amazon EC2 Image Builder se ejecute una vez al día para crear una AMI y copiar la AMI en las regiones adicionales.
AnswerDiscussion
Correct Answer: A
Configurar una política en Amazon Data Lifecycle Manager (Amazon DLM) es la solución más adecuada. DLM automatiza el proceso de copia de instantáneas de EBS a regiones adicionales, lo que garantiza el cumplimiento de los requisitos de recuperación ante desastres y minimiza la sobrecarga operativa. Proporciona una forma sencilla y automatizada de administrar instantáneas sin requerir configuración o administración adicionales, alineándose perfectamente con la necesidad de una sobrecarga operativa baja.
Question 351 of 529
Una empresa tiene un proyecto que está lanzando instancias de Amazon EC2 que son más grandes de lo requerido. La cuenta del proyecto no puede formar parte de la organización de la compañía en AWS Organizations debido a restricciones de política para mantener esta actividad fuera de la TI corporativa. La compañía quiere permitir únicamente el lanzamiento de instancias t3.small EC2 por parte de los desarrolladores en la cuenta del proyecto. Estas instancias EC2 deben estar restringidas a la región us-east-2.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Crear una nueva cuenta de desarrollador. Mueva todas las instancias, usuarios y activos de EC2 a us-east-2. Agregar la cuenta a la organización de la compañía en AWS Organizations. Aplicar una política de etiquetado que denota afinidad por región.
B.
Cree un SCP que niegue el lanzamiento de todas las instancias EC2 excepto las instancias t3.small EC2 en us-east-2. Adjuntar el SCP a la cuenta del proyecto.
C.
Cree y compre una Instancia Reservada EC2 t3.small para cada desarrollador en us-east-2. Asigne a cada desarrollador una instancia EC2 específica con su nombre como etiqueta.
D.
Cree una política de IAM que permita el lanzamiento de solo instancias de EC2 t3.small en us-east-2. Adjuntar la política a los roles y grupos que los desarrolladores utilizan en la cuenta del proyecto.
AnswerDiscussion
Correct Answer: D
Para cumplir con el requisito de restringir a los desarrolladores a lanzar solo instancias t3.small EC2 en la región us-east-2, debe crear una política de IAM que aplique estas restricciones. Adjunte esta política a los roles y grupos que los desarrolladores utilizan en la cuenta del proyecto. Dado que la cuenta del proyecto no puede formar parte de las organizaciones de AWS de la compañía debido a restricciones de política, no se puede usar una SCP (Service Control Policy). Por lo tanto, la solución adecuada es utilizar una política de IAM adaptada a las necesidades específicas de la cuenta del proyecto.
Question 352 of 529
Una empresa científica necesita procesar datos de texto e imagen desde un bucket de Amazon S3. Los datos se recopilan de varias estaciones de radar durante una fase crítica en tiempo real de una misión en el espacio profundo. Las estaciones de radar cargan los datos al bucket S3 de origen. Los datos están prefijados por el número de identificación de la estación de radar.
La compañía creó un bucket S3 de destino en una segunda cuenta. Los datos deben copiarse del bucket S3 de origen al bucket S3 de destino para cumplir con un objetivo de cumplimiento. Esta replicación se produce mediante el uso de una regla de replicación S3 para cubrir todos los objetos en el bucket S3 de origen.
Se identifica que una estación de radar específica tiene los datos más precisos. La replicación de datos en esta estación de radar debe ser monitoreada para su finalización dentro de los 30 minutos posteriores a que la estación de radar carga los objetos en el bucket S3 de origen.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Configure un agente AWS DataSync para replicar los datos prefijados del bucket S3 de origen al bucket S3 de destino. Seleccione esta opción para usar todo el ancho de banda disponible en la tarea y monitorearla para asegurarse de que está en el estado TRANSFERENCIA. Cree una regla de Amazon EventBridge para iniciar una alerta si este estado cambia.
B.
En la segunda cuenta, cree otro bucket S3 para recibir datos de la estación de radar con los datos más precisos. Configure una nueva regla de replicación para este nuevo bucket S3 para separar la replicación de las otras estaciones de radar. Supervisar el tiempo máximo de replicación hasta el destino. Cree una regla de Amazon EventBridge para iniciar una alerta cuando el tiempo supere el umbral deseado.
C.
Habilite Amazon S3 Transfer Acceleration en el bucket S3 de origen y configure la estación de radar con los datos más precisos para usar el nuevo punto final. Supervise la métrica TotalRequestLatency del bucket de destino S3. Cree una regla de Amazon EventBridge para iniciar una alerta si este estado cambia.
D.
Cree una nueva regla de replicación S3 en el bucket S3 de origen que filtre las claves que utilizan el prefijo de la estación de radar con los datos más precisos. Habilite S3 Replication Time Control (S3 RTC). Supervisar el tiempo máximo de replicación hasta el destino. Cree una regla de Amazon EventBridge para iniciar una alerta cuando el tiempo supere el umbral deseado.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos, cree una nueva regla de replicación S3 en el bucket S3 de origen que filtre las claves que coincidan con el prefijo de la estación de radar con los datos más precisos. Habilite S3 Replication Time Control (S3 RTC), que proporciona un SLA para la replicación de 15 minutos, asegurando que los datos se transfieran dentro del marco de tiempo preciso. Supervise el tiempo máximo de replicación para el cumplimiento y cree una regla de Amazon EventBridge para alertar cuando el tiempo supere el umbral deseado. Este enfoque garantiza una replicación de datos oportuna y confiable específicamente para los datos más críticos de la estación de radar.
Question 353 of 529
Una empresa quiere migrar su centro de datos local a la nube de AWS. Esto incluye miles de servidores virtualizados Linux y Microsoft Windows, almacenamiento SAN, aplicaciones Java y PHP con MySQL y bases de datos Oracle. Hay muchos servicios dependientes alojados ya sea en el mismo centro de datos o externamente. La documentación técnica está incompleta y desactualizada. Un arquitecto de soluciones necesita comprender el entorno actual y estimar los costos de recursos en la nube después de la migración.
Qué herramientas o servicios debería utilizar el arquitecto de soluciones para planificar la migración a la nube? (Elija tres.)
A.
Servicio de descubrimiento de aplicaciones de AWS
B.
AWS SMS
C.
Rayos X de AWS
D.
Herramienta de preparación para la adopción de la nube de AWS (CART)
E.
Inspector de Amazon
F.
Centro de migración de AWS
AnswerDiscussion
Correct Answer: A, D, F
AWS Application Discovery Service, AWS Cloud Adoption Readiness Tool (CART) y AWS Migration Hub son herramientas adecuadas para planificar una migración a la nube. AWS Application Discovery Service ayuda a comprender el entorno actual al recopilar información sobre servidores locales, lo cual es fundamental cuando la documentación técnica está incompleta o desactualizada. AWS Cloud Adoption Readiness Tool (CART) es útil para evaluar la preparación de la organización para la adopción de la nube e identificar cualquier brecha, que es necesaria en la fase de planificación. AWS Migration Hub proporciona una ubicación única para realizar un seguimiento del progreso y el estado de las migraciones en varias soluciones de AWS y socios, lo que ayuda a estimar los costos de los recursos de la nube después de la migración.
Question 354 of 529
Un arquitecto de soluciones está revisando la resiliencia de una aplicación antes del lanzamiento. La aplicación se ejecuta en una instancia de Amazon EC2 que se implementa en una subred privada de una VPC. La instancia EC2 es aprovisionada por un grupo de Auto Scaling que tiene una capacidad mínima de 1 y una capacidad máxima de 1. La aplicación almacena datos en una instancia de base de datos de Amazon RDS para MySQL. La VPC tiene subredes configuradas en tres zonas de disponibilidad y se configura con una única puerta de enlace NAT.
El arquitecto de soluciones necesita recomendar una solución para garantizar que la aplicación opere en múltiples zonas de disponibilidad.
Qué solución cumplirá con este requisito?
A.
Despliegue una puerta de enlace NAT adicional en las otras zonas de disponibilidad. Actualizar las tablas de rutas con las rutas adecuadas. Modifique la instancia de base de datos RDS para MySQL a una configuración Multi-AZ. Configure el grupo Auto Scaling para lanzar las instancias en todas las zonas de disponibilidad. Establezca la capacidad mínima y la capacidad máxima del grupo Auto Scaling en 3.
B.
Reemplace la puerta de enlace NAT por una puerta de enlace privada virtual. Reemplace la instancia de base de datos RDS para MySQL por un clúster de base de datos MySQL de Amazon Aurora. Configure el grupo Auto Scaling para lanzar instancias en todas las subredes de la VPC. Establezca la capacidad mínima y la capacidad máxima del grupo Auto Scaling en 3.
C.
Reemplace la puerta de enlace NAT por una instancia NAT. Migre la instancia de base de datos RDS para MySQL a una instancia de base de datos RDS para PostgreSQL. Lanzar una nueva instancia EC2 en las otras zonas de disponibilidad.
D.
Despliegue una puerta de enlace NAT adicional en las otras zonas de disponibilidad. Actualizar las tablas de rutas con las rutas adecuadas. Modifique la instancia de base de datos RDS para MySQL para activar las copias de seguridad automáticas y conservar las copias de seguridad durante 7 días. Configure el grupo Auto Scaling para lanzar instancias en todas las subredes de la VPC. Mantener la capacidad mínima y la capacidad máxima del grupo Auto Scaling en 1.
ResponderDiscusión
Correct Answer: A
Para garantizar que la aplicación funcione en múltiples zonas de disponibilidad, la solución debe abordar la alta disponibilidad y tolerancia a fallas. La implementación de gateways NAT adicionales en cada zona de disponibilidad evita un solo punto de falla. La actualización de las tablas de ruta garantiza el enrutamiento correcto a través de las nuevas puertas de enlace NAT. La modificación de la instancia de base de datos RDS para MySQL a una configuración Multi-AZ proporciona redundancia de base de datos y tolerancia a fallas. La configuración del grupo Auto Scaling para lanzar instancias en varias zonas de disponibilidad y establecer la capacidad mínima y máxima adecuadas garantiza que la aplicación pueda manejar cargas más altas y permanezca disponible incluso si falla una zona de disponibilidad. Este enfoque proporciona una cobertura integral para alta disponibilidad, tolerancia a fallas y escalabilidad.
Question 355 of 529
Una empresa planea migrar su aplicación de procesamiento de transacciones en las instalaciones a AWS. La aplicación se ejecuta dentro de contenedores Docker alojados en máquinas virtuales en el centro de datos de la compañía. Los contenedores Docker tienen almacenamiento compartido donde la aplicación registra los datos de las transacciones.
Las transacciones son sensibles al tiempo. El volumen de transacciones dentro de la aplicación es impredecible. La compañía debe implementar una solución de almacenamiento de baja latencia que escalará automáticamente el rendimiento para satisfacer la mayor demanda. La compañía no puede desarrollar más la aplicación y no puede continuar administrando el entorno de alojamiento Docker.
Cómo debería la empresa migrar la aplicación a AWS para cumplir con estos requisitos?
A.
Migre los contenedores que ejecutan la aplicación a Amazon Elastic Kubernetes Service (Amazon EKS). Utilice Amazon S3 para almacenar los datos de transacción que comparten los contenedores.
B.
Migre los contenedores que ejecutan la aplicación a AWS Fargate para Amazon Elastic Container Service (Amazon ECS). Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Cree una definición de tarea de Fargate. Agregue un volumen a la definición de tarea para que apunte al sistema de archivos EFS.
C.
Migre los contenedores que ejecutan la aplicación a AWS Fargate para Amazon Elastic Container Service (Amazon ECS). Cree un volumen de Amazon Elastic Block Store (Amazon EBS). Cree una definición de tarea de Fargate. Adjunte el volumen de EBS a cada tarea en ejecución.
D.
Lanzar instancias de Amazon EC2. Instale Docker en las instancias EC2. Migre los contenedores a las instancias EC2. Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Agregue un punto de montaje a las instancias EC2 para el sistema de archivos EFS.
ResponderDiscusión
Correct Answer: B
La mejor manera de satisfacer las necesidades de la compañía de almacenamiento de baja latencia, escalado automático del rendimiento y no más desarrollo o sobrecarga administrativa es migrar los contenedores a AWS Fargate con Amazon Elastic Container Service (ECS). AWS Fargate elimina la necesidad de administrar servidores y permite que la empresa se centre únicamente en implementar y administrar contenedores. Amazon Elastic File System (EFS) escala automáticamente y proporciona una solución de almacenamiento compartida de baja latencia adecuada para los datos de transacción de la aplicación. Al crear una definición de tarea de Fargate y agregar un volumen que apunte al sistema de archivos de Amazon EFS, la compañía puede garantizar que el almacenamiento se escalará con la demanda mientras proporciona la baja latencia requerida.
Question 356 of 529
Una empresa planea migrar a la nube de AWS. La compañía aloja muchas aplicaciones en servidores Windows y servidores Linux. Algunos de los servidores son físicos, y algunos de los servidores son virtuales. La compañía utiliza varios tipos de bases de datos en su entorno local. La compañía no cuenta con un inventario preciso de sus servidores y aplicaciones locales.
La compañía quiere dimensionar correctamente sus recursos durante la migración. Un arquitecto de soluciones necesita obtener información sobre las conexiones de red y las relaciones de aplicación. El arquitecto de soluciones debe evaluar el entorno actual de la compañía y desarrollar un plan de migración.
Qué solución proporcionará al arquitecto de soluciones la información requerida para desarrollar el plan de migración?
A.
Utilice Migration Evaluator para solicitar una evaluación del entorno a AWS. Utilice AWS Application Discovery Service Agentless Collector para importar los detalles a un informe de Migration Evaluator Quick Insights.
B.
Utilice AWS Migration Hub e instale AWS Application Discovery Agent en los servidores. Implemente el recopilador de datos de la aplicación Migration Hub Strategy Recommendations. Genere un reporte usando las Recomendaciones de Estrategia de Migration Hub.
C.
Utilice AWS Migration Hub y ejecute AWS Application Discovery Service Agentless Collector en los servidores. Agrupe los servidores y bases de datos mediante AWS Application Migration Service. Genere un reporte usando las Recomendaciones de Estrategia de Migration Hub.
D.
Utilice la herramienta de importación de AWS Migration Hub para cargar los detalles del entorno local de la compañía. Genere un reporte usando las Recomendaciones de Estrategia de Migration Hub.
ResponderDiscusión
Correct Answer: B
Para desarrollar un plan de migración preciso, la compañía primero necesita obtener información detallada sobre su entorno local, incluidas las conexiones de red y las relaciones con las aplicaciones. Dado que el inventario de la compañía está incompleto, es esencial recopilar datos directamente de los servidores. El uso de AWS Migration Hub y la instalación de AWS Application Discovery Agent en los servidores capturarán detalles completos sobre las configuraciones del sistema, el rendimiento, los procesos en ejecución y las conexiones de red. La implementación del recopilador de datos de la aplicación Migration Hub Strategy Recommendations ayudará a generar un informe con los conocimientos necesarios. Por lo tanto, el uso de AWS Migration Hub junto con AWS Application Discovery Agent y el recopilador de datos es la solución más adecuada para este escenario.
Question 357 of 529
Una compañía de servicios financieros vende su plataforma de software como servicio (SaaS) para el cumplimiento de las aplicaciones a grandes bancos globales. La plataforma SaaS se ejecuta en AWS y utiliza varias cuentas de AWS que se administran en una organización en AWS Organizations. La plataforma SaaS utiliza muchos recursos de AWS a nivel mundial.
Para el cumplimiento normativo, todas las llamadas de API a los recursos de AWS deben auditarse, rastrearse para detectar cambios y almacenarse en un almacén de datos duradero y seguro.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree una nueva ruta de AWS CloudTrail. Utilice un bucket de Amazon S3 existente en la cuenta de administración de la organización para almacenar los registros. Implementar el rastro en todas las regiones de AWS. Habilite la eliminación y el cifrado de MFA en el bucket S3.
B.
Cree una nueva ruta de AWS CloudTrail en cada cuenta de miembro de la organización. Cree nuevos buckets de Amazon S3 para almacenar los registros. Implementar el rastro en todas las regiones de AWS. Habilite la eliminación y el cifrado de MFA en los buckets S3.
C.
Cree una nueva ruta de AWS CloudTrail en la cuenta de administración de la organización. Cree un nuevo bucket de Amazon S3 con el control de versiones activado para almacenar los registros. Desplegar el rastro para todas las cuentas de la organización. Habilite la eliminación y el cifrado de MFA en el bucket S3.
D.
Cree una nueva ruta de AWS CloudTrail en la cuenta de administración de la organización. Cree un nuevo bucket de Amazon S3 para almacenar los registros. Configure Amazon Simple Notification Service (Amazon SNS) para enviar notificaciones de entrega de archivos de registro a un sistema de administración externo que realice el seguimiento de los registros. Habilite la eliminación y el cifrado de MFA en el bucket S3.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de auditoría, seguimiento de cambios y almacenamiento de registros de llamadas de API en un data store duradero y seguro con la menor sobrecarga operativa, crear un nuevo rastro de AWS CloudTrail en la cuenta de administración de la organización y usar un bucket centralizado de Amazon S3 es la solución más eficiente. Esto permite una administración centralizada y auditoría de registros en todas las cuentas de la organización con una sobrecarga de administración mínima. Habilitar la eliminación y el cifrado de MFA garantiza la seguridad y durabilidad de los registros. Al implementar el rastro para todas las cuentas de la organización, el cumplimiento se puede lograr globalmente sin necesidad de configuraciones separadas para cada cuenta.
Question 358 of 529
Una empresa está implementando una base de datos distribuida en memoria en una flota de instancias de Amazon EC2. La flota consta de un nodo primario y ocho nodos de trabajadores. El nodo principal es responsable de monitorear el estado del clúster, aceptar solicitudes de usuario, distribuir las solicitudes de usuario a los nodos de trabajo y enviar una respuesta agregada a un cliente. Los nodos de trabajo se comunican entre sí para replicar particiones de datos.
La compañía requiere la menor latencia de red posible para lograr el máximo rendimiento.
Qué solución cumplirá con estos requisitos?
A.
Inicie instancias EC2 optimizadas para memoria en un grupo de ubicación de particiones.
B.
Lanzar instancias EC2 optimizadas para cómputos en un grupo de ubicación de particiones.
C.
Inicie instancias EC2 optimizadas para memoria en un grupo de ubicación de clúster.
D.
Inicie instancias EC2 optimizadas para cómputos en un grupo de ubicación extendida.
ResponderDiscusión
Correct Answer: C
Para una base de datos distribuida en memoria en instancias de Amazon EC2 que requieren la latencia de red más baja posible, lanzar instancias EC2 optimizadas para memoria en un grupo de ubicación de clúster es la mejor solución. Las instancias optimizadas para la memoria son ideales para bases de datos en memoria porque proporcionan una gran capacidad de memoria y ancho de banda. Un grupo de ubicación de clústeres está diseñado específicamente para garantizar una red de baja latencia al colocar las instancias físicamente cerca unas de otras dentro de una única zona de disponibilidad, lo que reduce significativamente el tiempo de comunicación entre nodos.
Question 359 of 529
Una empresa mantiene información en las instalaciones en aproximadamente 1 archivos million.csv que están alojados en una máquina virtual. Los datos inicialmente son de 10 TB de tamaño y crecen a una tasa de 1 TB cada semana. La compañía necesita automatizar las copias de seguridad de los datos en la nube de AWS.
Las copias de seguridad de los datos deben realizarse diariamente. La compañía necesita una solución que aplique filtros personalizados para hacer copias de seguridad solo de un subconjunto de los datos que se encuentran en los directorios de origen designados. La compañía ha establecido una conexión AWS Direct Connect.
Qué solución cumplirá con los requisitos de backup con la menor sobrecarga operativa?
A.
Utilice la operación de la API CopyObject de Amazon S3 con carga multiparte para copiar los datos existentes en Amazon S3. Utilice la operación de la API CopyObject para replicar nuevos datos en Amazon S3 diariamente.
B.
Cree un plan de copia de seguridad en AWS Backup para realizar copias de seguridad de los datos en Amazon S3. Programe el plan de respaldo para que se ejecute diariamente.
C.
Instale el agente AWS DataSync como una máquina virtual que se ejecute en el hipervisor local. Configure una tarea DataSync para replicar los datos en Amazon S3 diariamente.
D.
Utilice un dispositivo AWS Snowball Edge para la copia de seguridad inicial. Utilice AWS DataSync para realizar backups incrementales en Amazon S3 diariamente.
ResponderDiscusión
Correct Answer: C
Para automatizar las copias de seguridad de datos de una máquina virtual local a AWS con una sobrecarga operativa mínima, es óptimo instalar el agente AWS DataSync como una máquina virtual en el hipervisor local. AWS DataSync le permite configurar tareas para transferir y filtrar solo los datos necesarios a Amazon S3 diariamente, cumpliendo con el requisito de filtrado personalizado de los directorios de origen designados. La solución maneja de manera efectiva el creciente tamaño de los datos e implica una administración operativa mínima una vez configurada.
Question 360 of 529
Una compañía de servicios financieros tiene un producto de gestión de activos que miles de clientes utilizan en todo el mundo. Los clientes proporcionan comentarios sobre el producto a través de encuestas. La compañía está construyendo una nueva solución analítica que se ejecuta en Amazon EMR para analizar los datos de estas encuestas. Las siguientes personas de usuario necesitan acceder a la solución analítica para realizar diferentes acciones:
• Administrador: Aprovisiona el clúster de EMR para el equipo de análisis en función de los requisitos del equipo
• Ingeniero de datos: ejecuta scripts ETL para procesar, transformar y enriquecer los conjuntos de datos
• Analista de datos: Ejecuta consultas SQL y Hive sobre los datos
Un arquitecto de soluciones debe asegurarse de que todas las personas de usuario tengan menos privilegios de acceso a solo los recursos que necesitan. Las personas usuarias deben poder lanzar únicamente aplicaciones que estén aprobadas y autorizadas. La solución también debe garantizar el etiquetado de todos los recursos que crean las personas de usuario.
Qué solución cumplirá con estos requisitos?
A.
Crear roles de IAM para cada persona de usuario. Adjunte políticas basadas en identidad para definir qué acciones puede realizar el usuario que asume el rol. Cree una regla de AWS Config para verificar si hay recursos no conformes. Configure la regla para notificar al administrador para corregir los recursos no conformes.
B.
Configure la autenticación basada en Kerberos para clústeres EMR en el momento del lanzamiento. Especifique una configuración de seguridad Kerberos junto con las opciones de Kerberos específicas del clúster.
C.
Utilice AWS Service Catalog para controlar las versiones de Amazon EMR disponibles para la implementación, la configuración del clúster y los permisos para cada persona de usuario.
D.
Inicie el clúster de EMR mediante AWS CloudFormation, Adjunte políticas basadas en recursos al clúster de EMR durante la creación del clúster. Crear un AWS. Regla de configuración para verificar los clústeres no conformes y los buckets de Amazon S3 no conformes. Configure la regla para notificar al administrador para corregir los recursos no conformes.
ResponderDiscusión
Correct Answer: C
El uso de AWS Service Catalog es la solución más adecuada para cumplir con los requisitos. AWS Service Catalog permite a las organizaciones crear y administrar catálogos de servicios de TI aprobados para su uso en AWS, lo que garantiza que solo se implementen aplicaciones y configuraciones aprobadas. Admite la definición de permisos para cada persona de usuario, asegurando que tengan el menor acceso de privilegios. También hace cumplir el etiquetado de recursos, que es esencial para administrar y rastrear los recursos de manera efectiva.
Question 361 of 529
Una empresa de software como servicio (SaaS) utiliza AWS para alojar un servicio que funciona con AWS PrivateLink. El servicio consiste en software propietario que se ejecuta en tres instancias de Amazon EC2 detrás de un balanceador de carga de red (NLB). Las instancias están en subredes privadas en múltiples zonas de disponibilidad en la región eu-west-2. Todos los clientes de la compañía están en eu-west-2.
Sin embargo, la compañía adquiere ahora un nuevo cliente en la región us-este-1. La compañía crea una nueva VPC y nuevas subredes en us-east-1. La compañía establece pares de VPC interregionales entre las VPC en las dos regiones.
La compañía quiere darle al nuevo cliente acceso al servicio SaaS, pero la compañía no quiere implementar de inmediato nuevos recursos EC2 en us-east-1.
Qué solución cumplirá con estos requisitos?
A.
Configure un servicio de punto final PrivateLink en us-east-1 para usar el NLB existente que está en eu-west-2. Otorgue acceso a cuentas de AWS específicas para conectarse al servicio SaaS.
B.
Crea un NLB en us-east-1. Cree un grupo objetivo IP que utilice las direcciones IP de las instancias de la compañía en eu-west-2 que alojan el servicio SaaS. Configure un servicio de punto final PrivateLink que utilice el NLB que está en us-east-1. Otorgue acceso a cuentas de AWS específicas para conectarse al servicio SaaS.
C.
Cree un balanceador de carga de aplicaciones (ALB) frente a las instancias EC2 en eu-west-2. Crea un NLB en us-east-1. Asociar el NLB que está en us-este-1 con un grupo objetivo de ALB que usa el ALB que está en eu-west-2. Configure un servicio de punto final PrivateLink que utilice el NLB que está en us-east-1. Otorgue acceso a cuentas de AWS específicas para conectarse al servicio SaaS.
D.
Utilice AWS Resource Access Manager (AWS RAM) para compartir las instancias EC2 que se encuentran en eu-west-2. En us-east-1, cree un NLB y un grupo objetivo de instancias que incluya las instancias EC2 compartidas de eu-west-2. Configure un servicio de punto final PrivateLink que utilice el NLB que está en us-east-1. Otorgue acceso a cuentas de AWS específicas para conectarse al servicio SaaS.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de dar al nuevo cliente acceso al servicio SaaS sin implementar nuevos recursos EC2 en us-east-1, la mejor solución es configurar un servicio de punto final PrivateLink en us-east-1 que utilice el balanceador de carga de red (NLB) existente en eu-west-2. Esta configuración permite al nuevo cliente en us-east-1 acceder al servicio SaaS alojado en eu-west-2 sin requerir instancias EC2 adicionales en la región us-east-1. Además, otorgar acceso a cuentas de AWS específicas para conectarse al servicio SaaS garantiza que solo los usuarios autorizados puedan acceder a él, lo que cumple con los requisitos de seguridad.
Question 362 of 529
Una empresa necesita monitorear un número creciente de buckets de Amazon S3 en dos regiones de AWS. La compañía también necesita rastrear el porcentaje de objetos que están encriptados en Amazon S3. La compañía necesita un panel de control para mostrar esta información para los equipos internos de cumplimiento.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un nuevo panel de 3 lentes de almacenamiento en cada región para realizar un seguimiento de las métricas de bucket y cifrado. Agregue datos de ambos paneles de control de región en un solo panel en Amazon QuickSight para los equipos de cumplimiento.
B.
Implemente una función de AWS Lambda en cada región para enumerar el número de buckets y el estado de cifrado de los objetos. Almacene estos datos en Amazon S3. Utilice las consultas de Amazon Athena para mostrar los datos en un panel personalizado en Amazon QuickSight para los equipos de cumplimiento.
C.
Utilice el panel predeterminado de S3 Storage Lens para realizar un seguimiento de las métricas de bucket y cifrado. Dé a los equipos de cumplimiento acceso al panel directamente en la consola S3.
D.
Cree una regla de Amazon EventBridge para detectar eventos de AWS CloudTrail para la creación de objetos S3. Configure la regla para invocar una función de AWS Lambda para registrar métricas de cifrado en Amazon DynamoDB. Utilice Amazon QuickSight para mostrar las métricas en un panel de control para los equipos de cumplimiento.
ResponderDiscusión
Correct Answer: C
Para cumplir con el requisito de monitorear un número creciente de buckets de Amazon S3 en dos regiones de AWS y rastrear el porcentaje de objetos cifrados con la menor sobrecarga operativa, usar el panel predeterminado de S3 Storage Lens es la mejor solución. La lente de almacenamiento S3 proporciona capacidades integradas para rastrear varias métricas de almacenamiento, incluido el estado de cifrado, sin necesidad de desarrollo adicional o administración de infraestructura. Esta solución permite a los equipos de cumplimiento acceder directamente al panel de control en la consola S3, lo que garantiza una configuración mínima y un mantenimiento continuo. Otras opciones, como implementar funciones de AWS Lambda o usar EventBridge y DynamoDB, aumentarían la complejidad operativa y la sobrecarga.
Question 363 of 529
CISO de una compañía ha pedido a un arquitecto de soluciones que rediseñe las prácticas actuales de CI/CD de la compañía para asegurarse de que las implementaciones de parches en su aplicación puedan ocurrir lo más rápido posible con un tiempo de inactividad mínimo si se descubren vulnerabilidades. La compañía también debe ser capaz de hacer retroceder rápidamente un cambio en caso de errores.
La aplicación web se implementa en una flota de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. Actualmente, la compañía está usando GitHub para alojar el código fuente de la aplicación y ha configurado un proyecto de AWS CodeBuild para construir la aplicación. La compañía también tiene la intención de usar AWS CodePipeline para activar las construcciones a partir de los commits de GitHub usando el proyecto CodeBuild existente.
Qué configuración CI/CD cumple con todos los requisitos?
A.
Configure CodePipeline con una etapa de implementación mediante AWS CodeDeploy configurado para la implementación in situ. Supervise el código recién implementado y, si hay algún problema, presione otra actualización de código
B.
Configure CodePipeline con una etapa de implementación mediante AWS CodeDeploy configurado para implementaciones azul/verde. Supervise el código recién implementado y, si hay algún problema, active una reversión manual usando CodeDeploy.
C.
Configure CodePipeline con una etapa de implementación mediante AWS CloudFormation para crear una canalización para pilas de prueba y producción. Supervise el código recién implementado y, si hay algún problema, presione otra actualización de código.
D.
Configure CodePipeline con una etapa de implementación mediante AWS OPSWorks e implementaciones in place. Supervise el código recién implementado y, si hay algún problema, presione otra actualización de código.
ResponderDiscusión
Correct Answer: B
Para cumplir con el requisito de implementar parches lo más rápido posible con un tiempo de inactividad mínimo y garantizar una rápida reversión en caso de errores, AWS CodePipeline configurado con CodeDeploy para implementaciones azul/verde es la mejor opción. La estrategia de despliegue azul/verde permite configurar dos entornos separados: uno con la versión actual (azul) y otro con la nueva versión (verde). Al cambiar el tráfico entre estos entornos, se minimiza el tiempo de inactividad. Además, en caso de errores con la nueva implementación, el tráfico se puede enrutar rápidamente de nuevo al entorno estable, lo que garantiza una reversión rápida y confiable. Esto cumple con los criterios de implementación rápida, tiempo de inactividad mínimo y reversión eficiente.
Question 364 of 529
Una empresa administra muchas cuentas de AWS mediante el uso de una organización en AWS Organizations. Diferentes unidades de negocio de la compañía ejecutan aplicaciones en instancias de Amazon EC2. Todas las instancias EC2 deben tener una etiqueta BusinessUnit para que la compañía pueda rastrear el costo de cada unidad de negocio.
Una auditoría reciente reveló que a algunas instancias les faltaba esta etiqueta. La compañía agregó manualmente la etiqueta faltante a las instancias.
Qué debe hacer un arquitecto de soluciones para hacer cumplir el requisito de etiquetado en el futuro?
A.
Habilite las políticas de etiquetas en la organización. Cree una política de etiquetas para la etiqueta BusinessUnit. Asegúrese de que el cumplimiento de las mayúsculas de la clave de etiqueta esté desactivado. Implementar la política de etiquetas para el tipo de recurso ec2:instance. Adjunte la política de etiquetas a la raíz de la organización.
B.
Habilite las políticas de etiquetas en la organización. Cree una política de etiquetas para la etiqueta BusinessUnit. Asegúrese de que el cumplimiento de las mayúsculas de la clave de etiqueta esté activado. Implementar la política de etiquetas para el tipo de recurso ec2:instance. Adjunte la política de etiquetas a la cuenta de administración de la organización.
C.
Crear un SCP y adjuntar el SCP a la raíz de la organización. Incluya la siguiente declaración en el SCP:
D.
Crear un SCP y adjuntar el SCP a la cuenta de administración de la organización. Incluya la siguiente declaración en el SCP:
ResponderDiscusión
Correct Answer: C
Para exigir que todas las instancias EC2 estén etiquetadas con la etiqueta BusinessUnit, debe crear una Política de Control de Servicios (SCP) y adjuntarla a la raíz de la organización. Esta política debe incluir una regla que deniegue la creación de instancias EC2 si falta la etiqueta BusinessUnit. Las políticas de etiquetas por sí solas no impedirán la creación de recursos sin etiquetas; en cambio, ayudan a garantizar que las etiquetas tengan los valores clave correctos. Los SCP, por otro lado, pueden hacer cumplir el requisito de etiquetado evitando la instanciación de recursos que no cumplan con los criterios de etiquetado. Por lo tanto, el enfoque correcto implica usar un SCP con la condición adecuada para denegar la creación de instancias EC2 cuando la etiqueta requerida no está presente.
Question 365 of 529
Una empresa está ejecutando una carga de trabajo que consiste en miles de instancias de Amazon EC2. La carga de trabajo se ejecuta en una VPC que contiene varias subredes públicas y subredes privadas. Las subredes públicas tienen una ruta para 0.0.0.0/0 a una puerta de enlace de Internet existente. Las subredes privadas tienen una ruta para 0.0.0.0/0 a una puerta de enlace NAT existente.
Un arquitecto de soluciones necesita migrar toda la flota de instancias EC2 para usar IPv6. Las instancias EC2 que se encuentran en subredes privadas no deben ser accesibles desde la Internet pública.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Actualice la VPC existente y asocie un bloque CIDR IPv6 personalizado con la VPC y todas las subredes. Actualice todas las tablas de rutas de VPC y agregue una ruta para: :/0 a la puerta de enlace de Internet.
B.
Actualice la VPC existente y asocie un bloque CIDR IPv6 proporcionado por Amazon con la VPC y todas las subredes. Actualice las tablas de rutas de VPC para todas las subredes privadas y agregue una ruta para: :/0 a la puerta de enlace NAT.
C.
Actualice la VPC existente y asocie un bloque CIDR IPv6 proporcionado por Amazon con la VPC y todas las subredes. Cree una puerta de enlace de Internet solo para egresos. Actualice las tablas de rutas de VPC para todas las subredes privadas y agregue una ruta para: :/0 a la puerta de enlace de Internet solo para egresos.
D.
Actualice la VPC existente y asocie un bloque CIDR IPV6 personalizado con la VPC y todas las subredes. Cree una nueva puerta de enlace NAT y habilite la compatibilidad con IPV6. Actualice las tablas de rutas de VPC para todas las subredes privadas y agregue una ruta para: :/0 a la puerta de enlace NAT habilitada para IPv6.
ResponderDiscusión
Correct Answer: C
El enfoque correcto es actualizar la VPC existente y asociar un bloque CIDR IPv6 proporcionado por Amazon con la VPC y todas las subredes. Para las subredes privadas, es necesario crear una puerta de enlace de Internet solo para egresos y actualizar las tablas de rutas de VPC para agregar una ruta para: :/0 a la puerta de enlace de Internet solo para egresos. Esto asegura que las instancias en subredes privadas puedan llegar a direcciones IPv6 en Internet para la comunicación saliente sin ser accesibles desde la Internet pública, alineándose con el requisito de mantener la privacidad.
Question 366 of 529
Una empresa está utilizando Amazon API Gateway para implementar una API REST privada que proporcionará acceso a datos confidenciales. La API debe ser accesible solo desde una aplicación que se despliega en una VPC. La compañía despliega la API con éxito. Sin embargo, no se puede acceder a la API desde una instancia de Amazon EC2 implementada en la VPC.
Qué solución proporcionará conectividad entre la instancia EC2 y la API?
A.
Cree un punto final de VPC de interfaz para API Gateway. Adjuntar una política de punto final que permita apigateway: * acciones. Deshabilite la nomenclatura DNS privada para el punto final de la VPC. Configure una política de recursos API que permita el acceso desde la VPC. Utilice el nombre DNS del punto final de la VPC para acceder a la API.
B.
Cree un punto final de VPC de interfaz para API Gateway. Adjunte una política de punto final que permita la acción Ejecute-API:Invoke. Habilite la nomenclatura DNS privada para el endpoint de VPC. Configure una directiva de recursos de API que permita el acceso desde el punto de enlace de la VPC. Utilice los nombres DNS del punto final de la API para acceder a la API.
C.
Cree un balanceador de carga de red (NLB) y un enlace de VPC. Configure la integración privada entre API Gateway y NLB. Utilice los nombres DNS del punto final de la API para acceder a la API.
D.
Cree un balanceador de carga de aplicaciones (ALB) y un enlace de VPC. Configure la integración privada entre API Gateway y ALB. Utilice el nombre DNS del extremo ALB para acceder a la API.
ResponderDiscusión
Correct Answer: B
Para proporcionar conectividad entre la instancia EC2 y la API REST privada implementada en Amazon API Gateway, el enfoque correcto implica el uso de un punto de enlace de VPC de interfaz. Al adjuntar una política de punto final que permita la acción Ejecute-API:Invocar y habilitar la nomenclatura DNS privada, la instancia de EC2 puede resolver y conectarse a la API usando nombres DNS predefinidos. Además, la configuración de una política de recursos de API que permita el acceso desde el punto de enlace de la VPC garantiza que la API solo sea accesible dentro de la VPC deseada, manteniendo así la seguridad. Por lo tanto, crear un punto final de VPC de interfaz con la configuración especificada es la solución adecuada.
Question 367 of 529
Una gran compañía de nóminas se fusionó recientemente con una pequeña empresa de personal. La compañía unificada ahora tiene múltiples unidades de negocio, cada una con su propia cuenta de AWS existente.
Un arquitecto de soluciones debe asegurarse de que la compañía pueda administrar centralmente las políticas de facturación y acceso para todas las cuentas de AWS. El arquitecto de soluciones configura AWS Organizations enviando una invitación a todas las cuentas miembros de la compañía desde una cuenta de administración centralizada.
Qué debe hacer el arquitecto de soluciones a continuación para cumplir con estos requisitos?
A.
Cree el grupo OrganizationAccountAccess IAM en cada cuenta de miembro. Incluya los roles de IAM necesarios para cada administrador.
B.
Cree la política OrganizationAccountAccessPolicy IAM en cada cuenta de miembro. Conecte las cuentas de miembro a la cuenta de administración mediante el acceso entre cuentas.
C.
Cree el rol OrganizationAccountAccessRole IAM en cada cuenta de miembro. Otorgar permiso a la cuenta de administración para que asuma el rol de IAM.
D.
Crear el rol OrganizationAccountAccessRole IAM en la cuenta de administración. Adjunte la política administrada de AdministratorAccess AWS al rol de IAM. Asigne el rol de IAM a los administradores en cada cuenta de miembro.
ResponderDiscusión
Correct Answer: C
Para administrar de forma centralizada las políticas de facturación y acceso para todas las cuentas de AWS mediante AWS Organizations, el arquitecto de soluciones debe crear el rol de IAM de OrganizationAccountAccessRole en cada cuenta de miembro. Este rol de IAM debe otorgar permiso a la cuenta de administración para que asuma el rol. Esta configuración permite a los administradores de la cuenta de administración asumir el rol de IAM en las cuentas de los miembros, lo que permite la administración centralizada y el control de acceso en todas las cuentas.
Question 368 of 529
Una empresa cuenta con servicios de aplicaciones que han sido contenerizados e implementados en múltiples instancias de Amazon EC2 con IP públicas. Se ha desplegado un clúster Apache Kafka en las instancias EC2. Se ha migrado una base de datos PostgreSQL a Amazon RDS para PostgreSQL. La compañía espera un aumento significativo de los pedidos en su plataforma cuando se lance una nueva versión de su producto estrella.
Qué cambios en la arquitectura actual reducirán la sobrecarga operativa y darán soporte al lanzamiento del producto?
A.
Cree un grupo EC2 Auto Scaling detrás de un balanceador de carga de aplicaciones. Cree réplicas de lectura adicionales para la instancia de base de datos. Cree transmisiones de datos de Amazon Kinesis y configure los servicios de aplicaciones para usar las transmisiones de datos. Almacene y sirva contenido estático directamente desde Amazon S3.
B.
Cree un grupo EC2 Auto Scaling detrás de un balanceador de carga de aplicaciones. Implemente la instancia de base de datos en modo Multi-AZ y habilite el escalado automático de almacenamiento. Cree transmisiones de datos de Amazon Kinesis y configure los servicios de aplicaciones para usar las transmisiones de datos. Almacene y sirva contenido estático directamente desde Amazon S3.
C.
Implemente la aplicación en un clúster de Kubernetes creado en las instancias EC2 detrás de un balanceador de carga de aplicaciones. Implemente la instancia de base de datos en modo Multi-AZ y habilite el escalado automático de almacenamiento. Cree un clúster de Amazon Managed Streaming para Apache Kafka y configure los servicios de aplicaciones para usar el clúster. Almacene contenido estático en Amazon S3 detrás de una distribución de Amazon CloudFront.
D.
Implemente la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS) con AWS Fargate y habilite el escalado automático detrás de un balanceador de carga de aplicaciones. Cree réplicas de lectura adicionales para la instancia de base de datos. Cree un clúster de Amazon Managed Streaming para Apache Kafka y configure los servicios de aplicaciones para usar el clúster. Almacene contenido estático en Amazon S3 detrás de una distribución de Amazon CloudFront.
ResponderDiscusión
Correct Answer: D
Para reducir la sobrecarga operativa y mejorar la eficiencia, los servicios de aplicaciones deben implementarse en Amazon Elastic Kubernetes Service (EKS) con AWS Fargate, lo que proporciona una experiencia sin servidor para contenedores y reduce la necesidad de administrar instancias EC2 directamente. Habilitar el escalado automático con Fargate manejará picos inesperados en el tráfico. La implementación de la base de datos en modo Multi-AZ con réplicas de lectura garantiza una alta disponibilidad y tolerancia a fallas, cumpliendo con el aumento esperado de pedidos. El uso de Amazon Managed Streaming para Apache Kafka garantiza servicios Kafka gestionados y escalables, reduciendo la carga operativa. El almacenamiento de contenido estático en Amazon S3 detrás de una distribución de CloudFront garantiza una alta disponibilidad y una entrega de contenido más rápida, lo que respalda aún más el lanzamiento del producto.
Question 369 of 529
Una empresa aloja una VPN en un centro de datos local. Actualmente, los empleados se conectan a la VPN para acceder a los archivos de sus directorios de inicio de Windows. Recientemente, ha habido un gran crecimiento en el número de empleados que trabajan de forma remota. Como resultado, el uso del ancho de banda para las conexiones al centro de datos ha comenzado a alcanzar el 100% durante el horario comercial.
La compañía debe diseñar una solución en AWS que respalde el crecimiento de la fuerza de trabajo remota de la compañía, reduzca el uso de ancho de banda para las conexiones al centro de datos y reduzca la sobrecarga operativa.
Qué combinación de pasos cumplirá estos requisitos con la menor sobrecarga operativa? (Elija dos.)
A.
Cree una puerta de enlace de volúmenes de AWS Storage Gateway. Monte un volumen desde Volume Gateway al servidor de archivos local.
B.
Migre los directorios de inicio a Amazon FSx para Windows File Server.
C.
Migrar los directorios de inicio a Amazon FSx para Lustre.
D.
Migre usuarios remotos a AWS Client VPN.
E.
Cree una conexión de AWS Direct Connect desde el centro de datos local a AWS.
ResponderDiscusión
Correct Answer: B, D
Diseñar una solución en AWS que respalde el crecimiento de la fuerza de trabajo remota de la compañía, reduzca el uso de ancho de banda para las conexiones al centro de datos y reduzca la sobrecarga operativa, migrar los directorios de inicio a Amazon FSx para Windows File Server y migrar usuarios remotos a AWS Client VPN son los pasos más adecuados. Amazon FSx para Windows File Server proporciona un sistema de archivos nativo de Windows completamente administrado, lo que simplifica el proceso de almacenamiento de archivos y reduce la sobrecarga operativa. AWS Client VPN permite a los usuarios remotos conectarse de forma segura a los recursos de AWS, incluido Amazon FSx para Windows File Server, sin depender de la infraestructura VPN local, lo que reduce el uso del ancho de banda en el centro de datos.
Question 370 of 529
Una empresa tiene múltiples cuentas de AWS. La compañía recientemente tuvo una auditoría de seguridad que reveló muchos volúmenes no cifrados de Amazon Elastic Block Store (Amazon EBS) conectados a instancias de Amazon EC2.
Un arquitecto de soluciones debe cifrar los volúmenes no cifrados y asegurarse de que los volúmenes no cifrados se detecten automáticamente en el futuro. Además, la compañía quiere una solución que pueda administrar de forma centralizada múltiples cuentas de AWS con un enfoque en el cumplimiento y la seguridad.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Crear una organización en AWS Organizations. Configure AWS Control Tower y active los controles altamente recomendados (barandas). Únete a todas las cuentas a la organización. Categorizar las cuentas de AWS en unidades organizativas.
B.
Utilice la CLI de AWS para enumerar todos los volúmenes no cifrados en todas las cuentas de AWS. Ejecute un script para cifrar todos los volúmenes no cifrados en su lugar.
C.
Crea una instantánea de cada volumen sin encriptar. Cree un nuevo volumen cifrado a partir de la instantánea no cifrada. Separe el volumen existente y reemplázelo por el volumen cifrado.
D.
Crear una organización en AWS Organizations. Configure AWS Control Tower y encienda los controles obligatorios (barandillas). Únete a todas las cuentas a la organización. Categorizar las cuentas de AWS en unidades organizativas.
E.
Encienda AWS CloudTrail. Configure una regla de Amazon EventBridge para detectar y cifrar automáticamente volúmenes no cifrados.
ResponderDiscusión
Correct Answer: A, C
Para cumplir con los requisitos de encriptar volúmenes de EBS no cifrados y garantizar que los volúmenes no cifrados se detecten automáticamente en el futuro, son necesarios dos pasos. Primero, configurar AWS Control Tower y activar los controles altamente recomendados (barandas) dentro de una organización en AWS Organizations proporcionará una administración centralizada en varias cuentas de AWS con un enfoque en el cumplimiento y la seguridad. Esta configuración permitirá el monitoreo continuo para detectar cualquier volumen de EBS sin cifrar. En segundo lugar, dado que los volúmenes de EBS no se pueden cifrar en su lugar, es necesario crear primero una instantánea de cada volumen sin cifrar, crear un nuevo volumen cifrado a partir de la instantánea sin cifrar y luego separar el volumen no cifrado existente y reemplazarlo con el volumen cifrado. Esto asegura que todos los volúmenes estén cifrados según sea necesario.
Question 371 of 529
Una empresa aloja una aplicación web de intranet en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). Actualmente, los usuarios se autentican en la aplicación contra una base de datos interna de usuarios.
La compañía necesita autenticar a los usuarios en la aplicación mediante un directorio existente de AWS Directory Service para Microsoft Active Directory. Todos los usuarios con cuentas en el directorio deben tener acceso a la aplicación.
Qué solución cumplirá con estos requisitos?
A.
Crea un nuevo cliente de app en el directorio. Cree una regla de oyente para el ALB. Especifique la acción autenticar-oidc para la regla del listener. Configure la regla de escucha con el emisor, el ID de cliente y el secreto adecuados, y los detalles de punto final para el servicio de Active Directory. Configure el nuevo cliente de la aplicación con la URL de devolución de llamada que proporciona el ALB.
B.
Configure un grupo de usuarios de Amazon Cognito. Configure el grupo de usuarios con un proveedor de identidades federadas (LdP) que tenga metadatos del directorio. Crear un cliente de aplicación. Asociar el cliente de la aplicación con el grupo de usuarios. Cree una regla de escucha para ALEspecifique la acción autenticar-cognito para la regla de escucha. Configure la regla de escucha para usar el grupo de usuarios y el cliente de la aplicación.
C.
Agregue el directorio como un nuevo proveedor de identidad de IAM (LdP). Cree un nuevo rol de IAM que tenga un tipo de entidad de federación SAML 2.0. Configure una política de rol que permita el acceso al ALB. Configure el nuevo rol como el rol de usuario autenticado predeterminado para el LdP. Cree una regla de oyente para el ALB. Especifique la acción autenticar-oidc para la regla del listener.
D.
Habilite AWS IAM Identity Center (AWS Single Sign-On). Configure el directorio como un proveedor de identidad externo (LdP) que utilice SAML. Utilice el método de aprovisionamiento automático. Cree un nuevo rol de IAM que tenga un tipo de entidad de federación SAML 2.0. Configure una política de rol que permita el acceso al ALB. Adjuntar el nuevo rol a todos los grupos. Cree una regla de oyente para el ALB. Especifique la acción autenticado-cognito para la regla del listener.
ResponderDiscusión
Correct Answer: B
La compañía necesita autenticar a los usuarios en una aplicación web interna mediante AWS Directory Service para Microsoft Active Directory. Una de las soluciones más adecuadas es utilizar Amazon Cognito, que puede federar identidades desde el servicio de directorio. La configuración de un grupo de usuarios de Amazon Cognito con un proveedor de identidad federado mediante metadatos del directorio permite una integración perfecta con el Active Directory existente. Crear un cliente de aplicación asociado a este grupo de usuarios y una regla de escucha para el ALB que especifique la acción autenticar-cognito garantizará que los usuarios se autentiquen correctamente. Esta configuración cumple con el requisito de aprovechar el AWS Directory Service existente para la autenticación de usuarios.
Question 372 of 529
Una empresa tiene un sitio web que atiende a muchos visitantes. La compañía implementa un servicio de backend para el sitio web en una región primaria de AWS y una región de recuperación ante desastres (DR).
Se implementa una única distribución de Amazon CloudFront para el sitio web. La compañía crea un conjunto de registros Amazon Route 53 con comprobaciones de estado y una política de enrutamiento de conmutación por error para el servicio backend de la Región principal. La compañía configura el conjunto de registros Route 53 como origen para la distribución de CloudFront. La compañía configura otro conjunto de registros que apunta al punto final del servicio backend en la región DR como un tipo de registro de conmutación por error secundario. El TTL para ambos conjuntos de registros es de 60 segundos.
Actualmente, la conmutación por error tarda más de 1 minuto. Un arquitecto de soluciones debe diseñar una solución que proporcione el tiempo de conmutación por error más rápido.
Qué solución logrará este objetivo?
A.
Implementar una distribución adicional de CloudFront. Cree un nuevo conjunto de registros de conmutación por error de Route 53 con comprobaciones de estado para ambas distribuciones de CloudFront.
B.
Establezca el TTL en 4 segundos para los conjuntos de registros existentes de Route 53 que se utilizan para el servicio de backend en cada región.
C.
Cree nuevos conjuntos de registros para los servicios de backend mediante una política de enrutamiento de latencia. Utilice los conjuntos de registros como origen en la distribución de CloudFront.
D.
Cree un grupo de origen de CloudFront que incluya dos orígenes, uno para cada región de servicio de backend. Configure la conmutación por error de origen como un comportamiento de caché para la distribución de CloudFront.
ResponderDiscusión
Correct Answer: D
Para lograr el tiempo de conmutación por error más rápido, crear un grupo de origen de CloudFront que incluya dos orígenes, uno para cada región de servicio de backend, y configurar la conmutación por error de origen como un comportamiento de caché para la distribución de CloudFront es el mejor enfoque. Este método permite que CloudFront cambie inmediatamente al origen de backup si detecta una falla, lo que proporciona una conmutación por error más rápida en comparación con la conmutación por error basada en DNS que se basa en la configuración de TTL. Esta configuración minimiza el tiempo de inactividad y garantiza que las solicitudes se redireccionen rápidamente al servicio de backend operativo.
Question 373 of 529
Una empresa utiliza varias cuentas de AWS y tiene varios equipos de DevOps que ejecutan cargas de trabajo de producción y no producción en estas cuentas. A la compañía le gustaría restringir centralmente el acceso a algunos de los servicios de AWS que los equipos de DevOps no utilizan. La compañía decidió utilizar AWS Organizations e invitó con éxito a todas las cuentas de AWS a la Organización. A ellos les gustaría permitir el acceso a servicios que actualmente están en uso y negar algunos servicios específicos. También les gustaría administrar múltiples cuentas juntas como una sola unidad.
Qué combinación de pasos debe tomar el arquitecto de soluciones para satisfacer estos requisitos? (Elija tres.)
A.
Usa una estrategia de Denegar lista.
B.
Revise el Access Advisor en AWS IAM para determinar los servicios utilizados recientemente
C.
Revise el informe de AWS Trusted Advisor para determinar los servicios utilizados recientemente.
D.
Elimine el SCP predeterminado de FullawsAccess.
E.
Definir las unidades organizativas (OU) y colocar las cuentas de los miembros en las unidades organizativas.
F.
Elimine el SCP DenyawsAccess predeterminado.
ResponderDiscusión
Correct Answer: A, B, E
Para restringir de manera centralizada el acceso a los servicios de AWS que los equipos de DevOps no utilizan, el arquitecto de soluciones debe implementar los siguientes pasos. Utilice una estrategia Denegar lista para denegar explícitamente el acceso a los servicios de AWS específicos que no son necesarios. De esta manera, todos los demás servicios permanecen accesibles, alineándose con los requerimientos de la compañía. Revise Access Advisor en AWS IAM para determinar qué servicios se han utilizado recientemente. Esto ayuda a identificar los servicios que se utilizan activamente y distinguirlos de aquellos que pueden restringirse. Adicionalmente, definir unidades organizativas (OU) y colocar las cuentas de los miembros en estas unidades organizativas ayudará a administrar múltiples cuentas juntas como una sola unidad. Esta estructura organizativa simplifica la gestión de las políticas en múltiples cuentas.
Question 374 of 529
Una empresa de eventos en vivo está diseñando una solución de escalado para su aplicación de tickets en AWS. La aplicación tiene altos picos de utilización durante eventos de venta. Cada evento de venta es un evento único que está programado. La aplicación se ejecuta en instancias de Amazon EC2 que se encuentran en un grupo de Auto Scaling. La aplicación utiliza PostgreSQL para la capa de base de datos.
La compañía necesita una solución de escalado para maximizar la disponibilidad durante los eventos de venta.
Qué solución cumplirá con estos requisitos?
A.
Utilice una política de escalado predictivo para las instancias EC2. Aloje la base de datos en una instancia de base de datos Multi-AZ de Amazon Aurora PostgreSQL Serverless v2 con réplicas de lectura que escalan automáticamente. Cree una máquina de estado AWS Step Functions para ejecutar funciones paralelas de AWS Lambda para precalentar la base de datos antes de un evento de venta. Cree una regla de Amazon EventBridge para invocar la máquina de estado.
B.
Utilice una política de escalado programado para las instancias EC2. Aloje la base de datos en una instancia de base de datos de Amazon RDS para PostgreSQL Mulli-AZ con réplicas de lectura de escalado automático. Cree una regla de Amazon EventBridge que invoque una función de AWS Lambda para crear una réplica de lectura más grande antes de un evento de venta. Fallar a la réplica de lectura más grande. Cree otra regla EventBridge que invoque otra función Lambda para reducir la réplica de lectura después del evento de venta.
C.
Utilice una política de escalado predictivo para las instancias EC2. Aloje la base de datos en una instancia de base de datos de Amazon RDS para PostgreSQL MultiAZ con réplicas de lectura de escalado automático. Cree una máquina de estado AWS Step Functions para ejecutar funciones paralelas de AWS Lambda para precalentar la base de datos antes de un evento de venta. Cree una regla de Amazon EventBridge para invocar la máquina de estado.
D.
Utilice una política de escalado programado para las instancias EC2. Hospedar la base de datos en un clúster de base de datos Multi-AZ de Amazon Aurora PostgreSQL. Cree una regla de Amazon EventBridge que invoque una función de AWS Lambda para crear una réplica Aurora más grande antes de un evento de venta. Fallar a la réplica Aurora más grande. Cree otra regla EventBridge que invoque otra función Lambda para reducir la réplica Aurora después del evento de venta.
ResponderDiscusión
Correct Answer: D
Utilice una política de escalado programado para las instancias EC2. Hospedar la base de datos en un clúster de base de datos Multi-AZ de Amazon Aurora PostgreSQL. Cree una regla de Amazon EventBridge que invoque una función de AWS Lambda para crear una réplica Aurora más grande antes de un evento de venta. Fallar a la réplica Aurora más grande. Cree otra regla EventBridge que invoque otra función Lambda para reducir la réplica Aurora después del evento de venta. Esta solución aprovecha el alto rendimiento y la fiabilidad de Amazon Aurora, utiliza escalado programado para manejar picos predecibles de alto tráfico y garantiza una utilización eficiente de los recursos escalando hacia arriba y hacia abajo según sea necesario.
Question 375 of 529
Una empresa ejecuta una aplicación de intranet en las instalaciones. La compañía quiere configurar una copia de seguridad en la nube de la aplicación. La compañía ha seleccionado AWS Elastic Disaster Recovery para esta solución.
La compañía requiere que el tráfico de replicación no viaje a través de la internet pública. La aplicación tampoco debe ser accesible desde internet. La compañía no quiere que esta solución consuma todo el ancho de banda de red disponible porque otras aplicaciones requieren ancho de banda.
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Cree una VPC que tenga al menos dos subredes privadas, dos puertas de enlace NAT y una puerta de enlace privada virtual.
B.
Cree una VPC que tenga al menos dos subredes públicas, una puerta de enlace privada virtual y una puerta de enlace a Internet.
C.
Cree una conexión VPN de sitio a sitio de AWS entre la red local y la red de AWS de destino.
D.
Cree una conexión AWS Direct Connect y una puerta de enlace Direct Connect entre la red local y la red de AWS de destino.
E.
Durante la configuración de los servidores de replicación, seleccione la opción para usar direcciones IP privadas para la replicación de datos.
F.
Durante la configuración de los ajustes de inicio para los servidores de destino, seleccione la opción para asegurarse de que la dirección IP privada de la instancia de recuperación coincida con la dirección IP privada del servidor de origen.
ResponderDiscusión
Correct Answer: A, D, E
Para cumplir con los requisitos de la compañía, que incluyen garantizar que el tráfico de replicación no viaje a través de Internet público y evitar el consumo de todo el ancho de banda de red disponible, se recomiendan los siguientes pasos. Primero, cree una VPC con al menos dos subredes privadas y una puerta de enlace privada virtual para garantizar que la aplicación permanezca inaccesible desde Internet. AWS Direct Connect debe utilizarse para establecer una conexión privada dedicada entre la red local y la red de AWS, evitando así la competencia potencial de ancho de banda con otras aplicaciones. Durante la configuración de los servidores de replicación, seleccionar la opción de usar direcciones IP privadas para la replicación de datos asegurará que el tráfico de replicación permanezca dentro de la red privada.
Question 376 of 529
Una empresa que proporciona servicios de almacenamiento de imágenes quiere implementar una solución orientada al cliente en AWS. Millones de clientes individuales utilizarán la solución. La solución recibirá lotes de archivos de imagen de gran tamaño, cambiará el tamaño de los archivos y almacenará los archivos en un bucket de Amazon S3 hasta por 6 meses.
La solución debe manejar varianza significativa en la demanda. La solución también debe ser confiable a escala empresarial y tener la capacidad de volver a ejecutar los trabajos de procesamiento en caso de falla.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Utilice AWS Step Functions para procesar el evento S3 que se produce cuando un usuario almacena una imagen. Ejecute una función de AWS Lambda que cambie el tamaño de la imagen en su lugar y sustituya el archivo original en el bucket S3. Cree una política de caducidad del ciclo de vida de S3 para caducar todas las imágenes almacenadas después de 6 meses.
B.
Utilice Amazon EventBridge para procesar el evento S3 que se produce cuando un usuario carga una imagen. Ejecute una función de AWS Lambda que cambie el tamaño de la imagen en su lugar y sustituya el archivo original en el bucket S3. Cree una política de caducidad del ciclo de vida de S3 para caducar todas las imágenes almacenadas después de 6 meses.
C.
Utilice Notificaciones de eventos S3 para invocar una función de AWS Lambda cuando un usuario almacene una imagen. Utilice la función Lambda para cambiar el tamaño de la imagen en su lugar y para almacenar el archivo original en el bucket S3. Cree una política de ciclo de vida de S3 para mover todas las imágenes almacenadas a S3 Standard-Infrequent Access (S3 Standard-IA) después de 6 meses.
D.
Utilice Amazon Simple Queue Service (Amazon SQS) para procesar el evento S3 que se produce cuando un usuario almacena una imagen. Ejecute una función de AWS Lambda que cambie el tamaño de la imagen y almacene el archivo redimensionado en un bucket S3 que utilice S3 Standard-Infrequent Access (S3 Standard-IA). Cree una política de ciclo de vida de S3 para mover todas las imágenes almacenadas a S3 Glacier Deep Archive después de 6 meses.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de manejo de varianza significativa en la demanda, confiabilidad a escala empresarial y la capacidad de volver a ejecutar trabajos de procesamiento en caso de falla, usar Notificaciones de eventos S3 para activar una función de AWS Lambda es un enfoque apropiado. Esto asegura escalabilidad y confiabilidad. La función Lambda puede manejar eficientemente el cambio de tamaño de la imagen en su lugar. Además, la creación de una política de ciclo de vida de S3 para mover archivos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 6 meses se alinea con la solución de almacenamiento rentable. El enfoque redundante de archivar o agregar pasos para almacenamiento de información de solo 6 meses en la Opción D es innecesario, lo que convierte a la Opción C en la opción más rentable y práctica.
Question 377 of 529
Una empresa tiene una organización en AWS Organizations que incluye una cuenta de AWS separada para cada uno de los departamentos de la compañía. Equipos de aplicaciones de diferentes departamentos desarrollan e implementan soluciones de forma independiente.
La compañía quiere reducir los costos de cómputos y administrar los costos de manera adecuada en todos los departamentos. La compañía también quiere mejorar la visibilidad de la facturación para departamentos individuales. La compañía no quiere perder flexibilidad operativa cuando la compañía selecciona recursos de cómputos.
Qué solución cumplirá con estos requisitos?
A.
Utilice los presupuestos de AWS para cada departamento. Utilice el Editor de etiquetas para aplicar etiquetas a los recursos apropiados. Compra Planes de Ahorro de Instancias EC2.
B.
Configure las organizaciones de AWS para que utilicen la facturación consolidada. Implementar una estrategia de etiquetado que identifique departamentos. Utilice SCP para aplicar etiquetas a los recursos apropiados. Compra Planes de Ahorro de Instancias EC2.
C.
Configure las organizaciones de AWS para que utilicen la facturación consolidada. Implementar una estrategia de etiquetado que identifique departamentos. Utilice el Editor de etiquetas para aplicar etiquetas a los recursos apropiados. Compra Planes de Ahorro de Cómputos.
D.
Utilice los presupuestos de AWS para cada departamento. Utilice SCP para aplicar etiquetas a los recursos apropiados. Compra Planes de Ahorro de Cómputos.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de la compañía de reducir los costos informáticos, administrar los costos en todos los departamentos y mejorar la visibilidad de la facturación sin perder flexibilidad operativa, el mejor enfoque es configurar las organizaciones de AWS para que utilicen la facturación consolidada. La facturación consolidada proporcionará una visión centralizada de los costos incurridos por cada departamento. La implementación de una estrategia de etiquetado y el uso del Editor de etiquetas para aplicar estas etiquetas garantiza que los recursos y costos de cada departamento puedan identificarse y rastrearse con precisión. Además, comprar planes de ahorro de cómputos es ventajoso porque estos planes ofrecen ahorros de costos para una variedad de recursos informáticos, incluidas instancias EC2, AWS Fargate y AWS Lambda, manteniendo así la flexibilidad operativa.
Question 378 of 529
Una empresa tiene una aplicación web que carga fotos y videos de forma segura a un bucket de Amazon S3. La compañía requiere que solo los usuarios autenticados puedan publicar contenido. La aplicación genera una URL prefirmada que se utiliza para cargar objetos a través de una interfaz de navegador. La mayoría de los usuarios están reportando tiempos de carga lentos para objetos de más de 100 MB.
Qué puede hacer un arquitecto de soluciones para mejorar el rendimiento de estas cargas y garantizar que solo los usuarios autenticados puedan publicar contenido?
A.
Configure una puerta de enlace de API de Amazon con un punto final de API optimizado para bordes que tenga un recurso como proxy de servicio S3. Configure el método PUT para este recurso para exponer la operación S3 PutObject. Proteja la puerta de enlace API usando un autorizador COGNITO_USER_POOLS. Haga que la interfaz del navegador use API Gateway en lugar de la URL prefirmada para cargar objetos.
B.
Configure una puerta de enlace de API de Amazon con un punto final de API regional que tenga un recurso como proxy de servicio S3. Configure el método PUT para este recurso para exponer la operación S3 PutObject. Proteja la puerta de enlace API con un autorizador de AWS Lambda. Haga que la interfaz del navegador use API Gateway en lugar de la URL prefirmada para cargar objetos.
C.
Habilite un punto final de Aceleración de transferencia S3 en el bucket S3. Utilice el punto final al generar la URL prefirmada. Haga que la interfaz del navegador cargue los objetos a esta URL usando la API de carga multiparte S3.
D.
Configure una distribución de Amazon CloudFront para el bucket S3 de destino. Habilite los métodos PUT y POST para el comportamiento de la caché de CloudFront. Actualice el origen de CloudFront para usar una identidad de acceso de origen (OAI). Otorgar al usuario de OAI 3: PutObject permisos en la política de bucket. Hacer que la interfaz del navegador cargue objetos usando la distribución CloudFront.
ResponderDiscusión
Correct Answer: C
El uso de S3 Transfer Acceleration y la carga multiparte aborda directamente el problema de las cargas lentas para objetos grandes. Habilitar la aceleración de transferencia S3 permite el uso de ubicaciones de borde para acelerar la transferencia de datos al bucket S3. Además, la API de carga multiparte puede optimizar la velocidad de carga dividiendo el archivo en partes más pequeñas. Las URL prefirmadas mantienen el requisito de que solo los usuarios autenticados pueden cargar contenido, ya que se generan con credenciales de autenticación y tienen permisos temporales.
Question 379 of 529
Una gran empresa está migrando toda su cartera de TI a AWS. Cada unidad de negocio de la compañía tiene una cuenta de AWS independiente que admite entornos de desarrollo y prueba. Pronto se necesitarán nuevas cuentas para soportar cargas de trabajo de producción.
El departamento de finanzas requiere un método de pago centralizado pero debe mantener la visibilidad del gasto de cada grupo para asignar costos.
El equipo de seguridad requiere un mecanismo centralizado para controlar el uso de IAM en todas las cuentas de la compañía.
Qué combinación de las siguientes opciones satisface las necesidades de la compañía con el MENOR esfuerzo? (Elija dos.)
A.
Utilice una colección de plantillas parametrizadas de AWS CloudFormation que definan permisos de IAM comunes que se lanzan en cada cuenta. Requerir que todas las cuentas nuevas y existentes lancen las pilas apropiadas para aplicar el modelo de menor privilegio.
B.
Utilice AWS Organizations para crear una nueva organización a partir de una cuenta de pagador elegida y definir una jerarquía de unidades organizativas. Invite a las cuentas existentes a unirse a la organización y crear nuevas cuentas usando Organizaciones.
C.
Requerir que cada unidad de negocio utilice sus propias cuentas de AWS. Etiquete cada cuenta de AWS de manera adecuada y habilite Cost Explorer para administrar reversiones de cargo.
D.
Habilite todas las funciones de las organizaciones de AWS y establezca políticas de control de servicios adecuadas que filtren los permisos de IAM para las subcuentas.
E.
Consolide todas las cuentas de AWS de la compañía en una sola cuenta de AWS. Use etiquetas para fines de facturación y la función Access Advisor de IAM para aplicar el modelo de menor privilegio.
ResponderDiscusión
Correct Answer: B, D
El uso de AWS Organizations para crear una nueva organización a partir de una cuenta de pagador elegida y definir una jerarquía de unidades organizativas aborda los requisitos del departamento de finanzas de un método de pago centralizado mientras se mantiene la visibilidad de los gastos de cada grupo. Además, al habilitar todas las funciones de las organizaciones de AWS y establecer políticas de control de servicios adecuadas, se filtran los permisos de IAM de manera efectiva para el control centralizado del equipo de seguridad del uso de IAM en todas las cuentas de la empresa. Esta combinación satisface las necesidades con el menor esfuerzo y garantiza políticas adecuadas de asignación de costos, administración y seguridad.
Question 380 of 529
Una empresa cuenta con una solución que analiza datos meteorológicos de miles de estaciones meteorológicas. Las estaciones meteorológicas envían los datos a través de una API REST de Amazon API Gateway que tiene una integración con la función AWS Lambda. La función Lambda llama a un servicio de terceros para el preprocesamiento de datos. El servicio de terceros se sobrecarga y falla el preprocesamiento, provocando una pérdida de datos.
Un arquitecto de soluciones debe mejorar la resiliencia de la solución. El arquitecto de soluciones debe asegurarse de que no se pierdan datos y que los datos puedan procesarse posteriormente si ocurren fallas.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una cola de Amazon Simple Queue Service (Amazon SQS). Configure la cola como cola de letra muerta para la API.
B.
Cree dos colas de Amazon Simple Queue Service (Amazon SQS): una cola principal y otra secundaria. Configure la cola secundaria como la cola de letra muerta para la cola principal. Actualice la API para usar una nueva integración a la cola principal. Configure la función Lambda como el destino de invocación para la cola principal.
C.
Cree dos autobuses para eventos Amazon EventBridge: un autobús de eventos principal y un autobús de eventos secundario. Actualice la API para usar una nueva integración en el bus de eventos principal. Configure una regla EventBridge para que reaccione a todos los eventos en el bus de eventos principal. Especifique la función Lambda como destino de la regla. Configure el bus de eventos secundario como destino de falla para la función Lambda.
D.
Cree un autobús de eventos personalizado de Amazon EventBridge. Configure el bus de eventos como destino de falla para la función Lambda.
ResponderDiscusión
Correct Answer: B
Para garantizar que no se pierdan datos y que los datos puedan procesarse posteriormente si ocurren fallas, crear dos colas de Amazon Simple Queue Service (Amazon SQS) es la solución más confiable. La cola principal servirá como punto de recopilación inicial para los datos de la puerta de enlace API, y la cola secundaria actuará como cola de letra muerta (DLQ). En esta configuración, si el servicio de terceros falla durante el preprocesamiento, los datos no procesados se moverán a la cola secundaria. Esto permite el posterior reprocesamiento de los datos una vez resueltos los problemas, mejorando efectivamente la resiliencia de la solución.
Question 381 of 529
Una empresa construyó un sitio web de comercio electrónico en AWS utilizando una arquitectura web de tres niveles. La aplicación está basada en Java y está compuesta por una distribución de Amazon CloudFront, una capa de servidor web Apache de instancias de Amazon EC2 en un grupo de Auto Scaling y una base de datos backend de Amazon Aurora MySQL.
El mes pasado, durante un evento de ventas promocionales, los usuarios reportaron errores y tiempos de espera al agregar artículos a sus carritos de compras. El equipo de operaciones recuperó los registros creados por los servidores web y revisó las métricas de rendimiento del clúster Aurora DB. Algunos de los servidores web se terminaron antes de que se pudieran recopilar los registros y las métricas de Aurora no fueron suficientes para el análisis del rendimiento de las consultas.
Qué combinación de pasos debe tomar el arquitecto de soluciones para mejorar la visibilidad del rendimiento de las aplicaciones durante los eventos de pico de tráfico? (Elija tres.)
A.
Configure el clúster de base de datos Aurora MySQL para publicar registros lentos de consultas y errores en Amazon CloudWatch Logs.
B.
Implemente el SDK de AWS X-Ray para rastrear las solicitudes HTTP entrantes en las instancias EC2 e implementar el rastreo de consultas SQL con el SDK de X-Ray para Java.
C.
Configure el clúster de base de datos Aurora MySQL para transmitir registros lentos de consultas y errores a Amazon Kinesis.
D.
Instale y configure un agente de Amazon CloudWatch Logs en las instancias EC2 para enviar los registros de Apache a CloudWatch Logs.
E.
Habilitar y configurar AWS CloudTrail para recopilar y analizar la actividad de las aplicaciones de Amazon EC2 y Aurora
F.
Habilite la evaluación comparativa del rendimiento del clúster de base de datos Aurora MySQL y publique la transmisión en AWS X-Ray.
ResponderDiscusión
Correct Answer: A, B, D
Para mejorar la visibilidad del rendimiento de las aplicaciones durante los eventos de pico de tráfico, configure el clúster de base de datos Aurora MySQL para publicar registros lentos de consultas y errores en Amazon CloudWatch Logs. Esto ayudará a analizar y diagnosticar problemas de rendimiento de bases de datos. Implemente el SDK de AWS X-Ray para rastrear las solicitudes HTTP entrantes en las instancias EC2 y rastrear las consultas SQL para obtener información sobre cómo estas consultas afectan el rendimiento. Además, instale y configure un agente de Amazon CloudWatch Logs en las instancias EC2 para enviar los registros de Apache a CloudWatch Logs, proporcionando una ubicación centralizada para el análisis de registros.
Question 382 of 529
Una empresa que provee bolsas de trabajo para una fuerza laboral estacional está viendo un aumento en el tráfico y el uso. Los servicios backend se ejecutan en un par de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones con Amazon DynamoDB como almacén de datos. El tráfico de lectura y escritura de aplicaciones es lento durante las temporadas pico.
Qué opción proporciona una arquitectura de aplicaciones escalable para manejar las temporadas pico con el MENOR esfuerzo de desarrollo?
A.
Migre los servicios backend a AWS Lambda. Aumentar la capacidad de lectura y escritura de DynamoDB.
B.
Migre los servicios backend a AWS Lambda. Configure DynamoDB para usar tablas globales.
C.
Utilice grupos de Auto Scaling para los servicios de backend. Utilice el escalado automático de DynamoDB.
D.
Utilice grupos de Auto Scaling para los servicios de backend. Utilice Amazon Simple Queue Service (Amazon SQS) y una función de AWS Lambda para escribir en DynamoDB.
ResponderDiscusión
Correct Answer: C
El uso de grupos de Auto Scaling para los servicios backend y el escalado automático de DynamoDB proporciona una arquitectura de aplicación escalable para manejar las estaciones pico con el menor esfuerzo de desarrollo. Auto Scaling garantiza que las instancias EC2 escalen automáticamente hacia dentro o hacia fuera según las demandas de tráfico, sin requerir cambios significativos en la arquitectura ni reescribir la aplicación para AWS Lambda. El escalado automático de DynamoDB ajusta dinámicamente la capacidad de lectura y escritura de las tablas, lo que garantiza que la base de datos pueda manejar las variaciones de tráfico de manera eficiente.
Question 383 of 529
Una empresa está migrando a la nube. Quiere evaluar las configuraciones de las máquinas virtuales en su entorno de centro de datos existente para garantizar que pueda dimensionar las nuevas instancias de Amazon EC2 con precisión. La compañía quiere recopilar métricas, como CPU, memoria y utilización del disco, y necesita un inventario de los procesos que se ejecutan en cada instancia. A la compañía también le gustaría monitorear las conexiones de red para mapear las comunicaciones entre servidores.
Cuál permitiría la recolección de estos datos de manera más rentable?
A.
Utilice AWS Application Discovery Service e implemente el agente de recopilación de datos en cada máquina virtual del centro de datos.
B.
Configure el agente de Amazon CloudWatch en todos los servidores del entorno local y publique métricas en Amazon CloudWatch Logs.
C.
Utilice AWS Application Discovery Service y habilite el descubrimiento sin agentes en el entorno de virtualización existente.
D.
Habilite AWS Application Discovery Service en la consola de administración de AWS y configure el firewall corporativo para permitir escaneos a través de una VPN.
ResponderDiscusión
Correct Answer: A
Para recopilar métricas detalladas como la CPU, la memoria y la utilización del disco, así como para obtener un inventario de los procesos en ejecución y monitorear las conexiones de red, es necesario implementar el agente de recopilación de datos. AWS Application Discovery Service con el agente de recopilación de datos puede lograr esto de manera eficiente. El agente proporciona visibilidad de todas estas métricas y procesos en ejecución, ofreciendo una visión completa del entorno existente para obtener un tamaño preciso de las instancias de Amazon EC2.
Question 384 of 529
Una empresa proporciona una aplicación de software como servicio (SaaS) que se ejecuta en la nube de AWS. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un balanceador de carga de red (NLB). Las instancias están en un grupo de Auto Scaling y se distribuyen en tres zonas de disponibilidad en una sola región de AWS.
La compañía está implementando la aplicación en regiones adicionales. La compañía debe proporcionar direcciones IP estáticas para la aplicación a los clientes para que los clientes puedan agregar las direcciones IP para permitir listas. La solución debe enrutar automáticamente a los clientes a la Región que esté geográficamente más cercana a ellos.
Qué solución cumplirá con estos requisitos?
A.
Cree una distribución de Amazon CloudFront. Cree un grupo de origen de CloudFront. Agregar el NLB para cada Región adicional al grupo de origen. Proporcione a los clientes los rangos de direcciones IP de las ubicaciones de borde de la distribución.
B.
Cree un acelerador estándar de AWS Global Accelerator. Cree un punto final de acelerador estándar para el NLB en cada región adicional. Proporcionar a los clientes la dirección IP de Global Accelerator.
C.
Cree una distribución de Amazon CloudFront. Cree un origen personalizado para el NLB en cada región adicional. Proporcione a los clientes los rangos de direcciones IP de las ubicaciones de borde de la distribución.
D.
Cree un acelerador de enrutamiento personalizado de AWS Global Accelerator. Cree un oyente para el acelerador de enrutamiento personalizado. Agregue la dirección IP y los puertos para el NLB en cada región adicional. Proporcionar a los clientes la dirección IP de Global Accelerator.
ResponderDiscusión
Correct Answer: B
La solución correcta es usar el acelerador estándar de AWS Global Accelerator. AWS Global Accelerator proporciona direcciones IP estáticas que los clientes pueden utilizar en sus listas de permisos. Los aceleradores estándar enrutan automáticamente el tráfico al punto final saludable más cercano, lo que cumple con el requisito de enrutar a los clientes a la región geográficamente más cercana a ellos. La creación de un punto final acelerador estándar para el balanceador de carga de red en cada región adicional y proporcionar a los clientes la dirección IP de Global Accelerator logra el resultado deseado sin la complejidad de enumerar rangos de IP dinámicos de servicios como CloudFront.
Question 385 of 529
Una empresa está ejecutando múltiples cargas de trabajo en la nube de AWS. La compañía cuenta con unidades separadas para el desarrollo de software. La compañía utiliza AWS Organizations y federación con SAML para otorgar permisos a los desarrolladores para administrar recursos en sus cuentas de AWS. Cada una de las unidades de desarrollo despliega sus cargas de trabajo de producción en una cuenta de producción común.
Recientemente, ocurrió un incidente en la cuenta de producción en el que miembros de una unidad de desarrollo dieron por terminada una instancia EC2 que pertenecía a una unidad de desarrollo diferente. Un arquitecto de soluciones debe crear una solución que evite que ocurra un incidente similar en el futuro. La solución también debe permitir a los desarrolladores la posibilidad de administrar las instancias utilizadas para sus cargas de trabajo.
Qué estrategia cumplirá con estos requisitos?
A.
Cree unidades organizativas separadas en AWS Organizations para cada unidad de desarrollo. Asigne las unidades organizativas creadas a las cuentas de AWS de la compañía. Cree SCP separado con una acción de denegar y una condición StringNotequals para la etiqueta de recurso DevelopmentUnit que coincida con el nombre de la unidad de desarrollo. Asignar el SCP a la unidad organizativa correspondiente.
B.
Pasar un atributo para DevelopmentUnit como una etiqueta de sesión de AWS Security Token Service (AWS STS) durante la federación SAML. Actualice la política de IAM para el rol asumido de IAM de los desarrolladores con una acción de denegar y una condición StringNotequals para la etiqueta de recurso DevelopmentUnit y aws:PrincipalTag/DevelopmentUnit.
C.
Pasar un atributo para DevelopmentUnit como una etiqueta de sesión de AWS Security Token Service (AWS STS) durante la federación SAML. Cree un SCP con una acción allow y una condición StringEquals para la etiqueta de recurso DevelopmentUnit y aws:PrincipalTag/DevelopmentUnit. Asigne el SCP a la OU raíz.
D.
Crear políticas de IAM separadas para cada unidad de desarrollo. Para cada política de IAM, agregue una acción allow y una condición StringEquals para la etiqueta de recurso DevelopmentUnit y el nombre de la unidad de desarrollo. Durante la federación SAML, utilice AWS Security Token Service (AWS STS) para asignar la política de IAM y hacer coincidir el nombre de la unidad de desarrollo con el rol asumido de IAM.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos, la mejor estrategia es pasar un atributo para DevelopmentUnit como una etiqueta de sesión de AWS Security Token Service (AWS STS) durante la federación SAML. Luego, actualice la política de IAM para el rol asumido de IAM de los desarrolladores con una acción de denegar y una condición StringNotequals para la etiqueta de recurso DevelopmentUnit y AWS:PrincipalTag/DevelopmentUnit. Este enfoque asegura que cada desarrollador solo pueda administrar recursos etiquetados con su unidad de desarrollo específica, evitando que interfieran con recursos pertenecientes a otras unidades. Este método une efectivamente los permisos a la identidad federada y proporciona un control de acceso detallado que se alinea con el requisito de permitir a los desarrolladores administrar instancias utilizadas para sus cargas de trabajo al tiempo que evita la interferencia entre unidades.
Question 386 of 529
Una empresa está construyendo una plataforma de servicios de infraestructura para sus usuarios. La empresa cuenta con los siguientes requisitos:
• Proporcionar el acceso de menor privilegio a los usuarios al lanzar la infraestructura de AWS para que los usuarios no puedan proporcionar servicios no aprobados.
• Utilizar una cuenta central para gestionar la creación de servicios de infraestructura.
• Proporcionar la capacidad de distribuir servicios de infraestructura a múltiples cuentas en organizaciones de AWS.
• Proporcionar la capacidad de aplicar etiquetas en cualquier infraestructura iniciada por los usuarios.
Qué combinación de acciones con los servicios de AWS cumplirá estos requisitos? (Elija tres.)
A.
Desarrolle servicios de infraestructura utilizando plantillas de AWS CloudFormation. Agregue las plantillas a un bucket central de Amazon S3 y agregue los roles de IAM o los usuarios que requieran acceso a la política de bucket de S3.
B.
Desarrolle servicios de infraestructura utilizando plantillas de AWS CloudFormation. Cargue cada plantilla como un producto de AWS Service Catalog en carteras creadas en una cuenta central de AWS. Compartir estos portafolios con la estructura de Organizaciones creada para la empresa.
C.
Permitir que los roles de IAM de usuario tengan permisos AWSCloudFormationFullAccess y Amazons3ReadOnlyAccess. Agregue un SCP de organizaciones en el nivel de usuario raíz de la cuenta de AWS para denegar todos los servicios excepto AWS CloudFormation y Amazon S3.
D.
Permitir que los roles de IAM de usuario tengan únicamente permisos ServiceCatalogendUserAccess. Utilice un script de automatización para importar las carteras centrales a cuentas locales de AWS, copiar TagOption, asignar acceso a los usuarios y aplicar restricciones de lanzamiento.
E.
Utilice la biblioteca de etiquetas de AWS Service Catalog TagOption para mantener una lista de etiquetas requeridas por la empresa. Aplicar TagOption a los productos o carteras de AWS Service Catalog.
F.
Utilice la propiedad Etiquetas de recursos de AWS CloudFormation para aplicar la aplicación de etiquetas a cualquier plantilla de CloudFormation que se creará para los usuarios.
ResponderDiscusión
Correct Answer: B, D, E
Para cumplir con los requisitos de la compañía, el uso de AWS Service Catalog es esencial. Desarrollar servicios de infraestructura con plantillas de AWS CloudFormation y subirlas como productos en las carteras de AWS Service Catalog (B) permite la administración central y el intercambio de servicios aprobados. Otorgar a los usuarios ServiceCatalogendUserAccess y usar un script de automatización para administrar carteras y aplicar restricciones (D) garantiza que los usuarios tengan los permisos adecuados sin aprovisionar servicios no aprobados. Por último, el uso de AWS Service Catalog TagOption Library (E) permite la aplicación de etiquetas requeridas en cualquier infraestructura iniciada, cumpliendo con el requisito de etiquetado.
Question 387 of 529
Una empresa despliega una nueva aplicación web. Como parte de la configuración, la compañía configura AWS WAF para iniciar sesión en Amazon S3 a través de Amazon Kinesis Data Firehose. La compañía desarrolla una consulta de Amazon Athena que se ejecuta una vez al día para devolver los datos de registro de AWS WAF de las 24 horas anteriores. El volumen de registros diarios es constante. No obstante, con el tiempo, la misma consulta está tardando más tiempo en ejecutarse.
Un arquitecto de soluciones necesita diseñar una solución para evitar que el tiempo de consulta continúe aumentando. La solución debe minimizar la sobrecarga operativa.
Qué solución cumplirá con estos requisitos?
A.
Cree una función de AWS Lambda que consolide los registros de AWS WAF de cada día en un archivo de registro.
B.
Reduzca la cantidad de datos escaneados configurando AWS WAF para enviar registros a un bucket S3 diferente cada día.
C.
Actualice la configuración de Kinesis Data Firehose para particionar los datos en Amazon S3 por fecha y hora. Crear tablas externas para Amazon Redshift. Configure Amazon Redshift Spectrum para consultar la fuente de datos.
D.
Modifique la configuración de Kinesis Data Firehose y la definición de la tabla Athena para particionar los datos por fecha y hora. Cambie la consulta de Athena para ver las particiones relevantes.
ResponderDiscusión
Correct Answer: D
Particionar los datos por fecha y hora aborda el problema directamente al reducir la cantidad de datos escaneados por Athena para cada consulta. Esta solución asegura que solo se lean y procesen las particiones relevantes (es decir, los registros de las 24 horas anteriores), lo que evita que el tiempo de consulta aumente a medida que crece el conjunto de datos. Este enfoque minimiza la sobrecarga operativa porque la partición se puede automatizar dentro de la configuración existente de Kinesis Data Firehose y Athena.
Question 388 of 529
Una empresa está desarrollando una aplicación web que se ejecuta en instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones (ALB) de cara al público. Solo los usuarios de un país específico pueden acceder a la aplicación. La empresa necesita la capacidad de registrar las solicitudes de acceso que han sido bloqueadas. La solución debe requerir el menor mantenimiento posible.
Qué solución cumple con estos requisitos?
A.
Cree un IPSet que contenga una lista de rangos de IP que pertenezcan al país especificado. Cree una ACL web de AWS WAF. Configure una regla para bloquear cualquier solicitud que no se origine desde un rango de IP en el IPSet. Asociar la regla con la ACL web. Asociar la ACL web con el ALB.
B.
Cree una ACL web de AWS WAF. Configure una regla para bloquear cualquier solicitud que no se origine del país especificado. Asociar la regla con la ACL web. Asociar la ACL web con el ALB.
C.
Configure AWS Shield para bloquear cualquier solicitud que no se origine en el país especificado. Asocie AWS Shield con el ALB.
D.
Crear una regla de grupo de seguridad que permita los puertos 80 y 443 a partir de rangos de IP que pertenecen al país especificado. Asociar el grupo de seguridad con el ALB.
ResponderDiscusión
Correct Answer: B
La solución que cumple con los requisitos es crear una ACL web de AWS WAF, configurar una regla para bloquear cualquier solicitud que no se origine del país especificado, y asociar la regla con la ACL web y la ALB. AWS WAF proporciona la capacidad de crear reglas de geocoincidencia, lo que permite bloquear solicitudes de países específicos sin administrar rangos de IP manualmente. Esta configuración registra las solicitudes bloqueadas, requiere un mantenimiento mínimo y ofrece la granularidad requerida para bloquear el acceso en función de la ubicación geográfica.
Question 389 of 529
Una empresa está migrando una aplicación de la infraestructura local a la nube de AWS. Durante las reuniones de diseño de migración, la compañía expresó su preocupación por la disponibilidad y las opciones de recuperación para su servidor de archivos Windows heredado. El servidor de archivos contiene datos confidenciales críticos para el negocio que no se pueden recrear en caso de corrupción o pérdida de datos. De acuerdo con los requisitos de cumplimiento, los datos no deben viajar a través de la internet pública. La compañía quiere trasladarse a los servicios gestionados de AWS cuando sea posible.
La compañía decide almacenar los datos en un sistema de archivos Amazon FSx para Windows File Server. Un arquitecto de soluciones debe diseñar una solución que copie los datos a otra región de AWS para fines de recuperación ante desastres (DR).
Qué solución cumplirá con estos requisitos?
A.
Cree un bucket de Amazon S3 de destino en la región DR. Establezca conectividad entre el sistema de archivos FSx para Windows File Server en la región principal y el bucket S3 en la región DR mediante Amazon FSx File Gateway. Configure el bucket S3 como fuente de backup continuo en FSx File Gateway.
B.
Cree un sistema de archivos FSx para Windows File Server en la región DR. Establezca conectividad entre la VPC, la región principal y la VPC en la región de recuperación ante desastres mediante la VPN de sitio a sitio de AWS. Configure AWS DataSync para comunicarse mediante endpoints VPN.
C.
Cree un sistema de archivos FSx para Windows File Server en la región DR. Establezca conectividad entre la VPC en la región primaria y la VPC en la región DR mediante el uso de pares de VPC. Configure AWS DataSync para comunicarse mediante puntos finales de interfaz de VPC con AWS PrivateLink.
D.
Cree un sistema de archivos FSx para Windows File Server en la región DR. Establezca conectividad entre la VPC en la región principal y la VPC en la región DR mediante AWS Transit Gateway en cada región. Utilice la familia AWS Transfer para copiar archivos entre el sistema de archivos FSx para Windows File Server en la región principal y el sistema de archivos FSx para Windows File Server en la región DR a través de la red troncal privada de AWS.
ResponderDiscusión
Correct Answer: C
Para abordar las preocupaciones de la compañía sobre la disponibilidad y las opciones de recuperación para su servidor de archivos Windows heredado y garantizar que los datos no viajen a través de Internet pública, la solución más adecuada consiste en crear un sistema de archivos FSx para Windows File Server en la región de recuperación ante desastres (DR). Establecer conectividad entre la VPC en la región primaria y la VPC en la región DR a través del peering de VPC es una opción segura que mantiene los datos dentro de la red privada de AWS. El uso de puntos finales de VPC de interfaz con AWS PrivateLink para AWS DataSync garantiza que el proceso de sincronización de datos permanezca seguro y privado, cumpliendo con los requisitos de conformidad.
Question 390 of 529
Una empresa se encuentra actualmente en fase de diseño de una aplicación que necesitará un RPO de menos de 5 minutos y un RTO de menos de 10 minutos. El equipo de arquitectura de soluciones está pronosticando que la base de datos almacenará aproximadamente 10 TB de datos. Como parte del diseño, están buscando una solución de base de datos que brinde a la compañía la capacidad de fallar a una Región secundaria.
Qué solución cumplirá con estos requisitos de negocio al menor costo?
A.
Implemente un clúster de base de datos de Amazon Aurora y tome instantáneas del clúster cada 5 minutos. Una vez que se complete una instantánea, copie la instantánea en una región secundaria para que sirva como copia de seguridad en caso de falla.
B.
Implemente una instancia de Amazon RDS con una réplica de lectura entre regiones en una región secundaria. En caso de falla, promover que la réplica de lectura se convierta en la primaria.
C.
Implemente un clúster de base de datos de Amazon Aurora en la región principal y otro en una región secundaria. Utilice AWS DMS para mantener sincronizada la región secundaria.
D.
Implemente una instancia de Amazon RDS con una réplica de lectura en la misma región. En caso de falla, promover que la réplica de lectura se convierta en la primaria.
ResponderDiscusión
Correct Answer: B
La implementación de una instancia de Amazon RDS con una réplica de lectura entre regiones en una región secundaria es la solución más rentable que cumple con los requisitos. Garantiza un objetivo de punto de recuperación (RPO) de menos de 5 minutos al replicar continuamente los datos en la réplica de lectura entre regiones. En caso de falla, la promoción de la réplica de lectura a la primaria se puede lograr dentro del Objetivo de Tiempo de Recuperación (RTO) requerido de menos de 10 minutos. Esta configuración aprovecha las capacidades integradas de AWS RDS sin incurrir en los costos más altos asociados con clústeres Aurora adicionales o soluciones complejas de migración de datos.
Question 391 of 529
Una compañía financiera necesita crear una cuenta de AWS separada para una nueva aplicación de billetera digital. La compañía utiliza AWS Organizations para administrar sus cuentas. Un arquitecto de soluciones utiliza el usuario de IAM Support1 de la cuenta de administración para crear una nueva cuenta de miembro con finance1@example.com como dirección de correo electrónico.
Qué debe hacer el arquitecto de soluciones para crear usuarios de IAM en la nueva cuenta de miembro?
A.
Inicie sesión en la consola de administración de AWS con las credenciales de usuario raíz de la cuenta de AWS utilizando la contraseña de 64 caracteres del correo electrónico inicial de AWS Organizations enviado a finance1@example.com. Configura los usuarios de IAM según sea necesario.
B.
Desde la cuenta de administración, cambie los roles para asumir el rol OrganizationAccountAccessRole con el ID de cuenta de la nueva cuenta de miembro. Configura los usuarios de IAM según sea necesario.
C.
Vaya a la página de inicio de sesión de AWS Management Console. Elija “Iniciar sesión usando las credenciales de la cuenta raíz”. Ingresa usando la dirección de correo electrónico finance 1@example.com y la contraseña root de la cuenta de administración. Configura los usuarios de IAM según sea necesario.
D.
Vaya a la página de inicio de sesión de AWS Management Console. Inicie sesión usando el ID de cuenta de la nueva cuenta de miembro y las credenciales de IAM de Support1. Configura los usuarios de IAM según sea necesario.
ResponderDiscusión
Correct Answer: B
Para crear usuarios de IAM en la nueva cuenta de miembro, el arquitecto de soluciones debe cambiar los roles de la cuenta de administración para asumir el rol OrganizationAccountAccessRole con el ID de cuenta de la nueva cuenta de miembro. Este rol es creado automáticamente por las organizaciones de AWS cuando se configura la cuenta de miembro y otorga permisos administrativos completos. Este enfoque mejora la seguridad y simplifica la administración al evitar el uso de credenciales raíz y acceder directamente a la cuenta de miembro a través de un rol establecido y seguro.
Question 392 of 529
Una compañía de alquiler de autos ha creado una API REST sin servidor para proporcionar datos a su aplicación móvil. La aplicación consiste en una API de Amazon API Gateway con un punto final regional, funciones de AWS Lambda y un clúster de base de datos Amazon Aurora MySQL Serverless. La compañía abrió recientemente la API a las aplicaciones móviles de los socios. Se produjo un incremento significativo en el número de solicitudes, ocasionando esporádicos errores de memoria en la base de datos.
El análisis del tráfico API indica que los clientes están realizando múltiples solicitudes HTTP GET para las mismas consultas en un corto período de tiempo. El tráfico se concentra durante el horario comercial, con picos alrededor de las vacaciones y otros eventos.
La compañía necesita mejorar su capacidad para soportar el uso adicional al tiempo que minimiza el aumento de costos asociados con la solución.
Qué estrategia cumple con estos requisitos?
A.
Convierta el punto final regional de API Gateway en un punto final optimizado para el borde. Habilite el almacenamiento en caché en la etapa de producción.
B.
Implemente una caché de Amazon ElastiCache para Redis para almacenar los resultados de las llamadas a la base de datos. Modificar las funciones de Lambda para usar la caché.
C.
Modifique la configuración del clúster de base de datos Aurora Serverless para aumentar la cantidad máxima de memoria disponible.
D.
Habilite el estrangulamiento en la etapa de producción de API Gateway. Establezca los valores de velocidad y ráfaga para limitar las llamadas entrantes.
ResponderDiscusión
Correct Answer: A
La compañía necesita manejar un aumento significativo en el número de solicitudes al tiempo que minimiza los costos. La conversión del punto final regional de API Gateway en un punto final optimizado para el borde con el almacenamiento en caché habilitado puede reducir significativamente el número de solicitudes que llegan a las funciones de Lambda y a la base de datos. Este enfoque utiliza la infraestructura de AWS para almacenar en caché las respuestas más cercanas a los usuarios, reduciendo así la frecuencia de consultas repetidas que llegan al backend, y ayuda a controlar mejor los costos en comparación con la implementación de una capa de almacenamiento en caché separada con ElastiCache para Redis.
Question 393 of 529
Una empresa está migrando una aplicación local y una base de datos MySQL a AWS. La aplicación procesa datos altamente sensibles y los nuevos datos se actualizan constantemente en la base de datos. Los datos no deben ser transferidos a través de internet. La empresa también debe cifrar los datos en tránsito y en reposo.
La base de datos tiene un tamaño de 5 TB. La compañía ya ha creado el esquema de base de datos en una instancia de base de datos de Amazon RDS para MySQL. La compañía ha establecido una conexión AWS Direct Connect de 1 Gbps a AWS. La compañía también ha establecido un VIF público y un VIF privado. Un arquitecto de soluciones necesita diseñar una solución que migre los datos a AWS con el menor tiempo de inactividad posible.
Qué solución cumplirá con estos requisitos?
A.
Realizar una copia de seguridad de base de datos. Copie los archivos de copia de seguridad en un dispositivo AWS Snowball Edge Storage Optimized. Importe la copia de seguridad a Amazon S3. Utilice el cifrado del lado del servidor con las claves de cifrado administradas de Amazon S3 (SSE-S3) para el cifrado en reposo. Utilice TLS para el cifrado en tránsito. Importe los datos de Amazon S3 a la instancia de base de datos.
B.
Utilice AWS Database Migration Service (AWS DMS) para migrar los datos a AWS. Cree una instancia de replicación DMS en una subred privada. Cree puntos finales de VPC para AWS DMS. Configure una tarea de DMS para copiar datos de la base de datos local a la instancia de base de datos mediante la captura de datos de carga completa más cambios (CDC). Utilice la clave predeterminada de AWS Key Management Service (AWS KMS) para el cifrado en reposo. Utilice TLS para el cifrado en tránsito.
C.
Realizar una copia de seguridad de base de datos. Utilice AWS DataSync para transferir los archivos de copia de seguridad a Amazon S3. Utilice el cifrado del lado del servidor con las claves de cifrado administradas de Amazon S3 (SSE-S3) para el cifrado en reposo. Utilice TLS para el cifrado en tránsito. Importe los datos de Amazon S3 a la instancia de base de datos.
D.
Utilice Amazon S3 File Gateway. Configure una conexión privada a Amazon S3 mediante AWS PrivateLink. Realizar una copia de seguridad de base de datos. Copie los archivos de copia de seguridad en Amazon S3. Utilice el cifrado del lado del servidor con las claves de cifrado administradas de Amazon S3 (SSE-S3) para el cifrado en reposo. Utilice TLS para el cifrado en tránsito. Importe los datos de Amazon S3 a la instancia de base de datos.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos de migrar una base de datos MySQL de 5 TB con datos altamente sensibles a AWS con el menor tiempo de inactividad posible, usar AWS Database Migration Service (AWS DMS) es la solución más adecuada. AWS DMS permite la replicación continua de datos mediante Change Data Capture (CDC), lo que garantiza un tiempo de inactividad mínimo. La creación de una instancia de replicación DMS en una subred privada y el uso de puntos finales de VPC para AWS DMS garantiza que los datos no se transfieran a través de Internet. Para el cifrado en reposo, se puede usar la clave predeterminada de AWS Key Management Service (AWS KMS), mientras que TLS se puede usar para el cifrado en tránsito.
Question 394 of 529
Acompañar está implementando un nuevo clúster para análisis de big data en AWS. El clúster se ejecutará en muchas instancias Linux Amazon EC2 distribuidas en varias zonas de disponibilidad.
Todos los nodos del clúster deben tener acceso de lectura y escritura al almacenamiento de archivos subyacente común. El almacenamiento de archivos debe estar altamente disponible, debe ser resistente, debe ser compatible con la Interfaz del Sistema Operativo Portátil (POSIX) y debe adaptarse a altos niveles de rendimiento.
Qué solución de almacenamiento cumplirá con estos requisitos?
A.
Aprovisione un recurso compartido de archivos NFS de la puerta de enlace de archivos de AWS Storage Gateway que se adjunta a un bucket de Amazon S3. Monte el recurso compartido de archivos NFS en cada instancia EC2 del clúster.
B.
Aprovisione un nuevo sistema de archivos de Amazon Elastic File System (Amazon EFS) que utilice el modo de rendimiento de propósito general. Monte el sistema de archivos EFS en cada instancia EC2 del clúster.
C.
Aprovisione un nuevo volumen de Amazon Elastic Block Store (Amazon EBS) que utilice el tipo de volumen io2. Adjunte el volumen de EBS a todas las instancias EC2 del clúster.
D.
Aprovisione un nuevo sistema de archivos de Amazon Elastic File System (Amazon EFS) que utilice el modo de rendimiento máximo de E/S. Monte el sistema de archivos EFS en cada instancia EC2 del clúster.
ResponderDiscusión
Correct Answer: D
Para cumplir con los requisitos de alta disponibilidad, resiliencia, compatibilidad con la interfaz de sistema operativo portátil (POSIX) y alojamiento de altos niveles de rendimiento para un clúster de análisis de big data que se ejecuta en múltiples instancias de Linux Amazon EC2 repartidas en varias zonas de disponibilidad, la opción más adecuada es aprovisionar un nuevo sistema de archivos de Amazon Elastic File System (Amazon EFS) que utilice el modo de rendimiento de E/S máximo. El modo de rendimiento máximo de E/S está diseñado para escalar a niveles más altos de rendimiento agregado y operaciones por segundo, lo que es ideal para cargas de trabajo de análisis de datos que requieren realizar operaciones paralelas desde numerosos nodos. Si bien esto tiene el costo de latencias ligeramente más altas, la necesidad principal de un alto rendimiento se alinea mejor con las capacidades del modo de rendimiento de E/S máximo en comparación con otras opciones.
Question 395 of 529
Una empresa aloja una solución de software como servicio (SaaS) en AWS. La solución cuenta con una API de Amazon API Gateway que sirve a un punto final HTTPS. La API utiliza funciones de AWS Lambda para la computación. Las funciones Lambda almacenan datos en una base de datos de Amazon Aurora Serverless v1.
La compañía utilizó el modelo de aplicación sin servidor de AWS (AWS SAM) para implementar la solución. La solución se extiende a través de múltiples zonas de disponibilidad y no tiene un plan de recuperación ante desastres (DR).
Un arquitecto de soluciones debe diseñar una estrategia de DR que pueda recuperar la solución en otra región de AWS. La solución tiene un RTO de 5 minutos y un RPO de 1 minuto.
Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una réplica de lectura de la base de datos Aurora Serverless v1 en la región de destino. Utilice AWS SAM para crear un runbook para implementar la solución en la región de destino. Promover la réplica de lectura a primaria en caso de desastre.
B.
Cambie la base de datos Aurora Serverless v1 a una base de datos global estándar Aurora MySQL que se extienda a través de la región de origen y la región de destino. Utilice AWS SAM para crear un runbook para implementar la solución en la región de destino.
C.
Cree un clúster de base de datos Aurora Serverless v1 que tenga varias instancias de escritor en la región de destino. Lanzar la solución en la Región objetivo. Configure las dos soluciones regionales para que funcionen en una configuración activo-pasiva.
D.
Cambie la base de datos Aurora Serverless v1 a una base de datos global estándar Aurora MySQL que se extienda a través de la región de origen y la región de destino. Lanzar la solución en la Región objetivo. Configure las dos soluciones regionales para que funcionen en una configuración activo-pasiva.
ResponderDiscusión
Correct Answer: D
Para cumplir con los requisitos de un objetivo de tiempo de recuperación (RTO) de 5 minutos y un objetivo de punto de recuperación (RPO) de 1 minuto, el mejor enfoque es cambiar la base de datos Aurora Serverless v1 a una base de datos global estándar Aurora MySQL que se extienda a través de la región de origen y la región de destino. Luego, lanza la solución en la Región objetivo y configura las dos soluciones Regionales para que funcionen en una configuración activo-pasiva. Esta configuración garantiza una rápida conmutación por error y replicación de datos entre regiones, que son esenciales para cumplir con los estrictos requisitos de RTO y RPO.
Question 396 of 529
Una empresa posee una cadena de agencias de viajes y está ejecutando una aplicación en la nube de AWS. Los empleados de la empresa utilizan la aplicación para buscar información sobre destinos de viaje. El contenido de destino se actualiza cuatro veces al año.
Dos instancias fijas de Amazon EC2 sirven a la aplicación. La compañía utiliza una zona alojada pública de Amazon Route 53 con un registro multivalue de travel.example.com que devuelve las direcciones IP elásticas para las instancias EC2. La aplicación utiliza Amazon DynamoDB como su almacén de datos principal. La compañía utiliza una instancia de Redis autoalojada como solución de almacenamiento en caché.
Durante las actualizaciones de contenido, la carga en las instancias EC2 y la solución de almacenamiento en caché aumenta drásticamente. Este aumento de carga ha provocado tiempos de inactividad en varias ocasiones. Un arquitecto de soluciones debe actualizar la aplicación para que la aplicación esté altamente disponible y pueda manejar la carga que se genera por las actualizaciones de contenido.
Qué solución cumplirá con estos requisitos?
A.
Configure DynamoDB Accelerator (DAX) como caché en memoria. Actualiza la aplicación para usar DAX. Cree un grupo de Auto Scaling para las instancias EC2. Cree un balanceador de carga de aplicaciones (ALB). Establezca el grupo Auto Scaling como objetivo para el ALB. Actualice el registro Route 53 para usar una política de enrutamiento simple que se dirija al alias DNS del ALB. Configure el escalado programado para las instancias EC2 antes de que se actualice el contenido.
B.
Configura Amazon ElastiCache para Redis. Actualiza la aplicación para usar ElastiCache. Cree un grupo de Auto Scaling para las instancias EC2. Cree una distribución de Amazon CloudFront y establezca el grupo Auto Scaling como origen para la distribución. Actualice el registro Route 53 para usar una política de enrutamiento simple que se dirija al alias DNS de la distribución de CloudFront. Escale manualmente las instancias EC2 antes de que se actualice el contenido.
C.
Configure Amazon ElastiCache para Memcached. Actualiza la aplicación para usar ElastiCache. Cree un grupo de Auto Scaling para las instancias EC2. Cree un balanceador de carga de aplicaciones (ALB). Establezca el grupo Auto Scaling como objetivo para el ALB. Actualice el registro Route 53 para usar una política de enrutamiento simple que se dirija al alias DNS del ALB. Configure el escalado programado para la aplicación antes de que se actualice el contenido.
D.
Configure DynamoDB Accelerator (DAX) como caché en memoria. Actualiza la aplicación para usar DAX. Cree un grupo de Auto Scaling para las instancias EC2. Cree una distribución de Amazon CloudFront y establezca el grupo Auto Scaling como origen para la distribución. Actualice el registro Route 53 para usar una política de enrutamiento simple que se dirija al alias DNS de la distribución de CloudFront. Escale manualmente las instancias EC2 antes de que se actualice el contenido.
ResponderDiscusión
Correct Answer: A
Para garantizar que la aplicación esté altamente disponible y pueda manejar el aumento de la carga durante las actualizaciones de contenido, es esencial establecer DynamoDB Accelerator (DAX) como caché en memoria porque DAX está específicamente optimizado para DynamoDB, que es el almacén de datos principal para la aplicación. La creación de un grupo de Auto Scaling para las instancias EC2 combinado con un balanceador de carga de aplicaciones (ALB) permitirá que la aplicación distribuya la carga de manera eficiente y escale dinámicamente. Además, actualizar el registro Route 53 para apuntar al alias DNS del ALB y configurar el escalado programado para las instancias EC2 garantizará que los recursos se escalen adecuadamente antes de las actualizaciones de contenido. Este enfoque aborda la necesidad de una administración automatizada y eficiente de los recursos durante los períodos de alta carga, asegurando una alta disponibilidad y minimizando el tiempo de inactividad.
Question 397 of 529
Una empresa necesita almacenar y procesar datos de imágenes que se cargarán desde dispositivos móviles usando una aplicación móvil personalizada. El uso alcanza su punto máximo entre las 8 AM y las 5 PM de lunes a viernes, con miles de subidas por minuto. La aplicación rara vez se usa en cualquier otro momento. Se notifica a un usuario cuando se completa el procesamiento de imágenes.
Qué combinación de acciones debe tomar un arquitecto de soluciones para garantizar que el procesamiento de imágenes pueda escalar para manejar la carga? (Elija tres.)
A.
Cargue archivos desde el software móvil directamente a Amazon S3. Utilice las notificaciones de eventos S3 para crear un mensaje en una cola de Amazon MQ.
B.
Cargue archivos desde el software móvil directamente a Amazon S3. Utilice las notificaciones de eventos de S3 para crear un mensaje en una cola estándar de Amazon Simple Queue Service (Amazon SQS).
C.
Invoque una función de AWS Lambda para realizar el procesamiento de imágenes cuando un mensaje esté disponible en la cola.
D.
Invocar un trabajo de S3 Batch Operations para realizar el procesamiento de imágenes cuando haya un mensaje disponible en la cola.
E.
Envíe una notificación push a la aplicación móvil mediante Amazon Simple Notification Service (Amazon SNS) cuando se complete el procesamiento.
F.
Envíe una notificación push a la aplicación móvil mediante Amazon Simple Email Service (Amazon SES) cuando se complete el procesamiento.
ResponderDiscusión
Correct Answer: B, C, E
Para garantizar que el procesamiento de imágenes pueda escalar para manejar la carga: Primero, cargue archivos desde la aplicación móvil directamente a Amazon S3. Utilice las notificaciones de eventos S3 para crear un mensaje en una cola estándar de Amazon Simple Queue Service (Amazon SQS), que es más adecuada para la cola de mensajes escalable y de alto rendimiento. En segundo lugar, invoque una función de AWS Lambda para realizar el procesamiento de imágenes cuando un mensaje esté disponible en la cola SQS; Lambda puede escalar automáticamente para acomodar la carga. Finalmente, envíe una notificación push a la aplicación móvil mediante el uso de Amazon Simple Notification Service (Amazon SNS) cuando se complete el procesamiento, ya que SNS está diseñado específicamente para notificaciones y puede manejar fácilmente las notificaciones push requeridas a aplicaciones móviles.
Question 398 of 529
Una empresa está construyendo una aplicación en AWS. La aplicación envía registros a un clúster de Amazon OpenSearch Service para su análisis. Todos los datos deben ser almacenados dentro de una VPC.
Algunos de los desarrolladores de la compañía trabajan desde casa. Otros desarrolladores trabajan desde tres ubicaciones diferentes de oficinas de la compañía. Los desarrolladores necesitan acceder al Servicio OpenSearch para analizar y visualizar los registros directamente desde sus máquinas de desarrollo locales.
Qué solución cumplirá con estos requisitos?
A.
Configure y configure un punto final de VPN de cliente de AWS. Asocie el punto final de VPN de cliente con una subred en la VPC. Configure un portal de autoservicio de VPN de cliente. Instruya a los desarrolladores para que se conecten usando el cliente para VPN de cliente.
B.
Cree una puerta de enlace de tránsito y conéctelo a la VPC. Cree una VPN de sitio a sitio de AWS. Cree un archivo adjunto a la puerta de enlace de tránsito. Instruya a los desarrolladores para que se conecten usando un cliente OpenVPN.
C.
Cree una puerta de enlace de tránsito y conéctela al vPorder y una conexión AWS Direct Connect. Configure un VIF público en la conexión Direct Connect. Asociar el VIF público con la puerta de tránsito. Instruya a los desarrolladores para que se conecten a la conexión Direct Connect.
D.
Crear y configurar un host bastión en una subred pública de la VPC. Configure el grupo de seguridad de host bastión para permitir el acceso SSH desde los rangos CIDR de la compañía. Instruya a los desarrolladores para que se conecten mediante SSH.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de permitir a los desarrolladores, tanto de ubicaciones domésticas como de oficinas, acceder al servicio Amazon OpenSearch y garantizar que todos los datos se almacenen dentro de una VPC, configurar y configurar un endpoint de VPN de cliente de AWS es la mejor solución. El punto final de VPN de cliente se puede asociar a una subred en la VPC y se puede configurar un portal de autoservicio para facilitar el acceso. Los desarrolladores pueden conectarse de forma segura usando el cliente VPN, lo que garantiza un acceso seguro y remoto al Servicio OpenSearch desde varias ubicaciones.
Question 399 of 529
Una empresa quiere migrar su sitio web desde un centro de datos local a AWS. Al mismo tiempo, quiere migrar el sitio web a una arquitectura basada en microservicios en contenedores para mejorar la disponibilidad y la rentabilidad. La política de seguridad de la compañía establece que los privilegios y permisos de red deben configurarse de acuerdo con las mejores prácticas, utilizando el menor privilegio.
Un arquitecto de soluciones debe crear una arquitectura contenerizada que cumpla con los requisitos de seguridad y haya implementado la aplicación en un clúster de Amazon ECS.
Qué pasos se requieren después de la implementación para cumplir con los requisitos? (Elija dos.)
A.
Crear tareas usando el modo de red puente.
B.
Crea tareas usando el modo de red awsvpc.
C.
Aplique grupos de seguridad a instancias de Amazon EC2 y use roles de IAM para instancias EC2 para acceder a otros recursos.
D.
Aplique grupos de seguridad a las tareas y pase las credenciales de IAM al contenedor en el momento del lanzamiento para acceder a otros recursos.
E.
Aplique grupos de seguridad a las tareas y use roles de IAM para que las tareas accedan a otros recursos.
ResponderDiscusión
Correct Answer: B, E
Para garantizar que la arquitectura contenerizada se adhiera a la política de seguridad de la compañía y siga el principio de menor privilegio, se deben tomar dos pasos críticos. Primero, las tareas deben crearse usando el modo de red awsvpc. Este modo de red asigna a cada tarea una Interfaz de Red Elástica (ENI), que permite un control granular del tráfico de red mediante grupos de seguridad aplicados específicamente a las tareas. Segundo, los roles de IAM para tareas deben ser utilizados para acceder a otros recursos. Esto asegura que cada tarea tenga los permisos mínimos requeridos, alineándose con el principio de menor privilegio. La aplicación de grupos de seguridad directamente a las tareas y el uso de roles de IAM para las tareas proporciona una mejor seguridad y aislamiento en comparación con el uso de soluciones más generales, como la aplicación de roles y grupos de seguridad en el nivel de instancia EC2.
Question 400 of 529
Una empresa está ejecutando una aplicación sin servidor que consta de varias funciones de AWS Lambda y tablas de Amazon DynamoDB. La compañía ha creado una nueva funcionalidad que requiere las funciones Lambda para acceder a un clúster de base de datos de Amazon Neptune. El clúster de base de datos Neptune se encuentra en tres subredes en una VPC.
Cuál de las posibles soluciones permitirá que las funciones de Lambda accedan al clúster de base de datos de Neptune y a las tablas DynamoDB? (Elija dos.)
A.
Cree tres subredes públicas en la VPC de Neptune y dirija el tráfico a través de una puerta de enlace a Internet. Aloje las funciones Lambda en las tres nuevas subredes públicas.
B.
Cree tres subredes privadas en la VPC de Neptune y enrute el tráfico de Internet a través de una puerta de enlace NAT. Alojar las funciones Lambda en las tres nuevas subredes privadas.
C.
Aloje las funciones Lambda fuera del VPUpDate el grupo de seguridad Neptune para permitir el acceso desde los rangos IP de las funciones de Lambda.
D.
Aloje las funciones Lambda fuera de la VPC. Cree un punto final de VPC para la base de datos Neptune y haga que las funciones de Lambda accedan a Neptune a través del punto final de VPC.
E.
Cree tres subredes privadas en la VPC de Neptune. Alojar las funciones Lambda en las tres nuevas subredes aisladas. Cree un punto de enlace de VPC para DynamoDB y enrute el tráfico de DynamoDB al endpoint de VPC.
ResponderDiscusión
Correct Answer: B, E
Para permitir que las funciones de AWS Lambda accedan a un clúster de base de datos de Amazon Neptune, que se encuentra en subredes dentro de una VPC, las funciones de Lambda también deben residir dentro de la misma VPC. Además, para interactuar con las tablas de Amazon DynamoDB, la conexión no requiere estar en una VPC, pero es importante administrar el tráfico de manera eficiente. La creación de tres subredes privadas en la VPC de Neptune y el enrutamiento del tráfico de Internet a través de una puerta de enlace NAT garantiza que las funciones de Lambda puedan acceder a servicios externos mientras residen en la misma VPC que Neptune, cumpliendo parte del requisito. Además, la creación de tres subredes privadas en la VPC de Neptune y el establecimiento de un punto final de VPC para DynamoDB garantiza un acceso seguro y eficiente a las tablas de DynamoDB y al clúster de base de datos Neptune desde las funciones Lambda dentro de la VPC. Por lo tanto, las soluciones correctas son crear subredes privadas para las funciones Lambda en la VPC de Neptune, enrutar el tráfico en consecuencia y usar un punto final de VPC para DynamoDB.
Question 401 of 529
Una empresa quiere diseñar una solución de recuperación ante desastres (DR) para una aplicación que se ejecute en el centro de datos de la compañía. La aplicación escribe en un recurso compartido de archivos SMB y crea una copia en un segundo recurso compartido de archivos. Ambos archivos compartidos están en el centro de datos. La aplicación utiliza dos tipos de archivos: archivos de metadatos y archivos de imagen.
La compañía quiere almacenar la copia en AWS. La compañía necesita la capacidad de usar SMB para acceder a los datos ya sea desde el centro de datos o AWS si ocurre un desastre. Rara vez se accede a la copia de los datos, pero debe estar disponible dentro de los 5 minutos.
A.
Implementar AWS Outposts con almacenamiento de Amazon S3. Configure una instancia de Amazon EC2 de Windows en Outposts como servidor de archivos.
B.
Implemente una puerta de enlace de archivos de Amazon FSx. Configure un sistema de archivos Multi-AZ de Amazon FSx para Windows File Server que utilice almacenamiento SSD.
C.
Implemente una puerta de enlace de archivos de Amazon S3. Configure S3 File Gateway para usar Amazon S3 Standard-Infrequent Access (S3 Standard-IA) para los archivos de metadatos y para usar S3 Glacier Deep Archive para los archivos de imagen.
D.
Implemente una puerta de enlace de archivos de Amazon S3. Configure S3 File Gateway para usar Amazon S3 Standard-Infrequent Access (S3 Standard-IA) para los archivos de metadatos y archivos de imagen.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos dados, implementar una puerta de enlace de archivos Amazon FSx y configurar un sistema de archivos Multi-AZ de Amazon FSx para Windows File Server con almacenamiento SSD es la opción más adecuada. Esta configuración proporciona acceso compartido de archivos SMB y garantiza que se pueda acceder a los datos desde el centro de datos o desde AWS en caso de desastre. El servidor de archivos AWS FSx para Windows está diseñado para un acceso rápido, lo que cumple con el requisito de que los datos estén disponibles en 5 minutos. Adicionalmente, soporta el protocolo SMB, haciéndolo accesible tanto desde el centro de datos como desde AWS, alineándose con las necesidades de recuperación ante desastres.
Question 402 of 529
Una empresa está creando una solución que puede trasladar a 400 empleados a un entorno de trabajo remoto en caso de un desastre inesperado. Los escritorios de usuario tienen una mezcla de sistemas operativos Windows y Linux. Múltiples tipos de software, como navegadores web y clientes de correo, están instalados en cada escritorio.
Un arquitecto de soluciones necesita implementar una solución que pueda integrarse con el Active Directory local de la compañía para permitir a los empleados usar sus credenciales de identidad existentes. La solución debe proporcionar autenticación multifactor (MFA) y debe replicar la experiencia del usuario desde los escritorios existentes.
Qué solución cumplirá con estos requisitos?
A.
Utilice Amazon WorkSpaces para el servicio de escritorio en la nube. Configure una conexión VPN a la red local. Cree un conector AD y conéctese a Active Directory local. Active MFA para Amazon WorkSpaces mediante la consola de administración de AWS.
B.
Utilice Amazon AppStream 2.0 como un servicio de transmisión de aplicaciones. Configurar Vista de Escritorio para los empleados. Configure una conexión VPN a la red local. Configure los Servicios de Federación de Active Directory (AD FS) en las instalaciones. Conecte la red VPC a AD FS a través de la conexión VPN.
C.
Utilice Amazon WorkSpaces para el servicio de escritorio en la nube. Configure una conexión VPN a la red local. Cree un conector AD y conéctese a Active Directory local. Configure un servidor RADIUS para MFA.
D.
Utilice Amazon AppStream 2.0 como un servicio de transmisión de aplicaciones. Configure los Servicios de Federación de Active Directory en las instalaciones. Configure MFA para otorgar acceso a los usuarios en AppStream 2.0.
AnswerDiscussion
Correct Answer: C
El método más adecuado es usar Amazon WorkSpaces para el servicio de escritorio en la nube, configurar una conexión VPN a la red local, crear un conector de AD para conectarse al Active Directory local y configurar un servidor RADIUS para MFA. Esta solución garantiza que los empleados puedan usar sus credenciales de identidad existentes al integrarse con el Directorio Activo de la compañía y proporcionar la autenticación multifactor necesaria. Además, Amazon WorkSpaces admite escritorios Windows y Linux, lo que coincide con el entorno existente de la compañía.
Question 403 of 529
Una empresa ha desplegado un centro de contacto de Amazon Connect. Los agentes del centro de contacto están reportando un gran número de llamadas generadas por computadora. A la compañía le preocupan los efectos de costo y productividad de estas llamadas. La compañía quiere una solución que permita a los agentes marcar la llamada como spam y bloquear automáticamente los números para que no vayan a un agente en el futuro.
Cuál es la solución más eficiente desde el punto de vista operativo para cumplir con estos requisitos?
A.
Personalice el Panel de control de contacto (CCP) agregando un botón de llamada de bandera que invocará una función de AWS Lambda que llame a la API UpdateContactAttributes. Utilice una tabla de Amazon DynamoDB para almacenar los números de spam. Modifique los flujos de contacto para buscar el atributo actualizado y usar una función Lambda para leer y escribir en la tabla DynamoDB.
B.
Usa una regla de lentes de contacto para Amazon Connect que buscará llamadas spam. Utilice una tabla de Amazon DynamoDB para almacenar los números de spam. Modifique los flujos de contacto para buscar la regla e invocar una función de AWS Lambda para leer y escribir en la tabla DynamoDB.
C.
Utilice una tabla de Amazon DynamoDB para almacenar los números de spam. Cree una conexión rápida a la que los agentes puedan transferir la llamada spam desde el Panel de Control de Contacto (CCP). Modifique el flujo de contacto de conexión rápida para invocar una función de AWS Lambda para escribir en la tabla DynamoDB.
D.
Modifique el flujo de contacto inicial para solicitar la entrada de la persona que llama. Si el agente no recibe entrada, el agente debe marcar a la persona que llama como spam. Utilice una tabla de Amazon DynamoDB para almacenar los números de spam. Utilice una función de AWS Lambda para leer y escribir en la tabla de DynamoDB.
AnswerDiscussion
Correct Answer: A
La personalización del Panel de Control de Contacto (CCP) agregando un botón de 'llamada de bander' permite a los agentes marcar fácilmente las llamadas como spam. Este botón puede invocar una función de AWS Lambda que llama a la API UpdateContactAttributes para marcar la llamada. El uso de una tabla de Amazon DynamoDB para almacenar los números de spam garantiza que haya un mecanismo de almacenamiento confiable para rastrear los números bloqueados. La modificación de los flujos de contacto para verificar el atributo de spam e interactuar con la tabla DynamoDB a través de Lambda garantiza que las llamadas futuras de estos números se bloqueen automáticamente. Esta solución proporciona una experiencia perfecta para los agentes, requiere una interrupción mínima de su flujo de trabajo y aprovecha los servicios de AWS de manera eficiente para el procesamiento y almacenamiento en tiempo real.
Question 404 of 529
Una compañía ha montado sensores para recopilar información sobre parámetros ambientales como la humedad y la luz en todas las fábricas de la compañía. La compañía necesita transmitir y analizar los datos en la nube de AWS en tiempo real. Si alguno de los parámetros cae fuera de los rangos aceptables, el equipo de operaciones de la fábrica debe recibir una notificación de inmediato.
Qué solución cumplirá con estos requisitos?
A.
Transmita los datos a una transmisión de entrega de Amazon Kinesis Data Firehose. Utilice AWS Step Functions para consumir y analizar los datos en la transmisión de entrega de Kinesis Data Firehose. Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de operaciones.
B.
Transmita los datos a un clúster de Amazon Managed Streaming para Apache Kafka (Amazon MSK). Configure un disparador en Amazon MSK para invocar una tarea de AWS Fargate para analizar los datos. Utilice Amazon Simple Email Service (Amazon SES) para notificar al equipo de operaciones.
C.
Transmite los datos a una transmisión de datos de Amazon Kinesis. Cree una función de AWS Lambda para consumir el flujo de datos de Kinesis y analizar los datos. Utilice Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de operaciones.
D.
Transmita los datos a una aplicación de Amazon Kinesis Data Analytics. Utilice un servicio escalado y contenerizado automáticamente en Amazon Elastic Container Service (Amazon ECS) para consumir y analizar los datos. Utilice Amazon Simple Email Service (Amazon SES) para notificar al equipo de operaciones.
AnswerDiscussion
Correct Answer: C
En este escenario, la compañía necesita una solución que pueda manejar capacidades de transmisión de datos en tiempo real, análisis y notificación inmediata. La transmisión de los datos a una transmisión de datos de Amazon Kinesis y el uso de una función de AWS Lambda para consumir y analizar los datos proporciona una forma eficiente y escalable de procesar la información en tiempo real. Los activadores de AWS Lambda pueden actuar sobre los datos inmediatamente a medida que ingresan a la transmisión. El uso de Amazon Simple Notification Service (Amazon SNS) garantiza que el equipo de operaciones reciba notificaciones sin demora. Esta solución cubre todos los requisitos: procesamiento de datos en tiempo real, análisis y notificación instantánea.
Question 405 of 529
Una empresa se está preparando para implementar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) para una carga de trabajo. La compañía espera que el clúster admita un número impredecible de pods sin estado. Muchos de los pods se crearán durante un corto período de tiempo ya que la carga de trabajo escala automáticamente el número de réplicas que utiliza la carga de trabajo.
Qué solución maximizará la resiliencia de los nodos?
A.
Utilice una plantilla de lanzamiento independiente para implementar el plano de control EKS en un segundo clúster que sea independiente de los grupos de nodos de carga de trabajo.
B.
Actualizar los grupos de nodos de carga de trabajo. Utilice un número menor de grupos de nodos e instancias más grandes en los grupos de nodos.
C.
Configure el escalador automático de clústeres de Kubernetes para garantizar que la capacidad informática de los grupos de nodos de carga de trabajo permanezca subaprovisionada.
D.
Configure la carga de trabajo para utilizar restricciones de dispersión de topología basadas en la zona de disponibilidad.
AnswerDiscussion
Correct Answer: D
Para maximizar la resiliencia de nodos en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) que se espera que admita un número impredecible de pods sin estado, debe configurar la carga de trabajo para utilizar restricciones de dispersión de topología basadas en la zona de disponibilidad. Este enfoque mejora la estabilidad y disponibilidad del clúster EKS al distribuir la carga de trabajo de manera uniforme en diferentes zonas de disponibilidad, lo que reduce el impacto de cualquier falla específica de zona o problemas de rendimiento. Este método asegura que los nodos permanezcan resilientes al limitar los efectos de las interrupciones zonales.
Question 406 of 529
Una empresa necesita implementar un plan de recuperación ante desastres (DR) para una aplicación web. La aplicación se ejecuta en una sola región de AWS.
La aplicación utiliza microservicios que se ejecutan en contenedores. Los contenedores están alojados en AWS Fargate en Amazon Elastic Container Service (Amazon ECS). La aplicación tiene una instancia de base de datos de Amazon RDS para MySQL como su capa de datos y utiliza Amazon Route 53 para la resolución DNS. Una alarma de Amazon CloudWatch invoca una regla de Amazon EventBridge si la aplicación experimenta un error.
Un arquitecto de soluciones debe diseñar una solución de DR para proporcionar recuperación de aplicaciones a una región separada. La solución debe minimizar el tiempo necesario para recuperarse de una falla.
Qué solución cumplirá con estos requisitos?
A.
Configure un segundo clúster ECS y un servicio ECS en Fargate en la región separada. Cree una función de AWS Lambda para realizar las siguientes acciones: tomar una instantánea de la instancia de base de datos RDS, copiar la instantánea a la región separada, crear una nueva instancia de base de datos RDS a partir de la instantánea y actualizar Route 53 para enrutar el tráfico al segundo clúster ECS. Actualice la regla EventBridge para agregar un destino que invocará la función Lambda.
B.
Cree una función de AWS Lambda que cree un segundo clúster de ECS y un servicio ECS en la región separada. Configure la función Lambda para realizar las siguientes acciones: tomar una instantánea de la instancia de base de datos RDS, copiar la instantánea a la región separada, crear una nueva instancia de base de datos RDS a partir de la instantánea y actualizar Route 53 para enrutar el tráfico al segundo clúster ECS. Actualice la regla EventBridge para agregar un destino que invocará la función Lambda.
C.
Configure un segundo clúster ECS y un servicio ECS en Fargate en la región separada. Cree una réplica de lectura entre regiones de la instancia de base de datos RDS en la región separada. Cree una función de AWS Lambda para promover la réplica de lectura a la base de datos primaria. Configure la función Lambda para actualizar Route 53 para enrutar el tráfico al segundo clúster ECS. Actualice la regla EventBridge para agregar un destino que invocará la función Lambda.
D.
Configure un segundo clúster ECS y un servicio ECS en Fargate en la región separada. Tome una instantánea de la instancia de base de datos RDS. Convierta la instantánea en una tabla global de Amazon DynamoDB. Cree una función de AWS Lambda para actualizar Route 53 y enrutar el tráfico al segundo clúster ECS. Actualice la regla EventBridge para agregar un destino que invocará la función Lambda.
AnswerDiscussion
Correct Answer: C
La mejor solución para minimizar el tiempo de recuperación implica configurar un segundo clúster ECS y un servicio ECS en Fargate en la región separada y usar una réplica de lectura entre regiones de la instancia de base de datos RDS. En caso de falla, la réplica de lectura puede promoverse rápidamente a la base de datos primaria, lo que garantiza un tiempo de inactividad mínimo. La solución también debe incluir una función de AWS Lambda para promover la réplica de lectura a la base de datos primaria y actualizar Route 53 para enrutar el tráfico al segundo clúster ECS. La actualización de la regla EventBridge para invocar la función Lambda garantiza la conmutación por error automática cuando se detecta una falla.
Question 407 of 529
Una empresa tiene cuentas de AWS que están en una organización en AWS Organizations. La compañía quiere realizar un seguimiento del uso de Amazon EC2 como métrica. El equipo de arquitectura de la compañía debe recibir una alerta diaria si el uso de EC2 es más de 10% mayor que el uso promedio de EC2 de los últimos 30 días.
Qué solución cumplirá con estos requisitos?
A.
Configure los presupuestos de AWS en la cuenta de administración de la organización. Especifique un tipo de uso de las horas de funcionamiento de EC2. Especificar un periodo diario. Establezca el monto del presupuesto en un 10% más que el uso promedio reportado durante los últimos 30 días de AWS Cost Explorer. Configurar una alerta para notificar al equipo de arquitectura si se cumple el umbral de uso
B.
Configure AWS Cost Anomaly Detection en la cuenta de administración de la organización. Configure un tipo de monitor de AWS Service. Aplicar un filtro de Amazon EC2. Configure una suscripción de alerta para notificar al equipo de arquitectura si el uso es 10% más que el uso promedio de los últimos 30 días.
C.
Habilite AWS Trusted Advisor en la cuenta de administración de la organización. Configure una alerta de asesoría de optimización de costos para notificar al equipo de arquitectura si el uso de EC2 es 10% más que el uso promedio reportado durante los últimos 30 días.
D.
Configure Amazon Detective en la cuenta de administración de la organización. Configure una alerta de anomalía de uso de EC2 para notificar al equipo de arquitectura si Detective identifica una anomalía de uso superior al 10%.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de rastrear el uso de Amazon EC2 y recibir una alerta diaria si el uso excede el promedio de los últimos 30 días en más de 10%, la mejor solución sería configurar los presupuestos de AWS. Los presupuestos de AWS permiten realizar un seguimiento y alertas detallados basados en métricas de costo y uso, incluidos tipos de uso específicos, como las horas de funcionamiento de EC2. Al especificar el tipo de uso y establecer el monto del presupuesto en función del uso promedio de los últimos 30 días, se puede establecer una alerta para notificar al equipo de arquitectura cuando el uso excede el umbral definido. Otras opciones, como AWS Cost Anomaly Detection, están más enfocadas en anomalías de costos que en métricas de uso específicas. Por lo tanto, AWS Presupuestos es la herramienta adecuada para este escenario.
Question 408 of 529
Una empresa de comercio electrónico está modernizando su infraestructura de TI y planea utilizar los servicios de AWS. El CIO de la compañía ha pedido a un arquitecto de soluciones que diseñe una aplicación de procesamiento de pedidos simple, altamente disponible y poco acoplada. La aplicación se encarga de recibir y procesar los pedidos antes de almacenarlos en una tabla de Amazon DynamoDB. La aplicación tiene un patrón de tráfico esporádico y debe poder escalar durante las campañas de marketing para procesar los pedidos con retrasos mínimos.
Cuál de los siguientes es el enfoque MÁS confiable para cumplir con los requisitos?
A.
Reciba los pedidos en una base de datos alojada en Amazon EC2 y utilice instancias EC2 para procesarlos.
B.
Reciba los pedidos en una cola de Amazon SQS e invoque una función de AWS Lambda para procesarlos.
C.
Reciba los pedidos utilizando el programa AWS Step Functions y lance un contenedor de Amazon ECS para procesarlos.
D.
Reciba los pedidos en Amazon Kinesis Data Flujos y utilice instancias de Amazon EC2 para procesarlos.
AnswerDiscussion
Correct Answer: B
El enfoque más confiable para los requisitos dados es usar Amazon SQS para recibir pedidos y AWS Lambda para procesarlos. Amazon SQS (Simple Queue Service) garantiza que la aplicación esté acoplada de manera flexible y pueda manejar patrones de tráfico esporádicos al poner en cola los pedidos entrantes de manera eficiente. AWS Lambda proporciona escalado automático, lo que permite que la aplicación se escale durante las campañas de marketing para procesar pedidos con retrasos mínimos. Esta configuración es simple, altamente disponible y elimina la necesidad de administrar servidores, haciéndola adecuada para los requisitos especificados.
Question 409 of 529
Una empresa está implementando funciones de AWS Lambda que acceden a una base de datos de Amazon RDS para PostgreSQL. La compañía necesita lanzar las funciones Lambda en un entorno de QA y en un entorno de producción.
La empresa no debe exponer las credenciales dentro del código de la aplicación y debe rotar las contraseñas automáticamente.
Qué solución cumplirá con estos requisitos?
A.
Almacene las credenciales de la base de datos para ambos entornos en AWS Systems Manager Parameter Store. Cifrar las credenciales mediante una clave de AWS Key Management Service (AWS KMS). Dentro del código de aplicación de las funciones Lambda, extraiga las credenciales del parámetro Parameter Store mediante el SDK de AWS para Python (Boto3). Agregue un rol a las funciones de Lambda para proporcionar acceso al parámetro Almacenamiento de parámetros.
B.
Almacene las credenciales de la base de datos para ambos entornos en AWS Secrets Manager con una entrada de clave distinta para el entorno de control de calidad y el entorno de producción. Encienda la rotación. Proporcionar una referencia a la clave Secrets Manager como una variable de entorno para las funciones Lambda.
C.
Almacene las credenciales de la base de datos para ambos entornos en AWS Key Management Service (AWS KMS). Encienda la rotación. Proporcione una referencia a las credenciales que se almacenan en AWS KMS como una variable de entorno para las funciones de Lambda.
D.
Cree depósitos S3 separados para el entorno de control de calidad y el entorno de producción. Active el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) para los buckets S3. Utilice un patrón de nombres de objetos que le dé al código de aplicación de cada función Lambda la capacidad de extraer las credenciales correctas para el entorno correspondiente de la función. Otorgue acceso a cada función de ejecución de la función Lambda a Amazon S3.
AnswerDiscussion
Correct Answer: B
AWS Secrets Manager es la opción óptima para almacenar y administrar credenciales de bases de datos tanto en entornos de control de calidad como de producción, ya que proporciona soporte integrado para la rotación automática de contraseñas, lo cual es un requisito crítico. Al almacenar las credenciales en AWS Secrets Manager y habilitar la rotación, se asegura de que las contraseñas se actualizan automáticamente sin intervención manual. Adicionalmente, proporcionar una referencia a la clave Secrets Manager como variable de entorno para las funciones de Lambda permite un acceso fácil y seguro a las credenciales, satisfaciendo la necesidad de evitar exponerlas dentro del código de la aplicación.
Question 410 of 529
Una empresa utiliza AWS Control Tower para administrar cuentas de AWS en una organización de AWS Organizations. La compañía tiene una unidad OU que contiene cuentas. La compañía debe evitar que cualquier instancia nueva o existente de Amazon EC2 en las cuentas de la unidad organizativa obtenga una dirección IP pública.
Qué solución cumplirá con estos requisitos?
A.
Configure todas las instancias en cada cuenta de la unidad organizativa para usar AWS Systems Manager. Utilice un runbook de automatización de Systems Manager para evitar que las direcciones IP públicas se adjunten a las instancias.
B.
Implemente el control proactivo de AWS Control Tower para verificar si las instancias en las cuentas de la unidad organizativa tienen una dirección IP pública. Establezca la propiedad AssociatePublicipAddress en False. Adjuntar el control proactivo a la unidad organizativa.
C.
Crear un SCP que impida el lanzamiento de instancias que tengan una dirección IP pública. Adicionalmente, configure el SCP para evitar la conexión de una dirección IP pública a instancias existentes. Adjuntar el SCP a la OU.
D.
Cree una regla personalizada de AWS Config que detecte instancias que tengan una dirección IP pública. Configure una acción de corrección que utilice una función de AWS Lambda para separar las direcciones IP públicas de las instancias.
AnswerDiscussion
Correct Answer: C
Para cumplir con el requisito de evitar que cualquier instancia nueva o existente de Amazon EC2 en las cuentas de la organización obtenga una dirección IP pública, crear una SCP (Service Control Policy) es una solución adecuada. Un SCP puede hacer cumplir políticas a nivel de cuenta u OU para restringir acciones específicas, en este caso, evitando tanto el lanzamiento de nuevas instancias con direcciones IP públicas como el apego de IPs públicas a instancias existentes. Este enfoque garantiza un control integral sobre las políticas de direccionamiento IP en todas las cuentas dentro de la unidad organizativa.
Question 411 of 529
Una empresa está implementando una aplicación web de terceros en AWS. La aplicación está empaquetada como una imagen Docker. La compañía ha implementado la imagen Docker como un servicio de AWS Fargate en Amazon Elastic Container Service (Amazon ECS). Un balanceador de carga de aplicaciones (ALB) dirige el tráfico a la aplicación.
La empresa necesita dar solo una lista específica de usuarios la posibilidad de acceder a la aplicación desde internet. La empresa no puede cambiar la aplicación y no puede integrar la aplicación con un proveedor de identidad. Todos los usuarios deben ser autenticados a través de la autenticación multifactor (MFA).
Qué solución cumplirá con estos requisitos?
A.
Crear un grupo de usuarios en Amazon Cognito. Configure el pool para la aplicación. Llenar la piscina con los usuarios requeridos. Configure el grupo para que requiera MFConfigure una regla de escucha en el ALB para requerir autenticación a través de la interfaz de usuario alojada de Amazon Cognito.
B.
Configure los usuarios en AWS Identity and Access Management (IAM). Adjunte una política de recursos al servicio Fargate para requerir que los usuarios usen MFA. Configure una regla de escucha en el ALB para requerir autenticación a través de IAM.
C.
Configure los usuarios en AWS Identity and Access Management (IAM). Habilite AWS IAM Identity Center (AWS Single Sign-On). Configure la protección de recursos para el ALB. Cree una regla de protección de recursos para requerir que los usuarios usen MFA.
D.
Crear un grupo de usuarios en AWS Amplify. Configure el pool para la aplicación. Llenar la piscina con los usuarios requeridos. Configure el pool para que requiera MFA. Configure una regla de escucha en el ALB para requerir autenticación a través de la interfaz de usuario alojada de Amplify.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de restringir el acceso únicamente a una lista específica de usuarios con autenticación multifactor (MFA) y no cambiar la aplicación o integrarla con un proveedor de identidad, Amazon Cognito es la solución adecuada. Al crear un grupo de usuarios en Amazon Cognito, puede administrar la autenticación del usuario y asegurarse de que se requiera MFA. El balanceador de carga de aplicaciones (ALB) se puede configurar con una regla de escucha para usar Cognito para la autenticación, dirigiendo a los usuarios a la interfaz de usuario alojada para iniciar sesión y verificar MFA. Este método asegura que solo los usuarios autenticados con el MFA requerido puedan acceder a la aplicación, cumpliendo con todos los requisitos establecidos.
Question 412 of 529
Un arquitecto de soluciones se está preparando para implementar una nueva herramienta de seguridad en varias regiones de AWS no utilizadas anteriormente. El arquitecto de soluciones implementará la herramienta mediante el uso de un conjunto de pila de AWS CloudFormation. La plantilla del conjunto de pila contiene un rol de IAM que tiene un nombre personalizado. Al crear el conjunto de pila, no se crean instancias de pila satisfactoriamente.
Qué debe hacer el arquitecto de soluciones para desplegar las pilas con éxito?
A.
Habilite las nuevas Regiones en todas las cuentas relevantes. Especifique la capacidad CAPABILITY_NAMED_IAM durante la creación del conjunto de pila.
B.
Utilice la consola de cuotas de servicio para solicitar un aumento de cuota para el número de pilas de CloudFormation en cada nueva región en todas las cuentas relevantes. Especifique la capacidad CAPABILITY_IAM durante la creación del conjunto de pila.
C.
Especifique la capacidad CAPABILITY_NAMED_IAM y el modelo de permisos SELF_MANAGED durante la creación del conjunto de pila.
D.
Especifique un ARN de rol de administración y la capacidad CAPABILITY_IAM durante la creación del conjunto de pila.
AnswerDiscussion
Correct Answer: A
Para implementar correctamente las pilas utilizando una pila de CloudFormation establecida en regiones de AWS no utilizadas anteriormente, es crucial asegurarse de que estas regiones estén habilitadas en todas las cuentas relevantes. Además, dado que la plantilla del conjunto de pila contiene un rol de IAM con un nombre personalizado, es necesario especificar la capacidad CAPABILITY_NAMED_IAM durante la creación del conjunto de pila. Esta capacidad reconoce explícitamente que la pila de CloudFormation contiene recursos de IAM con nombres personalizados, que se requieren para la implementación adecuada de dichos recursos.
Question 413 of 529
Una empresa tiene una aplicación que utiliza un clúster de base de datos de Amazon Aurora PostgreSQL para la base de datos de la aplicación. El clúster de base de datos contiene una instancia primaria pequeña y tres instancias de réplica más grandes. La aplicación se ejecuta en una función de AWS Lambda. La aplicación realiza muchas conexiones de corta duración a las instancias de réplica de la base de datos para realizar operaciones de solo lectura.
Durante periodos de alto tráfico, la aplicación se vuelve poco confiable y la base de datos informa que se están estableciendo demasiadas conexiones. La frecuencia de los periodos de alto tráfico es impredecible.
Qué solución mejorará la confiabilidad de la aplicación?
A.
Utilice Amazon RDS Proxy para crear un proxy para el clúster de base de datos. Configure un punto final de solo lectura para el proxy. Actualice la función Lambda para conectarse al punto final del proxy.
B.
Aumente la configuración max_connections en el grupo de parámetros del clúster de base de datos. Reinicie todas las instancias del clúster de base de datos. Actualice la función Lambda para conectarse al punto final del clúster de base de datos.
C.
Configure el escalado de instancias para que el clúster de base de datos se produzca cuando la métrica DatabaseConnections esté cerca de la configuración de conexiones máximas. Actualice la función Lambda para conectarse al punto final del lector Aurora.
D.
Utilice Amazon RDS Proxy para crear un proxy para el clúster de base de datos. Configure un punto final de solo lectura para Aurora Data API en el proxy. Actualice la función Lambda para conectarse al punto final del proxy.
AnswerDiscussion
Correct Answer: A
Para abordar el problema de que se establezcan demasiadas conexiones durante los períodos de alto tráfico, usar Amazon RDS Proxy es una solución adecuada. RDS Proxy puede administrar un grupo de conexiones de base de datos y compartirlas entre múltiples clientes, lo que puede ayudar a reducir la sobrecarga de crear y cerrar conexiones con frecuencia. Al configurar un punto final de solo lectura para el proxy y actualizar la función Lambda para conectarse a este punto final proxy, la aplicación puede mejorar su confiabilidad durante períodos de alto tráfico. Aumentar la configuración max_connections o configurar el escalado de instancias, como se menciona en otras opciones, puede no abordar de manera efectiva la causa raíz del problema, que es la alta frecuencia de conexiones de corta duración. Por lo tanto, usar Amazon RDS Proxy con un endpoint de solo lectura es la mejor solución.
Question 414 of 529
Una empresa minorista está montando sensores IoT en todas sus tiendas en todo el mundo. Durante la fabricación de cada sensor, la autoridad de certificación privada (CA) de la compañía emite un certificado X.509 que contiene un número de serie único. Luego, la compañía despliega cada certificado en su sensor respectivo.
Un arquitecto de soluciones necesita dar a los sensores la capacidad de enviar datos a AWS después de que se instalen. Los sensores no deben poder enviar datos a AWS hasta que estén instalados.
Qué solución cumplirá con estos requisitos?
A.
Cree una función de AWS Lambda que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección Parámetros. Agregue la función Lambda como un gancho de preaprovisionamiento. Durante la fabricación, llame a la operación de API RegisterThing y especifique la plantilla y los parámetros.
B.
Cree una máquina de estado AWS Step Functions que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección Parámetros. Especifique la máquina de estado Step Functions para validar los parámetros. Llame a la operación de la API StartThingRegistrationTask durante la instalación.
C.
Cree una función de AWS Lambda que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección Parámetros. Agregue la función Lambda como un gancho de preaprovisionamiento. Registre la CA con AWS IoT Core, especifique la plantilla de aprovisionamiento y establezca el parámetro permitir el registro automático.
D.
Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección Parámetros. Incluir validación de parámetros en la plantilla. Aprovisione un certificado de reclamo y una clave privada para cada dispositivo que utilice la CA. Otorgue permisos de servicio AWS IoT Core para actualizar cosas de AWS IoT durante el aprovisionamiento.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de que los sensores no envíen datos a AWS hasta que se instalen, la solución más adecuada consiste en validar el número de serie solo en el momento de la instalación y no durante el proceso de fabricación. La opción A sugiere crear una función de AWS Lambda para validar el número de serie y usar una plantilla de aprovisionamiento de AWS IoT Core con un gancho de preaprovisionamiento. El gancho de preaprovisionamiento garantiza que los sensores sean validados y aprovisionados solo en el momento de la instalación llamando a la operación de la API RegisterThing y especificando la plantilla y los parámetros. Este enfoque restringe de manera efectiva que los sensores envíen datos hasta que se instalen correctamente, alineándose con los requisitos.
Question 415 of 529
Una empresa de nueva creación migró recientemente un gran sitio web de comercio electrónico a AWS. El sitio web ha experimentado un incremento del 70% en las ventas. Los ingenieros de software están utilizando un repositorio privado de GitHub para administrar el código. El equipo de DevOps está utilizando Jenkins para las construcciones y pruebas unitarias. Los ingenieros necesitan recibir notificaciones de malas construcciones y cero tiempo de inactividad durante las implementaciones. Los ingenieros también deben asegurarse de que cualquier cambio en la producción sea perfecto para los usuarios y se pueda revertir en caso de un problema importante.
Los ingenieros de software han decidido utilizar AWS CodePipeline para administrar su proceso de compilación e implementación.
Qué solución cumplirá con estos requisitos?
A.
Usa websockets de GitHub para activar la canalización CodePipeline. Utilice el complemento Jenkins para AWS CodeBuild para realizar pruebas unitarias. Envía alertas a un tema de Amazon SNS para cualquier versión incorrecta. Implemente en una configuración de implementación in situ y todo a la vez con AWS CodeDeploy.
B.
Usa webhooks de GitHub para activar la canalización CodePipeline. Utilice el complemento Jenkins para AWS CodeBuild para realizar pruebas unitarias. Envía alertas a un tema de Amazon SNS para cualquier versión incorrecta. Implemente en una implementación azul/verde con AWS CodeDeploy.
C.
Usa websockets de GitHub para activar la canalización CodePipeline. Utilice AWS X-Ray para pruebas unitarias y análisis de código estático. Envía alertas a un tema de Amazon SNS para cualquier versión incorrecta. Implemente en una implementación azul/verde con AWS CodeDeploy.
D.
Usa webhooks de GitHub para activar la canalización CodePipeline. Utilice AWS X-Ray para pruebas unitarias y análisis de código estático. Envía alertas a un tema de Amazon SNS para cualquier versión incorrecta. Implemente en una configuración de implementación in situ y todo a la vez con AWS CodeDeploy.
AnswerDiscussion
Correct Answer: B
La solución correcta implica activar la canalización de CodePipeline usando webhooks de GitHub, ya que proporcionan un método más sencillo y confiable para integrarse con AWS CodePipeline. Dado que los ingenieros ya están utilizando Jenkins para versiones y pruebas unitarias, integrarlo con AWS CodeBuild es una opción estratégica para mantener la consistencia y la eficiencia. Las alertas de cualquier generación fallida se pueden enviar de manera eficiente a un tema de Amazon SNS, que cumple con el requisito de notificación. Es importante destacar que para garantizar implementaciones perfectas y reversiones fáciles, es esencial contar con una estrategia de implementación azul/verde con AWS CodeDeploy. Este enfoque permite cero tiempos de inactividad durante las implementaciones y la capacidad de volver a la versión anterior si ocurre algún problema, cumpliendo con todos los requisitos especificados.
Question 416 of 529
Una compañía de software como servicio (SaaS) ha desarrollado un entorno multi-inquilino. La compañía utiliza tablas de Amazon DynamoDB que comparten los inquilinos para la capa de almacenamiento. La compañía utiliza las funciones de AWS Lambda para los servicios de la aplicación.
La compañía quiere ofrecer un modelo de suscripción por niveles que se base en el consumo de recursos por cada inquilino. Cada inquilino es identificado por un ID de inquilino único que se envía como parte de cada solicitud a las funciones de Lambda. La compañía ha creado un informe de costos y uso de AWS (AWS CUR) en una cuenta de AWS. La compañía quiere asignar los costos de DynamoDB a cada inquilino para que coincida con el consumo de recursos de ese inquilino.
Qué solución proporcionará una visión granular del costo de DynamoDB para cada inquilino con el MENOR esfuerzo operativo?
A.
Asocie una nueva etiqueta denominada ID de inquilino con cada tabla de DynamoDB. Active la etiqueta como etiqueta de asignación de costos en la consola de AWS Billing and Cost Management. Implemente el nuevo código de función Lambda para registrar el ID de inquilino en Amazon CloudWatch Logs. Utilice el CUR de AWS para separar el costo de consumo de DynamoDB para cada ID de inquilino.
B.
Configure las funciones de Lambda para registrar el ID de inquilino y el número de RCUs y WCUs consumidos de DynamoDB para cada transacción en Amazon CloudWatch Logs. Implemente otra función Lambda para calcular los costos del inquilino utilizando las unidades de capacidad registradas y el costo general de DynamoDB de la API de AWS Cost Explorer. Cree una regla de Amazon EventBridge para invocar la función de cálculo Lambda en un horario.
C.
Cree una nueva clave de partición que asocie los elementos de DynamoDB con inquilinos individuales. Despliegue una función Lambda para llenar la nueva columna como parte de cada transacción. Implemente otra función Lambda para calcular los costos de inquilino mediante Amazon Athena para calcular el número de elementos de inquilino de DynamoDB y el costo general de DynamoDB a partir del CUR de AWS. Cree una regla de Amazon EventBridge para invocar la función de cálculo Lambda en un horario.
D.
Implemente una función Lambda para registrar el ID de inquilino, el tamaño de cada respuesta y la duración de la llamada a la transacción como métricas personalizadas en Amazon CloudWatch Logs. Utilice CloudWatch Logs Insights para consultar las métricas personalizadas de cada inquilino. Utilice AWS Pricing Calculator para obtener los costos generales de DynamoDB y calcular los costos de inquilino.
AnswerDiscussion
Correct Answer: B
La solución óptima debe proporcionar una asignación de costos de grano fino con un mínimo esfuerzo operativo. La configuración de las funciones de Lambda para registrar el ID de inquilino y el consumo de unidades de capacidad de lectura y escritura (RCUs y WCUs) en CloudWatch Logs permite el seguimiento preciso del uso de cada inquilino. La implementación de una función Lambda adicional para calcular periódicamente los costos de los inquilinos en función de los datos registrados y los costos generales de DynamoDB a través de la API de AWS Cost Explorer garantiza un enfoque automatizado y escalable. Este método aprovecha los servicios de AWS existentes de manera efectiva sin una amplia intervención manual.
Question 417 of 529
Una empresa tiene una aplicación que almacena datos en un solo bucket de Amazon S3. La empresa deberá conservar todos los datos durante 1 año. Al equipo de seguridad de la compañía le preocupa que un atacante pueda obtener acceso a la cuenta de AWS a través de credenciales filtradas a largo plazo.
Qué solución garantizará que los objetos existentes y futuros en el bucket S3 estén protegidos?
A.
Cree una nueva cuenta de AWS a la que solo pueda acceder el equipo de seguridad a través de un rol asumido. Crea un bucket S3 en la nueva cuenta. Habilite el control de versiones de S3 y el bloqueo de objetos S3. Configure un periodo de retención predeterminado de 1 año. Configure la replicación desde el bucket S3 existente al nuevo bucket S3. Cree un trabajo de Replicación por Lotes S3 para copiar todos los datos existentes.
B.
Utilice la regla administrada de AWS Config habilitada para la versión de s3-bucket-versioning-enabled. Configure una acción de corrección automática que utilice una función de AWS Lambda para habilitar S3 Versioning y MFA Delete en recursos no conformes. Agregue una regla de ciclo de vida de S3 para eliminar objetos después de 1 año.
C.
Denegar explícitamente la creación de bucket de todos los usuarios y roles, excepto un rol de restricción de lanzamiento de AWS Service Catalog. Defina un producto de Catálogo de servicios para la creación del bucket S3 para forzar la habilitación de S3 Versioning y MFA Delete. Autorizar a los usuarios a lanzar el producto cuando necesiten crear un bucket S3.
D.
Habilite Amazon GuardDuty con la función de protección S3 para la cuenta y la región de AWS. Agregue una regla de ciclo de vida de S3 para eliminar objetos después de 1 año.
AnswerDiscussion
Correct Answer: A
Para garantizar que los objetos existentes y futuros del bucket S3 estén protegidos contra el acceso no autorizado o la eliminación debido a las credenciales filtradas a largo plazo, la mejor solución es usar una configuración de cuenta aislada donde solo el equipo de seguridad pueda asumir roles para administrarla. Al crear una nueva cuenta de AWS específicamente para el equipo de seguridad, configurar un bucket S3 con Versioning y Object Lock habilitados, y configurar un período de retención predeterminado de 1 año, los datos están protegidos contra la eliminación accidental o maliciosa. Además, replicar el contenido del bucket existente en el nuevo bucket S3 asegura que incluso si las credenciales de la cuenta original están comprometidas, los datos permanezcan seguros en el nuevo bucket. Este enfoque combina los principios de menor privilegio, aislamiento de cuentas y medidas de integridad de datos para ofrecer una protección sólida.
Question 418 of 529
Una empresa necesita mejorar la seguridad de su aplicación basada en web en AWS. La aplicación utiliza Amazon CloudFront con dos orígenes personalizados. El primer origen personalizado enruta las solicitudes a una API HTTP de Amazon API Gateway. El segundo origen personalizado enruta el tráfico a un balanceador de carga de aplicaciones (ALB). La aplicación se integra con un proveedor de identidad (IdP) OpenID Connect (OIDC) para la administración de usuarios.
Una auditoría de seguridad muestra que un autorizador JSON Web Token (JWT) proporciona acceso a la API. La auditoría de seguridad también muestra que el ALB acepta solicitudes de usuarios no autenticados.
Un arquitecto de soluciones debe diseñar una solución para garantizar que todos los servicios de backend respondan solo a usuarios autenticados.
Qué solución cumplirá con este requisito?
A.
Configure el ALB para hacer cumplir la autenticación y autorización integrando el ALB con el IdP. Permitir que solo los usuarios autenticados accedan a los servicios de backend.
B.
Modifique la configuración de CloudFront para usar URL firmadas. Implementar una política de firma permisiva que permita que cualquier solicitud acceda a los servicios de backend.
C.
Cree una ACL web de AWS WAF que filtre las solicitudes no autenticadas a nivel ALB. Permitir que solo el tráfico autenticado llegue a los servicios de backend.
D.
Habilite AWS CloudTrail para registrar todas las solicitudes que llegan al ALB. Cree una función de AWS Lambda para analizar los registros y bloquear cualquier solicitud que provenga de usuarios no autenticados.
AnswerDiscussion
Correct Answer: A
Para garantizar que todos los servicios backend respondan solo a usuarios autenticados, la mejor solución es configurar el balanceador de carga de aplicaciones (ALB) para hacer cumplir la autenticación y autorización integrándolo con el proveedor de identidad (IdP) de OpenID Connect (OIDC). Esto permitirá que solo los usuarios autenticados accedan a los servicios de backend, asegurando que el ALB no acepte solicitudes de usuarios no autenticados. Este enfoque aborda directamente el problema que se encuentra en la auditoría de seguridad y cumple con el requisito de autenticar a los usuarios antes de que puedan llegar a cualquier servicio de backend.
Question 419 of 529
Una empresa crea una zona de aterrizaje de AWS Control Tower para administrar y gobernar un entorno de AWS con varias cuentas. El equipo de seguridad de la compañía implementará controles preventivos y controles de detectives para monitorear los servicios de AWS en todas las cuentas. El equipo de seguridad necesita una visión centralizada del estado de seguridad de todas las cuentas.
Qué solución cumplirá con estos requisitos?
A.
Desde la cuenta de administración de AWS Control Tower, use AWS CloudFormation StackSets para implementar un paquete de conformidad de AWS Config en todas las cuentas de la organización.
B.
Habilite Amazon Detective para la organización en organizaciones de AWS. Designe una cuenta de AWS como administrador delegado para Detective.
C.
Desde la cuenta de administración de AWS Control Tower, implemente un conjunto de pila de AWS CloudFormation que utilice la opción de implementación automática para habilitar Amazon Detective para la organización.
D.
Habilite AWS Security Hub para la organización en las organizaciones de AWS. Designe una cuenta de AWS como administrador delegado para Security Hub.
AnswerDiscussion
Correct Answer: D
El equipo de seguridad requiere una visión centralizada del estado de seguridad en todas las cuentas, y AWS Security Hub está diseñado para proporcionar esta funcionalidad. Al habilitar AWS Security Hub para la organización en AWS Organizations y designar una cuenta de AWS como administrador delegado para Security Hub, la compañía puede agregar y centralizar los hallazgos de seguridad de varios servicios y cuentas de AWS. Esta solución cumple con los requisitos de tener una visión general de seguridad integral y centralizada, permitiendo el despliegue de controles preventivos y de detective de manera efectiva.
Question 420 of 529
Una empresa que desarrolla electrónica de consumo con oficinas en Europa y Asia cuenta con 60 TB de imágenes de software almacenadas en locales de Europa. La compañía quiere transferir las imágenes a un bucket de Amazon S3 en la región ap-northeast-1. Las nuevas imágenes de software se crean diariamente y deben ser encriptadas en tránsito. La compañía necesita una solución que no requiera desarrollo personalizado para transferir automáticamente todas las imágenes de software existentes y nuevas a Amazon S3.
Cuál es el siguiente paso en el proceso de transferencia?
A.
Implemente un agente AWS DataSync y configure una tarea para transferir las imágenes al bucket S3.
B.
Configure Amazon Kinesis Data Firehose para transferir las imágenes mediante S3 Transfer Acceleration.
C.
Utilice un dispositivo AWS Snowball para transferir las imágenes con el bucket S3 como destino.
D.
Transfiera las imágenes a través de una conexión VPN de sitio a sitio mediante la API S3 con carga multiparte.
AnswerDiscussion
Correct Answer: A
Implementar un agente AWS DataSync y configurar una tarea para transferir las imágenes al bucket S3 es la mejor solución. AWS DataSync está diseñado para simplificar y automatizar el proceso de transferencia de datos entre el almacenamiento local y los servicios de almacenamiento de AWS, como Amazon S3. Admite el cifrado en tránsito y puede manejar de manera eficiente tanto los archivos existentes como los nuevos. Esta solución no requiere desarrollo personalizado y cumple con los requisitos de la compañía para transferencias continuas y automatizadas de nuevas imágenes de software.
Question 421 of 529
Una empresa cuenta con una aplicación web que utiliza Amazon API Gateway. AWS Lambda y Amazon DynamoDB. Una reciente campaña de mercadotecnia ha incrementado la demanda. El software de monitoreo informa que muchas solicitudes tienen tiempos de respuesta significativamente más largos que antes de la campaña de marketing.
Un arquitecto de soluciones habilitó Amazon CloudWatch Logs para API Gateway y notó que se producen errores en el 20% de las solicitudes. En CloudWatch, la función Lambda Límites métrica representa el 1% de las solicitudes y la métrica Errores representa el 10% de las solicitudes. Los registros de aplicaciones indican que, cuando ocurren errores, hay una llamada a DynamoDB.
Qué cambio debe hacer el arquitecto de soluciones para mejorar los tiempos de respuesta actuales a medida que la aplicación web se vuelve más popular?
A.
Aumentar el límite de concurrencia de la función Lambda.
B.
Implemente el escalado automático de DynamoDB en la mesa.
C.
Aumente el límite del acelerador de API Gateway.
D.
Vuelva a crear la tabla DynamoDB con un índice primario mejor particionado.
AnswerDiscussion
Correct Answer: B
El problema reportado proviene de los errores que ocurren en DynamoDB, como lo indican los registros de la aplicación. La implementación del escalado automático de DynamoDB en la mesa ajustará dinámicamente la capacidad de rendimiento aprovisionada, lo que le permitirá manejar la mayor demanda de manera eficiente. Este cambio debería reducir los errores y mejorar los tiempos de respuesta a medida que la aplicación web se vuelve más popular, abordando el problema principal relacionado con la capacidad de DynamoDB.
Question 422 of 529
Una empresa tiene una aplicación que tiene un frontend web. La aplicación se ejecuta en el centro de datos local de la compañía y requiere acceso al almacenamiento de archivos para datos críticos. La aplicación se ejecuta en tres VM Linux para redundancia. La arquitectura incluye un equilibrador de carga con enrutamiento HTTP basado en solicitudes.
La compañía necesita migrar la aplicación a AWS lo más rápido posible. La arquitectura en AWS debe estar altamente disponible.
Qué solución cumplirá estos requisitos con el MENOR de cambios en la arquitectura?
A.
Migre la aplicación a contenedores de Amazon Elastic Container Service (Amazon ECS) que utilizan el tipo de lanzamiento Fargate en tres zonas de disponibilidad. Utilice Amazon S3 para proporcionar almacenamiento de archivos para los tres contenedores. Utilice un balanceador de carga de red para dirigir el tráfico a los contenedores.
B.
Migre la aplicación a instancias de Amazon EC2 en tres zonas de disponibilidad. Utilice Amazon Elastic File System (Amazon EFS) para el almacenamiento de archivos. Monte el almacenamiento de archivos en las tres instancias EC2. Utilice un balanceador de carga de aplicaciones para dirigir el tráfico a las instancias EC2.
C.
Migre la aplicación a contenedores de Amazon Elastic Kubernetes Service (Amazon EKS) que utilizan el tipo de lanzamiento Fargate en tres zonas de disponibilidad. Utilice Amazon FSx for Lustre para proporcionar almacenamiento de archivos para los tres contenedores. Utilice un balanceador de carga de red para dirigir el tráfico a los contenedores.
D.
Migre la aplicación a instancias de Amazon EC2 en tres regiones de AWS. Utilice Amazon Elastic Block Store (Amazon EBS) para el almacenamiento de archivos. Habilite la replicación entre regiones (CRR) para las tres instancias EC2. Utilice un balanceador de carga de aplicaciones para dirigir el tráfico a las instancias EC2.
AnswerDiscussion
Correct Answer: B
Para migrar la aplicación a AWS con la menor cantidad de cambios en la arquitectura existente, la solución adecuada es utilizar instancias de Amazon EC2 en tres zonas de disponibilidad, Amazon Elastic File System (EFS) para el almacenamiento de archivos y un balanceador de carga de aplicaciones (ALB) para dirigir el tráfico. Esta configuración refleja estrechamente la arquitectura local de la compañía al mantener el uso de instancias EC2 como equivalentes directos a las máquinas virtuales Linux actuales para la capacidad informática y al usar Amazon EFS para el almacenamiento de archivos compartidos, similar al almacenamiento de archivos locales. Además, un ALB coincide con el requisito de enrutamiento basado en solicitudes HTTP, lo que garantiza una alta disponibilidad y cambios mínimos en la configuración existente.
Question 423 of 529
Una empresa planea migrar un centro de datos local a AWS. Actualmente, la compañía aloja el centro de datos en máquinas virtuales VMware basadas en Linux. Un arquitecto de soluciones debe recopilar información sobre las dependencias de red entre las máquinas virtuales. La información debe estar en forma de diagrama que detalle las direcciones IP del host, los nombres de host y la información de conexión de red.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS Application Discovery Service. Seleccione una región de AWS de origen de AWS Migration Hub. Instale AWS Application Discovery Agent en los servidores locales para la recopilación de datos. Otorgue permisos a Application Discovery Service para usar los diagramas de red de Migration Hub.
B.
Utilice AWS Application Discovery Service Agentless Collector para la recopilación de datos del servidor. Exporte los diagramas de red desde AWS Migration Hub en formato.png.
C.
Instale el agente de AWS Application Migration Service en los servidores locales para la recopilación de datos. Utilice los datos de AWS Migration Hub en Workflow Discovery en AWS para generar diagramas de red.
D.
Instale el agente de AWS Application Migration Service en los servidores locales para la recopilación de datos. Exporte datos de AWS Migration Hub en formato.csv a un panel de Amazon CloudWatch para generar diagramas de red.
AnswerDiscussion
Correct Answer: A
Para recopilar información sobre las dependencias de red entre las máquinas virtuales, incluidas las direcciones IP del host, los nombres de host y la información de conexión de red, la solución adecuada es utilizar AWS Application Discovery Service. Este servicio requiere seleccionar una región de AWS de origen de AWS Migration Hub e instalar AWS Application Discovery Agent en los servidores locales para obtener datos de forma precisa. También requiere otorgar permisos al Servicio de Descubrimiento de Aplicaciones para usar Migration Hub para generar diagramas de red.
Question 424 of 529
Una empresa ejecuta una aplicación de software como servicio (SaaS) en AWS. La aplicación consta de funciones de AWS Lambda y una base de datos Multi-AZ de Amazon RDS para MySQL. Durante los eventos del mercado, la aplicación tiene una carga de trabajo mucho mayor de lo normal. Los usuarios notan tiempos de respuesta lentos durante los períodos pico debido a muchas conexiones de base de datos. La empresa necesita mejorar el rendimiento escalable y la disponibilidad de la base de datos.
Qué solución cumple con estos requisitos?
A.
Cree una acción de alarma de Amazon CloudWatch que active una función Lambda para agregar una réplica de lectura de Amazon RDS para MySQL cuando la utilización de recursos alcanza un umbral.
B.
Migre la base de datos a Amazon Aurora y agregue una réplica de lectura. Agregue un pool de conexiones de base de datos fuera de la función del controlador Lambda.
C.
Migre la base de datos a Amazon Aurora y agregue una réplica de lectura. Utilice registros ponderados Amazon Route 53.
D.
Migre la base de datos a Amazon Aurora y agregue una réplica Aurora. Configure Amazon RDS Proxy para administrar grupos de conexiones de bases de datos.
AnswerDiscussion
Correct Answer: D
La migración de la base de datos a Amazon Aurora y la adición de una réplica Aurora mejorará la escalabilidad y disponibilidad de la base de datos al proporcionar replicación integrada. La configuración de Amazon RDS Proxy administrará grupos de conexiones de bases de datos de manera efectiva, evitando que las funciones de Lambda abran demasiadas conexiones de base de datos y reduciendo la sobrecarga de conexión. Esta combinación aborda los problemas de rendimiento y escalado causados por los períodos de carga de trabajo pico, lo que garantiza que la base de datos pueda manejar una mayor demanda con mejores tiempos de respuesta.
Question 425 of 529
Una empresa planea migrar una aplicación desde las instalaciones a la nube de AWS. La compañía comenzará la migración moviendo el almacenamiento de datos subyacente de la aplicación a AWS. Los datos de la aplicación se almacenan en un sistema de archivos compartidos en las instalaciones y los servidores de aplicaciones se conectan al sistema de archivos compartido a través de SMB.
Un arquitecto de soluciones debe implementar una solución que utilice un bucket de Amazon S3 para almacenamiento compartido. Hasta que la aplicación se migre por completo y se reescriba el código para usar las API nativas de Amazon S3, la aplicación debe continuar teniendo acceso a los datos a través de SMB. El arquitecto de soluciones debe migrar los datos de la aplicación a AWS a su nueva ubicación sin dejar de permitir que la aplicación local acceda a los datos.
Qué solución cumplirá con estos requisitos?
A.
Cree un nuevo sistema de archivos Amazon FSx para Windows File Server. Configure AWS DataSync con una ubicación para el recurso compartido de archivos local y una ubicación para el nuevo sistema de archivos de Amazon FSx. Cree una nueva tarea de DataSync para copiar los datos de la ubicación del recurso compartido de archivos local al sistema de archivos de Amazon FSx.
B.
Cree un bucket S3 para la aplicación. Copie los datos del almacenamiento local al bucket S3.
C.
Implemente una máquina virtual de AWS Server Migration Service (AWS SMS) en el entorno local. Utilice AWS SMS para migrar el servidor de almacenamiento de archivos desde las instalaciones a una instancia de Amazon EC2.
D.
Cree un bucket S3 para la aplicación. Implemente una nueva puerta de enlace de archivos de AWS Storage Gateway en una máquina virtual local. Cree un nuevo recurso compartido de archivos que almacene datos en el bucket S3 y esté asociado con la puerta de enlace de archivos. Copie los datos del almacenamiento local al nuevo endpoint de puerta de enlace de archivos.
AnswerDiscussion
Correct Answer: D
Para facilitar la migración mientras se garantiza que la aplicación continúe accediendo a los datos a través de SMB, implementar una puerta de enlace de archivos de AWS Storage Gateway es la mejor solución. Esto permite que la aplicación interactúe con el bucket S3 como si se tratara de un sistema de archivos SMB tradicional. La puerta de enlace de archivos manejará la traducción entre SMB y las API de S3, asegurando un acceso sin interrupciones a los datos durante la fase de migración. Este enfoque cumple con el requisito de usar un bucket de Amazon S3 para almacenamiento compartido mientras se mantiene el acceso SMB. Copiar los datos en el nuevo punto final de puerta de enlace de archivos garantiza que la aplicación pueda continuar funcionando sin cambios importantes hasta que se migre y vuelva a factorizar por completo. Por lo tanto, crear un bucket S3 e implementar una puerta de enlace de archivos en las instalaciones es el enfoque correcto.
Question 426 of 529
Una compañía global tiene una aplicación móvil que muestra códigos de barras de boletos. Los clientes utilizan los boletos en la aplicación móvil para asistir a eventos en vivo. Los escáneres de eventos leen los códigos de barras de los tickets y llaman a una API de backend para validar los datos del código de barras contra los datos de una base de datos. Después de escanear el código de barras, la lógica del backend escribe en la tabla única de la base de datos para marcar el código de barras como utilizado.
La compañía necesita implementar la aplicación en AWS con un nombre DNS de api.example.com. La compañía albergará la base de datos en tres regiones de AWS en todo el mundo.
Qué solución cumplirá estos requisitos con la latencia MÁS BAJA?
A.
Aloje la base de datos en clústeres de bases de datos globales de Amazon Aurora. Aloje el backend en tres clústeres de Amazon Elastic Container Service (Amazon ECS) que se encuentran en las mismas regiones que la base de datos. Cree un acelerador en AWS Global Accelerator para enrutar las solicitudes al clúster ECS más cercano. Crear un registro de Amazon Route 53 que asigne api.example.com al punto final del acelerador
B.
Aloje la base de datos en clústeres de bases de datos globales de Amazon Aurora. Aloje el backend en tres clústeres de Amazon Elastic Kubernetes Service (Amazon EKS) que se encuentran en las mismas regiones que la base de datos. Cree una distribución de Amazon CloudFront con los tres clústeres como orígenes. Enrutar las solicitudes al clúster EKS más cercano. Cree un registro de Amazon Route 53 que asigne api.example.com a la distribución de CloudFront.
C.
Aloje la base de datos en tablas globales de Amazon DynamoDB. Cree una distribución de Amazon CloudFront. Asocie la distribución de CloudFront con una función CloudFront que contenga la lógica de backend para validar los códigos de barras. Cree un registro de Amazon Route 53 que asigne api.example.com a la distribución de CloudFront.
D.
Aloje la base de datos en tablas globales de Amazon DynamoDB. Cree una distribución de Amazon CloudFront. Asocie la distribución CloudFront con una función Lambda @Edge que contiene la lógica de backend para validar los códigos de barras. Cree un registro de Amazon Route 53 que asigne api.example.com a la distribución de CloudFront.
AnswerDiscussion
Correct Answer: D
Para lograr la latencia más baja, el mejor enfoque es usar tablas globales de Amazon DynamoDB para la base de datos y Amazon CloudFront con Lambda @Edge para la lógica de backend. Las tablas globales de DynamoDB proporcionan replicación en varias regiones, lo que garantiza que el acceso a los datos sea rápido desde cualquier región. El uso de Lambda @Edge le permite ejecutar la lógica de backend en las ubicaciones de borde más cercanas a los usuarios, reduciendo drásticamente la latencia al evitar la necesidad de enrutar las solicitudes a un servidor central. Esta configuración garantiza que la validación del código de barras ocurra lo más cerca posible del escáner, proporcionando la solución de latencia más baja.
Question 427 of 529
Una compañía médica está ejecutando una API REST en un conjunto de instancias de Amazon EC2. Las instancias EC2 se ejecutan en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones (ALB). El ALB se ejecuta en tres subredes públicas y las instancias EC2 se ejecutan en tres subredes privadas. La compañía ha implementado una distribución de Amazon CloudFront que tiene el ALB como único origen.
Qué solución debería recomendar un arquitecto de soluciones para mejorar la seguridad de origen?
A.
Almacene una cadena aleatoria en AWS Secrets Manager. Cree una función AWS Lambda para la rotación automática de secretos. Configure CloudFront para inyectar la cadena aleatoria como un encabezado HTTP personalizado para la solicitud de origen. Cree una regla de ACL web de AWS WAF con una regla de coincidencia de cadenas para el encabezado personalizado. Asociar la ACL web con el ALB.
B.
Cree una regla de ACL web de AWS WAF con una condición de coincidencia de IP de los rangos de direcciones IP del servicio de CloudFront. Asociar la ACL web con la ALMover el ALB a las tres subredes privadas.
C.
Almacene una cadena aleatoria en AWS Systems Manager Parameter Store. Configurar Parámetro Almacenar rotación automática para la cadena. Configure CloudFront para inyectar la cadena aleatoria como un encabezado HTTP personalizado para la solicitud de origen. Inspeccione el valor del encabezado HTTP personalizado y bloquee el acceso en el ALB.
D.
Configurar AWS Shield Advanced Cree una política de grupo de seguridad para permitir conexiones desde rangos de direcciones IP del servicio CloudFront. Agregue la política a AWS Shield Advanced y adjunte la política al ALB.
AnswerDiscussion
Correct Answer: A
Para mejorar la seguridad de origen de la API REST de la compañía que se ejecuta en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB), es esencial garantizar que solo las solicitudes enrutadas a través de CloudFront puedan llegar al ALB. Una solución efectiva implica el uso de una combinación de servicios de AWS para lograr este objetivo. Al almacenar una cadena aleatoria en AWS Secrets Manager y usar AWS Lambda para la rotación automática de secretos, puede crear un encabezado HTTP personalizado en CloudFront que incluya esta cadena aleatoria. A continuación, crea una regla de ACL web de AWS WAF para que coincida con este encabezado personalizado, asegurando que solo las solicitudes que contengan el valor de encabezado correcto puedan llegar al ALB. Este enfoque restringe el acceso al origen y mejora la seguridad. Por lo tanto, almacenar la cadena aleatoria en AWS Secrets Manager, configurar CloudFront para inyectarla como un encabezado HTTP personalizado y utilizar AWS WAF para hacer cumplir esto en el ALB es la solución recomendada.
Question 428 of 529
Para cumplir con las regulaciones de la industria, un arquitecto de soluciones debe diseñar una solución que almacene los datos críticos de una compañía en múltiples regiones públicas de AWS, incluso en Estados Unidos, donde se encuentra la sede de la compañía. Se requiere que el arquitecto de soluciones proporcione acceso a los datos almacenados en AWS a la red WAN global de la compañía. El equipo de seguridad exige que ningún tráfico que acceda a estos datos debe atravesar la Internet pública.
Cómo debería el arquitecto de soluciones diseñar una solución de alta disponibilidad que cumpla con los requisitos y sea rentable?
A.
Establezca conexiones de AWS Direct Connect desde la sede de la empresa a todas las regiones de AWS en uso. Utilice la WAN de la compañía para enviar tráfico a la sede y luego a la conexión DX respectiva para acceder a los datos.
B.
Establezca dos conexiones de AWS Direct Connect desde la sede de la empresa a una región de AWS. Utilice la WAN de la compañía para enviar tráfico a través de una conexión DX. Utilice el peering de VPC entre regiones para acceder a los datos en otras regiones de AWS.
C.
Establezca dos conexiones de AWS Direct Connect desde la sede de la empresa a una región de AWS. Utilice la WAN de la compañía para enviar tráfico a través de una conexión DX. Utilice una solución de VPC de tránsito de AWS para acceder a los datos en otras regiones de AWS.
D.
Establezca dos conexiones de AWS Direct Connect desde la sede de la empresa a una región de AWS. Utilice la WAN de la compañía para enviar tráfico a través de una conexión DX. Utilice Direct Connect Gateway para acceder a datos en otras regiones de AWS.
AnswerDiscussion
Correct Answer: D
Para garantizar que los datos críticos de la compañía sean accesibles en varias regiones públicas de AWS, incluidos los Estados Unidos, y que ningún tráfico atraviese la Internet pública, la solución debe estar altamente disponible y ser rentable. El establecimiento de dos conexiones de AWS Direct Connect a una región de AWS garantiza la redundancia. El uso de Direct Connect Gateway permite un acceso seguro a los datos en varias regiones de AWS sin la complejidad y el costo adicional de administrar VPC de tránsito o interconexión de VPC entre regiones. Direct Connect Gateway proporciona una forma escalable y centralizada de administrar las conexiones a múltiples regiones de manera eficiente.
Question 429 of 529
Una compañía ha desarrollado una aplicación que está ejecutando Windows Server en VMs de VMware vSphere que la compañía aloja en las instalaciones. Los datos de la aplicación se almacenan en un formato propietario que debe leerse a través de la aplicación. La empresa aprovisionó manualmente los servidores y la aplicación.
Como parte de su plan de recuperación ante desastres, la compañía quiere la capacidad de alojar su aplicación en AWS temporalmente si el entorno local de la compañía deja de estar disponible. La compañía quiere que la aplicación regrese al alojamiento local después de que se complete un evento de recuperación ante desastres. El RPO es de 5 minutos.
Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?
A.
Configure AWS DataSync. Replique los datos en volúmenes de Amazon Elastic Block Store (Amazon EBS). Cuando el entorno local no esté disponible, utilice las plantillas de AWS CloudFormation para aprovisionar instancias de Amazon EC2 y adjuntar los volúmenes de EBS.
B.
Configure AWS Elastic Disaster Recovery. Replique los datos en instancias de Amazon EC2 de replicación que se adjuntan a volúmenes de Amazon Elastic Block Store (Amazon EBS). Cuando el entorno local no esté disponible, utilice Elastic Disaster Recovery para lanzar instancias EC2 que utilicen los volúmenes replicados.
C.
Aprovisione una puerta de enlace de archivos de AWS Storage Gateway. Replicar los datos en un bucket de Amazon S3. Cuando el entorno local no esté disponible, utilice AWS Backup para restaurar los datos en volúmenes de Amazon Elastic Block Store (Amazon EBS) y lanzar instancias de Amazon EC2 desde estos volúmenes de EBS.
D.
Aprovisione un sistema de archivos Amazon FSx para Windows File Server en AWS. Replicar los datos en el sistema de archivos. Cuando el entorno local no esté disponible, utilice las plantillas de AWS CloudFormation para aprovisionar instancias de Amazon EC2 y utilice los comandos de AWS: :CloudFormation: :Init para montar los recursos compartidos de archivos de Amazon FSx.
AnswerDiscussion
Correct Answer: B
La mejor solución para los requisitos de recuperación ante desastres de la compañía es usar AWS Elastic Disaster Recovery. Este servicio minimiza la sobrecarga operativa al replicar continuamente los datos del entorno local a AWS, lo que garantiza que se cumpla el RPO (Recovery Point Objective) de 5 minutos. Cuando el entorno local deja de estar disponible, la empresa puede utilizar Elastic Disaster Recovery para lanzar rápidamente instancias de Amazon EC2 que utilicen los volúmenes replicados de Amazon Elastic Block Store (EBS). Esta configuración permite una transición perfecta a AWS durante un desastre y una migración sencilla de regreso al entorno local una vez que se resuelve el evento de recuperación ante desastres.
Question 430 of 529
Una empresa ejecuta una aplicación de recopilación de datos de alta disponibilidad en Amazon EC2 en la región eu-north-1. La aplicación recopila datos de dispositivos de usuario final y escribe registros en una transmisión de datos de Amazon Kinesis y un conjunto de funciones de AWS Lambda que procesan los registros. La compañía persiste la salida del procesamiento de registros a un bucket de Amazon S3 en eu-north-1. La compañía utiliza los datos del bucket S3 como fuente de datos para Amazon Athena.
La compañía quiere incrementar su presencia global. Un arquitecto de soluciones debe lanzar las capacidades de recopilación de datos en las regiones sa-east-1 y ap-northeast-1. El arquitecto de soluciones implementa la aplicación, el flujo de datos de Kinesis y las funciones Lambda en las dos nuevas regiones. El arquitecto de soluciones mantiene el bucket S3 en eu-north-1 para cumplir con un requisito para centralizar el análisis de datos.
Durante las pruebas de la nueva configuración, el arquitecto de soluciones nota un retraso significativo en la llegada de los datos de las nuevas Regions al bucket S3.
Qué solución mejorará más este tiempo de retraso?
A.
En cada una de las dos nuevas Regiones, configure las funciones de Lambda para que se ejecuten en una VPC. Configure un punto final de puerta de enlace S3 en esa VPC.
B.
Active S3 Transfer Acceleration en el bucket S3 en eu-north-1. Cambie la aplicación para usar el nuevo punto final acelerado S3 cuando la aplicación cargue datos en el bucket S3.
C.
Cree un bucket S3 en cada una de las dos nuevas Regiones. Establezca la aplicación en cada nueva Región para cargarla en su respectivo bucket S3. Configure S3 Cross-Region Replication para replicar datos en el bucket S3 en eu-north-1.
D.
Aumente los requisitos de memoria de las funciones de Lambda para garantizar que tengan múltiples núcleos disponibles. Utilice la función de carga multiparte cuando la aplicación cargue datos a Amazon S3 desde Lambda.
AnswerDiscussion
Correct Answer: C
La mejor solución para mejorar el tiempo de retraso es crear un bucket S3 en cada una de las dos nuevas Regiones y configurar la aplicación en cada región para cargarla en su respectivo bucket S3. Luego, configure S3 Cross-Region Replication para replicar datos en el bucket S3 en eu-north-1. Este enfoque garantiza que los datos se carguen primero en un bucket dentro de la misma región, lo que reduce el tiempo de transferencia inicial y, a continuación, utiliza la replicación optimizada entre regiones de AWS para centralizar los datos en eu-north-1. Este método aprovecha eficazmente la infraestructura de AWS para minimizar la latencia y cumplir con el requisito de centralizar el análisis de datos en la región eu-north-1.
Question 431 of 529
Una empresa proporciona una aplicación centralizada de Amazon EC2 alojada en una única VPC compartida. La aplicación centralizada debe ser accesible desde aplicaciones cliente que se ejecutan en las VPC de otras unidades de negocio. El front-end de aplicaciones centralizado se configura con un balanceador de carga de red (NLB) para mayor escalabilidad.
Se necesitarán conectar hasta 10 VPC de unidades de negocio a la VPC compartida. Algunos de los bloques CIDR de la VPC de la unidad de negocio se superponen con la VPC compartida, y algunos se superponen entre sí La conectividad de red a la aplicación centralizada en la VPC compartida solo se debe permitir desde las VPC de unidad de negocio autorizadas.
Qué configuración de red debe usar un arquitecto de soluciones para proporcionar conectividad desde las aplicaciones cliente en las VPC de la unidad de negocio hasta la aplicación centralizada en la VPC compartida?
A.
Cree una puerta de enlace de tránsito de AWS. Conecte la VPC compartida y las VPC de la unidad de negocio autorizadas a la puerta de enlace de tránsito. Cree una única tabla de rutas de puerta de enlace de tránsito y asóciela con todas las VPC conectadas. Permitir la propagación automática de rutas desde los adjuntos a la tabla de rutas. Configure las tablas de enrutamiento de VPC para enviar tráfico a la puerta de enlace de tránsito.
B.
Cree un servicio de punto final de VPC utilizando la aplicación centralizada NLB y habilite la opción para requerir la aceptación del punto final. Cree un punto final de VPC en cada una de las VPC de la unidad de negocio utilizando el nombre de servicio del servicio de punto final. Acepte solicitudes de punto final autorizadas desde la consola de servicio de punto final.
C.
Cree una conexión de interconexión de VPC desde cada unidad de negocio VPC a la VPN compartidaAceptar las conexiones de interconexión de VPC desde la consola de VPC compartida. Configure las tablas de enrutamiento de VPC para enviar tráfico a la conexión de interconexión de VPC.
D.
Configure una puerta de enlace privada virtual para la VPC compartida y cree pasarelas de cliente para cada una de las VPC de unidad de negocio autorizadas. Establezca una conexión VPN de sitio a sitio desde las VPC de la unidad de negocio a la VPC compartida. Configure las tablas de enrutamiento de VPC para enviar tráfico a la conexión VPN.
AnswerDiscussion
Correct Answer: B
Para proporcionar conectividad desde las aplicaciones cliente en las VPC de la unidad de negocio a la aplicación centralizada en la VPC compartida, especialmente cuando los bloques CIDR de las VPC se superponen, la mejor solución es crear un servicio de punto final de VPC utilizando la aplicación centralizada NLB y habilitar la opción para requerir la aceptación del punto final. A continuación, cree un punto final de VPC en cada una de las VPC de la unidad de negocio utilizando el nombre de servicio del servicio de punto final y acepte solicitudes de punto final autorizadas desde la consola de servicio de punto final. Esta configuración permite un acceso seguro y controlado a la aplicación centralizada a pesar de las direcciones IP superpuestas.
Question 432 of 529
Una empresa quiere migrar su sitio web a AWS. El sitio web utiliza microservicios y se ejecuta en contenedores que se implementan en un clúster de Kubernetes local y autoadministrado. Todos los manifiestos que definen las implementaciones para los contenedores en la implementación de Kubernetes están en control de origen.
Todos los datos del sitio web se almacenan en una base de datos PostgreSQL. Un repositorio de imágenes de contenedor de código abierto se ejecuta junto con el entorno local.
Un arquitecto de soluciones necesita determinar la arquitectura que la compañía utilizará para el sitio web en AWS.
Qué solución cumplirá estos requisitos con el MENOR esfuerzo para migrar?
A.
Cree un servicio de AWS App Runner. Conecte el servicio App Runner al repositorio de imágenes de contenedor de código abierto. Implemente los manifiestos desde las instalaciones al servicio App Runner. Cree una base de datos de Amazon RDS para PostgreSQL.
B.
Cree un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) que tenga grupos de nodos administrados. Copie los contenedores de aplicaciones en un nuevo repositorio de Amazon Elastic Container Registry (Amazon ECR). Desplegar los manifiestos desde las instalaciones al clúster de EKS. Cree un clúster de base de datos de Amazon Aurora PostgreSQL.
C.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS) que tenga un pool de capacidad de Amazon EC2. Copie los contenedores de aplicaciones en un nuevo repositorio de Amazon Elastic Container Registry (Amazon ECR). Registre cada imagen de contenedor como una nueva definición de tarea. Configure los servicios ECS para cada definición de tarea para que coincidan con las implementaciones originales de Kubernetes. Cree un clúster de base de datos de Amazon Aurora PostgreSQL.
D.
Reconstruya el clúster de Kubernetes local alojándolo en instancias de Amazon EC2. Migre el repositorio de imágenes de contenedor de código abierto a las instancias EC2. Implemente los manifiestos desde las instalaciones al nuevo clúster en AWS. Despliegue una base de datos PostgreSQL de código abierto en el nuevo clúster.
AnswerDiscussion
Correct Answer: B
La mejor solución es crear un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) que haya administrado grupos de nodos, copiar los contenedores de aplicaciones en un nuevo repositorio de Amazon Elastic Container Registry (Amazon ECR), implementar los manifiestos desde las instalaciones en el clúster de EKS y crear un clúster de base de datos de Amazon Aurora PostgreSQL. Esta opción es óptima porque implica el menor esfuerzo en términos de migración: los manifiestos existentes se pueden reutilizar en gran medida con modificaciones mínimas, lo que permite una transición más fluida a un servicio administrado. El uso de EKS también proporciona una administración familiar de Kubernetes, que se alinea estrechamente con la configuración local actual, lo que reduce la necesidad de reconfiguración o reentrenamiento extensos. Además, Amazon Aurora PostgreSQL es un servicio de base de datos administrado que simplificaría las operaciones y el mantenimiento de la base de datos. Otras opciones requieren cambios más significativos ya sea en términos de configuración de implementación o implican administrar la infraestructura de manera más manual, aumentando la complejidad y el esfuerzo. Por lo tanto, la opción B es la más adecuada con el menor esfuerzo requerido.
Question 433 of 529
Una empresa utiliza una aplicación móvil en AWS para realizar concursos en línea. La compañía selecciona un ganador al azar al final de cada concurso. Los concursos se ejecutan por períodos de tiempo variables. La empresa no necesita conservar ningún dato de un concurso una vez finalizado el concurso.
La compañía utiliza código personalizado alojado en instancias de Amazon EC2 para procesar los datos del concurso y seleccionar un ganador. Las instancias EC2 se ejecutan detrás de un balanceador de carga de aplicaciones y almacenan las entradas del concurso en instancias de base de datos de Amazon RDS. La compañía debe diseñar una nueva arquitectura para reducir el costo de dirigir los concursos.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Migrar el almacenamiento de las entradas del concurso a Amazon DynamoDB. Cree un clúster de acelerador DynamoDB (DAX). Vuelva a escribir el código para ejecutarlo como contenedores de Amazon Elastic Container Service (Amazon ECS) que utilizan el tipo de lanzamiento Fargate. Al finalizar el concurso, elimine la tabla de DynamoDB.
B.
Migrar el almacenamiento de las entradas del concurso a Amazon Redshift. Reescriba el código como funciones de AWS Lambda. Al finalizar el concurso, elimine el clúster de Redshift.
C.
Agregue un clúster de Amazon ElastiCache para Redis frente a las instancias de base de datos RDS para almacenar en caché las entradas del concurso. Vuelva a escribir el código para ejecutarlo como contenedores de Amazon Elastic Container Service (Amazon ECS) que utilizan el tipo de lanzamiento Fargate. Establezca el atributo TTL de ElastiCache en cada entrada para caducar cada entrada al final del concurso.
D.
Migre el almacenamiento de las entradas del concurso a Amazon DynamoDB. Reescriba el código como funciones de AWS Lambda. Establezca el atributo TTL de DynamoDB en cada entrada para que caduque cada entrada al final del concurso.
AnswerDiscussion
Correct Answer: D
Para lograr una solución rentable, migre el almacenamiento a Amazon DynamoDB debido a su escalabilidad y vencimiento automático eficiente de los datos cuando TTL está configurado en cada entrada para que caduque al final del concurso. Reescriba el código como funciones de AWS Lambda para ejecutar las operaciones necesarias como agregar/recuperar entradas y seleccionar un ganador. Dado que los concursos se ejecutan por períodos de tiempo variables, establecer manualmente el TTL para cada concurso asegura que los datos caduquen automáticamente cuando concluya el concurso, evitando la necesidad de retener o eliminar datos manualmente y minimizando los costos mediante el uso de recursos solo cuando sea necesario.
Question 434 of 529
Una empresa ha implementado un nuevo requisito de seguridad. De acuerdo con el nuevo requisito, la compañía debe escanear todo el tráfico de instancias corporativas de AWS en la VPC de la compañía en busca de violaciones a las políticas de seguridad de la compañía. Como resultado de estos escaneos, la compañía puede bloquear el acceso a y desde direcciones IP específicas.
Para cumplir con el nuevo requisito, la compañía implementa un conjunto de instancias de Amazon EC2 en subredes privadas para que sirvan como proxies transparentes. La compañía instala software de servidor proxy aprobado en estas instancias EC2. La compañía modifica las tablas de ruta en todas las subredes para utilizar las instancias EC2 correspondientes con software proxy como ruta predeterminada. La compañía también crea grupos de seguridad que cumplen con las políticas de seguridad y asigna estos grupos de seguridad a las instancias EC2.
A pesar de estas configuraciones, el tráfico de las instancias EC2 en sus subredes privadas no se reenvía correctamente a Internet.
Qué debe hacer un arquitecto de soluciones para resolver este problema?
A.
Deshabilite las comprobaciones de origen/destino en las instancias EC2 que ejecutan el software proxy.
B.
Agregue una regla al grupo de seguridad que está asignado a las instancias EC2 proxy para permitir todo el tráfico entre instancias que tienen este grupo de seguridad. Asigne este grupo de seguridad a todas las instancias EC2 en la VPC.
C.
Cambie el conjunto de opciones de DHCP de las VPC. Establezca las opciones del servidor DNS para que apunten a las direcciones de las instancias EC2 proxy.
D.
Asigne una interfaz de red elástica adicional a cada instancia de EC2 proxy. Asegúrese de que una de estas interfaces de red tenga una ruta a las subredes privadas. Asegúrese de que la otra interfaz de red tenga una ruta a Internet.
AnswerDiscussion
Correct Answer: A
El problema probablemente se deba a que las comprobaciones de origen/destino están habilitadas en las instancias EC2 que actúan como proxies transparentes. De forma predeterminada, las instancias EC2 no están diseñadas para reenviar tráfico; están pensadas para ser el punto final. La desactivación de las comprobaciones de origen/destino en las instancias proxy les permite reenviar el tráfico correctamente, lo cual es necesario para que funcionen como proxies y enrute el tráfico según lo previsto.
Question 435 of 529
Una empresa está ejecutando su solución en AWS en una VPC creada manualmente. La compañía está utilizando AWS CloudFormation para aprovisionar otras partes de la infraestructura. De acuerdo con un nuevo requisito, la empresa debe administrar toda la infraestructura de manera automática.
Qué debe hacer la empresa para cumplir con este nuevo requisito con el MENOR esfuerzo?
A.
Cree una nueva pila de AWS Cloud Development Kit (AWS CDK) que aprovisione estrictamente los recursos y la configuración de VPC existentes. Utilice AWS CDK para importar la VPC a la pila y administrar la VPC.
B.
Cree un conjunto de pila de CloudFormation que cree la VPC. Utilice el conjunto de pila para importar la VPC a la pila.
C.
Cree una nueva plantilla de CloudFormation que aprovisione estrictamente los recursos y la configuración de VPC existentes. Desde la consola de CloudFormation, cree una nueva pila importando los recursos existentes.
D.
Cree una nueva plantilla de CloudFormation que cree la VPC. Utilice la CLI de AWS Serverless Application Model (AWS SAM) para importar la VPC.
AnswerDiscussion
Correct Answer: C
Para administrar toda la infraestructura automáticamente con el menor esfuerzo, la compañía debe crear una nueva plantilla de CloudFormation que aprovisione estrictamente los recursos y la configuración de VPC existentes. Desde la consola de CloudFormation, la compañía puede crear una nueva pila importando los recursos existentes. Esta opción permite a la empresa integrar la VPC en CloudFormation sin necesidad de recrearla, asegurando un proceso de administración automatizado al tiempo que aprovecha la configuración existente de CloudFormation.
Question 436 of 529
Una compañía ha desarrollado un nuevo lanzamiento de un popular videojuego y quiere ponerlo a disposición para su descarga pública. El nuevo paquete de lanzamiento tiene aproximadamente 5 GB de tamaño. La compañía proporciona descargas para versiones existentes de un sitio FTP basado en Linux y orientado al público alojado en un centro de datos local. La compañía espera que el nuevo lanzamiento sea descargado por usuarios de todo el mundo. La compañía quiere una solución que proporcione un mejor rendimiento de descarga y bajos costos de transferencia, independientemente de la ubicación del usuario.
A.
Almacene los archivos del juego en volúmenes de Amazon EBS montados en instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Configure un servicio FTP en las instancias EC2. Utilice un balanceador de carga de aplicaciones frente al grupo Auto Scaling. Publica la URL de descarga del juego para que los usuarios descarguen el paquete.
B.
Almacene los archivos del juego en volúmenes de Amazon EFS que están conectados a instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Configure un servicio FTP en cada una de las instancias EC2. Utilice un balanceador de carga de aplicaciones frente al grupo Auto Scaling. Publica la URL de descarga del juego para que los usuarios descarguen el paquete.
C.
Configure Amazon Route 53 y un bucket de Amazon S3 para el alojamiento de sitios web. Sube los archivos del juego al bucket S3. Utilice Amazon CloudFront para el sitio web. Publica la URL de descarga del juego para que los usuarios descarguen el paquete.
D.
Configure Amazon Route 53 y un bucket de Amazon S3 para el alojamiento de sitios web. Sube los archivos del juego al bucket S3. Establecer el Solicitante Paga por el cucharón S3. Publica la URL de descarga del juego para que los usuarios descarguen el paquete.
AnswerDiscussion
Correct Answer: C
Para mejorar el rendimiento de las descargas y proporcionar bajos costos de transferencia para una base de usuarios global, lo mejor es usar Amazon S3 para almacenar los archivos del juego porque es altamente escalable y rentable. El uso de Amazon CloudFront como red de entrega de contenido (CDN) frente al bucket S3 garantiza que los archivos del juego se almacenen en caché y se distribuyan a los usuarios de todo el mundo, minimizando la latencia y mejorando las velocidades de descarga. Amazon Route 53 se puede utilizar para la administración de DNS para enrutar a los usuarios a la ubicación de borde de CloudFront más cercana. Esta configuración cumple con los requisitos para mejorar el rendimiento y bajos costos de transferencia para los usuarios en diferentes ubicaciones.
Question 437 of 529
Una empresa ejecuta una aplicación en la nube que consiste en una base de datos y un sitio web. Los usuarios pueden publicar datos en el sitio web, procesar los datos y enviarles los datos en un correo electrónico. Los datos se almacenan en una base de datos MySQL que se ejecuta en una instancia de Amazon EC2. La base de datos se ejecuta en una VPC con dos subredes privadas. El sitio web se ejecuta en Apache Tomcat en una sola instancia EC2 en una VPC diferente con una subred pública. Existe una única conexión de pares de VPC entre la base de datos y la VPC del sitio web.
El sitio web ha sufrido varias interrupciones durante el último mes debido al alto tráfico.
Qué acciones debe tomar un arquitecto de soluciones para aumentar la confiabilidad de la aplicación? (Elija tres.)
A.
Coloque el servidor Tomcat en un grupo de Auto Scaling con varias instancias EC2 detrás de un balanceador de carga de aplicaciones.
B.
Aprovisione una conexión de interconexión de VPC adicional.
C.
Migre la base de datos MySQL a Amazon Aurora con una réplica de Aurora.
D.
Aprovisione dos gateways NAT en la base de datos VPC.
E.
Mover el servidor Tomcat a la base de datos VPC.
F.
Crear una subred pública adicional en una zona de disponibilidad diferente en la VPC del sitio web.
AnswerDiscussion
Correct Answer: A, C, F
Para mejorar la confiabilidad de la aplicación, se deben implementar varias estrategias. Colocar el servidor Tomcat en un grupo de Auto Scaling con varias instancias EC2 detrás de un balanceador de carga de aplicaciones ayuda a manejar el alto tráfico y garantiza la disponibilidad a través del equilibrio de carga y el escalado automático. La migración de la base de datos MySQL a Amazon Aurora con una réplica de Aurora proporciona un mejor rendimiento y alta disponibilidad, ya que Aurora está diseñada para entornos en la nube con copias de seguridad automatizadas y capacidades de conmutación por error. La creación de una subred pública adicional en una zona de disponibilidad diferente en la VPC del sitio web garantiza una mayor disponibilidad y tolerancia a fallas al distribuir la infraestructura en varias zonas de disponibilidad, lo que reduce el riesgo de tiempo de inactividad desde un único punto de falla.
Question 438 of 529
Una empresa minorista está operando su aplicación de comercio electrónico en AWS. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). La compañía utiliza una instancia de base de datos de Amazon RDS como backend de base de datos. Amazon CloudFront se configura con un origen que apunta al ALB. El contenido estático se guarda en caché. Amazon Route 53 se utiliza para alojar todas las zonas públicas.
Después de una actualización de la aplicación, el ALB ocasionalmente devuelve un error de código de estado 502 (Bad Gateway). La causa raíz son los encabezados HTTP mal formados que se devuelven al ALB. La página web regresa con éxito cuando un arquitecto de soluciones vuelve a cargar la página web inmediatamente después de que se produce el error.
Mientras la compañía está trabajando en el problema, el arquitecto de soluciones necesita proporcionar una página de error personalizada en lugar de la página de error ALB estándar a los visitantes.
Qué combinación de pasos cumplirá con este requisito con la MENOR cantidad de gastos generales operativos? (Elija dos.)
A.
Cree un bucket de Amazon S3. Configure el bucket S3 para alojar una página web estática. Cargue las páginas de error personalizadas en Amazon S3.
B.
Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si el objetivo de respuesta de comprobación de estado de ALB.FailedHealthChecks es mayor que 0. Configure la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web de acceso público.
C.
Modifique los registros existentes de Amazon Route 53 agregando verificaciones de estado. Configure un destino de reserva si falla la comprobación de estado. Modificar los registros DNS para que apunten a una página web de acceso público.
D.
Cree una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de comprobación de estado de ALB elb.InternalError es mayor que 0. Configure la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web de acceso público.
E.
Agregue una respuesta de error personalizada configurando una página de error personalizada de CloudFront. Modificar los registros DNS para que apunten a una página web de acceso público.
AnswerDiscussion
Correct Answer: A, E
Para cumplir con el requisito de proporcionar una página de error personalizada con la menor cantidad de sobrecarga operativa, la mejor solución implica pasos que aprovechan los servicios de AWS existentes con cambios mínimos de configuración. Primero, cree un bucket de Amazon S3 para alojar la página de error personalizada estática, ya que S3 es una solución rentable y sencilla para servir contenido estático (A). En segundo lugar, configure CloudFront para usar una respuesta de error personalizada, que permita manejar códigos de error HTTP específicos y devolver una página de error personalizada almacenada en el bucket S3 (E). Este enfoque utiliza las capacidades de CloudFront para manejar errores y evita la necesidad de configuraciones complejas de verificación de estado o funciones Lambda para modificar las reglas del equilibrador de carga, lo que reduce la sobrecarga operativa.
Question 439 of 529
Una empresa quiere migrar un clúster de base de datos Amazon Aurora MySQL de una cuenta de AWS existente a una nueva cuenta de AWS en la misma región de AWS. Ambas cuentas son miembros de una misma organización en AWS Organizations.
La compañía debe minimizar la interrupción del servicio de la base de datos antes de que la compañía realice el cambio de DNS a la nueva base de datos.
Qué estrategia migratoria cumplirá con este requisito? (Elija dos.)
A.
Tome una instantánea de la base de datos Aurora existente. Comparta la instantánea con la nueva cuenta de AWS. Cree un clúster de base de datos Aurora en la nueva cuenta a partir de la instantánea.
B.
Cree un clúster de base de datos Aurora en la nueva cuenta de AWS. Utilice AWS Database Migration Service (AWS DMS) para migrar datos entre los dos clústeres de base de datos Aurora.
C.
Utilice AWS Backup para compartir una copia de seguridad de base de datos Aurora desde la cuenta de AWS existente con la nueva cuenta de AWS. Cree un clúster de base de datos Aurora en la nueva cuenta de AWS a partir de la instantánea.
D.
Cree un clúster de base de datos Aurora en la nueva cuenta de AWS. Utilice AWS Application Migration Service para migrar datos entre los dos clústeres de base de datos Aurora.
AnswerDiscussion
Correct Answer: A, B
Para migrar un clúster de base de datos Amazon Aurora MySQL de una cuenta de AWS a otra con una interrupción mínima del servicio, se pueden emplear dos estrategias efectivas. Primero, tomar una instantánea de la base de datos Aurora existente y compartirla con la nueva cuenta de AWS le permite crear un clúster de base de datos Aurora en la nueva cuenta a partir de esta instantánea. Este método proporciona una manera directa y confiable de transferir los datos de la base de datos por completo. En segundo lugar, configurar un clúster de base de datos Aurora en la nueva cuenta de AWS y usar AWS Database Migration Service (AWS DMS) para migrar datos entre los dos clústeres garantiza que la sincronización de datos se mantenga antes del cambio de DNS, minimizando así el tiempo de inactividad y asegurando la continuidad de los datos.
Question 440 of 529
Una empresa de software como servicio (SaaS) proporciona una solución de software de medios a los clientes. La solución está alojada en 50 VPC en varias regiones de AWS y cuentas de AWS. Una de las VPC se designa como VPC de administración. Los recursos de cómputos en las VPC funcionan de forma independiente.
La compañía ha desarrollado una nueva característica que requiere que las 50 VPC puedan comunicarse entre sí. La nueva característica también requiere acceso unidireccional desde la VPC de cada cliente a la VPC de administración de la compañía. La VPC de administración aloja un recurso informático que valida las licencias para la solución de software multimedia.
El número de VPC que utilizará la compañía para alojar la solución seguirá aumentando a medida que la solución crezca.
Qué combinación de pasos proporcionará la conectividad VPC requerida con la menor sobrecarga operativa? (Elija dos.)
A.
Crear una puerta de enlace de tránsito. Adjunte todas las VPC de la compañía y las subredes relevantes a la puerta de enlace de tránsito.
B.
Cree conexiones de interconexión de VPC entre todas las VPC de la compañía.
C.
Cree un balanceador de carga de red (NLB) que apunte al recurso informático para la validación de licencias. Cree un servicio de punto final de AWS PrivateLink que esté disponible para el VPASsociate de cada cliente el servicio de punto final con el NLB.
D.
Cree un dispositivo VPN en la VPC de cada cliente. Conecte la VPC de administración de la compañía a la VPC de cada cliente mediante la VPN de sitio a sitio de AWS.
E.
Cree una conexión de pares de VPC entre la VPC de administración de la compañía y la VPC de cada cliente.
AnswerDiscussion
Correct Answer: A, C
La creación de una puerta de enlace de tránsito y la conexión de todas las VPC y subredes relevantes a ella ofrece una solución escalable para administrar la comunicación entre un número cada vez mayor de VPC con una sobrecarga operativa mínima. La puerta de enlace de tránsito facilita la administración centralizada de los adjuntos y el enrutamiento de VPC, lo que facilita el manejo de un número creciente de VPC en varias regiones y cuentas de AWS. En segundo lugar, crear un balanceador de carga de red (NLB) para el recurso informático en la VPC de administración y asociarlo con un servicio de punto final de AWS PrivateLink garantiza un acceso seguro y unidireccional desde la VPC de cada cliente a la VPC de administración. Este método aprovecha AWS PrivateLink para mantener la seguridad a la vez que proporciona la comunicación necesaria sin la complejidad y la carga operativa asociada con la administración de numerosas conexiones de interconexión de VPC o configuraciones de VPN.
Question 441 of 529
Una empresa tiene múltiples líneas de negocio (LOB) que se enrollan hasta la empresa matriz. La compañía ha pedido a su arquitecto de soluciones desarrollar una solución con los siguientes requisitos:
• Producir una sola factura de AWS para todas las cuentas de AWS utilizadas por sus LOB.
• Los costos de cada cuenta LOB deben estar desglosados en la factura.
• Proporcionar la capacidad de restringir servicios y características en las cuentas LOB, según lo definido por la política de gobierno de la compañía.
• A cada cuenta LOB se le deben delegar permisos de administrador completos, independientemente de la política de gobierno.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Utilice AWS Organizations para crear una organización en la cuenta principal para cada LOB. Después, invite a cada cuenta LOB a la organización correspondiente.
B.
Utilice AWS Organizations para crear una sola organización en la cuenta principal. Luego, invite a la cuenta de AWS de cada LOB a unirse a la organización.
C.
Implementar cuotas de servicio para definir los servicios y características que se permiten y aplicar las cuotas a cada LOB. según corresponda.
D.
Cree un SCP que permita solo servicios y funciones aprobados, luego aplique la póliza a las cuentas LOB.
E.
Habilite la facturación consolidada en la consola de facturación de la cuenta principal y vincule las cuentas LOB.
AnswerDiscussion
Correct Answer: B, E
La opción B es necesaria porque usar AWS Organizations para crear una sola organización en la cuenta principal e invitar a cada cuenta de AWS de LOB a unirse a la organización centralizará la administración y la facturación. La opción E es esencial porque habilitar la facturación consolidada en la consola de facturación de la cuenta principal y vincular las cuentas LOB garantizará que se produzca una sola factura de AWS para todas las cuentas, con costos desglosados para cada cuenta LOB. Estos pasos cumplen con los requisitos de producir una sola factura con desgloses detallados de costos y proporcionar gobierno al tiempo que permiten a cada cuenta LOB permisos administrativos completos.
Question 442 of 529
Un arquitecto de soluciones ha implementado una aplicación web que sirve a los usuarios en dos regiones de AWS bajo un dominio personalizado. La aplicación utiliza el enrutamiento basado en latencia de Amazon Route 53. El arquitecto de soluciones ha asociado conjuntos de registros ponderados con un par de servidores web en zonas de disponibilidad separadas para cada región.
El arquitecto de soluciones ejecuta un escenario de recuperación ante desastres. Cuando se detienen todos los servidores web de una Región, la Ruta 53 no redirige automáticamente a los usuarios a la otra Región.
Cuáles de las siguientes son posibles causas raíz de este problema? (Elija dos.)
A.
El peso para la Región donde se pararon los servidores web es mayor que el peso para la otra Región.
B.
Uno de los servidores web de la Región secundaria no pasó su comprobación de estado HTTP.
C.
Los conjuntos de registros de recursos de latencia no se pueden usar en combinación con conjuntos de registros de recursos ponderados.
D.
La configuración para evaluar el estado de destino no está activada para el conjunto de registros de recursos de alias de latencia que está asociado con el dominio en la Región donde se detuvieron los servidores web.
E.
No se ha configurado una comprobación de estado HTTP para uno o más de los conjuntos de registros de recursos ponderados asociados con los servidores web detenidos.
AnswerDiscussion
Correct Answer: D, E
Los conjuntos de registros de recursos de latencia se pueden usar en combinación con otras políticas de enrutamiento, como los conjuntos de registros de recursos ponderados. Sin embargo, para que Route 53 realice la conmutación por error correctamente al usar el enrutamiento basado en latencia, se deben configurar comprobaciones de estado y se debe habilitar la configuración de 'evaluar la salud del objetivo'. Sin comprobaciones de estado, Route 53 no sabrá si un servidor web está caído y no redirigirá el tráfico en consecuencia. Esto sugiere que las causas raíz probables son no tener activada la configuración de 'evaluar la salud del objetivo' y no tener comprobaciones de estado HTTP establecidas para los conjuntos de registros de recursos ponderados.
Question 443 of 529
Una agencia de monitoreo de inundaciones ha desplegado más de 10,000 sensores de monitoreo de nivel de agua. Los sensores envían actualizaciones continuas de datos y cada actualización tiene menos de 1 MB de tamaño. La agencia cuenta con una flota de servidores de aplicaciones locales. Estos servidores reciben actualizaciones de los sensores, convierten los datos sin procesar a un formato legible por humanos y escriben los resultados en un servidor de base de datos relacional local. Luego, los analistas de datos utilizan consultas SQL simples para monitorear los datos.
La agencia quiere aumentar la disponibilidad general de las aplicaciones y reducir el esfuerzo que se requiere para realizar las tareas de mantenimiento. Estas tareas de mantenimiento, que incluyen actualizaciones y parches a los servidores de aplicaciones, causan tiempo de inactividad. Mientras un servidor de aplicaciones está inactivo, los datos se pierden de los sensores porque los servidores restantes no pueden manejar toda la carga de trabajo.
La agencia quiere una solución que optimice los gastos generales y los costos operativos. Un arquitecto de soluciones recomienda el uso de AWS IoT Core para recopilar los datos del sensor.
Qué más debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?
A.
Envíe los datos del sensor a Amazon Kinesis Data Firehose. Utilice una función de AWS Lambda para leer los datos de Kinesis Data Firehose, convertirlos a formato.csv e insertarlos en una instancia de base de datos MySQL de Amazon Aurora. Instruya a los analistas de datos para que consulten los datos directamente desde la instancia de base de datos.
B.
Envíe los datos del sensor a Amazon Kinesis Data Firehose. Utilice una función de AWS Lambda para leer los datos de Kinesis Data Firehose, convertirlos al formato Apache Parquet y guardarlos en un bucket de Amazon S3. Instruir a los analistas de datos para que consulten los datos utilizando Amazon Athena.
C.
Envíe los datos del sensor a una aplicación Amazon Managed Service para Apache Flink (anteriormente conocida como Amazon Kinesis Data Analytics) para convertir los datos al formato.csv y almacenarlos en un bucket de Amazon S3. Importe los datos a una instancia de base de datos MySQL de Amazon Aurora. Instruya a los analistas de datos para que consulten los datos directamente desde la instancia de base de datos.
D.
Envíe los datos del sensor a una aplicación Amazon Managed Service for Apache Flink (anteriormente conocida como Amazon Kinesis Data Analytics) para convertir los datos al formato Apache Parquet y almacenarlos en un bucket de Amazon S3. Instruir a los analistas de datos para que consulten los datos utilizando Amazon Athena.
AnswerDiscussion
Correct Answer: B
Para aumentar la disponibilidad general de las aplicaciones y reducir las tareas de mantenimiento mientras se manejan datos continuos de más de 10,000 sensores de monitoreo de nivel de agua de manera eficiente, el enfoque recomendado es usar Amazon Kinesis Data Firehose para ingerir y procesar los datos de streaming. Usar una función AWS Lambda para transformar los datos al formato Apache Parquet y almacenarlos en un bucket de Amazon S3 ofrece varias ventajas. Apache Parquet es un formato de almacenamiento columnar optimizado para cargas de trabajo de análisis, que proporciona compresión eficiente y rendimiento de consultas. Los analistas de datos pueden usar Amazon Athena para consultar los datos directamente desde S3. Esta solución minimiza la sobrecarga operativa y garantiza una alta disponibilidad al aprovechar los servicios administrados de AWS que escalan y manejan automáticamente la carga de trabajo entrante sin tiempo de inactividad.
Question 444 of 529
Una aplicación web comercial pública utiliza un balanceador de carga de aplicaciones (ALB) frente a instancias de Amazon EC2 que se ejecutan en varias zonas de disponibilidad (AZ) en una región respaldada por una implementación de Amazon RDS MySQL Multi-AZ. Las comprobaciones de estado del grupo objetivo se configuran para usar HTTP y se señalan a la página del catálogo de productos. Auto Scaling está configurado para mantener el tamaño de la flota web en función de la verificación del estado de ALB.
Recientemente, la aplicación experimentó una interrupción. Auto Scaling reemplazó continuamente las instancias durante la interrupción. Una investigación posterior determinó que las métricas del servidor web estaban dentro del rango normal, pero el nivel de la base de datos estaba experimentando una carga alta, lo que resultó en tiempos de respuesta de consulta severamente elevados.
Cuál de los siguientes cambios juntos solucionaría estos problemas al tiempo que mejoraría las capacidades de monitoreo para la disponibilidad y funcionalidad de toda la pila de aplicaciones para el crecimiento futuro? (Elija dos.)
A.
Configure réplicas de lectura para Amazon RDS MySQL y utilice el punto final de lector único en la aplicación web para reducir la carga en el nivel de la base de datos backend.
B.
Configure la comprobación de estado del grupo objetivo para que apunte a una página HTML simple en lugar de una página de catálogo de productos y la comprobación de estado de Amazon Route 53 con la página del producto para evaluar la funcionalidad completa de la aplicación. Configure las alarmas de Amazon CloudWatch para notificar a los administradores cuando el sitio falla.
C.
Configure la comprobación de estado del grupo de destino para utilizar una comprobación TCP del servidor web de Amazon EC2 y la comprobación de estado de Amazon Route 53 en la página del producto para evaluar la funcionalidad completa de la aplicación. Configure las alarmas de Amazon CloudWatch para notificar a los administradores cuando el sitio falla.
D.
Configure una alarma de Amazon CloudWatch para Amazon RDS con una acción para recuperar una instancia de RDS deteriorada y de alta carga en el nivel de base de datos.
E.
Configure un clúster de Amazon ElastiCache y colóquelo entre la aplicación web y las instancias MySQL de RDS para reducir la carga en el nivel de la base de datos backend.
AnswerDiscussion
Correct Answer: A, E
Para remediar el problema y mejorar las capacidades de monitoreo, se deben implementar dos cambios críticos. Primero, configure réplicas de lectura para Amazon RDS MySQL y utilice el punto final de lector único en la aplicación web para reducir la carga en el nivel de la base de datos backend. Esto garantiza que las operaciones de lectura se distribuyan entre réplicas, aliviando la tensión en la instancia de base de datos primaria durante escenarios de alta carga. En segundo lugar, colocar un clúster de Amazon ElastiCache entre la aplicación web y las instancias MySQL de RDS también puede reducir la carga en el nivel de la base de datos backend al almacenar en caché los datos a los que se accede con frecuencia. Esto mejora los tiempos de respuesta y el rendimiento general de la aplicación, abordando así los elevados tiempos de respuesta de consulta experimentados durante los períodos de alta carga.
Question 445 of 529
Una compañía tiene un centro de datos local y está utilizando Kubernetes para desarrollar una nueva solución en AWS. La compañía utiliza clústeres de Amazon Elastic Kubernetes Service (Amazon EKS) para sus entornos de desarrollo y prueba.
El plano de control EKS y el plano de datos para cargas de trabajo de producción deben residir en las instalaciones. La compañía necesita una solución administrada por AWS para la administración de Kubernetes.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Instale un servidor AWS Outposts en el centro de datos local. Implemente Amazon EKS mediante una configuración de clúster local en el servidor Outposts para las cargas de trabajo de producción.
B.
Instale Amazon EKS Anywhere en el hardware de la compañía en el centro de datos local. Implemente las cargas de trabajo de producción en un clúster de EKS Anywhere.
C.
Instale un servidor AWS Outposts en el centro de datos local. Implemente Amazon EKS mediante una configuración de clúster extendida en el servidor Outposts para las cargas de trabajo de producción.
D.
Instale un servidor AWS Outposts en el centro de datos local. Instale Amazon EKS Anywhere en el servidor Outposts. Implemente las cargas de trabajo de producción en un clúster de EKS Anywhere.
AnswerDiscussion
Correct Answer: A
El requisito es tener tanto el plano de control como el plano de datos para las cargas de trabajo de producción en las instalaciones con la administración de Kubernetes administrada por AWS. Amazon EKS on Outposts con una configuración de clúster local cumple estos criterios, ya que el plano de control y el plano de datos residen en el servidor Outposts y son administrados por AWS. Por el contrario, EKS Anywhere es un producto administrado por el cliente, que no cumple con los requisitos para la administración de AWS. Por lo tanto, instalar un servidor AWS Outposts en el centro de datos local e implementar Amazon EKS mediante una configuración de clúster local es la solución correcta.
Question 446 of 529
Una empresa utiliza AWS Organizations para administrar su entorno de desarrollo. Cada equipo de desarrollo de la compañía tiene su propia cuenta de AWS. Cada cuenta tiene un solo bloque de VPC y CIDR que no se superponen.
La compañía tiene un clúster de base de datos de Amazon Aurora en una cuenta de servicios compartidos. Todos los equipos de desarrollo necesitan trabajar con datos en vivo del clúster de base de datos.
Qué solución proporcionará la conectividad requerida al clúster de base de datos con la menor sobrecarga operativa?
A.
Cree un recurso compartido de recursos de AWS Resource Access Manager (AWS RAM) para el clúster de base de datos. Comparte el clúster de base de datos con todas las cuentas de desarrollo.
B.
Cree una puerta de enlace de tránsito en la cuenta de servicios compartidos. Cree un recurso compartido de recursos de AWS Resource Access Manager (AWS RAM) para la puerta de enlace de tránsito. Comparte la pasarela de tránsito con todas las cuentas de desarrollo. Instruir a los desarrolladores a aceptar el recurso compartido. Configurar redes.
C.
Cree un balanceador de carga de aplicaciones (ALB) que apunte a la dirección IP del clúster de base de datos. Cree un servicio de endpoint de AWS PrivateLink que utilice el ALB. Agregar permisos para permitir que cada cuenta de desarrollo se conecte al servicio de endpoints.
D.
Cree una conexión VPN de sitio a sitio de AWS en la cuenta de servicios compartidos. Configurar redes. Utilice el software AWS Marketplace VPN en cada cuenta de desarrollo para conectarse a la conexión VPN de sitio a sitio.
AnswerDiscussion
Correct Answer: B
La solución que proporciona conectividad al clúster de base de datos de Amazon Aurora con la menor sobrecarga operativa es crear una puerta de enlace de tránsito en la cuenta de servicios compartidos y crear un recurso compartido de recursos de AWS Resource Access Manager (AWS RAM) para la puerta de enlace de tránsito. Compartir la puerta de enlace de tránsito con todas las cuentas de desarrollo y configurar redes proporciona un enfoque centralizado y sencillo que permite a todos los equipos acceder a los datos en vivo desde el clúster de base de datos. Esto evita las complejidades y limitaciones de otras opciones, como la clonación con RAM de AWS o el requisito de un balanceador de carga de red con PrivateLink.
Question 447 of 529
Una empresa utilizó AWS CloudFormation para crear toda la infraestructura nueva en sus cuentas de miembros de AWS. Los recursos rara vez cambian y se dimensionan adecuadamente para la carga esperada. La factura mensual de AWS es consistente.
Ocasionalmente, un desarrollador crea un nuevo recurso para probar y se olvida de eliminar el recurso cuando se completa la prueba. La mayoría de estas pruebas duran unos días antes de que los recursos ya no sean necesarios.
La compañía quiere automatizar el proceso de búsqueda de recursos no utilizados. Un arquitecto de soluciones necesita diseñar una solución que determine si el costo en la factura de AWS está aumentando. La solución debe ayudar a identificar los recursos que causan un aumento en el costo y debe notificar automáticamente al equipo de operaciones de la compañía.
Qué solución cumplirá con estos requisitos?
A.
Activar alertas de facturación. Utilice AWS Cost Explorer para determinar los costos del último mes. Cree una alarma de Amazon CloudWatch para los cargos totales estimados. Especifique un umbral de costos que sea mayor que los costos que determinó el Explorador de costos. Agregue una notificación para alertar al equipo de operaciones si se incumple el umbral de alarma.
B.
Activar alertas de facturación. Utilice AWS Cost Explorer para determinar los costos mensuales promedio de los últimos 3 meses. Cree una alarma de Amazon CloudWatch para los cargos totales estimados. Especifique un umbral de costos que sea mayor que los costos que determinó el Explorador de costos. Agregue una notificación para alertar al equipo de operaciones si se incumple el umbral de alarma.
C.
Utilice AWS Cost Anomaly Detection para crear un monitor de costos que tenga un tipo de cuenta vinculada de monitor. Cree una suscripción para enviar resúmenes diarios de costos de AWS al equipo de operaciones. Especifique un umbral para la varianza de costos.
D.
Utilice AWS Cost Anomaly Detection para crear un monitor de costos que tenga un tipo de monitor de servicios de AWS. Cree una suscripción para enviar resúmenes diarios de costos de AWS al equipo de operaciones. Especifique un umbral para la varianza de costos.
AnswerDiscussion
Correct Answer: D
Para identificar y administrar los recursos no utilizados que causan un aumento en los costos, es esencial monitorear el gasto a nivel granular en todos los servicios individuales de AWS. El uso de AWS Cost Anomaly Detection para crear un monitor de costos con un tipo de monitor de servicios de AWS permite realizar este seguimiento detallado. Puede detectar patrones de gasto inusuales específicos de diferentes servicios, incluso dentro de una sola cuenta, lo que ayuda a identificar exactamente qué recurso está contribuyendo a aumentar los costos. Establecer resúmenes de costos diarios y especificar un umbral para la varianza de costos garantiza que el equipo de operaciones sea notificado rápidamente de cualquier anomalía, lo que permite acciones correctivas oportunas.
Question 448 of 529
Una empresa está implementando una nueva aplicación basada en la web y necesita una solución de almacenamiento para los servidores de aplicaciones Linux. La compañía quiere crear una única ubicación para las actualizaciones de los datos de las aplicaciones para todas las instancias. El conjunto de datos activo tendrá un tamaño de hasta 100 GB. Un arquitecto de soluciones ha determinado que las operaciones máximas ocurrirán durante 3 horas diarias y requerirán un total de 225 MiBps de rendimiento de lectura.
El arquitecto de soluciones debe diseñar una solución Multi-AZ que haga que una copia de los datos esté disponible en otra región de AWS para la recuperación ante desastres (DR). El ejemplar DR tiene un RPO de menos de 1 hora.
Qué solución cumplirá con estos requisitos?
A.
Implemente un nuevo sistema de archivos Multi-AZ de Amazon Elastic File System (Amazon EFS). Configure el sistema de archivos para 75 MiBps de rendimiento aprovisionado. Implementar replicación en un sistema de archivos en la Región DR.
B.
Implemente un nuevo sistema de archivos Amazon FSx para Lustre. Configure el modo de rendimiento de ráfagas para el sistema de archivos. Utilice AWS Backup para hacer una copia de seguridad del sistema de archivos en la región de recuperación ante desastres.
C.
Implemente un volumen SSD de uso general (gp3) Amazon Elastic Block Store (Amazon EBS) con 225 MiBps de rendimiento. Habilite la conexión múltiple para el volumen de EBS. Utilice AWS Elastic Disaster Recovery para replicar el volumen de EBS en la región de recuperación ante desastres.
D.
Implemente un sistema de archivos Amazon FSx para OpenZFS tanto en la región de producción como en la región de DR. Cree una tarea programada de AWS DataSync para replicar los datos del sistema de archivos de producción al sistema de archivos DR cada 10 minutos.
AnswerDiscussion
Correct Answer: A
La solución correcta es implementar un nuevo sistema de archivos Multi-AZ de Amazon Elastic File System (Amazon EFS). EFS soporta replicación entre regiones, cumpliendo con los requisitos de una solución Multi-AZ con una copia de recuperación ante desastres en otra región. EFS puede acumular créditos de ruptura, lo que le permite manejar los requisitos de rendimiento máximo. Con un rendimiento aprovisionado de 75 MiBps y la capacidad de ráfagas de hasta 300 MiBps por 100 GB de almacenamiento, EFS puede administrar de manera efectiva las necesidades operativas máximas mientras mantiene un RPO consistente y confiable de menos de 1 hora a través de sus capacidades de replicación.
Question 449 of 529
Una empresa necesita recopilar datos de un experimento en una ubicación remota que no tenga conectividad a Internet. Durante el experimento, los sensores que están conectados a una red local generarán 6 TB de datos en un formato propietario en el transcurso de 1 semana. Los sensores se pueden configurar para cargar sus archivos de datos a un servidor FTP periódicamente, pero los sensores no tienen su propio servidor FTP. Los sensores tampoco soportan otros protocolos. La compañía necesita recopilar los datos de forma centralizada y trasladar los datos al almacenamiento de objetos en la nube de AWS lo antes posible después del experimento.
Qué solución cumplirá con estos requisitos?
A.
Solicite un dispositivo AWS Snowball Edge Compute Optimized. Conecte el dispositivo a la red local. Configure AWS DataSync con un nombre de bucket de destino y descargue los datos a través de NFS en el dispositivo. Después del experimento, devuelva el dispositivo a AWS para que los datos puedan cargarse en Amazon S3.
B.
Ordene un dispositivo AWS Snowcone, incluida una AMI de Amazon Linux 2. Conecte el dispositivo a la red local. Inicie una instancia de Amazon EC2 en el dispositivo. Cree un script de shell que descargue periódicamente datos de cada sensor. Después del experimento, devuelva el dispositivo a AWS para que los datos puedan cargarse como un volumen de Amazon Elastic Block Store (Amazon EBS).
C.
Ordene un dispositivo AWS Snowcone, incluida una AMI de Amazon Linux 2. Conecte el dispositivo a la red local. Inicie una instancia de Amazon EC2 en el dispositivo. Instale y configure un servidor FTP en la instancia EC2. Configure los sensores para cargar datos a la instancia EC2. Después del experimento, devuelva el dispositivo a AWS para que los datos puedan cargarse en Amazon S3.
D.
Solicite un dispositivo AWS Snowcone. Conecte el dispositivo a la red local. Configure el dispositivo para usar Amazon FSx. Configure los sensores para cargar datos en el dispositivo. Configure AWS DataSync en el dispositivo para sincronizar los datos cargados con un bucket de Amazon S3. Devuelva el dispositivo a AWS para que los datos puedan cargarse como un volumen de Amazon Elastic Block Store (Amazon EBS).
AnswerDiscussion
Correct Answer: C
En este escenario, los sensores solo pueden usar el protocolo FTP para cargar sus datos. La mejor solución es ordenar un dispositivo AWS Snowcone e instalar y configurar un servidor FTP en una instancia EC2 ejecutándose en Snowcone. Esta configuración permite que los sensores carguen sus datos directamente al servidor FTP. Una vez que se recopilan los datos, el dispositivo Snowcone se puede devolver a AWS y los datos se pueden cargar en Amazon S3. Esto garantiza que los datos se recopilen de manera confiable y se transporten de manera eficiente a la nube de AWS.
Question 450 of 529
Una empresa que tiene múltiples unidades de negocio está utilizando AWS Organizations con todas las funciones habilitadas. La compañía ha implementado una estructura de cuentas en la que cada unidad de negocio tiene su propia cuenta de AWS. Los administradores de cada cuenta de AWS necesitan ver los datos detallados de costos y utilización de su cuenta mediante Amazon Athena.
Cada unidad de negocio puede tener acceso solo a sus propios datos de costo y utilización. Se han implementado las políticas de IAM que rigen la capacidad de configurar los informes de costos y uso de AWS. Un informe central de costos y uso que contiene todos los datos de la organización ya está disponible en un bucket de Amazon S3.
Qué solución cumplirá estos requisitos con la MENOR complejidad operativa?
A.
En la cuenta de administración de la organización, use AWS Resource Access Manager (AWS RAM) para compartir los datos del Informe de costo y uso con cada cuenta de miembro.
B.
En la cuenta de administración de la organización, configure un evento S3 para invocar una función de AWS Lambda cada vez que llegue un nuevo archivo al bucket de S3 que contiene el Informe de costo y uso central. Configure la función Lambda para extraer los datos de cada cuenta de miembro y colocar los datos en Amazon S3 bajo un prefijo separado. Modifique la política de bucket de S3 para permitir que cada cuenta de miembro acceda a su propio prefijo.
C.
En cada cuenta de miembro, acceda a AWS Cost Explorer. Crear un nuevo informe que contenga información de costos relevante para la cuenta. Guarde el informe en el Explorador de costos. Proporcione instrucciones que los administradores de cuentas puedan usar para acceder al informe guardado.
D.
En cada cuenta de miembro, cree un nuevo bucket S3 para almacenar los datos del Informe de Costo y Uso. Configure un Informe de Costo y Uso para entregar los datos al nuevo bucket S3.
AnswerDiscussion
Correct Answer: D
La solución que cumple con los requisitos con la menor complejidad operativa es hacer que cada cuenta de miembro cree un nuevo bucket S3 para almacenar los datos del Informe de Costo y Uso. La configuración de un Informe de Costo y Uso separado para entregar datos a los nuevos buckets S3 en cada cuenta permite que cada unidad de negocio tenga acceso aislado solo a sus datos, sin configuraciones complejas que involucren funciones Lambda o mecanismos de intercambio entre cuentas. Esto simplifica el proceso al permitir la administración independiente de los Informes de Costo y Uso dentro de cada cuenta.
Question 451 of 529
Una empresa está diseñando un entorno de AWS para una aplicación de fabricación. La aplicación ha sido exitosa con los clientes y la base de usuarios de la aplicación ha aumentado. La compañía ha conectado el entorno de AWS al centro de datos local de la compañía a través de una conexión AWS Direct Connect de 1 Gbps. La compañía ha configurado BGP para la conexión.
La compañía debe actualizar la solución de conectividad de red existente para garantizar que la solución sea altamente disponible, tolerante a fallas y segura.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Agregue una IP privada dinámica AWS Site-to-Site VPN como ruta secundaria para proteger los datos en tránsito y proporcionar resiliencia para la conexión Direct Connect. Configure MacSec para cifrar el tráfico dentro de la conexión Direct Connect.
B.
Aprovisione otra conexión Direct Connect entre el centro de datos local de la compañía y AWS para aumentar la velocidad de transferencia y proporcionar resiliencia. Configure MacSec para cifrar el tráfico dentro de la conexión Direct Connect.
C.
Configure múltiples VIF privados. Equilibrar la carga de los datos a través de los VIF entre el centro de datos local y AWS para proporcionar resiliencia.
D.
Agregue una VPN estática de sitio a sitio de AWS como ruta secundaria para proteger los datos en tránsito y proporcionar resiliencia para la conexión Direct Connect.
AnswerDiscussion
Correct Answer: D
Agregar una VPN estática de sitio a sitio de AWS como ruta secundaria garantiza una alta disponibilidad y tolerancia a fallas para la conexión Direct Connect. Este enfoque también es seguro ya que las VPN cifran inherentemente los datos en tránsito. Además, es rentable en comparación con la configuración de una conexión Direct Connect adicional. Configurar MacSec no es una opción ya que MacSec solo es compatible con enlaces Direct Connect de 10 Gbps y 100 Gbps, y la compañía actualmente tiene una conexión de 1 Gbps.
Question 452 of 529
Una empresa necesita modernizar una aplicación y migrar la aplicación a AWS. La aplicación almacena los datos del perfil de usuario como texto en una sola tabla en una base de datos MySQL local.
Después de la modernización, los usuarios utilizarán la aplicación para subir archivos de video de hasta 4 GB de tamaño. Otros usuarios deben poder descargar los archivos de video de la aplicación. La compañía necesita una solución de almacenamiento de video que proporcione escalado rápido. La solución no debe afectar el rendimiento de la aplicación.
Qué solución cumplirá con estos requisitos?
A.
Migre la base de datos a Amazon Aurora PostgreSQL mediante AWS Database Migration Service (AWS DMS). Almacene los videos como cadenas codificadas en base64 en una columna TEXTO en la base de datos.
B.
Migre la base de datos a Amazon DynamoDB mediante AWS Database Migration Service (AWS DMS) con la herramienta de conversión de esquemas de AWS (AWS SCT). Almacene los videos como objetos en Amazon S3. Almacene la clave S3 en el elemento de DynamoDB correspondiente.
C.
Migre la base de datos a Amazon Keyspaces (para Apache Cassandra) mediante AWS Database Migration Service (AWS DMS) con la herramienta de conversión de esquemas de AWS (AWS SCT). Almacene los videos como objetos en Amazon S3. Almacene el identificador de objeto S3 en la entrada correspondiente de Amazon Keyspaces.
D.
Migre la base de datos a Amazon DynamoDB mediante AWS Database Migration Service (AWS DMS) con la herramienta de conversión de esquemas de AWS (AWS SCT). Almacene los videos como cadenas codificadas en base64 en el elemento correspondiente de DynamoDB.
AnswerDiscussion
Correct Answer: B
Para cumplir con los requisitos de modernizar la aplicación, migrar a AWS y manejar archivos de video de hasta 4 GB de tamaño, la mejor solución es almacenar los videos como objetos en Amazon S3. S3 proporciona almacenamiento escalable que puede manejar archivos grandes de manera eficiente y rentable sin afectar el rendimiento de las aplicaciones. El uso de DynamoDB para almacenar metadatos, incluidas las claves S3, garantiza un acceso rápido y una administración de los videos. Este enfoque separa el almacenamiento de video de la base de datos, evitando problemas de rendimiento asociados con el almacenamiento de datos binarios grandes directamente dentro de la base de datos.
Question 453 of 529
Una empresa almacena y administra documentos en un sistema de archivos Amazon Elastic File System (Amazon EFS). El sistema de archivos está cifrado con una clave de AWS Key Management Service (AWS KMS). El sistema de archivos está montado en una instancia de Amazon EC2 que ejecuta software propietario.
La compañía ha habilitado copias de seguridad automáticas para el sistema de archivos. Las copias de seguridad automáticas utilizan el plan de respaldo predeterminado de AWS Backup.
Un arquitecto de soluciones debe asegurarse de que los documentos eliminados se puedan recuperar dentro de un RPO de 100 minutos.
Qué solución cumplirá con estos requisitos?
A.
Crear un nuevo rol de IAM. Crear un nuevo plan de respaldo. Utilice el nuevo rol de IAM para crear copias de seguridad. Actualice la política de claves KMS para permitir que el nuevo rol de IAM utilice la clave. Implementar un horario de respaldo por hora para el sistema de archivos.
B.
Crear un nuevo plan de respaldo. Actualice la política de claves KMS para permitir que el rol de IAM AWSServiceRoleForBackup use la clave. Implemente una expresión cron personalizada para ejecutar una copia de seguridad del sistema de archivos cada 30 minutos.
C.
Crear un nuevo rol de IAM. Utilice el plan de respaldo existente. Actualice la política de claves KMS para permitir que el nuevo rol de IAM utilice la clave. Habilite backups continuos para una recuperación puntual.
D.
Utilice el plan de respaldo existente. Actualice la política de claves KMS para permitir que el rol de IAM AWSServiceRoleForBackup use la clave. Habilite la replicación entre regiones para el sistema de archivos.
AnswerDiscussion
Correct Answer: A
Para garantizar que los documentos eliminados se puedan recuperar dentro de un RPO de 100 minutos, es necesario tener un horario de respaldo frecuente. La creación de un nuevo rol de IAM y un nuevo plan de respaldo garantiza que se implementen los permisos adecuados. La actualización de la política de claves KMS permite que el nuevo rol de IAM utilice la clave, facilitando las copias de seguridad cifradas. La implementación de un programa de respaldo por hora cumple con el requisito de recuperar datos en 100 minutos, ya que las copias de seguridad por hora garantizarán que ningún dato tenga más de 60 minutos en el peor de los casos. Este enfoque proporciona un equilibrio entre la frecuencia y la administración de la sobrecarga operativa sin requerir soluciones no estándar como tareas cron personalizadas.
Question 454 of 529
Un arquitecto de soluciones debe proporcionar una forma segura para que un equipo de ingenieros en la nube utilice la CLI de AWS para cargar objetos en un bucket de Amazon S3. Cada ingeniero de nube tiene un usuario de IAM, claves de acceso de IAM y un dispositivo virtual de autenticación multifactor (MFA). Los usuarios de IAM para los ingenieros de la nube están en un grupo que se llama S3-Access. Los ingenieros de la nube deben usar MFA para realizar cualquier acción en Amazon S3.
Qué solución cumplirá con estos requisitos?
A.
Adjunte una política al bucket S3 para solicitar al usuario de IAM un código MFA cuando el usuario de IAM realice acciones en el bucket S3. Utilice las claves de acceso de IAM con la CLI de AWS para llamar a Amazon S3.
B.
Actualice la política de confianza para el grupo S3-Access para requerir que los directores usen MFA cuando los directores asuman el grupo. Utilice las claves de acceso de IAM con la CLI de AWS para llamar a Amazon S3.
C.
Adjunte una política al grupo S3-Access para denegar todas las acciones de S3 a menos que esté presente MFA. Utilice las claves de acceso de IAM con la CLI de AWS para llamar a Amazon S3.
D.
Adjunte una política al grupo S3-Access para denegar todas las acciones de S3 a menos que esté presente MFA. Solicitar credenciales temporales de AWS Security Token Service (AWS STS). Adjunte las credenciales temporales en un perfil al que Amazon S3 hará referencia cuando el usuario realice acciones en Amazon S3.
AnswerDiscussion
Correct Answer: D
Para garantizar una forma segura para que los ingenieros de la nube carguen objetos en un bucket de Amazon S3 mediante la CLI de AWS, la mejor solución consiste en implementar MFA (Multi-Factor Authentication). Adjuntar una política al grupo S3-Access que deniegue todas las acciones de S3 a menos que esté presente MFA garantiza que se aplique MFA. El uso de AWS STS (Security Token Service) para solicitar credenciales temporales agrega una capa adicional de seguridad mediante el uso de credenciales temporales de corta duración en lugar de claves de acceso a largo plazo. Las credenciales temporales, que pueden vincularse al MFA del usuario, se pueden adjuntar en un perfil al que hace referencia Amazon S3 al realizar acciones. Esto garantiza que se requiera MFA y maneje de forma segura las credenciales utilizadas para acceder a S3.
Question 455 of 529
Una empresa necesita migrar 60 aplicaciones heredadas locales a AWS. Las aplicaciones se basan en NET Framework y se ejecutan en Windows.
La empresa necesita una solución que minimice el tiempo de migración y no requiera cambios en el código de la aplicación. La compañía tampoco quiere administrar la infraestructura.
Qué solución cumplirá con estos requisitos?
A.
Refactorizar las aplicaciones y contenerizarlas mediante el uso de AWS Toolkit for NET Refactoring. Utilice Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate para alojar las aplicaciones contenerizadas.
B.
Utilice el Asistente de migración de aplicaciones web de Windows para migrar las aplicaciones a AWS Elastic Beanstalk. Utilice Elastic Beanstalk para implementar y administrar las aplicaciones.
C.
Utilice el Asistente de migración de aplicaciones web de Windows para migrar las aplicaciones a instancias de Amazon EC2. Utilice las instancias EC2 para implementar y administrar las aplicaciones.
D.
Refactorizar las aplicaciones y contenerizarlas mediante el uso de AWS Toolkit for NET Refactoring. Utilice Amazon Elastic Kubernetes Service (Amazon EKS) con el tipo de lanzamiento Fargate para alojar las aplicaciones contenerizadas.
AnswerDiscussion
Correct Answer: B
Para migrar a AWS 60 aplicaciones heredadas.NET Framework locales que se ejecutan en Windows, la solución necesita minimizar el tiempo de migración, no requerir cambios en el código de la aplicación y evitar responsabilidades de administración de infraestructura. El uso del Asistente de migración de aplicaciones web de Windows para migrar las aplicaciones a AWS Elastic Beanstalk cumple estos requisitos. Elastic Beanstalk simplifica la implementación y administración de aplicaciones al manejar automáticamente el aprovisionamiento, el escalado y la administración de la infraestructura necesarios, lo que permite a la empresa centrarse en sus aplicaciones sin necesidad de administrar la infraestructura subyacente.
Question 456 of 529
Una empresa necesita ejecutar grandes trabajos de procesamiento por lotes en datos que se almacenan en un bucket de Amazon S3. Los trabajos realizan simulaciones. Los resultados de los trabajos no son sensibles al tiempo, y el proceso puede soportar interrupciones.
Cada trabajo debe procesar 15-20 GB de datos cuando los datos se almacenan en el bucket S3. La compañía almacenará la salida de los trabajos en un bucket diferente de Amazon S3 para su posterior análisis.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree una canalización de datos sin servidor. Utilice AWS Step Functions para la orquestación. Utilice las funciones de AWS Lambda con capacidad aprovisionada para procesar los datos.
B.
Cree un entorno informático por lotes de AWS que incluya instancias puntuales de Amazon EC2. Especifique la estrategia de asignación SPOT_CAPACITY_OPTIMIED.
C.
Cree un entorno informático por lotes de AWS que incluya instancias bajo demanda e instancias puntuales de Amazon EC2. Especifique la estrategia de asignación SPOT_CAPACITY_OPTIMIED para las Instancias de spot.
D.
Utilice Amazon Elastic Kubernetes Service (Amazon EKS) para ejecutar los trabajos de procesamiento. Utilice grupos de nodos administrados que contengan una combinación de instancias bajo demanda e instancias puntuales de Amazon EC2.
AnswerDiscussion
Correct Answer: B
El uso de AWS Batch con instancias puntuales de Amazon EC2 mientras se especifica la estrategia de asignación SPOT_CAPACITY_OPTIMIED es la solución más rentable para ejecutar grandes trabajos de procesamiento por lotes en datos almacenados en un bucket de Amazon S3. Las instancias puntuales suelen estar disponibles a un costo menor en comparación con las instancias bajo demanda y, dado que los trabajos no son urgentes y pueden soportar interrupciones, esta estrategia de asignación maximiza el ahorro de costos y minimiza la probabilidad de interrupciones en los trabajos.
Question 457 of 529
Una empresa cuenta con una aplicación que analiza y almacena datos de imagen en las instalaciones. La aplicación recibe millones de nuevos archivos de imagen todos los días. Los archivos tienen un tamaño promedio de 1 MB. Los archivos se analizan en lotes de 1 GB. Cuando la aplicación analiza un lote, la aplicación une las imágenes. Luego, la aplicación archiva las imágenes como un solo archivo en un servidor NFS local para almacenamiento a largo plazo.
La compañía cuenta con un entorno Microsoft Hyper-V en las instalaciones y cuenta con capacidad de cómputos disponible. La compañía no tiene capacidad de almacenamiento y quiere archivar las imágenes en AWS. La empresa necesita la capacidad de recuperar datos archivados dentro de una semana de una solicitud.
La compañía tiene una conexión AWS Direct Connect de 10 Gbps entre su centro de datos local y AWS. La compañía necesita establecer límites de ancho de banda y programar imágenes archivadas para que se copien en AWS durante el horario no comercial.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Implemente un agente AWS DataSync en una nueva instancia de Amazon EC2 basada en GPUs. Configure el agente DataSync para copiar el lote de archivos del servidor local NFS a Amazon S3 Glacier Instant Retrieval. Después de la copia correcta, elimine los datos del almacenamiento local.
B.
Implemente un agente AWS DataSync como una máquina virtual Hyper-V in situ. Configure el agente DataSync para copiar el lote de archivos del servidor local NFS a Amazon S3 Glacier Deep Archive. Después de la copia correcta, elimine los datos del almacenamiento local.
C.
Implemente un agente AWS DataSync en una nueva instancia de Amazon EC2 de uso general. Configure el agente DataSync para copiar el lote de archivos del servidor local NFS a Amazon S3 Standard. Después de la copia correcta, elimine los datos del almacenamiento local. Cree una regla de ciclo de vida de S3 para hacer la transición de objetos de S3 Standard a S3 Glacier Deep Archive después de 1 día.
D.
Implemente una puerta de enlace de cinta de AWS Storage Gateway in premise en el entorno Hyper-V. Conecte la puerta de enlace de cinta a AWS. Utilice la creación automática de cinta. Especifique un grupo de Amazon S3 Glacier Deep Archive. Expulsar la cinta después de copiar el lote de imágenes.
AnswerDiscussion
Correct Answer: B
La compañía necesita archivar datos de imágenes en AWS de manera rentable con la capacidad de recuperar datos archivados en el plazo de una semana. La implementación de un agente AWS DataSync como una máquina virtual Hyper-V en las instalaciones (donde se encuentran los datos) garantiza una transferencia de datos eficiente. La configuración del agente DataSync para copiar las imágenes directamente en Amazon S3 Glacier Deep Archive minimiza los costos, ya que Deep Archive es la opción de almacenamiento más rentable para datos a los que rara vez se accede y tiene tiempos de recuperación flexibles en una semana. Después de una copia exitosa, la eliminación de los datos del almacenamiento local ayuda a administrar el uso del almacenamiento local.
Question 458 of 529
Una empresa quiere registrar indicadores clave de rendimiento (KPI) desde su aplicación como parte de una estrategia para convertir a un esquema de licencia basado en el usuario. La aplicación es una aplicación de varios niveles con una interfaz de usuario basada en la web. La compañía guarda todos los archivos de registro en Amazon CloudWatch mediante el agente de CloudWatch. Todos los inicios de sesión en la aplicación se guardan en un archivo de registro.
Como parte del nuevo esquema de licencia, la compañía necesita averiguar cuántos usuarios únicos tiene cada cliente a diario, semanalmente y mensualmente.
Qué solución proporcionará esta información con el MENOR cambio en la aplicación?
A.
Configure un filtro de métricas de Amazon CloudWatch Logs que guarde cada inicio de sesión exitoso como métrica. Configure el nombre de usuario y el nombre del cliente como dimensiones para la métrica.
B.
Cambie la lógica de la aplicación para que cada inicio de sesión exitoso genere una llamada al SDK de AWS para incrementar una métrica personalizada que registre las dimensiones del nombre de usuario y del nombre del cliente en CloudWatch.
C.
Configure el agente de CloudWatch para extraer métricas de inicio de sesión satisfactorias de los registros. Además, configure el agente de CloudWatch para guardar las métricas de inicio de sesión correctas como una métrica personalizada que utilice el nombre de usuario y el nombre del cliente como dimensiones para la métrica.
D.
Configure una función de AWS Lambda para consumir una transmisión de Amazon CloudWatch Logs de los registros de la aplicación. Además, configure la función Lambda para incrementar una métrica personalizada en CloudWatch que utilice el nombre de usuario y el nombre del cliente como dimensiones para la métrica.
AnswerDiscussion
Correct Answer: A
Configurar un filtro de métricas de Amazon CloudWatch Logs para guardar cada inicio de sesión exitoso como métrica y usar el nombre de usuario y el nombre del cliente como dimensiones para la métrica es la solución óptima. Este método aprovecha la funcionalidad existente de CloudWatch Logs y el agente CloudWatch Logs, lo que requiere cambios mínimos en la aplicación. Las otras opciones sugieren modificar la lógica de la aplicación o agregar componentes de infraestructura adicionales, que son innecesarios para este requisito.
Question 459 of 529
Una compañía está usando GitHub Actions para ejecutar una canalización de CI/CD que accede a los recursos en AWS. La compañía tiene un usuario de IAM que utiliza una clave secreta en la canalización para autenticarse en AWS. Un rol de IAM existente con una política adjunta otorga los permisos necesarios para implementar recursos.
El equipo de seguridad de la compañía implementa un nuevo requisito de que las tuberías ya no puedan usar claves secretas de larga duración. Un arquitecto de soluciones debe reemplazar la clave secreta por una solución de corta duración.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Cree un proveedor de identidad (IdP) SAML 2.0 de IAM en AWS Identity and Access Management (IAM). Cree un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API STS:AssumeRole. Adjuntar la política de IAM existente al nuevo rol de IAM. Actualiza GitHub para usar la autenticación SAML para la canalización.
B.
Cree un proveedor de identidad (IdP) de IAM OpenID Connect (OIDC) en AWS Identity and Access Management (IAM). Cree un nuevo rol de IAM con la política de confianza apropiada que permita la llamada a la API sts:AssumeroleWithWebIdentity desde el IdP de GitHub OIDC. Actualiza GitHub para asumir el rol de la canalización.
C.
Crear un pool de identidades de Amazon Cognito. Configura el proveedor de autenticación para usar GitHub. Cree un nuevo rol de IAM con la política de confianza apropiada que permita la llamada a la API sts:AssumeroleWithWebIdentity desde el proveedor de autenticación GitHub. Configure la canalización para usar Cognito como su proveedor de autenticación.
D.
Cree un anclaje de confianza para AWS Private Certificate Authority. Genere un certificado de cliente para usar con AWS IAM Roles Anywhere. Cree un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API STS:AssumeRole. Adjuntar la política de IAM existente al nuevo rol de IAM. Configure la canalización para usar la herramienta de ayuda de credenciales y para hacer referencia a la clave pública del certificado de cliente para asumir el nuevo rol de IAM.
AnswerDiscussion
Correct Answer: B
Para cumplir con el nuevo requisito de seguridad de evitar claves secretas de larga duración y minimizar la sobrecarga operativa, usar un proveedor de identidad IAM OpenID Connect (OIDC) es la mejor opción. El IdP de OIDC permite a GitHub Actions asumir roles a través de tokens de corta duración, que se administran de forma segura, y este proceso es soportado de forma nativa por GitHub. Este método simplifica la integración y la administración, proporcionando una transición perfecta desde claves secretas de larga duración con una configuración adicional mínima.
Question 460 of 529
Una empresa está ejecutando un proceso de rastreo web en una lista de URL de destino para obtener documentos de capacitación para algoritmos de capacitación de aprendizaje automático. Una flota de instancias t2.micro de Amazon EC2 extrae las URL de destino de una cola de Amazon Simple Queue Service (Amazon SQS). A continuación, las instancias escriben el resultado del algoritmo de rastreo como un archivo.csv en un volumen de Amazon Elastic File System (Amazon EFS). El volumen EFS está montado en todas las instancias de la flota.
Un sistema separado agrega las URL a la cola de SQS a tasas poco frecuentes. Las instancias rastrean cada URL en 10 segundos o menos.
Las métricas indican que algunas instancias están inactivas cuando no hay URL en la cola de SQS. Un arquitecto de soluciones necesita rediseñar la arquitectura para optimizar los costos.
Qué combinación de pasos cumplirá con estos requisitos de manera más rentable? (Elija dos.)
A.
Utilice instancias m5.8xlarge en lugar de instancias t2.micro para el proceso de rastreo web. Reducir el número de instancias en la flota en un 50%.
B.
Convierta el proceso de rastreo web en una función de AWS Lambda. Configure la función Lambda para obtener URL de la cola SQS.
C.
Modifique el proceso de rastreo web para almacenar resultados en Amazon Neptune.
D.
Modifique el proceso de rastreo web para almacenar los resultados en una instancia de MySQL sin servidor de Amazon Aurora.
E.
Modifique el proceso de rastreo web para almacenar los resultados en Amazon S3.
AnswerDiscussion
Correct Answer: B, E
En el escenario actual, la compañía quiere optimizar los costos de un proceso de rastreo web que se ejecuta en instancias EC2, que extraen URL de una cola SQS y almacenan los resultados en un volumen EFS. La conversión del proceso de rastreo web en una función de AWS Lambda eliminará la necesidad de ejecutar constantemente instancias EC2, reduciendo los costos significativamente ya que los cargos de AWS Lambda se basan en el tiempo de cómputo real consumido, no en la capacidad reservada. Almacenar los resultados en Amazon S3 es una solución rentable y escalable para el almacenamiento, ya que S3 proporciona almacenamiento de bajo costo con alta durabilidad y disponibilidad. La combinación de AWS Lambda y Amazon S3 optimizará los costos de computación y almacenamiento.
Question 461 of 529
Una empresa necesita migrar su sitio web de un centro de datos local a AWS. El sitio web consiste en un balanceador de carga, un sistema de gestión de contenido (CMS) que se ejecuta en un sistema operativo Linux y una base de datos MySQL.
El CMS requiere almacenamiento persistente compatible con NPS para un sistema de archivos. La nueva solución en AWS debe poder escalar de 2 instancias de Amazon EC2 a 30 instancias EC2 en respuesta a aumentos impredecibles de tráfico. La nueva solución tampoco debe requerir cambios en el sitio web y debe evitar la pérdida de datos.
Qué solución cumplirá con estos requisitos?
A.
Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Implemente el CMS en AWS Elastic Beanstalk con un balanceador de carga de aplicaciones y un grupo de Auto Scaling. Utilice .ebextensions para montar el sistema de archivos EFS en las instancias EC2. Cree una base de datos MySQL de Amazon Aurora independiente del entorno de Elastic Beanstalk.
B.
Cree un volumen de conexión múltiple de Amazon Elastic Block Store (Amazon EBS). Implemente el CMS en AWS Elastic Beanstalk con un balanceador de carga de red y un grupo de Auto Scaling. Utilice .ebextensions para montar el volumen de EBS en las instancias EC2. Cree una base de datos de Amazon RDS para MySQL en el entorno de Elastic Beanstalk.
C.
Cree un sistema de archivos de Amazon Elastic File System (Amazon EFS). Cree una plantilla de lanzamiento y un grupo de Auto Scaling para lanzar instancias EC2 para admitir el CMS. Cree un balanceador de carga de red para distribuir el tráfico. Cree una base de datos MySQL de Amazon Aurora. Utilice un gancho de ciclo de vida escalable EC2 Auto Scaling para montar el sistema de archivos EFS en las instancias EC2.
D.
Cree un volumen de conexión múltiple de Amazon Elastic Block Store (Amazon EBS). Cree una plantilla de lanzamiento y un grupo de Auto Scaling para lanzar instancias EC2 para admitir el CMS. Cree un balanceador de carga de aplicaciones para distribuir el tráfico. Cree un clúster de Amazon ElastiCache para Redis para admitir la base de datos MySQL. Utilice los datos de usuario de EC2 para adjuntar el volumen de EBS a las instancias de EC2.
AnswerDiscussion
Correct Answer: A
Amazon Elastic File System (Amazon EFS) es la opción adecuada para el almacenamiento persistente compatible con NFS requerido por el CMS. La implementación de CMS en AWS Elastic Beanstalk con un balanceador de carga de aplicaciones y un grupo de Auto Scaling garantiza que la solución pueda escalar de 2 a 30 instancias EC2 en respuesta a aumentos de tráfico. Al usar .ebextensions para montar el sistema de archivos EFS en las instancias EC2, se cumple el requisito de no tener cambios en el sitio web. La separación de la base de datos MySQL de Amazon Aurora del entorno de Elastic Beanstalk proporciona una solución de base de datos robusta y escalable que garantiza la integridad de los datos y evita la pérdida de datos.
Question 462 of 529
Una empresa necesita implementar la recuperación ante desastres para una aplicación crítica que se ejecute en una sola región de AWS. Los usuarios de la aplicación interactúan con una interfaz web alojada en instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). La aplicación escribe en una instancia de base de datos de Amazon RDS para MySQL. La aplicación también genera documentos procesados que se almacenan en un bucket de Amazon S3.
El equipo de finanzas de la compañía consulta directamente a la base de datos para ejecutar informes. Durante los periodos ocupados, estas consultas consumen recursos y afectan negativamente el rendimiento de las aplicaciones.
Un arquitecto de soluciones debe diseñar una solución que proporcione resiliencia durante un desastre. La solución debe minimizar la pérdida de datos y resolver los problemas de rendimiento que resultan de las consultas del equipo de finanzas.
Qué solución cumplirá con estos requisitos?
A.
Migre la base de datos a Amazon DynamoDB y utilice tablas globales de DynamoDB. Instruir al equipo de finanzas para consultar una tabla global en una región separada. Cree una función AWS Lambda para sincronizar periódicamente el contenido del bucket S3 original con un nuevo bucket S3 en la región separada. Lanzar instancias EC2 y crear un ALB en la región separada. Configure la aplicación para que apunte al nuevo bucket S3.
B.
Inicie instancias EC2 adicionales que alojen la aplicación en una región separada. Agregue las instancias adicionales a la existente en la región separada, cree una réplica de lectura de la instancia de base de datos RDS. Instruya al equipo de finanzas para que ejecute consultas contra la réplica de lectura. Utilice S3 Cross-Region Replication (CRR) desde el bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, promueva la réplica de lectura a una instancia de base de datos independiente. Configure la aplicación para que apunte al nuevo bucket S3 y a la réplica de lectura recién promocionada.
C.
Cree una réplica de lectura de la instancia de base de datos RDS en una región separada. Instruya al equipo de finanzas para que ejecute consultas contra la réplica de lectura. Cree AMI de las instancias EC2 que alojan el frontend de la aplicación. Copiar las AMI a la Región separada. Utilice S3 Cross-Region Replication (CRR) desde el bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, promueva la réplica de lectura a una instancia de base de datos independiente. Lanzar instancias EC2 desde las AMI y crear un ALB para presentar la aplicación a los usuarios finales. Configure la aplicación para que apunte al nuevo bucket S3.
D.
Cree instantáneas por hora de la instancia de base de datos RDS. Copie las instantáneas en una región separada. Agregue un clúster de Amazon ElastiCache frente a la base de datos RDS existente. Cree AMI de las instancias EC2 que alojan el frontend de la aplicación. Copiar las AMI a la Región separada. Utilice S3 Cross-Region Replication (CRR) desde el bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, restaure la base de datos a partir de la última instantánea de RDS. Lanzar instancias EC2 desde las AMI y crear un ALB para presentar la aplicación a los usuarios finales. Configure la aplicación para que apunte al nuevo bucket S3.
AnswerDiscussion
Correct Answer: C
Para garantizar la recuperación ante desastres con una pérdida mínima de datos y resolver problemas de rendimiento a partir de las consultas del equipo financiero, la solución óptima consiste en crear una réplica de lectura de la instancia de base de datos RDS en una región diferente. El equipo de finanzas debe ejecutar sus consultas contra la réplica de lectura para minimizar el impacto en el rendimiento de la aplicación. Además, la creación de AMI de las instancias EC2 permite una implementación rápida en caso de desastre. La replicación entre regiones de S3 mantendrá las salidas seguras al replicar los datos del bucket S3 en otra región. Si ocurre un desastre, la réplica de lectura se puede promover a una instancia de base de datos independiente y se pueden lanzar nuevas instancias EC2 desde las AMI con un ALB para servir a la aplicación, lo que garantiza la continuidad y el acceso a los datos mínimamente interrumpido.
Question 463 of 529
Una empresa tiene muchos servicios ejecutándose en su centro de datos local. El centro de datos está conectado a AWS mediante AWS Direct Connect (DX) y una VPN IPSec. Los datos del servicio son sensibles y la conectividad no puede atravesar Internet. La compañía quiere expandirse a un nuevo segmento de mercado y comenzar a ofrecer sus servicios a otras empresas que están utilizando AWS.
Qué solución cumplirá con estos requisitos?
A.
Cree un servicio de punto final de VPC que acepte tráfico TCP, alojarlo detrás de un balanceador de carga de red y haga que el servicio esté disponible a través de DX.
B.
Cree un servicio de punto final de VPC que acepte tráfico HTTP o HTTPS, alojarlo detrás de un balanceador de carga de aplicaciones y haga que el servicio esté disponible a través de DX.
C.
Conecte una puerta de enlace de Internet a la VPC y asegúrese de que el control de acceso a la red y las reglas de grupo de seguridad permitan el tráfico entrante y saliente relevante.
D.
Conecte una puerta de enlace NAT a la VPC y asegúrese de que el control de acceso a la red y las reglas de grupo de seguridad permitan el tráfico entrante y saliente relevante.
AnswerDiscussion
Correct Answer: A
Para cumplir con el requisito de garantizar que los datos del servicio no atraviesen Internet y sean accesibles de forma segura, la mejor solución es usar un servicio de punto final de VPC alojado detrás de un balanceador de carga de red (NLB). Los servicios de punto final de VPC, también conocidos como PrivateLink, permiten la conectividad segura y privada entre VPC sin cruzar Internet. El uso de un NLB es ideal porque puede manejar el tráfico TCP, que es versátil y puede cubrir varios tipos de servicios. Esto garantiza que los datos confidenciales del servicio permanezcan dentro de los límites de red seguros proporcionados por AWS Direct Connect.
Question 464 of 529
Una empresa utiliza AWS Organizations para administrar sus cuentas de AWS. Un arquitecto de soluciones debe diseñar una solución en la que solo los roles de administrador puedan usar acciones de IAM. Sin embargo, el arquitecto de soluciones no tiene acceso a todas las cuentas de AWS en toda la compañía.
Qué solución cumple con estos requisitos con la menor sobrecarga operativa?
A.
Cree un SCP que se aplique a todas las cuentas de AWS para permitir acciones de IAM solo para roles de administrador. Aplicar el SCP a la OU raíz.
B.
Configure AWS CloudTrail para invocar una función de AWS Lambda para cada evento relacionado con acciones de IAM. Configure la función para denegar la acción si el usuario que invocó la acción no es un administrador.
C.
Cree un SCP que se aplique a todas las cuentas de AWS para denegar acciones de IAM para todos los usuarios excepto aquellos con roles de administrador. Aplicar el SCP a la OU raíz.
D.
Establezca un límite de permisos de IAM que permita acciones de IAM. Adjunte el límite de permisos a cada rol de administrador en todas las cuentas de AWS.
AnswerDiscussion
Correct Answer: C
La solución más efectiva con la menor sobrecarga operativa es crear una Política de Control de Servicios (SCP) que se aplique a todas las cuentas de AWS para denegar acciones de IAM para todos los usuarios excepto aquellos con roles de administrador y aplicar este SCP a la Unidad Organizacional (OU) raíz. Los SCP administran permisos dentro de una organización de AWS y pueden aplicar dichas políticas en todas las cuentas de la organización a un nivel alto, lo que facilita el mantenimiento y la administración de permisos de manera consistente sin necesidad de acceder a cada cuenta de AWS individual.
Question 465 of 529
Una empresa utiliza una organización en AWS Organizations para administrar varias cuentas de AWS. La compañía aloja algunas aplicaciones en una VPC en la cuenta de servicios compartidos de la compañía.
La compañía ha adjuntado una puerta de enlace de tránsito a la VPC en la cuenta de servicios compartidos.
La compañía está desarrollando una nueva capacidad y ha creado un entorno de desarrollo que requiere acceso a las aplicaciones que se encuentran en la cuenta de servicios compartidos. La compañía pretende eliminar y recrear recursos frecuentemente en la cuenta de desarrollo. La compañía también quiere darle a un equipo de desarrollo la capacidad de recrear la conexión del equipo con la cuenta de servicios compartidos según sea necesario.
Qué solución cumplirá con estos requisitos?
A.
Crear una puerta de enlace de tránsito en la cuenta de desarrollo. Cree una solicitud de peering de puerta de enlace de tránsito a la cuenta de servicios compartidos. Configure la puerta de enlace de tránsito de servicios compartidos para aceptar automáticamente conexiones entre pares.
B.
Activa la aceptación automática de la puerta de enlace de tránsito en la cuenta de servicios compartidos. Utilice AWS Resource Access Manager (AWS RAM) para compartir el recurso de puerta de enlace de tránsito en la cuenta de servicios compartidos con la cuenta de desarrollo. Aceptar el recurso en la cuenta de desarrollo. Crear un archivo adjunto de puerta de enlace de tránsito en la cuenta de desarrollo.
C.
Active la aceptación automática de la puerta de enlace de tránsito en la cuenta de servicios compartidos. Cree un punto final de VPC. Utilice la política de punto final para otorgar permisos en el punto final de VPC para la cuenta de desarrollo. Configure el servicio de punto final para aceptar automáticamente las solicitudes de conexión. Proporcionar los detalles del punto final al equipo de desarrollo.
D.
Cree una regla de Amazon EventBridge para invocar una función de AWS Lambda que acepte el adjunto de puerta de enlace de tránsito cuando la cuenta de desarrollo realice una solicitud de datos adjuntos. Utilice AWS Network Manager para compartir la puerta de enlace de tránsito en la cuenta de servicios compartidos con la cuenta de desarrollo. Acepte la pasarela de tránsito en la cuenta de desarrollo.
AnswerDiscussion
Correct Answer: B
La cuenta de desarrollo necesita una solución flexible y automatizada para recrear con frecuencia la conexión a las aplicaciones en la cuenta de servicios compartidos. Al activar la aceptación automática de la puerta de enlace de tránsito en la cuenta de servicios compartidos y usar AWS Resource Access Manager (AWS RAM) para compartir el recurso de puerta de enlace de tránsito, el equipo de desarrollo está facultado para crear adjuntos de puerta de enlace de tránsito según sea necesario sin intervención manual, cumpliendo así el requisito de eliminaciones y recreaciones frecuentes. Este enfoque proporciona una solución eficiente, segura y manejable.
Question 466 of 529
Una empresa quiere migrar cargas de trabajo virtuales de Microsoft desde un centro de datos local a AWS. La compañía ha probado con éxito algunas cargas de trabajo de muestra en AWS. La compañía también ha creado una conexión VPN de sitio a sitio de AWS a una VPC. Un arquitecto de soluciones necesita generar un informe de costo total de propiedad (TCO) para la migración de todas las cargas de trabajo desde el centro de datos.
Se ha habilitado el protocolo simple de administración de redes (SNMP) en cada VM del centro de datos. La compañía no puede agregar más máquinas virtuales en el centro de datos y no puede instalar software adicional en las máquinas virtuales. Los datos de descubrimiento deben importarse automáticamente a AWS Migration Hub.
Qué solución cumplirá con estos requisitos?
A.
Utilice el servicio sin agente de AWS Application Migration Service y las recomendaciones de estrategia de AWS Migration Hub para generar el informe de TCO.
B.
Inicie una instancia de Amazon EC2 de Windows. Instale el recopilador sin agente de Migration Evaluator en la instancia EC2. Configure Migration Evaluator para generar el reporte de TCO.
C.
Inicie una instancia de Amazon EC2 de Windows. Instale el recopilador sin agente de Migration Evaluator en la instancia EC2. Configure Migration Hub para generar el informe de TCO.
D.
Utilice la herramienta AWS Migration Readiness Assessment dentro de la VPC. Configure Migration Evaluator para generar el reporte de TCO.
AnswerDiscussion
Correct Answer: B
La compañía necesita generar un informe de TCO para migrar todas las cargas de trabajo desde el centro de datos, y los datos deben importarse automáticamente a AWS Migration Hub. Dadas las limitaciones de no poder instalar software adicional en las máquinas virtuales locales, el uso de un recopilador sin agente es crucial. Al lanzar una instancia de Amazon EC2 de Windows e instalar el recopilador sin agente de Migration Evaluator en esta instancia, la compañía puede recopilar los datos necesarios a través de SNMP. Migration Evaluator está diseñado específicamente para analizar dichos datos y generar pronósticos financieros, incluyendo reportes de TCO. Esta solución cumple con todos los requisitos y aprovecha las herramientas de AWS de manera efectiva.
Question 467 of 529
Una compañía que está desarrollando un juego móvil está haciendo que los activos del juego estén disponibles en dos regiones de AWS. Los activos del juego se sirven desde un conjunto de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB) en cada región. La compañía requiere que los activos del juego se obtengan de la región más cercana. Si los activos del juego no están disponibles en la región más cercana, deben buscarse de la otra región.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una distribución de Amazon CloudFront. Crear un grupo de origen con un origen para cada ALB. Establecer uno de los orígenes como primario.
B.
Crear una comprobación de estado de Amazon Route 53 para cada ALCrear un registro de enrutamiento de conmutación por error de Route 53 que apunte a los dos ALB. Establezca el valor Evaluar salud objetivo en Sí.
C.
Cree dos distribuciones de Amazon CloudFront, cada una con un ALB como origen. Cree un registro de enrutamiento de conmutación por error de Amazon Route 53 que apunte a las dos distribuciones de CloudFront. Establezca el valor Evaluar salud objetivo en Sí.
D.
Crear una revisión de estado de Amazon Route 53 para cada ALB. Cree un registro de alias de latencia de Route 53 que apunte a los dos ALB. Establezca el valor Evaluar salud objetivo en Sí.
AnswerDiscussion
Correct Answer: D
Para cumplir con los requisitos de obtener activos del juego de la región más cercana y fallar a la otra región si la región más cercana no está disponible, es apropiado usar los registros de alias de latencia de Amazon Route 53. El alias de latencia registra el tráfico directo a la región con la latencia más baja, por lo que generalmente apunta a la región más cercana. Las comprobaciones de estado aseguran que si la región más cercana se vuelve insalubre, el tráfico se redirige a la otra región. Este método distribuye de manera eficiente el tráfico en función de la latencia y garantiza una alta disponibilidad en caso de falla regional.
Question 468 of 529
Una empresa implementa cargas de trabajo en varias cuentas de AWS. Cada cuenta tiene una VPC con registros de flujo de VPC publicados en formato de registro de texto en un bucket centralizado de Amazon S3. Cada archivo de registro se comprime con compresión gzip. La empresa deberá conservar los archivos de registro indefinidamente.
Un ingeniero de seguridad ocasionalmente analiza los registros utilizando Amazon Athena para consultar los registros de flujo de VPC. El rendimiento de la consulta se está degradando con el tiempo a medida que aumenta el número de registros ingeridos. Un arquitecto de soluciones debe mejorar el rendimiento del análisis de registros y reducir el espacio de almacenamiento que utilizan los registros de flujo de VPC.
Qué solución cumplirá estos requisitos con la mayor mejora de rendimiento?
A.
Cree una función AWS Lambda para descomprimir los archivos gzip y comprimir los archivos con compresión bzip2. Suscríbase la función Lambda a una notificación de evento s3:ObjectCreated:put S3 para el bucket S3.
B.
Habilite la aceleración de transferencia S3 para el bucket S3. Cree una configuración del ciclo de vida de S3 para mover archivos a la clase de almacenamiento S3 Intelligent-Tiering tan pronto como se carguen los archivos.
C.
Actualice la configuración del registro de flujo de VPC para almacenar los archivos en formato Apache Parquet. Especifique particiones por hora para los archivos de registro.
D.
Cree un nuevo grupo de trabajo Athena sin límites de control de uso de datos. Utiliza el motor Athena versión 2.
AnswerDiscussion
Correct Answer: C
Para abordar tanto la degradación del rendimiento de las consultas como la optimización del uso del espacio de almacenamiento, convertir archivos de registro al formato Apache Parquet es una solución efectiva. Apache Parquet es un formato de archivo de almacenamiento columnar que proporciona esquemas eficientes de compresión y codificación de datos, lo que mejora el rendimiento y reduce el espacio de almacenamiento. Además, especificar particiones por hora para los archivos de registro ayuda a organizar y administrar los datos de manera eficiente, mejorando aún más el rendimiento de las consultas en Amazon Athena. Este enfoque aprovecha las ventajas del almacenamiento columnar y la partición para cumplir con los requisitos con la mayor mejora de rendimiento.
Question 469 of 529
Una empresa quiere establecer una conexión dedicada entre su infraestructura local y AWS. La compañía está configurando una conexión AWS Direct Connect de 1 Gbps a su cuenta VPC. La arquitectura incluye una puerta de enlace de tránsito y una puerta de enlace de conexión directa para conectar varias VPC y la infraestructura local.
La compañía debe conectarse a los recursos de VPC a través de un VIF de tránsito mediante la conexión Direct Connect.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Actualice la conexión Direct Connect de 1 Gbps a 10 Gbps.
B.
Anuncie los prefijos de red locales sobre el VIF de tránsito.
C.
Anuncie los prefijos de VPC desde la puerta de enlace Direct Connect a la red local a través del VIF de tránsito.
D.
Actualice el atributo del modo de cifrado MacSec de la conexión Direct Connect a must_encrypt.
E.
Asocie un par de Nombre de Clave de Conexión MacSec/Clave de Asociación de Conectividad (CKN/CAK) con la conexión Direct Connect.
AnswerDiscussion
Correct Answer: B, C
Para establecer una conexión dedicada entre la infraestructura local y AWS mediante AWS Direct Connect y un VIF de tránsito, los pasos adecuados son anunciar los prefijos de red local a través del VIF de tránsito para garantizar el enrutamiento entre las instalaciones y la VPC, y anunciar los prefijos de VPC desde la puerta de enlace Direct Connect a la red local a través del VIF de tránsito. La actualización de la conexión a 10 Gbps, los requisitos de cifrado y la asociación de un nombre de clave de conexión MACSec/clave de asociación de conectividad no son necesarios para los requisitos básicos de conectividad y enrutamiento en este escenario.
Question 470 of 529
Una empresa quiere utilizar Amazon WorkSpaces en combinación con dispositivos de cliente ligero para reemplazar escritorios antiguos. Los empleados utilizan los escritorios para acceder a aplicaciones que funcionan con datos de ensayos clínicos. La política de seguridad corporativa establece que el acceso a las aplicaciones debe restringirse solo a las sucursales de la compañía. La compañía está considerando agregar una sucursal adicional en los próximos 6 meses.
Qué solución cumple con estos requisitos con la mayor eficiencia operativa?
A.
Crear una regla de grupo de control de acceso IP con la lista de direcciones públicas de las sucursales. Asocie el grupo de control de acceso IP con el directorio WorkSpaces.
B.
Utilice AWS Firewall Manager para crear una regla de ACL web con un IPSet con la lista de direcciones públicas de las ubicaciones de las sucursales. Asociar la ACL web con el directorio de WorkSpaces.
C.
Utilice AWS Certificate Manager (ACM) para emitir certificados de dispositivos de confianza a las máquinas implementadas en las sucursales. Habilite el acceso restringido en el directorio de WorkSpaces.
D.
Cree una imagen personalizada de WorkSpace con Firewall de Windows configurado para restringir el acceso a las direcciones públicas de las sucursales. Utilice la imagen para implementar los WorkSpaces.
ResponderDiscusión
Correct Answer: A
Crear un grupo de control de acceso IP con la lista de direcciones públicas de las sucursales y asociarlo con el directorio de WorkSpaces es la solución más eficiente desde el punto de vista operativo. Este enfoque aborda directamente el requisito de restringir el acceso a las aplicaciones desde ubicaciones específicas de oficinas y permite actualizaciones fáciles cuando se agregan nuevas sucursales. Es sencillo de implementar y administrar, asegurando que solo los dispositivos dentro del rango de IP especificado puedan acceder a los WorkSpaces.
Question 471 of 529
Una empresa utiliza AWS Organizations. La compañía ejecuta dos dispositivos de firewall en una cuenta de red centralizada. Cada dispositivo de firewall se ejecuta en una instancia de Amazon EC2 de alta disponibilidad configurada manualmente. Una puerta de enlace de tránsito conecta la VPC desde la cuenta de red centralizada a las VPC de las cuentas de miembro. Cada dispositivo de firewall utiliza una dirección IP privada estática que luego se usa para enrutar el tráfico de las cuentas de los miembros a Internet.
Durante un incidente reciente, un script mal configurado inició la terminación de ambos dispositivos de firewall. Durante la reconstrucción de los dispositivos de firewall, la compañía escribió un nuevo script para configurar los dispositivos de firewall al inicio.
La compañía quiere modernizar el despliegue de los dispositivos cortafuegos. Los dispositivos de firewall necesitan la capacidad de escalar horizontalmente para manejar el aumento del tráfico cuando la red se expande. La compañía debe continuar utilizando los dispositivos cortafuegos para cumplir con la política de la compañía. El proveedor de los dispositivos de firewall ha confirmado que la última versión del código de firewall funcionará con todos los servicios de AWS.
Qué combinación de pasos debería recomendar el arquitecto de soluciones para cumplir con estos requisitos de manera más rentable? (Elija tres.)
A.
Implementar un balanceador de carga de puerta de enlace en la cuenta de red centralizada. Configure un servicio de punto final que utilice AWS PrivateLink.
B.
Implementar un balanceador de carga de red en la cuenta de red centralizada. Configure un servicio de punto final que utilice AWS PrivateLink.
C.
Cree un grupo de Auto Scaling y una plantilla de lanzamiento que utilice el nuevo script como datos de usuario para configurar los dispositivos de firewall. Cree un grupo de destino que utilice el tipo de destino de instancia.
D.
Cree un grupo de Auto Scaling. Configure una implementación de AWS Launch Wizard que utilice el nuevo script como datos de usuario para configurar los dispositivos de firewall. Cree un grupo de destino que utilice el tipo de destino IP.
E.
Crear endpoints de VPC en cada cuenta de miembro. Actualice las tablas de ruta para que apunten a los puntos finales de la VPC.
F.
Cree endpoints de VPC en la cuenta de red centralizada. Actualice las tablas de ruta en cada cuenta de miembro para que apunten a los puntos finales de VPC.
ResponderDiscusión
Correct Answer: A, C, E
Para cumplir con los requisitos de modernizar la implementación de dispositivos de firewall de manera rentable, primero, es esencial implementar un balanceador de carga de puerta de enlace en la cuenta de red centralizada. Esto proporcionará capacidades de equilibrio de carga y escalado adecuadas para manejar el tráfico a través de los dispositivos de firewall. En segundo lugar, la creación de un grupo de Auto Scaling y una plantilla de lanzamiento que utilice el nuevo script como datos de usuario automatizará la implementación y escalado de los dispositivos de firewall. Este enfoque garantiza una alta disponibilidad y escalabilidad horizontal. Finalmente, es necesario crear endpoints de VPC en cada cuenta de miembro y actualizar sus tablas de ruta para apuntar a estos endpoints de VPC para garantizar que el tráfico se redirija a través de la cuenta de red centralizada de manera efectiva, manteniendo el cumplimiento de la política de la compañía.
Question 472 of 529
Un arquitecto de soluciones debe implementar una arquitectura de varias regiones para una base de datos de Amazon RDS para PostgreSQL que admita una aplicación web. La base de datos se lanza a partir de una plantilla de AWS CloudFormation que incluye servicios y características de AWS que están presentes tanto en la región primaria como en la secundaria.
La base de datos está configurada para copias de seguridad automatizadas, y tiene un RTO de 15 minutos y un RPO de 2 horas. La aplicación web está configurada para utilizar un registro Amazon Route 53 para enrutar el tráfico a la base de datos.
Qué combinación de pasos dará como resultado una arquitectura de alta disponibilidad que cumpla con todos los requisitos? (Elija dos.)
A.
Crear una réplica de lectura entre regiones de la base de datos en la Región secundaria. Configure una función de AWS Lambda en la región secundaria para promover la réplica de lectura durante un evento de conmutación por error.
B.
En la región primaria, cree una comprobación de estado en la base de datos que invocará una función de AWS Lambda cuando se detecte una falla. Programe la función Lambda para recrear la base de datos a partir de la última instantánea de la base de datos en la Región secundaria y actualizar los registros de host Route 53 para la base de datos.
C.
Cree una función de AWS Lambda para copiar la última copia de seguridad automatizada en la región secundaria cada 2 horas.
D.
Cree una política de enrutamiento de conmutación por error en Route 53 para el registro DNS de la base de datos. Establezca los puntos finales primarios y secundarios en los puntos finales en cada región.
E.
Cree una base de datos en espera activa en la región secundaria. Utilice una función de AWS Lambda para restaurar la base de datos secundaria a la última copia de seguridad automática de RDS en caso de que falle la base de datos primaria.
ResponderDiscusión
Correct Answer: A, D
Para lograr una arquitectura de alta disponibilidad para una base de datos de Amazon RDS para PostgreSQL con una configuración de varias regiones, es esencial implementar una réplica de lectura entre regiones y configurar un mecanismo de conmutación por error. La creación de una réplica de lectura entre regiones permite una replicación casi en tiempo real y una promoción rápida durante una conmutación por error, cumpliendo con los requisitos de RTO y RPO. La configuración de una política de enrutamiento de conmutación por error en Route 53 garantiza que el tráfico se reenruta a la región secundaria sin problemas en caso de que se produzca un error de región principal. Juntos, estos pasos proporcionan una solución de recuperación ante desastres resiliente y eficiente.
Question 473 of 529
Una empresa de comercio electrónico ejecuta una aplicación en AWS. La aplicación tiene una API de Amazon API Gateway que invoca una función de AWS Lambda. Los datos se almacenan en una instancia de base de datos de Amazon RDS para PostgreSQL.
Durante la venta flash más reciente de la compañía, un aumento repentino en las llamadas API afectó negativamente el rendimiento de la aplicación. Un arquitecto de soluciones revisó las métricas de Amazon CloudWatch durante ese tiempo y notó un aumento significativo en las invocaciones de Lambda y las conexiones de bases de datos. La utilización de la CPU también fue alta en la instancia de base de datos.
Qué debería recomendar el arquitecto de soluciones para optimizar el rendimiento de la aplicación?
A.
Aumentar la memoria de la función Lambda. Modifique la función Lambda para cerrar las conexiones de base de datos cuando se recuperen los datos.
B.
Agregue un clúster de Amazon ElastiCache para Redis para almacenar los datos a los que se accede con frecuencia desde la base de datos RDS.
C.
Cree un proxy RDS mediante la consola Lambda. Modifique la función Lambda para usar el punto final proxy.
D.
Modifique la función Lambda para conectarse a la base de datos fuera del controlador de la función. Verifique si hay una conexión de base de datos existente antes de crear una nueva conexión.
ResponderDiscusión
Correct Answer: C
Durante una venta flash, la aplicación experimentó un aumento de las llamadas a la API, lo que llevó a mayores invocaciones de Lambda y conexiones de base de datos, lo que resultó en una alta utilización de la CPU en la instancia de RDS. El uso de un proxy RDS puede ayudar a optimizar el rendimiento al administrar un grupo de conexiones de base de datos de manera eficiente. De esta manera, las funciones de Lambda pueden reutilizar las conexiones existentes en lugar de abrir otras nuevas con frecuencia, reduciendo la carga en la base de datos y mejorando el rendimiento general. Por lo tanto, crear un proxy RDS y modificar la función Lambda para usar el punto final del proxy es la mejor solución. Además, es posible crear un proxy RDS desde la consola Lambda, lo que garantiza una integración perfecta.
Question 474 of 529
Una empresa minorista quiere mejorar su arquitectura de aplicaciones. Las aplicaciones de la compañía registran nuevos pedidos, manejan devoluciones de mercancía y proporcionan análisis. Las aplicaciones almacenan datos minoristas en una base de datos MySQL y una base de datos de análisis Oracle OLAP. Todas las aplicaciones y bases de datos están alojadas en instancias de Amazon EC2.
Cada aplicación consta de varios componentes que manejan diferentes partes del proceso de pedido. Estos componentes utilizan datos entrantes de diferentes fuentes. Cada semana se ejecuta un trabajo ETL separado y copia los datos de cada aplicación a la base de datos de análisis.
Un arquitecto de soluciones debe rediseñar la arquitectura para convertirla en una solución basada en eventos que utilice servicios sin servidor. La solución debe proporcionar análisis actualizados casi en tiempo real.
Qué solución cumplirá con estos requisitos?
A.
Migre las aplicaciones individuales como microservicios a contenedores de Amazon Elastic Container Service (Amazon ECS) que utilizan AWS Fargate. Mantenga la base de datos MySQL minorista en Amazon EC2. Mueva la base de datos de análisis a Amazon Neptune. Utilice Amazon Simple Queue Service (Amazon SQS) para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis.
B.
Cree un grupo de Auto Scaling para cada aplicación. Especifique el número necesario de instancias EC2 en cada grupo de Auto Scaling. Migre la base de datos MySQL minorista y la base de datos de análisis a Amazon Aurora MySQL. Utilice Amazon Simple Notification Service (Amazon SNS) para enviar todos los datos entrantes a las instancias EC2 correctas y a la base de datos de análisis.
C.
Migre las aplicaciones individuales como microservicios a contenedores de Amazon Elastic Kubernetes Service (Amazon EKS) que utilizan AWS Fargate. Migre la base de datos MySQL minorista a Amazon Aurora Serverless MySQL. Migre la base de datos de análisis a Amazon Redshift Serverless. Utilice Amazon EventBridge para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis.
D.
Migre las aplicaciones individuales como microservicios a Amazon AppStream 2.0. Migre la base de datos MySQL minorista a Amazon Aurora MySQL. Migre la base de datos de análisis a Amazon Redshift Serverless. Utilice AWS IoT Core para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis.
ResponderDiscusión
Correct Answer: C
Para diseñar una solución basada en eventos utilizando servicios sin servidor que proporcionen análisis actualizados casi en tiempo real, la migración de aplicaciones individuales como microservicios a contenedores de Amazon Elastic Kubernetes Service (Amazon EKS) mediante AWS Fargate garantiza un entorno escalable y en contenedores. Mover la base de datos MySQL minorista a Amazon Aurora Serverless MySQL proporciona una solución de base de datos relacional sin servidor de alta disponibilidad. La migración de la base de datos de análisis a Amazon Redshift Serverless ofrece un almacén de datos escalable y sin servidor optimizado para análisis en tiempo real. El uso de Amazon EventBridge para enviar datos entrantes tanto a los microservicios como a la base de datos de análisis facilita una arquitectura basada en eventos, proporcionando las capacidades necesarias de transmisión de datos en tiempo real.
Question 475 of 529
Una empresa está planeando una migración de un centro de datos local a la nube de AWS. La compañía planea usar múltiples cuentas de AWS que se administran en una organización en AWS Organizations. La compañía creará un pequeño número de cuentas inicialmente y agregará cuentas según sea necesario. Un arquitecto de soluciones debe diseñar una solución que active AWS CloudTrail en todas las cuentas de AWS.
Cuál es la solución más eficiente desde el punto de vista operativo que cumple con estos requisitos?
A.
Cree una función de AWS Lambda que cree una nueva ruta de CloudTrail en todas las cuentas de AWS de la organización. Invocar la función Lambda diariamente mediante una acción programada en Amazon EventBridge.
B.
Crear un nuevo rastro de CloudTrail en la cuenta de administración de la organización. Configure el rastro para registrar todos los eventos de todas las cuentas de AWS en la organización.
C.
Cree una nueva ruta de CloudTrail en todas las cuentas de AWS de la organización. Crea nuevos senderos cada vez que se crea una nueva cuenta. Definir un SCP que evite la eliminación o modificación de rastros. Aplicar el SCP a la OU raíz.
D.
Cree un runbook de AWS Systems Manager Automation que cree un rastro de CloudTrail en todas las cuentas de AWS de la organización. Invoque la automatización mediante el uso de Systems Manager State Manager.
ResponderDiscusión
Correct Answer: B
Crear un nuevo rastro de CloudTrail en la cuenta de administración de la organización y configurarlo para registrar todos los eventos de todas las cuentas de AWS en la organización es la solución más eficiente desde el punto de vista operativo. Este enfoque centraliza la configuración de registro, elimina la necesidad de administrar múltiples senderos en varias cuentas y garantiza un registro consistente sin la necesidad de una intervención manual continua. Adicionalmente, permite un monitoreo y auditoría más fácil de todas las actividades en la organización.
Question 476 of 529
Una empresa de desarrollo de software cuenta con múltiples ingenieros que trabajan de forma remota. La compañía está ejecutando Active Directory Domain Services (AD DS) en una instancia de Amazon EC2. La política de seguridad de la compañía establece que todos los servicios internos, no públicos, que se implementen en una VPC deben ser accesibles a través de una VPN. Se debe utilizar la autenticación multifactor (MFA) para acceder a una VPN.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Cree una conexión VPN de sitio a sitio de AWS. Configure la integración entre una VPN y AD DS. Utilice un cliente de Amazon WorkSpaces con soporte MFA habilitado para establecer una conexión VPN.
B.
Cree un punto final de VPN de cliente de AWS. Cree un directorio AD Connector para la integración con AD DS. Habilite el MFA para el conector AD. Utilice AWS Client VPN para establecer una conexión VPN.
C.
Cree varias conexiones VPN de sitio a sitio de AWS mediante AWS VPN CloudHub. Configure la integración entre AWS VPN CloudHub y AD DS. Utilice AWS Copilot para establecer una conexión VPN.
D.
Cree un endpoint de Amazon WorkLink. Configure la integración entre Amazon WorkLink y AD DS. Habilite MFA en Amazon WorkLink. Utilice AWS Client VPN para establecer una conexión VPN.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos de proporcionar acceso VPN seguro y habilitado para MFA a servicios internos no públicos implementados en una VPC mientras se integra con los Servicios de dominio de Active Directory (AD DS), la solución correcta es crear un punto final de VPN de cliente de AWS. Un punto final de AWS Client VPN permite conexiones seguras desde dispositivos cliente a AWS o redes locales. Al utilizar un directorio AD Connector para la integración con AD DS y habilitar la autenticación multifactor (MFA), las políticas de seguridad de la empresa se cumplen de manera efectiva. AWS Client VPN es compatible con MFA, lo que garantiza la autenticación segura para los usuarios que acceden a la VPN.
Question 477 of 529
Una empresa está ejecutando una aplicación web de tres niveles en un centro de datos local. El frontend es servido por un servidor web Apache, el nivel medio es una aplicación Java monolítica y el nivel de almacenamiento es una base de datos PostgreSQL.
Durante una reciente promoción de marketing, los clientes no pudieron realizar pedidos a través de la aplicación porque la aplicación se bloqueó. Un análisis mostró que los tres niveles estaban sobrecargados. La aplicación dejó de responder y la base de datos alcanzó su límite de capacidad debido a las operaciones de lectura. La compañía ya cuenta con varias promociones similares programadas en un futuro próximo.
Un arquitecto de soluciones debe desarrollar un plan de migración a AWS para resolver estos problemas. La solución debe maximizar la escalabilidad y minimizar el esfuerzo operativo
Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)
A.
Refactorizar el frontend para que los activos estáticos se puedan hospedar en Amazon S3. Utilice Amazon CloudFront para servir el frontend a los clientes. Conecte el frontend a la aplicación Java.
B.
Realoje el servidor web Apache del frontend en instancias de Amazon EC2 que se encuentran en un grupo de Auto Scaling. Use un equilibrador de carga frente al grupo Auto Scaling. Utilice Amazon Elastic File System (Amazon EFS) para alojar los activos estáticos que necesita el servidor web Apache.
C.
Rehospede la aplicación Java en un entorno de AWS Elastic Beanstalk que incluye escalado automático.
D.
Refactorizar la aplicación Java, Desarrollar un contenedor Docker para ejecutar la aplicación Java. Utilice AWS Fargate para alojar el contenedor.
E.
Utilice AWS Database Migration Service (AWS DMS) para reorganizar la base de datos PostgreSQL a una base de datos PostgreSQL de Amazon Aurora. Utilice Aurora Auto Scaling para réplicas de lectura.
F.
Rehospede la base de datos PostgreSQL en una instancia de Amazon EC2 que tenga el doble de memoria que el servidor local.
ResponderDiscusión
Correct Answer: A, C, E
Para abordar los problemas de escalabilidad y esfuerzo operativo de la aplicación web local, se recomiendan los siguientes pasos: Refactorar el frontend para que los activos estáticos puedan hospedarse en Amazon S3 y usar Amazon CloudFront para servir el frontend a los clientes, ya que esto descarga la entrega de contenido estático de la interfaz y mejora el rendimiento. Migre la aplicación Java a un entorno de AWS Elastic Beanstalk, que proporciona una implementación simplificada, escalado automático y una sobrecarga operativa reducida. Utilice AWS Database Migration Service para reorganizar la base de datos PostgreSQL a una base de datos PostgreSQL de Amazon Aurora, aprovechando Aurora Auto Scaling para administrar réplicas de lectura de manera eficiente y manejar una mayor carga. Estos pasos maximizan colectivamente la escalabilidad y minimizan el esfuerzo operativo, asegurando que la aplicación pueda manejar futuras promociones con éxito.
Question 478 of 529
Una empresa está implementando una nueva aplicación en AWS. La aplicación consta de un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) y un repositorio de Amazon Elastic Container Registry (Amazon ECR). El clúster EKS tiene un grupo de nodos administrados por AWS.
Las pautas de seguridad de la compañía establecen que todos los recursos en AWS deben analizarse continuamente en busca de vulnerabilidades de seguridad.
Qué solución cumplirá con este requisito con la menor sobrecarga operativa?
A.
Active AWS Security Hub. Configure Security Hub para escanear los nodos EKS y el repositorio ECR.
B.
Active Amazon Inspector para analizar los nodos EKS y el repositorio ECR.
C.
Inicie una nueva instancia de Amazon EC2 e instale una herramienta de análisis de vulnerabilidades desde AWS Marketplace. Configure la instancia EC2 para escanear los nodos EKS. Configure Amazon ECR para realizar una exploración básica al pulsar.
D.
Instale el agente de Amazon CloudWatch en los nodos EKS. Configure el agente de CloudWatch para que escanee continuamente. Configure Amazon ECR para realizar una exploración básica al pulsar.
ResponderDiscusión
Correct Answer: B
La activación de Amazon Inspector cumplirá con los requisitos con la menor sobrecarga operativa. Amazon Inspector descubre y analiza automáticamente instancias de Amazon EC2 (que incluyen nodos EKS en este contexto) e imágenes de contenedores en Amazon ECR en busca de vulnerabilidades de software conocidas y exposición involuntaria de la red. Esta solución proporciona una gestión continua y automatizada de vulnerabilidades sin necesidad de configuración adicional o intervención manual, minimizando así la sobrecarga operativa.
Question 479 of 529
Una empresa necesita mejorar la confiabilidad de su aplicación de venta de boletos. La aplicación se ejecuta en un clúster de Amazon Elastic Container Service (Amazon ECS). La compañía utiliza Amazon CloudFront para dar servicio a la aplicación. Un único servicio ECS del clúster de ECS es el origen de la distribución de CloudFront.
La aplicación permite que solo un número específico de usuarios activos ingresen a un flujo de compra de boletos. Estos usuarios son identificados por un atributo cifrado en su JSON Web Token (JWT). Todos los demás usuarios son redirigidos a un módulo de sala de espera hasta que haya capacidad de compra disponible.
La aplicación está experimentando altas cargas. El módulo de sala de espera funciona según lo diseñado, pero la carga en la sala de espera está interrumpiendo la disponibilidad de las aplicaciones.
Esta interrupción está afectando negativamente las transacciones de venta de boletos de la aplicación.
Qué solución brindará la MÁS confiabilidad para las transacciones de venta de boletos durante periodos de alta carga?
A.
Cree un servicio separado en el clúster ECS para la sala de espera. Utilice una configuración de escalado separada. Asegúrese de que el servicio de venta de boletos utilice la información de JWT y reenvíe adecuadamente las solicitudes al servicio de sala de espera.
B.
Mover la aplicación a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Divida el módulo de la sala de espera en una cápsula que esté separada de la cápsula de venta de boletos. Haga que la cápsula de venta de boletos sea parte de un StateFulset. Asegúrese de que el pod de venta de boletos use la información de JWT y reenvíe adecuadamente las solicitudes al pod de la sala de espera.
C.
Cree un servicio separado en el clúster ECS para la sala de espera. Utilice una configuración de escalado separada. Cree una función CloudFront que inspeccione la información de JWT y reenvíe adecuadamente las solicitudes al servicio de venta de boletos o al servicio de sala de espera.
D.
Mover la aplicación a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Divida el módulo de la sala de espera en una cápsula que esté separada de la cápsula de venta de boletos. Utilice AWS App Mesh aprovisionando el controlador App Mesh para Kubernetes. Habilite la autenticación MTL y la autenticación de servicio a servicio para la comunicación entre el pod de venta de boletos y el pod de la sala de espera. Asegúrese de que el pod de venta de boletos use la información de JWT y reenvíe adecuadamente las solicitudes al pod de la sala de espera.
ResponderDiscusión
Correct Answer: C
Para mejorar la confiabilidad de la aplicación de tickets durante períodos de alta carga, es clave crear un servicio separado en el clúster ECS para la sala de espera con una configuración de escalado distinta. Al utilizar una función CloudFront que inspecciona la información de JWT y reenvía adecuadamente las solicitudes al servicio de venta de boletos o al servicio de sala de espera, la solución descarga el proceso de toma de decisiones de los propios servicios ECS. Esto reduce la carga en el servicio de venta de boletos, asegurando que permanezca disponible para las transacciones de venta de boletos, mientras que el servicio de sala de espera dedicado maneja a los usuarios en espera de manera eficiente.
Question 480 of 529
Un arquitecto de soluciones está creando una plantilla de AWS CloudFormation a partir de un entorno de AWS que no es de producción creado manualmente. La plantilla CloudFormation se puede destruir y recrear según sea necesario. El entorno contiene una instancia de Amazon EC2. La instancia EC2 tiene un perfil de instancia que utiliza la instancia EC2 para asumir un rol en una cuenta principal.
El arquitecto de soluciones recrea el rol en una plantilla de CloudFormation y usa el mismo nombre de rol. Cuando se inicia la plantilla de CloudFormation en la cuenta secundaria, la instancia EC2 ya no puede asumir el rol en la cuenta principal debido a los permisos insuficientes
Qué debe hacer el arquitecto de soluciones para resolver este problema?
A.
En la cuenta principal, edite la política de confianza para el rol que la instancia EC2 necesita asumir. Asegúrese de que el ARN del rol de destino en la instrucción existente que permite la acción sts:Assumerole es correcto. Guarde la política de confianza.
B.
En la cuenta principal, edite la política de confianza para el rol que la instancia EC2 necesita asumir. Agrega una sentencia que permita la acción sts:Assumerole para el principal raíz de la cuenta hija. Guarde la política de confianza.
C.
Vuelva a actualizar la pila de CloudFormation. Especifique solo la capacidad CAPABILITY_NAMED_IAM.
D.
Vuelva a actualizar la pila de CloudFormation. Especifique la capacidad CAPABILITY_IAM y la capacidad CAPABILITY_NAMED_IAM.
ResponderDiscusión
Correct Answer: A
La respuesta correcta implica editar la política de confianza para garantizar que se especifique el ARN correcto para el rol en la cuenta secundaria. Cuando se recrea un rol, aunque tenga el mismo nombre, su ARN cambia. La instancia EC2 necesita el ARN de rol correcto para asumir el rol en la cuenta principal. No se recomienda permitir el principal raíz (como en la opción B) debido a riesgos de seguridad. Especificar solo las capacidades CAPABILITY_NAMED_IAM o ambas capacidades de IAM en CloudFormation (opciones C y D) no aborda el problema de la política de confianza. Por lo tanto, para resolver el problema, la política de confianza en la cuenta principal debe actualizarse con el ARN correcto para el rol, asegurando que la instancia EC2 pueda asumir el rol correctamente.
Question 481 of 529
La aplicación web de una empresa tiene problemas de confiabilidad. La aplicación sirve a los clientes a nivel mundial. La aplicación se ejecuta en una única instancia de Amazon EC2 y realiza operaciones de lectura intensiva en una base de datos de Amazon RDS para MySQL.
Durante una carga alta, la aplicación deja de responder y requiere un reinicio manual de la instancia EC2. Un arquitecto de soluciones debe mejorar la confiabilidad de la aplicación.
Cuál solución cumplirá este requisito con el MENOR esfuerzo de desarrollo?
A.
Cree una distribución de Amazon CloudFront. Especifique la instancia EC2 como origen de la distribución. Configure una implementación Multi-AZ para la base de datos RDS para MySQL. Utilice la instancia de base de datos en espera para las operaciones de lectura intensiva.
B.
Ejecute la aplicación en instancias EC2 que estén en un grupo de Auto Scaling. Coloque las instancias EC2 detrás de un balanceador de carga Elastic Load Balanceing (ELB). Reemplace el servicio de base de datos por Amazon Aurora. Utilice réplicas de Aurora para las operaciones de lectura intensiva.
C.
Implemente AWS Global Accelerator. Configure una implementación Multi-AZ para la base de datos RDS para MySQL. Utilice la instancia de base de datos en espera para las operaciones de lectura intensiva.
D.
Migre la aplicación a las funciones de AWS Lambda. Crear réplicas de lectura para la base de datos RDS for MySQL. Utilice las réplicas de lectura para las operaciones de lectura intensiva.
ResponderDiscusión
Correct Answer: B
Ejecutar la aplicación en instancias EC2 que forman parte de un grupo de Auto Scaling y colocarlas detrás de un balanceador de carga Elastic Load Balanceing (ELB) aborda la necesidad de reinicios automáticos y escalado basados en la carga. Reemplazar el servicio de base de datos con Amazon Aurora, que ofrece capacidades de replicación integradas a través de réplicas Aurora, garantiza que las operaciones de lectura intensiva se manejen de manera eficiente. Esta combinación mejora la confiabilidad y escalabilidad con un mínimo esfuerzo de desarrollo, ya que aprovecha los servicios administrados de AWS diseñados para tales casos de uso.
Question 482 of 529
Una empresa necesita utilizar un servidor habilitado para AWS Transfer Family SFTPcon un bucket de Amazon S3 para recibir actualizaciones de un proveedor de datos externo. Los datos están encriptados con cifrado Pretty Good Privacy (PGP). La compañía necesita una solución que descifrará automáticamente los datos después de que la compañía los reciba.
Un arquitecto de soluciones utilizará un flujo de trabajo administrado por Transfer Family. La compañía ha creado una función de servicio de IAM mediante una política de IAM que permite el acceso a AWS Secrets Manager y al bucket S3. La relación de confianza del rol permite que el servicio de transferencia amazonaws.com asuma el rol.
Qué debe hacer el arquitecto de soluciones a continuación para completar la solución para el descifrado automático?
A.
Almacenar la clave pública PGP en Secrets Manager. Agregue un paso nominal en el flujo de trabajo administrado de Transfer Family para descifrar archivos. Configure los parámetros de cifrado PGP en el paso nominal. Asociar el flujo de trabajo con el servidor Transfer Family.
B.
Almacene la clave privada PGP en Secrets Manager. Agregue un paso de manejo de excepciones en el flujo de trabajo administrado por Transfer Family para descifrar archivos. Configure los parámetros de cifrado PGP en el controlador de excepciones. Asociar el flujo de trabajo con el usuario SFTP.
C.
Almacene la clave privada PGP en Secrets Manager. Agregue un paso nominal en el flujo de trabajo administrado de Transfer Family para descifrar archivos. Configure los parámetros de descifrado PGP en el paso nominal. Asociar el flujo de trabajo con el servidor Transfer Family.
D.
Almacenar la clave pública PGP en Secrets Manager. Agregue un paso de manejo de excepciones en el flujo de trabajo administrado por Transfer Family para descifrar archivos. Configure los parámetros de descifrado PGP en el controlador de excepciones. Asociar el flujo de trabajo con el usuario SFTP.
ResponderDiscusión
Correct Answer: C
Para descifrar automáticamente los datos recibidos a través del servidor SFTP de la familia AWS Transfer, la clave privada PGP debe almacenarse en AWS Secrets Manager ya que es necesaria para el descifrado. Se debe agregar un paso nominal en el flujo de trabajo administrado por la familia de transferencias para manejar el proceso de descifrado. Los parámetros de descifrado deben configurarse en este paso, y luego el flujo de trabajo debe asociarse con el servidor de la familia de transferencias para garantizar que el descifrado ocurra como parte del flujo de trabajo administrado. El almacenamiento de la clave pública es incorrecto para fines de descifrado porque la clave privada es necesaria para descifrar los datos cifrados con PGP.
Question 483 of 529
Una compañía está migrando la infraestructura para su juego multijugador masivo a AWS. La aplicación del juego cuenta con una tabla de clasificación donde los jugadores pueden ver las clasificaciones en tiempo real. La tabla de clasificación requiere lecturas de microsegundos y latencias de escritura de un solo dígito-milisegundo. Los datasets tienen un tamaño de terabytes de un solo dígito y deben estar disponibles para aceptar escrituras en menos de un minuto si se produce una falla del nodo primario.
La compañía necesita una solución en la que los datos puedan persistir para su posterior procesamiento analítico a través de una canalización de datos.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
B.
Cree una base de datos de Amazon ROS con una réplica de lectura. Configure la aplicación para apuntar escrituras al punto final del escritor. Configure la aplicación para apuntar lecturas al punto final del lector.
C.
Crear un clúster de Amazon MemoryDB para Redis en modo Muit-AZ Configure la aplicación para interactuar con el nodo principal.
D.
Cree varios nodos Redis en instancias de Amazon EC2 repartidos en varias zonas de disponibilidad. Configure las copias de seguridad en Amazon S3.
ResponderDiscusión
Correct Answer: C
MemoryDB para Redis está diseñado para proporcionar un rendimiento ultrarrápido con latencias de lectura de microsegundos y escritura de milisegundos de un solo dígito, lo que lo hace ideal para una tabla de clasificación en tiempo real en una aplicación de juegos. Admite implementaciones Multi-AZ para una alta disponibilidad y puede manejar fallas de nodo primario promoviendo una réplica rápidamente. Además, puede persistir los datos, lo que los hace adecuados para el procesamiento analítico posterior, todo con una sobrecarga operativa mínima.
Question 484 of 529
Una empresa está ejecutando varias aplicaciones en la nube de AWS. Las aplicaciones son específicas para separar las unidades de negocio en la empresa. La compañía está ejecutando los componentes de las aplicaciones en varias cuentas de AWS que se encuentran en una organización en AWS Organizations.
Cada recurso en la nube en la organización de la compañía tiene una etiqueta que se llama BusinessUnit. Cada etiqueta ya tiene el valor apropiado del nombre de la unidad de negocio.
La compañía necesita destinar sus costos en la nube a diferentes unidades de negocio. La compañía también necesita visualizar los costos de la nube para cada unidad de negocio.
Qué solución cumplirá con estos requisitos?
A.
En la cuenta de administración de la organización, cree una etiqueta de asignación de costos que se llame BusinessUnit. También en la cuenta de administración, cree un bucket de Amazon S3 y un Informe de costo y uso de AWS (AWS CUR). Configure el bucket S3 como destino para el AWS CUR. Desde la cuenta de administración, consulte los datos de AWS CUR mediante Amazon Athena. Utilice Amazon QuickSight para la visualización.
B.
En cada cuenta de miembro, cree una etiqueta de asignación de costos que se llame BusinessUnit. En la cuenta de administración de la organización, cree un bucket de Amazon S3 y un Informe de costo y uso de AWS (AWS CUR). Configure el bucket S3 como destino para el AWS CUR. Cree un panel de Amazon CloudWatch para su visualización.
C.
En la cuenta de administración de la organización, cree una etiqueta de asignación de costos que se llame BusinessUnit. En cada cuenta de miembro, cree un bucket de Amazon S3 y un informe de costos y uso de AWS (AWS CUR). Configure cada bucket S3 como destino para sus respectivos AWS CUR. En la cuenta de administración, cree un panel de Amazon CloudWatch para su visualización.
D.
En cada cuenta de miembro, cree una etiqueta de asignación de costos que se llame BusinessUnit. También en cada cuenta de miembro, cree un bucket de Amazon S3 y un Informe de costo y uso de AWS (AWS CUR). Configure cada bucket S3 como destino para sus respectivos AWS CUR. Desde la cuenta de administración, consulte los datos de AWS CUR mediante Amazon Athena. Utilice Amazon QuickSight para la visualización.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de asignar costos en la nube a diferentes unidades de negocio y visualizar los costos, la solución adecuada implica tener un punto central para recopilar y procesar los datos de costos. El enfoque correcto es crear una etiqueta de asignación de costos llamada BusinessUnit en la cuenta de administración de la organización, lo que ayudará a categorizar los costos en función de las unidades de negocio. Además, la configuración de un informe de costos y uso de AWS (AWS CUR) en la cuenta de administración con un bucket de Amazon S3 como destino permite la recopilación centralizada de datos de costos. Consultar estos datos con Amazon Athena proporciona la capacidad de analizar los costos de manera efectiva, y el uso de Amazon QuickSight ofrece herramientas de visualización sólidas para presentar los datos de cada unidad de negocio de manera eficiente. Por lo tanto, la mejor solución es seguir estos pasos en la cuenta de administración para una asignación y visualización integral de costos.
Question 485 of 529
Una compañía de servicios públicos quiere recopilar datos de uso cada 5 minutos desde sus medidores inteligentes para facilitar la medición del tiempo de uso. Cuando un medidor envía datos a AWS, los datos se envían a Amazon API Gateway, se procesan mediante una función de AWS Lambda. y se almacenan en una tabla de Amazon DynamoDB. Durante la fase piloto, las funciones Lambda tardaron de 3 a 5 segundos en completarse.
A medida que se implementan más medidores inteligentes, los ingenieros notan que las funciones de Lambda están tardando de 1 a 2 minutos en completarse. Las funciones también están aumentando en duración a medida que se recopilan nuevos tipos de métricas de los dispositivos. Hay muchos errores ProvisionedThrough CeedException mientras se realizan operaciones PUT en DynamoDB, y también hay muchos errores TooAnyRequestsExclution de Lambda.
Qué combinación de cambios resolverá estos problemas? (Elija dos.)
A.
Aumente las unidades de capacidad de escritura en la tabla DynamoDB.
B.
Aumente la memoria disponible para las funciones Lambda.
C.
Aumente el tamaño de la carga útil de los medidores inteligentes para enviar más datos.
D.
Transmita los datos en una transmisión de datos de Amazon Kinesis desde API Gateway y procese los datos en lotes.
E.
Recopilar datos en una cola FIFO de Amazon SQS, que activa una función Lambda para procesar cada mensaje
ResponderDiscusión
Correct Answer: A, D
Para resolver los problemas que enfrenta la compañía de servicios públicos, aumentar las unidades de capacidad de escritura de la tabla DynamoDB ayudará a manejar el aumento de la carga y evitar errores provisionedThrough TexceedException. También es beneficioso transmitir los datos en una transmisión de datos de Amazon Kinesis desde API Gateway y procesar los datos en lotes. Este enfoque reducirá la carga en las funciones de Lambda y optimizará el flujo de trabajo de procesamiento de datos, abordando tanto los errores de TooAnyRequestsExclution como la mayor duración de las ejecuciones de Lambda.
Question 486 of 529
Una empresa completó recientemente una exitosa prueba de concepto de Amazon WorkSpaces. Un arquitecto de soluciones necesita que la solución esté altamente disponible en dos regiones de AWS. Amazon WorkSpaces se implementa en una región de conmutación por error y una zona alojada en Amazon Route 53.
Qué debe hacer el arquitecto de soluciones para configurar la alta disponibilidad de la solución?
A.
Cree un alias de conexión en la región principal y en la región de conmutación por error. Asociar los alias de conexión con un directorio en cada Región. Cree una política de enrutamiento de conmutación por error de Route 53. Establezca Evaluar salud objetivo en Sí.
B.
Cree un alias de conexión en la región principal y en la región de conmutación por error. Asociar los alias de conexión con un directorio en la Región primaria. Cree una política de enrutamiento de respuesta multivalue Route 53.
C.
Crear un alias de conexión en la Región principal. Asociar el alias de conexión con un directorio en la Región primaria. Cree una política de ruteo ponderada Route 53.
D.
Crear un alias de conexión en la región principal Asocie el alias de conexión con un directorio en la región de conmutación por error. Cree una política de enrutamiento de conmutación por error de Route 53. Establezca Evaluar salud objetivo en Sí.
ResponderDiscusión
Correct Answer: A
Para garantizar la alta disponibilidad de Amazon WorkSpaces en dos regiones de AWS, el enfoque correcto es crear un alias de conexión tanto en la región principal como en la región de conmutación por error y asociar cada alias con un directorio en su región respectiva. Esta configuración permite que WorkSpaces esté disponible en ambas regiones. El uso de una directiva de enrutamiento de conmutación por error de Route 53 con Evaluar estado de destino establecida en Sí garantiza que si los WorkSpaces en la región principal dejan de estar disponibles, el tráfico se redirigirá a los WorkSpaces en la región de conmutación por error. Esta configuración se alinea con las mejores prácticas para implementar mecanismos de alta disponibilidad y failover.
Question 487 of 529
Una empresa planea migrar muchas máquinas virtuales de un entorno local a AWS. La empresa requiere una evaluación inicial del entorno local antes de la migración, una visualización de las dependencias entre las aplicaciones que se ejecutan en las máquinas virtuales y un informe que proporcione una evaluación del entorno local.
Para obtener esta información, la empresa ha iniciado una solicitud de evaluación del Evaluador de Migración. La compañía tiene la capacidad de instalar software de colector en su entorno local sin ninguna restricción
Qué solución proporcionará a la compañía la información requerida con la menor sobrecarga operativa?
A.
Instale AWS Application Discovery Agent en cada máquina virtual local. Una vez finalizado el período de recopilación de datos, utilice AWS Migration Hub para ver las dependencias de la aplicación. Descargue el informe de evaluación de conocimientos rápidos de Migration Hub.
B.
Instale el recopilador del evaluador de migración en cada máquina virtual local. Una vez finalizado el periodo de recolección de datos, utilice Migration Evaluator para ver las dependencias de la aplicación. Descargue y exporte la lista de servidores descubiertos desde Migration Evaluator. Cargue la lista en Amazon QuickSight Cuando se genere el informe de QuickSight, descargue el informe de evaluación de Quick Insights.
C.
Configure AWS Application Discovery Service Agentless Collector en el entorno local. Una vez finalizado el período de recopilación de datos, utilice AWS Migration Hub para ver las dependencias de la aplicación. Exporte la lista de servidores descubiertos desde Application Discovery Service. Subir la lista a Evaluador de Migración. Cuando se genere el informe de Migration Evaluator, descargue la evaluación de Quick Insights.
D.
Configure el recopilador del evaluador de migración en el entorno local. Instale AWS Application Discovery Agent en cada máquina virtual. Una vez finalizado el período de recopilación de datos, utilice AWS Migration Hub para ver las dependencias de la aplicación. Descargue el informe de evaluación de Quick Insights de Migration Evaluator.
ResponderDiscusión
Correct Answer: A
Para adquirir una evaluación inicial del entorno local, visualizar las dependencias de las aplicaciones y obtener un informe de evaluación con la menor sobrecarga operativa, la compañía debe instalar AWS Application Discovery Agent en cada máquina virtual local. Una vez finalizado el período de recopilación de datos, AWS Migration Hub facilitará la visualización de las dependencias de la aplicación y el informe de evaluación de Quick Insights se puede descargar desde Migration Hub. Este enfoque minimiza la complejidad operativa al utilizar AWS Application Discovery Agent y las capacidades integradas de AWS Migration Hub para cumplir con todos los requisitos.
Question 488 of 529
Una empresa aloja su API principal en AWS mediante el uso de una API de Amazon API Gateway y funciones de AWS Lambda que contienen la lógica de los métodos API. Las aplicaciones internas de la compañía utilizan la API para la funcionalidad principal y la lógica de negocio. Los clientes de la compañía utilizan la API para acceder a los datos de sus cuentas. Varios clientes también tienen acceso a una API heredada que se ejecuta en una única instancia independiente de Amazon EC2.
La compañía quiere aumentar la seguridad de estas API para prevenir mejor los ataques de denegación de servicio (DoS), verificar si hay vulnerabilidades y protegerse contra exploits comunes.
Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?
A.
Utilice AWS WAF para proteger ambas API. Configure Amazon Inspector para analizar la API heredada. Configure Amazon GuardDuty para que supervise los intentos maliciosos de acceder a las API.
B.
Utilice AWS WAF para proteger la API de API Gateway. Configure Amazon Inspector para analizar ambas API. Configure Amazon GuardDuty para bloquear los intentos maliciosos de acceder a las API.
C.
Utilice AWS WAF para proteger la API de API Gateway. Configure Amazon Inspector para analizar la API heredada. Configure Amazon GuardDuty para que supervise los intentos maliciosos de acceder a las API.
D.
¡Utilice AWS WAF para proteger el AP de API Gateway! Configure Amazon Inspector para proteger la API heredada. Configure Amazon GuardDuty para bloquear los intentos maliciosos de acceder a las API.
ResponderDiscusión
Correct Answer: C
Para aumentar la seguridad, use AWS WAF para proteger la API de Amazon API Gateway, ya que ayuda a prevenir ataques de denegación de servicio (DoS) y exploits comunes. Configure Amazon Inspector para analizar la API heredada que se ejecuta en una instancia EC2 para verificar si hay vulnerabilidades. Por último, use Amazon GuardDuty para monitorear los intentos maliciosos de acceder a ambas API, ya que GuardDuty está diseñado para monitorear y analizar continuamente posibles amenazas.
Question 489 of 529
Una empresa está ejecutando una aplicación de comercio electrónico sin servidor en AWS. La aplicación utiliza Amazon API Gateway para invocar funciones Java de AWS Lambda. Las funciones de Lambda se conectan a una base de datos de Amazon RDS para MySQL para almacenar datos.
Durante un evento de venta reciente, un aumento repentino en el tráfico web resultó en un bajo rendimiento de API y fallas en la conexión de la base de datos. La compañía necesita implementar una solución para minimizar la latencia de las funciones Lambda y soportar ráfagas en el tráfico.
Qué solución cumplirá estos requisitos con la MENOR cantidad de cambio en la aplicación?
A.
Actualice el código de las funciones Lambda para que las funciones Lambda abran la conexión de base de datos fuera del controlador de funciones. Aumente la concurrencia aprovisionada para las funciones Lambda.
B.
Cree un punto final RDS Proxy para la base de datos. Almacene secretos de bases de datos en AWS Secrets Manager. Configure los permisos de IAM requeridos. Actualice las funciones de Lambda para conectarse al punto final RDS Proxy. Aumente la concurrencia aprovisionada para las funciones Lambda.
C.
Cree un grupo de parámetros personalizado. Aumentar el valor del parámetro max_connections. Asocie el grupo de parámetros personalizados con la instancia de base de datos de RDS y programe un reinicio. Aumente la concurrencia reservada para las funciones Lambda.
D.
Cree un punto final RDS Proxy para la base de datos. Almacene secretos de bases de datos en AWS Secrets Manager. Configure los permisos de IAM requeridos. Actualice las funciones de Lambda para conectarse al punto final RDS Proxy. Aumente la concurrencia reservada para las funciones Lambda.
ResponderDiscusión
Correct Answer: B
La creación de un punto final RDS Proxy para la base de datos administrará de manera eficiente los pools de conexiones para manejar ráfagas de tráfico. Además, almacenar secretos de bases de datos en AWS Secrets Manager y configurar los permisos de IAM requeridos garantiza una conexión segura y fluida. Al aumentar la concurrencia aprovisionada para las funciones de Lambda se precalentarán las instancias para manejar las subidas repentinas de tráfico de manera efectiva, minimizando la latencia. Este enfoque requiere la menor cantidad de cambios en la aplicación existente mientras se abordan los problemas de rendimiento y las fallas de conexión.
Question 490 of 529
Una empresa requiere que toda la conectividad de aplicaciones internas use direcciones IP privadas. Para facilitar esta política, un arquitecto de soluciones ha creado puntos finales de interfaz para conectarse a los servicios públicos de AWS. Tras las pruebas, el arquitecto de soluciones se da cuenta de que los nombres de los servicios se están resolviendo a direcciones IP públicas y que los servicios internos no pueden conectarse a los puntos finales de la interfaz.
Qué paso debe dar el arquitecto de soluciones para resolver este problema?
A.
Actualice la tabla de rutas de subred con una ruta al punto final de la interfaz.
B.
Habilite la opción DNS privado en los atributos de VPC.
C.
Configure el grupo de seguridad en el punto final de la interfaz para permitir la conectividad a los servicios de AWS.
D.
Configure una zona alojada privada de Amazon Route 53 con un reenviador condicional para la aplicación interna.
ResponderDiscusión
Correct Answer: B
Al habilitar la opción DNS privado en los atributos de la VPC, se garantiza que los nombres DNS de los servicios de AWS se resuelvan a las direcciones IP privadas proporcionadas por los puntos finales de la interfaz. Esto permite que los servicios internos dentro de la VPC se conecten a esos servicios de AWS utilizando direcciones IP privadas, alineándose con los requisitos de conectividad de aplicaciones internas de la compañía.
Question 491 of 529
Una empresa está desarrollando una aplicación sensible a la latencia. Parte de la aplicación incluye varias funciones de AWS Lambda que necesitan inicializarse lo más rápido posible. Las funciones Lambda se escriben en Java y contienen código de inicialización fuera de los controladores para cargar bibliotecas, inicializar clases y generar ID únicos.
Qué solución cumplirá con el requisito de rendimiento de inicio de manera más rentable?
A.
Mueva todo el código de inicialización a los manejadores para cada función Lambda. Active Lambda SnapStart para cada función Lambda. Configure SnapStart para hacer referencia a la versión $LAST de cada función Lambda.
B.
Publicar una versión de cada función Lambda. Cree un alias para cada función Lambda. Configure cada alias para que apunte a su versión correspondiente. Configure una configuración de concurrencia aprovisionada para que cada función Lambda apunte al alias correspondiente.
C.
Publicar una versión de cada función Lambda. Configure una configuración de concurrencia aprovisionada para que cada función Lambda apunte a la versión correspondiente. Active Lambda SnapStar para las versiones publicadas de las funciones Lambda.
D.
Actualice las funciones de Lambda para agregar un gancho previo a la instantánea. Mueva el código que genera ID únicos a los manejadores. Publicar una versión de cada función Lambda. Active Lambda SnapStart para las versiones publicadas de las funciones Lambda.
ResponderDiscusión
Correct Answer: D
Para cumplir con los requisitos de rendimiento de inicio de manera más rentable, la mejor opción es actualizar las funciones de Lambda agregando un gancho previo a la instantánea, mover el código que genera ID únicos a los manejadores, publicar una versión de cada función Lambda y activar Lambda SnapStart para las versiones publicadas de las funciones Lambda. Este enfoque aprovecha Lambda SnapStart para reducir significativamente el tiempo de inicio al preinicializar el entorno de ejecución de la función. Evita el costo continuo de la concurrencia aprovisionada y al mismo tiempo proporciona un mecanismo para minimizar la latencia.
Question 492 of 529
Un arquitecto de soluciones está importando una máquina virtual desde un entorno local mediante la función Amazon EC2 VM Import de AWS Import/Export. El arquitecto de soluciones ha creado una AMI y ha aprovisionado una instancia de Amazon EC2 basada en esa AMI. La instancia EC2 se ejecuta dentro de una subred pública en una VPC y tiene asignada una dirección IP pública.
La instancia EC2 no aparece como instancia administrada en la consola de AWS Systems Manager.
Qué combinación de pasos debe tomar el arquitecto de soluciones para solucionar este problema? (Elija dos.)
A.
Verifique que Systems Manager Agent esté instalado en la instancia y se esté ejecutando.
B.
Verifique que a la instancia se le asigne un rol de IAM apropiado para Systems Manager.
C.
Verifique la existencia de un punto final de VPC en la VPC.
D.
Verity que el agente de descubrimiento de aplicaciones de AWS está configurado.
E.
Verificar la configuración correcta de los roles vinculados a servicios para Systems Manager.
ResponderDiscusión
Correct Answer: A, B
Para solucionar por qué la instancia EC2 no aparece como instancia administrada en la consola de AWS Systems Manager, el arquitecto de soluciones debe verificar que el agente de Systems Manager esté instalado en la instancia y se esté ejecutando. Este agente es esencial para que la instancia se comunique con AWS Systems Manager. Adicionalmente, a la instancia se le debe asignar un rol de IAM apropiado para Systems Manager que otorgue los permisos necesarios para interactuar con los servicios de Systems Manager. Estos dos pasos son fundamentales para garantizar una comunicación y autorización adecuadas para que la instancia sea administrada por AWS Systems Manager.
Question 493 of 529
Una empresa está utilizando AWS CloudFormation como su herramienta de implementación para todas las aplicaciones. Etapas de todos los binarios y plantillas de aplicaciones dentro de los buckets de Amazon S3 con el control de versiones habilitado. Los desarrolladores tienen acceso a una instancia de Amazon EC2 que aloja el entorno de desarrollo integrado (IDE). Los desarrolladores descargan los binarios de la aplicación de Amazon S3 a la instancia EC2, realizan cambios y cargan los binarios en un bucket S3 después de ejecutar las pruebas unitarias localmente. Los desarrolladores quieren mejorar el mecanismo de implementación existente e implementar CI/CD usando AWS CodePipeline.
Los desarrolladores tienen los siguientes requisitos:
• Utilice AWS CodeCommit para el control de código fuente.
• Automatizar pruebas unitarias y escaneo de seguridad.
• Alertar a los desarrolladores cuando las pruebas unitarias fallan.
• Active y desactive las funciones de la aplicación y personalice la implementación dinámicamente como parte de CI/CD.
• Haga que el desarrollador principal proporcione la aprobación antes de implementar una aplicación.
Qué solución cumplirá con estos requisitos?
A.
Utilice AWS CodeBuild para ejecutar pruebas unitarias y análisis de seguridad. Utilice una regla de Amazon EventBridge para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallan. Escriba construcciones de AWS Cloud Development Kit (AWS CDK) para diferentes características de la solución y utilice un archivo de manifiesto para activar y desactivar las funciones en la aplicación AWS CDK. Use una etapa de aprobación manual en la tubería para permitir que el desarrollador principal apruebe las aplicaciones.
B.
Utilice AWS Lambda para ejecutar pruebas unitarias y escaneos de seguridad. Utilice Lambda en una etapa posterior de la canalización para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallan. Escriba los complementos de AWS Amplify para diferentes características de la solución y utilice las indicaciones del usuario para activar y desactivar las funciones. Utilice Amazon SES en proceso para permitir que el desarrollador principal apruebe aplicaciones.
C.
Use Jenkins para ejecutar pruebas unitarias y escaneos de seguridad. Utilice una regla de Amazon EventBridge en la canalización para enviar alertas de Amazon SES a los desarrolladores cuando las pruebas unitarias fallan Utilice las pilas anidadas de AWS CloudFormation para diferentes características y parámetros de la solución para activar y desactivar las características. Utilice AWS Lambda en proceso para permitir que el desarrollador principal apruebe aplicaciones.
D.
Utilice AWS CodeDeploy para ejecutar pruebas unitarias y análisis de seguridad. Utilice una alarma de Amazon CloudWatch en proceso para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallan. Utilice las imágenes de Docker para distintas funciones de la solución y la AWS CLI para activar y desactivar las funciones. Use una etapa de aprobación manual en la tubería para permitir que el desarrollador principal apruebe las aplicaciones.
ResponderDiscusión
Correct Answer: A
La solución aprovecha AWS CodeBuild para ejecutar pruebas unitarias y escaneos de seguridad, que es un servicio diseñado específicamente para tales tareas. Utiliza reglas de Amazon EventBridge para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallan, atendiendo el requisito de alertas. Las construcciones y los archivos de manifiesto de AWS Cloud Development Kit (AWS CDK) se pueden utilizar para activar y desactivar las funciones de la aplicación de forma dinámica, satisfaciendo los requisitos de personalización. Finalmente, una etapa de aprobación manual en la tubería garantiza que el desarrollador principal pueda revisar y aprobar las implementaciones antes de continuar, cumpliendo con el requisito de aprobación del desarrollador principal.
Question 494 of 529
Una compañía global de comercio electrónico tiene muchos centros de datos en todo el mundo. Con el crecimiento de sus datos almacenados, la compañía necesita configurar una solución para proporcionar almacenamiento escalable para aplicaciones de archivos locales heredadas. La empresa debe poder tomar copias puntuales de volúmenes mediante AWS Backup y debe conservar el acceso de baja latencia a los datos a los que se accede con frecuencia. La compañía también necesita tener volúmenes de almacenamiento que se puedan montar como dispositivos de Internet Small Computer System Interface (iSCSI) desde los servidores de aplicaciones locales de la compañía.
Qué solución cumplirá con estos requisitos?
A.
Aprovisione una puerta de enlace de cinta AWS Storage Gateway. Configure la puerta de enlace de cinta para almacenar datos en un bucket de Amazon S3. Implementar AWS Backup para tomar copias puntuales de los volúmenes.
B.
Aprovisione una puerta de enlace de archivos de Amazon FSx y una puerta de enlace de archivos de Amazon S3. Implementar AWS Backup para tomar copias puntuales de los datos.
C.
Aprovisione una puerta de enlace de volumen AWS Storage Gateway en modo caché. Haga una copia de seguridad de los volúmenes de Storage Gateway en las instalaciones con AWS Backup.
D.
Aprovisione una puerta de enlace de archivos de AWS Storage Gateway en modo caché. Implementar AWS Backup para tomar copias puntuales de los volúmenes.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de proporcionar almacenamiento escalable para aplicaciones de archivos locales, conservar el acceso de baja latencia a los datos a los que se accede con frecuencia, permitir capacidades de copia puntuales a través de AWS Backup y admitir volúmenes de almacenamiento que se pueden montar como dispositivos iSCSI, es apropiado aprovisionar una puerta de enlace de volumen AWS Storage Gateway en modo caché. Esta configuración garantiza que los datos a los que se accede con frecuencia permanezcan en las instalaciones para una latencia baja y, al mismo tiempo, ofrecen capacidades de escalabilidad y respaldo.
Question 495 of 529
Una empresa tiene una aplicación que utiliza AWS Key Management Service (AWS KMS) para cifrar y descifrar datos. La aplicación almacena datos en un bucket de Amazon S3 en una región de AWS. Las políticas de seguridad de la empresa requieren que los datos se cifren antes de que los datos se coloquen en el bucket S3. La aplicación debe descifrar los datos cuando la aplicación lee archivos del bucket S3.
La compañía replica el bucket S3 a otras Regiones. Un arquitecto de soluciones debe diseñar una solución para que la aplicación pueda cifrar y descifrar datos en todas las regiones. La aplicación deberá utilizar la misma clave para descifrar los datos en cada Región.
Qué solución cumplirá con estos requisitos?
A.
Cree una clave principal de varias regiones de KMS. Utilice la clave principal de varias regiones de KMS para crear una clave de réplica de varias regiones de KMS en cada región adicional en la que se esté ejecutando la aplicación. Actualice el código de la aplicación para usar la clave de réplica específica en cada región.
B.
Cree una nueva clave KMS administrada por el cliente en cada región adicional donde se esté ejecutando la aplicación. Actualiza el código de la aplicación para usar la clave KMS específica en cada Región.
C.
Utilice AWS Private Certificate Authority para crear una nueva entidad de certificación (CA) en la región principal. Emitir un nuevo certificado privado de la CA para la URL del sitio web de la aplicación. Comparta la CA con las regiones adicionales mediante AWS Resource Access Manager (AWS RAM). Actualice el código de la aplicación para usar los certificados de CA compartidos en cada región.
D.
Utilice AWS Systems Manager Parameter Store para crear un parámetro en cada región adicional en la que se ejecute la aplicación. Exporte el material clave de la clave KMS en la Región primaria. Almacene el material clave en el parámetro en cada Región. Actualiza el código de la aplicación para usar los datos clave del parámetro en cada Región.
ResponderDiscusión
Correct Answer: A
Para cumplir con el requisito de cifrar y descifrar datos en todas las regiones utilizando la misma clave, la mejor solución es usar claves de varias regiones de AWS KMS. Al crear una clave principal multiregión de KMS y luego crear claves de réplica en cada región adicional, la aplicación puede usar el mismo material clave en cada región. Este enfoque garantiza que los datos cifrados en una región se puedan descifrar en cualquier otra región donde se use la clave de réplica. Esta solución satisface la política de seguridad de encriptar datos antes de almacenarlos en S3 y permite que la aplicación los descifra en cualquier Región.
Question 496 of 529
Una empresa aloja una aplicación que utiliza varias instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un balanceador de carga de aplicaciones (ALB). Durante el inicio inicial de las instancias EC2, las instancias EC2 ejecutan scripts de datos de usuario para descargar contenido crítico para la aplicación desde un bucket de Amazon S3.
Las instancias EC2 se están lanzando correctamente. Sin embargo, después de un periodo de tiempo, las instancias EC2 se terminan con el siguiente mensaje de error: “Una instancia fue sacada de servicio en respuesta a una falla en la comprobación de estado del sistema ELB”. Las instancias EC2 continúan lanzándose y terminándose debido a eventos de Auto Scaling en un bucle sin fin.
El único cambio reciente en la implementación es que la compañía agregó una gran cantidad de contenido crítico al bucket S3. La empresa no quiere alterar los scripts de datos de usuario en producción.
Qué debe hacer un arquitecto de soluciones para que el entorno de producción pueda desplegarse con éxito?
A.
Aumente el tamaño de las instancias EC2.
B.
Aumentar el tiempo de espera de la comprobación de estado para el ALB.
C.
Cambiar la ruta de comprobación de estado para el ALB.
D.
Aumente el período de gracia de comprobación de estado para el grupo Auto Scaling.
ResponderDiscusión
Correct Answer: D
Para abordar el problema de manera efectiva, aumentar el período de gracia de verificación de estado para el grupo Auto Scaling es el mejor enfoque. Esto permite a las instancias EC2 tiempo adicional para completar sus tareas de inicio, incluida la descarga de una cantidad significativa de contenido nuevo del bucket S3, antes de que el balanceador de carga de aplicaciones realice las comprobaciones de estado. Esto garantiza que las instancias no se terminen prematuramente debido a fallas en las comprobaciones de estado, promoviendo la estabilidad y continuidad en el proceso de implementación sin alterar los scripts de datos de usuario existentes.
Question 497 of 529
Una empresa necesita trasladar algunas bases de datos Oracle locales a AWS. La compañía ha optado por mantener algunas de las bases de datos en las instalaciones por razones de cumplimiento comercial.
Las bases de datos locales contienen datos espaciales y ejecutan trabajos cron para mantenimiento. La compañía necesita conectarse a los sistemas locales directamente desde AWS para consultar datos como una tabla externa.
Qué solución cumplirá con estos requisitos?
A.
Cree tablas globales de Amazon DynamoDB con el escalado automático habilitado. Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) y AWS Database Migration Service (AWS DMS) para mover los datos de las instalaciones a DynamoDB. Cree una función de AWS Lambda para mover los datos espaciales a Amazon S3. Consulta los datos usando Amazon Athena. Utilice Amazon EventBridge para programar trabajos en DynamoDB para mantenimiento. Utilice Amazon API Gateway para soporte de tablas externas.
B.
Cree una instancia de base de datos de Amazon RDS para Microsoft SQL Server. Utilice la replicación nativa para mover los datos de las instalaciones locales a la instancia de base de datos. Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) para modificar el esquema de SQL Server según sea necesario después de la replicación. Mueva los datos espaciales a Amazon Redshift. Utilice procedimientos almacenados para el mantenimiento del sistema. Cree rastreadores de AWS Glue para conectarse a las bases de datos Oracle locales para soporte de tablas externas.
C.
Inicie instancias de Amazon EC2 para alojar las bases de datos Oracle. Coloque las instancias EC2 en un grupo de Auto Scaling. Utilice AWS Application Migration Service para mover los datos de las instancias locales a las instancias EC2 y para la sincronización de captura de datos de cambio bidireccional (CDC) en tiempo real. Utilice el soporte de datos espaciales nativos de Oracle. Cree una función de AWS Lambda para ejecutar trabajos de mantenimiento como parte de un flujo de trabajo de AWS Step Functions. Cree una puerta de enlace de Internet para soporte de mesa externa.
D.
Cree una instancia de base de datos de Amazon RDS para PostgreSQL. Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) y AWS Database Migration Service (AWS DMS) para mover los datos de las instalaciones locales a la instancia de base de datos. Utilice el soporte de datos espaciales nativos de PostgreSQL. Ejecute trabajos de cron en la instancia de base de datos para mantenimiento. Utilice AWS Direct Connect para conectar la instancia de base de datos al entorno local para obtener compatibilidad con tablas externas.
ResponderDiscusión
Correct Answer: D
La compañía necesita una solución para migrar bases de datos Oracle a AWS mientras mantiene algunas bases de datos en las instalaciones para su cumplimiento. También requiere consultar datos locales de AWS y administrar datos espaciales con trabajos cron para mantenimiento. La creación de una instancia de base de datos de Amazon RDS para PostgreSQL cumple estos requisitos de manera efectiva. PostgreSQL tiene soporte nativo para datos espaciales y puede ejecutar trabajos cron para mantenimiento. El uso de la herramienta de conversión de esquemas de AWS (AWS SCT) y AWS Database Migration Service (AWS DMS) permite una migración sin problemas de las instalaciones a AWS. AWS Direct Connect garantiza una conexión fiable y segura entre el entorno de AWS y los sistemas locales, lo que permite consultar tablas externas.
Question 498 of 529
Acompañar ejecuta una aplicación en Amazon EC2 y AWS Lambda. La aplicación almacena datos temporales en Amazon S3. Los objetos S3 se eliminan después de 24 horas.
La compañía implementa nuevas versiones de la aplicación mediante el lanzamiento de pilas de AWS CloudFormation. Las pilas crean los recursos requeridos. Después de validar una nueva versión, la compañía borra la vieja pila. Recientemente falló la eliminación de una pila de desarrollo antigua. Un arquitecto de soluciones necesita resolver este problema sin grandes cambios de arquitectura.
Qué solución cumplirá con estos requisitos?
A.
Cree una función Lambda para eliminar objetos de un bucket S3. Agregue la función Lambda como un recurso personalizado en la pila de CloudFormation con un atributo DependSON que apunte al recurso de bucket S3.
B.
Modifique la pila de CloudFormation para adjuntar un atributo DeletionPolicy con el valor Delete al bucket S3.
C.
Actualizar la pila de CloudFormation para agregar un atributo DeletionPolicy con un valor de Snapshot para el recurso de bucket S3
D.
Actualice la plantilla de CloudFormation para crear un sistema de archivos de Amazon Elastic File System (Amazon EFS) para almacenar archivos temporales en lugar de Amazon S3. Configure las funciones de Lambda para que se ejecuten en la misma VPC que el sistema de archivos EFS.
ResponderDiscusión
Correct Answer: A
Para resolver el problema del fallo de eliminación de pila de CloudFormation debido a buckets S3 no vacíos, la mejor solución es crear una función Lambda que elimine objetos del bucket S3. Esta función Lambda debe agregarse como un recurso personalizado en la pila de CloudFormation con un atributo DependSON que apunte al recurso de bucket S3. Esto asegura que se invoque la función Lambda para vaciar el bucket antes de que CloudFormation intente eliminarlo, evitando así cualquier falla de eliminación.
Question 499 of 529
Una empresa tiene una aplicación que almacena videos subidos por usuarios en un bucket de Amazon S3 que utiliza almacenamiento S3 Standard. Los usuarios acceden a los videos con frecuencia en los primeros 180 días después de que se suban los videos. El acceso después de 180 días es raro. Los usuarios nombrados y los usuarios anónimos acceden a los videos.
La mayoría de los videos tienen más de 100 MB de tamaño. Los usuarios suelen tener mala conectividad a Internet cuando suben videos, lo que resulta en subidas fallidas. La compañía utiliza cargas multiparte para los videos.
Un arquitecto de soluciones necesita optimizar los costos de S3 de la aplicación.
Qué combinación de acciones cumplirá con estos requisitos? (Elija dos.)
A.
Configure el bucket S3 para que sea un bucket de Requester Pays.
B.
Use S3 Transfer Acceleration para subir los videos al bucket S3.
C.
Cree una configuración del ciclo de vida de S3 o caduque las cargas multiparte incompletas 7 días después del inicio.
D.
Cree una configuración del ciclo de vida de S3 para hacer la transición de objetos a S3 Glacier Instant Retrival después de 1 día.
E.
Cree una configuración del ciclo de vida de S3 para hacer la transición de los objetos a S3 Standard-Infrequent Access (S3 Standard- IA) después de 180 días.
ResponderDiscusión
Correct Answer: C, E
Para optimizar los costos de S3, son adecuadas dos acciones. En primer lugar, la creación de una configuración del ciclo de vida de S3 para que caduque las cargas multiparte incompletas 7 días después del inicio garantizará que el espacio de almacenamiento no esté innecesariamente ocupado por cargas fallidas, lo que ahorrará costos. En segundo lugar, la transición de objetos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 180 días se alinea con el patrón de acceso donde los videos se accede con frecuencia en los primeros 180 días y rara vez se accede después. Esto reducirá los costos de almacenamiento de datos a los que se accede con poca frecuencia.
Question 500 of 529
Una empresa ejecuta una aplicación web de comercio electrónico en AWS. La aplicación web está alojada como un sitio web estático en Amazon S3 con Amazon CloudFront para la entrega de contenido. Una API de Amazon
La API de puerta de enlace invoca las funciones de AWS Lambda para manejar las solicitudes de los usuarios y el procesamiento de pedidos para la aplicación web Las funciones de Lambda almacenan datos en un clúster de base de datos de Amazon ROS para MySQL que utiliza instancias bajo demanda. El uso del clúster de base de datos ha sido consistente en los últimos 12 meses.
Recientemente, el sitio web ha experimentado la inyección de SQL y los intentos de explotación web. Los clientes también informan que el tiempo de procesamiento de pedidos ha aumentado durante los períodos de uso pico. Durante estos periodos, las funciones Lambda suelen tener arranques en frío. A medida que la compañía crece, la compañía necesita garantizar la escalabilidad y el acceso de baja latencia durante los picos de tráfico. La compañía también debe optimizar los costos de la base de datos y agregar protección contra la inyección SQL y los intentos de explotación web.
Qué solución cumplirá con estos requisitos?
A.
Configure las funciones de Lambda para que tengan un mayor valor de tiempo de espera durante los períodos pico. Utilice instancias reservadas de RDS para la base de datos. Utilice CloudFront y suscríbase a AWS Shield Advanced para protegerse contra la inyección SQL y los intentos de explotación web.
B.
Aumentar la memoria de las funciones Lambda, Transición a Amazon Redshift para la base de datos. Integre Amazon Inspector con CloudFront para protegerse contra la inyección SQL y los intentos de explotación web.
C.
Utilice las funciones de Lambda con concurrencia aprovisionada para la computación durante los períodos pico, Transición a Amazon Aurora Serverless para la base de datos. Utilice CloudFront y suscríbase a AWS Shield Advanced para protegerse contra la inyección SQL y los intentos de explotación web.
D.
Utilice funciones Lambda con concurrencia aprovisionada para cómputos durante períodos pico. Utilice instancias reservadas de RDS para la base de datos. Integre AWS WAF con CloudFront para protegerse contra la inyección SQL y los intentos de explotación web.
ResponderDiscusión
Correct Answer: D
El uso de la concurrencia aprovisionada de AWS Lambda garantiza que las funciones estén precalentadas y listas para manejar las solicitudes, minimizando así los arranques en frío y mejorando los tiempos de procesamiento de pedidos durante el uso máximo. Para la base de datos, las instancias reservadas para Amazon RDS proporcionan una solución rentable en comparación con las instancias bajo demanda, dado el patrón de uso consistente. Para protegerse contra la inyección SQL y los intentos de explotación web, AWS WAF (Web Application Firewall) integrado con CloudFront es el servicio recomendado ya que aborda específicamente tales amenazas, en lugar de AWS Shield Advanced, que está más enfocado en la protección DDoS.
Question 501 of 529
Una empresa ejecuta una aplicación web en una sola instancia de Amazon EC2. Los usuarios finales experimentan un rendimiento lento de las aplicaciones durante los momentos de uso máximo, cuando la utilización de la CPU es consistentemente superior al 95%.
Un script de datos de usuario instala los paquetes personalizados requeridos en la instancia EC2. El proceso de lanzamiento de la instancia toma varios minutos.
La compañía está creando un grupo de Auto Scaling que tiene grupos mixtos de instancias, CPU variadas y un límite de capacidad máxima. El grupo Auto Scaling utilizará una plantilla de lanzamiento para varias opciones de configuración. La compañía necesita disminuir la latencia de las aplicaciones cuando se lanzan nuevas instancias durante el escalado automático.
Qué solución cumplirá con estos requisitos?
A.
Utilice una política de escalado predictivo. Utilice una política de mantenimiento de instancias para ejecutar el script de datos de usuario. Establezca el tiempo de calentamiento de instancia predeterminado en 0 segundos.
B.
Utilice una política de escalado dinámico. Utilice ganchos de ciclo de vida para ejecutar el script de datos de usuario. Establezca el tiempo de calentamiento de instancia predeterminado en 0 segundos.
C.
Utilice una política de escalado predictivo. Habilite piscinas calientes para el grupo Auto Scaling. Utilice una política de mantenimiento de instancias para ejecutar el script de datos de usuario.
D.
Utilice una política de escalado dinámico. Habilite piscinas calientes para el grupo Auto Scaling. Utilice ganchos de ciclo de vida para ejecutar el script de datos de usuario.
ResponderDiscusión
Correct Answer: D
Para cumplir con los requisitos de disminuir la latencia de las aplicaciones cuando se lanzan nuevas instancias durante el escalado automático, el uso de una política de escalado dinámico es esencial para el ajuste en tiempo real basado en la demanda. La habilitación de piscinas calientes permite que las instancias se inicialicen previamente y se mantengan en un estado calentado, lo que reduce el tiempo que lleva atender el tráfico una vez que se necesitan. Los ganchos del ciclo de vida permiten que los scripts personalizados se ejecuten durante el lanzamiento de la instancia, lo que garantiza que todos los paquetes necesarios se instalen sin retrasar la preparación de la instancia para manejar el tráfico. Esta combinación minimiza efectivamente la latencia de las aplicaciones durante los eventos de escalamiento horizontal.
Question 502 of 529
Una empresa necesita migrar su flota de bases de datos locales a Amazon RDS. Actualmente, la compañía está utilizando una mezcla de bases de datos Microsoft SQL Server, MySQL y Oracle. Algunas de las bases de datos tienen esquemas personalizados y procedimientos almacenados.
Qué combinación de pasos debe tomar la empresa para la migración? (Elija dos.)
A.
Utilice Migration Evaluator Quick Insights para analizar las bases de datos de origen e identificar los procedimientos almacenados que deben migrarse.
B.
Utilice AWS Application Migration Service para analizar las bases de datos de origen e identificar los procedimientos almacenados que deben migrarse.
C.
Utilice la herramienta de conversión de esquemas de AWS (AWS SCT) para analizar las bases de datos de origen en busca de cambios que sean necesarios
D.
Utilice AWS Database Migration Service (AWS DMS) para migrar las bases de datos de origen a Amazon RDS.
E.
Utilice AWS DataSync para migrar los datos de las bases de datos de origen a Amazon RDS.
ResponderDiscusión
Correct Answer: C, D
Para migrar una variedad de bases de datos con esquemas personalizados y procedimientos almacenados a Amazon RDS, la empresa debe utilizar la herramienta de conversión de esquemas de AWS (AWS SCT) y AWS Database Migration Service (AWS DMS). AWS SCT puede analizar las bases de datos de origen e identificar los cambios necesarios, incluidas las modificaciones de esquemas y procedimientos almacenados. AWS DMS está diseñado para facilitar la migración de bases de datos a Amazon RDS, asegurando que los datos se transfieran de manera precisa y eficiente. Esta combinación asegura un análisis integral y una migración efectiva de las bases de datos.
Question 503 of 529
Una empresa está migrando su plataforma de blogs a AWS. Los servidores locales de la compañía se conectan a AWS a través de una conexión VPN de sitio a sitio de AWS. El contenido del blog es actualizado varias veces al día por varios autores y se sirve desde un recurso compartido de archivos en un servidor de almacenamiento conectado a la red (NAS).
La empresa necesita migrar la plataforma de blogs sin retrasar las actualizaciones de contenido. La compañía ha implementado instancias de Amazon EC2 en varias zonas de disponibilidad para ejecutar la plataforma de blog detrás de un balanceador de carga de aplicaciones. La compañía también necesita trasladar 200 TB de datos de archivo de sus servidores locales a Amazon S3 lo antes posible.
Qué combinación de topes cumplirá con estos requisitos? (Elija dos.)
A.
Crea un trabajo de cron semanal en Amazon EventBridge. Utilice el trabajo cron para invocar una función de AWS Lambda para actualizar las instancias EC2 desde el servidor NAS.
B.
Configure un volumen de conexión múltiple de Amazon Elastic Block Store (Amazon EBS) para que las instancias EC2 se compartan para acceder al contenido. Escriba código para sincronizar el volumen de EBS con el servidor NAS semanalmente.
C.
Monte un sistema de archivos de Amazon Elastic File System (Amazon EFS) en los servidores locales para que actúen como servidor NAS. Copie los datos del blog en el sistema de archivos EFS. Monte el sistema de archivos EFS en las instancias C2 para servir el contenido.
D.
Solicite un dispositivo AWS Snowball Edge Storage Optimized. Copie los artefactos de datos estáticos en el dispositivo. Envíe el dispositivo a AWS.
E.
Solicite un dispositivo AWS Snowcons SSD. Copie los artefactos de datos estáticos en el dispositivo. Envíe el dispositivo a AWS.
ResponderDiscusión
Correct Answer: C, D
Para cumplir con los requisitos, la compañía debe usar Amazon EFS para el contenido del blog y AWS Snowball Edge para transferir los datos de archivo. Amazon EFS proporciona una solución de almacenamiento de archivos escalable que se puede montar tanto en servidores locales como en instancias EC2, lo que garantiza actualizaciones inmediatas de contenido sin demoras en la sincronización. AWS Snowball Edge está diseñado para transferencias de datos a gran escala y puede trasladar de manera eficiente 200 TB de datos de archivo a Amazon S3.
Question 504 of 529
Una empresa planea migrar una aplicación local heredada a AWS. La aplicación es una aplicación web Java que se ejecuta en Apache Tomcat con una base de datos PostgreSQL.
La compañía no tiene acceso al código fuente pero puede desplegar los archivos Java Archive (JAR) de la aplicación. La aplicación ha incrementado el tráfico al final de cada mes.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Lanzar instancias de Amazon EC2 en varias zonas de disponibilidad. Implemente Tomcat y PostgreSQL en todas las instancias mediante los puntos de montaje de Amazon Elastic File System (Amazon EFS). Utilice AWS Step Functions para implementar instancias EC2 adicionales para escalar y aumentar el tráfico.
B.
Aprovisione Amazon Elastic Kubernetes Service (Amazon EKS) en un grupo de Auto Scaling en varias regiones de AWS. Implemente Tomcat y PostgreSQL en las imágenes del contenedor. Utilice un balanceador de carga de red para escalar para aumentar el tráfico.
C.
Refactorizar la aplicación Java en contenedores basados en Pitón. Utilice las funciones de AWS Lambda para la lógica de la aplicación. Almacene datos de aplicaciones en tablas globales de Amazon DynamoDB. Utilice AWS Storage Gateway y Lambda concurrencia para escalar y aumentar el tráfico.
D.
Utilice AWS Elastic Beanstalk para implementar los servidores Tomcat con escalado automático en varias zonas de disponibilidad. Almacene los datos de las aplicaciones en una base de datos de Amazon RDS para PostgreSQL. Implemente Amazon CloudFront y un balanceador de carga de aplicaciones para escalar y aumentar el tráfico.
ResponderDiscusión
Correct Answer: D
AWS Elastic Beanstalk proporciona una plataforma administrada que gestiona automáticamente la implementación, el aprovisionamiento de capacidad, el equilibrio de carga y el escalado automático para la aplicación web Java. Esto reduce significativamente la sobrecarga operativa. El almacenamiento de datos de aplicaciones en Amazon RDS para PostgreSQL garantiza operaciones de bases de datos administradas, incluidos backups automatizados y escalado. Además, el uso de Amazon CloudFront y un balanceador de carga de aplicaciones ayuda a administrar el aumento del tráfico y proporciona baja latencia. Esta solución cumple con los requisitos con la menor sobrecarga operativa dadas las limitaciones de la compañía.
Question 505 of 529
Una empresa está migrando su plataforma de IoT local a AWS. La plataforma consta de los siguientes componentes:
• Un clúster MongoDB como almacén de datos para todos los datos de IoT recopilados y procesados.
• Una aplicación que utiliza Message Queue Server Telemetry Transport (MQTT) para conectarse a dispositivos IoT cada 5 minutos para recopilar datos.
• Una aplicación que ejecuta trabajos periódicamente para generar informes a partir de los datos de IoT. Los trabajos tardan entre 120 y 600 segundos en terminar de funcionar.
• Una aplicación web que se ejecuta en un servidor web. Los usuarios finales utilizan la aplicación web para generar informes que son accesibles al público en general.
La compañía necesita migrar la plataforma a AWS para reducir la sobrecarga operativa mientras se mantiene el rendimiento.
Qué combinación de pasos cumplirá estos requisitos con la menor sobrecarga operativa? (Elija tres.)
A.
Cree máquinas de estado de AWS Step Functions con tareas de AUS Lambda para preparar los informes y escribir los informes en Amazon S3. Configurar una distribución de Amazon CloudFront que tenga un origen S3 para servir los informes
B.
Cree una función de AWS Lambda. Programe la función Lambda para conectarse a los dispositivos IoT. Procesar los datos y escribir los datos en el almacén de datos. Configure una capa Lambda para almacenar temporalmente los mensajes para su procesamiento.
C.
Configure un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) con instancias de Amazon EC2 para preparar los informes. Cree un controlador de ingreso en el clúster EKS para servir los informes.
D.
Conecte los dispositivos IoT a AWS IoT Core para publicar mensajes. Cree una regla de AWS IoT que se ejecute cuando se recibe un mensaje. Configure la regla para llamar a una función de AWS Lambda. Programe la función Lambda para analizar, transformar y almacenar datos de mensajes del dispositivo en el almacén de datos.
E.
Migre el clúster de MongoDB a Amazon DocumentDB (con compatibilidad con MongoDB).
F.
Migre el clúster MongoDB a instancias de Amazon EC2.
ResponderDiscusión
Correct Answer: A, D, E
Para cumplir con los requisitos con la menor sobrecarga operativa, los siguientes pasos son adecuados: Utilice AWS Step Functions con AWS Lambda para preparar y almacenar informes en Amazon S3 y configurar Amazon CloudFront para que sirva estos informes. Esta combinación maneja de manera eficiente los requisitos periódicos del trabajo al tiempo que minimiza los esfuerzos de administración. Conecte dispositivos IoT a AWS IoT Core, que facilita la mensajería MQTT y puede activar las funciones de AWS Lambda para procesar y almacenar datos, proporcionando una solución eficiente y escalable para manejar datos de IoT. Migre el clúster de MongoDB a Amazon DocumentDB (con compatibilidad con MongoDB) para eliminar la sobrecarga operativa de la administración de MongoDB, manteniendo al mismo tiempo las mismas funcionalidades y rendimiento requeridos para el data store de IoT.
Question 506 of 529
Una empresa crea una API de Amazon API Gateway y la comparte con un equipo de desarrollo externo. La API utiliza funciones de AWS Lambda y se implementa en una etapa que se denomina Producción.
El equipo de desarrollo externo es el único consumidor de la API. La API experimenta aumentos repentinos de uso en momentos específicos, lo que genera preocupaciones sobre el aumento de los costos. La compañía necesita limitar el costo y el uso sin reelaborar las funciones de Lambda.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Configure la API para enviar solicitudes a las colas de Amazon Simple Queue Service (Amazon SQS) en lugar de hacerlo directamente a las funciones de Lambda. Actualiza las funciones de Lambda para consumir mensajes de las colas y procesar las solicitudes. Configure las colas para invocar las funciones de Lambda cuando lleguen nuevos mensajes.
B.
Configure la concurrencia aprovisionada para cada función Lambda. Utilice AWS Application Auto Scaling para registrar las funciones de Lambda como objetivos. Configure programas de escalado para aumentar y disminuir la capacidad para hacer coincidir los cambios en el uso de API.
C.
Cree una clave API de puerta de enlace API y una ACL web regional de AWS WAF. Asociar el ACL web con la etapa de Producción. Agregue una regla basada en tarifas a la ACL web. En la regla, especifique el límite de velocidad y una agregación de solicitud personalizada que utilice el encabezado X-API-key. Comparta la clave API con el equipo de desarrollo externo.
D.
Cree una clave API de API Gateway y un plan de uso. Definir límites de estrangulamiento y cuotas en el plan de uso. Asociar el plan de uso con la etapa Producción y la clave API. Comparta la clave API con el equipo de desarrollo externo.
ResponderDiscusión
Correct Answer: D
La creación de una clave API y un plan de uso de API Gateway le permite controlar y limitar el uso de la API. El plan de uso le permite definir límites de limitación (solicitudes por segundo) y cuotas (solicitudes totales por día o mes), asegurando que el uso de la API se mantenga dentro de los límites deseados. Este enfoque ayuda a controlar los costos al limitar el número de solicitudes manejadas por las funciones de Lambda sin requerir ningún cambio en las funciones de Lambda existentes o la arquitectura general.
Question 507 of 529
Una compañía de entretenimiento aloja un servicio de venta de entradas en una flota de instancias Linux Amazon EC2 que se encuentran en un grupo de Auto Scaling. El servicio de venta de entradas utiliza un archivo de precios. El archivo de precios se almacena en un bucket de Amazon S3 que tiene almacenamiento S3 Standard. Una solución central de precios alojada por un tercero actualiza el archivo de precios.
El archivo de precios se actualiza cada 1-15 minutos y tiene varios miles de líneas de pedido. El archivo de precios se descarga en cada instancia EC2 cuando se inicia la instancia.
Las instancias EC2 ocasionalmente utilizan información de precios desactualizada que puede resultar en cargos incorrectos para los clientes.
Qué solución resolverá este problema de manera más rentable?
A.
Cree una función de AWS Lambda para actualizar una tabla de Amazon DynamoDB con nuevos precios cada vez que se actualice el archivo de precios. Actualizar el servicio de venta de entradas para usar DynraModb para buscar precios
B.
Cree una función de AWS Lambda para actualizar un recurso compartido de archivos de Amazon Elastic File System (Amazon EFS) con el archivo de precios cada vez que se actualice el archivo. Actualice el servicio de venta de boletos para usar Amazon EFS para acceder al archivo de precios.
C.
Cargue Mountpoint para Amazon S3 en la AMI de las instancias EC2. Configure Mountpoint para Amazon S3 para montar el bucket S3 que contiene el archivo de precios. Actualizar el servicio de tickets para que apunte al punto de montaje y la ruta para acceder al objeto $3,
D.
Cree un volumen de Amazon Elastic Block Store (Amazon EBS). Utilice Conexión múltiple de EBS para conectar el volumen a cada instancia EC2. Cuando se inicie una nueva instancia de EC2, configure la nueva instancia para actualizar el archivo de precios en el volumen de EBS. Actualizar el servicio de venta de entradas para que apunte a la nueva fuente local.
ResponderDiscusión
Correct Answer: C
La solución más rentable es cargar Mountpoint para Amazon S3 en la AMI de las instancias EC2 y configurarla para montar el bucket S3 que contiene el archivo de precios. Este enfoque permite que las instancias EC2 accedan directamente al bucket S3 como si se tratara de un file system local, asegurando que las instancias siempre accedan a la última versión del archivo de precios sin necesidad de descargarla cada vez. Esto evita el costo asociado con la descarga repetida del archivo y minimiza el riesgo de usar información de precios desactualizada. Además, esta solución simplifica la arquitectura al eliminar la necesidad de mecanismos adicionales de almacenamiento y sincronización de datos.
Question 508 of 529
Una empresa tiene una aplicación que utiliza instancias de Amazon EC2 en un grupo de Auto Scaling. El departamento de aseguramiento de la calidad (QA) necesita lanzar una gran cantidad de entornos de corta duración para probar la aplicación. Los entornos de aplicación son lanzados actualmente por el gerente del departamento utilizando una plantilla de AWS CloudFormation. Para lanzar la pila, el administrador utiliza un rol con permiso para usar las API de CloudFormation, EC2 y Auto Scaling. El gerente quiere permitir a los probadores lanzar sus propios entornos, pero no quiere otorgar amplios permisos a cada usuario.
Qué conjunto lograría estos objetivos?
A.
Cargue la plantilla de AWS CloudFormation en Amazon S3. Dar permiso a los usuarios del departamento de QA para asumir el rol de gerente y agregar una política que restrinja los permisos a la plantilla y a los recursos que crea. Capacite a los usuarios para que inicien la plantilla desde la consola de CloudFormation.
B.
Cree un producto de AWS Service Catalog a partir de la plantilla de entorno. Agregue una restricción de lanzamiento al producto con el rol existente. Otorgue a los usuarios del departamento de control de calidad permiso para usar solo las API de AWS Service Catalog. Capacite a los usuarios para lanzar la plantilla desde la consola de AWS Service Catalog.
C.
Cargue la plantilla de AWS CloudFormation en Amazon S3. Otorgar permiso a los usuarios del departamento de QA para usar las API de CloudFormation y S3, con condiciones que restrinjan los permisos a la plantilla y a los recursos que crea. Capacite a los usuarios para que inicien la plantilla desde la consola de CloudFormation.
D.
Cree una aplicación de AWS Elastic Beanstalk a partir de la plantilla de entorno. Otorgue a los usuarios del departamento de control de calidad permiso para usar únicamente permisos de Elastic Beanstalk. Capacite a los usuarios para que inicien entornos de Elastic Beanstalk con la CLI de Elastic Beanstalk, pasando el rol existente al entorno como rol de servicio.
ResponderDiscusión
Correct Answer: B
Crear un producto de AWS Service Catalog a partir de la plantilla de entorno y agregar una restricción de lanzamiento al producto con el rol existente logra el objetivo de permitir que los probadores lancen sus propios entornos sin otorgarles amplios permisos. Al otorgar a los usuarios del departamento de control de calidad permiso para usar solo las API de AWS Service Catalog, la configuración garantiza que los usuarios solo puedan lanzar la plantilla de entorno especificada, manteniendo la seguridad y el control de administración necesarios.
Question 509 of 529
Una empresa está utilizando una sola región de AWS para su sitio web de comercio electrónico. El sitio web incluye una aplicación web que se ejecuta en varias instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones (ALB). El sitio web también incluye una tabla de Amazon DynamoDB. Un nombre de dominio personalizado en Amazon Route 53 está vinculado al ALB. La compañía creó un certificado SSL/TLS en AWS Certificate Manager (ACM) y adjuntó el certificado al ALB. La compañía no está utilizando una red de entrega de contenido como parte de su diseño.
La compañía quiere replicar toda su pila de aplicaciones en una segunda región para proporcionar recuperación ante desastres, planificar el crecimiento futuro y proporcionar un mejor tiempo de acceso a los usuarios. Un arquitecto de soluciones necesita implementar una solución que logre estos objetivos y minimice la sobrecarga administrativa.
Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)
A.
Cree una plantilla de AWS CloudFormation para el diseño de infraestructura actual. Utilice parámetros para valores importantes del sistema, incluyendo Región. Utilice la plantilla CloudFormation para crear la nueva infraestructura en la segunda Región.
B.
Utilice la consola de administración de AWS para documentar el diseño de infraestructura existente en la primera región y para crear la nueva infraestructura en la segunda región.
C.
Actualice el registro de zona alojada Route 53 para que la aplicación utilice el enrutamiento ponderado. Enviar el 50% del tráfico al ALB en cada Región.
D.
Actualice el registro de zona alojada Route 53 para que la aplicación utilice el enrutamiento basado en latencia. Enviar tráfico al ALB en cada Región.
E.
Actualice la configuración de la tabla existente de DynamoDB habilitando DynamoDB Streams. Agrega la segunda Región para crear una tabla global.
F.
Crear una nueva tabla de DynamoDB. Habilite DynamoDB Flujos para la nueva tabla. Agrega la segunda Región para crear una tabla global. Copie los datos de la tabla existente de DynamoDB a la nueva tabla como una operación única.
ResponderDiscusión
Correct Answer: A, D, E
Para replicar toda la pila de aplicaciones en una segunda región con una sobrecarga administrativa mínima, el arquitecto de soluciones debe tomar los siguientes pasos: Crear una plantilla de AWS CloudFormation para el diseño de infraestructura actual para replicarla fácilmente en otras regiones. Actualice el registro de zona alojada Route 53 para que la aplicación utilice el enrutamiento basado en latencia que dirija el tráfico en función de la latencia más baja a los usuarios, asegurando un mejor tiempo de acceso. Habilite DynamoDB Streams para la tabla de DynamoDB existente y cree una tabla global para garantizar que los datos se replican en ambas regiones de manera fluida y eficiente.
Question 510 of 529
Una empresa quiere crear un único bucket de Amazon S3 para que sus científicos de datos almacenen documentos relacionados con el trabajo. La compañía utiliza AWS IAM Identity Center para autenticar a todos los usuarios. Se creó un grupo para los científicos de datos.
La compañía quiere dar acceso a los científicos de datos solo a su propio trabajo. La compañía también quiere crear reportes mensuales que muestren a qué documentos accedió cada usuario.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Cree un conjunto de permisos de IAM Identity Center personalizado para otorgar a los científicos de datos acceso a un prefijo de bucket de S3 que coincida con su etiqueta de nombre de usuario. Utilice una política para limitar el acceso a rutas con la condición $ {aws:principalTag/username} /*.
B.
Cree una función de IAM Identity Center para el grupo de científicos de datos que tiene acceso de lectura y escritura de Amazon S3. Agregue una política de bucket S3 que permita el acceso al rol de IAM Identity Center.
C.
Configure AWS CloudTrail para registrar eventos de datos de S3 y entregar los registros a un bucket de S3. Utilice Amazon Athena para ejecutar consultas en los registros de CloudTrail en Amazon S3 y generar informes.
D.
Configure AWS CloudTrail para registrar eventos de administración de S3 en CloudWatch. Utilice el conector CloudWatch de Amazon Athena para consultar los registros y generar informes.
E.
Habilite el registro de acceso S3 a EMR File System (EMRFS). Utilice Amazon S3 Select para consultar registros y generar informes.
ResponderDiscusión
Correct Answer: A, C
Para cumplir con los requisitos de la compañía, se deben implementar dos pasos: controlar el acceso y generar informes de acceso. La creación de un conjunto de permisos de IAM Identity Center personalizado permite a los científicos de datos acceder solo a su propio trabajo dentro del bucket de S3 mediante una política que limita el acceso en función de su etiqueta de nombre de usuario. Esto satisface el requisito de permitir el acceso solo a su propia obra. La configuración de AWS CloudTrail para registrar eventos de datos de S3 y entregar los registros a un bucket de S3 permite realizar un seguimiento de los documentos a los que ha accedido cada usuario. El uso de Amazon Athena para consultar estos registros y generar informes satisface el requisito de crear informes de acceso mensuales.
Question 511 of 529
Una empresa aloja una aplicación de procesamiento de datos en instancias de Amazon EC2. La aplicación sondea un sistema de archivos Amazon Elastic File System (Amazon EFS) para los archivos recién cargados. Cuando se detecta un nuevo archivo, la aplicación extrae datos del archivo y ejecuta la lógica para seleccionar una imagen de contenedor Docker para procesar el archivo. La aplicación inicia la imagen de contenedor apropiada y pasa la ubicación del archivo como parámetro.
El procesamiento de datos que realiza el contenedor puede tardar hasta 2 horas. Cuando se completa el procesamiento, el código que se ejecuta dentro del contenedor vuelve a escribir el archivo en Amazon EFS y sale.
La compañía necesita refactorizar la aplicación para eliminar las instancias EC2 que están ejecutando los contenedores.
Qué solución cumplirá con estos requisitos?
A.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS). Configure el procesamiento para que se ejecute como tareas de AWS Fargate. Extraiga la lógica de selección de contenedores para ejecutarla como una regla de Amazon EventBridge que inicia la tarea de Fargate adecuada. Configure la regla EventBridge para que se ejecute cuando se agreguen archivos al sistema de archivos EFS.
B.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS). Configure el procesamiento para que se ejecute como tareas de AWS Fargate. Actualice y conteneriza la lógica de selección de contenedores para que se ejecute como un servicio de Fargate que inicia la tarea de Fargate adecuada. Configure una notificación de evento EFS para invocar el servicio Fargate cuando se agreguen archivos al sistema de archivos EFS.
C.
Cree un clúster de Amazon Elastic Container Service (Amazon ECS). Configure el procesamiento para que se ejecute como tareas de AWS Fargate. Extraiga la lógica de selección de contenedores para ejecutarla como una función de AWS Lambda que inicie la tarea Fargate adecuada. Migre el almacenamiento de las cargas de archivos a un bucket de Amazon S3. Actualice el código de procesamiento para usar Amazon S3. Configure una notificación de evento S3 para invocar la función Lambda cuando se crean objetos.
D.
Cree imágenes de contenedores de AWS Lambda para el procesamiento. Configure las funciones de Lambda para usar las imágenes del contenedor. Extraiga la lógica de selección de contenedor para ejecutarla como una función Lambda de decisión que invoque la función de procesamiento Lambda apropiada. Migre el almacenamiento de las cargas de archivos a un bucket de Amazon S3. Actualice el código de procesamiento para usar Amazon S3. Configure una notificación de evento S3 para invocar la función Lambda de decisión cuando se crean objetos.
ResponderDiscusión
Correct Answer: C
Para cumplir con los requisitos de eliminar instancias EC2 y gestionar eficazmente tareas de procesamiento de datos de larga duración, es apropiado crear un clúster de Amazon Elastic Container Service (ECS) y configurar el procesamiento para que se ejecute como tareas de AWS Fargate. La migración del almacenamiento de cargas de archivos a Amazon S3 le permite aprovechar las notificaciones de eventos de S3, que pueden invocar una función de AWS Lambda para la lógica de selección de contenedores. La función Lambda puede entonces iniciar la tarea Fargate apropiada. Este enfoque permite la activación automática al cargar archivos y garantiza que el sistema de almacenamiento admita notificaciones de eventos.
Question 512 of 529
Una empresa de medios tiene un repositorio 30-T8 de videos de noticias digitales. Estos videos se almacenan en cinta en una biblioteca de cintas local y se hace referencia mediante un sistema de administración de activos de medios (MAM). La compañía quiere enriquecer los metadatos de estos videos de manera automatizada y colocarlos en un catálogo de búsqueda mediante el uso de una función MAM. La compañía debe poder realizar búsquedas en función de la información del video, como objetos, elementos de escenario o rostros de personas. Se encuentra disponible un catálogo que contiene rostros de personas que han aparecido en los videos que incluyen una imagen de cada persona. A la compañía le gustaría migrar estos videos a AWS.
La compañía cuenta con una conexión AWS Direct Connect de alta velocidad con AWS y le gustaría mover el contenido de video de la solución MAM directamente desde su sistema de archivos actual.
Cómo se pueden cumplir estos requisitos utilizando la MENOR cantidad de sobrecarga de administración continua y causando una interrupción MÍNIMA en el sistema existente?
A.
Configure un dispositivo de puerta de enlace de archivos de AWS Storage Gateway en las instalaciones. Utilice la solución MAM para extraer los videos del archivo actual e introducirlos en la puerta de enlace de archivos. Usa el catálogo de caras para construir una colección en Amazon Rekognition. Cree una función de AWS Lambda que invoque el SDK de Javascript de Rekognition para que Rekognition extraiga el video de los archivos de Amazon S3 que respaldan la puerta de enlace de archivos, recupere los metadatos necesarios y envíe los metadatos a la solución MAM.
B.
Configure un AWS Storage Gateway, dispositivo de puerta de enlace en cinta local. Utilice la solución MAM para extraer los videos del archivo actual e introducirlos en la puerta de enlace de cinta. Usa el catálogo de caras para construir una colección en Amazon Rekognition. Cree una función de AWS Lambda que invoque el SDK de Javascript de Rekognition para que Amazon Rekognition procese el video en la puerta de enlace de cinta, recupere los metadatos necesarios e inserte los metadatos en la solución MAM.
C.
Configure una transmisión de ingestión de video mediante Amazon Kinesis Video Streams. Usa el catálogo de caras para construir una colección en Amazon Rekognition. Transmita los videos de la solución MAM a Kinesis Video Streams. Configure Amazon Rekognition para procesar los videos transmitidos. Luego, use un consumidor de flujo para recuperar los metadatos requeridos e insertarlos en la solución MAM. Configure la transmisión para almacenar los videos en Amazon S3.
D.
Configure una instancia de Amazon EC2 que ejecute las bibliotecas OpenCV. Copie los vídeos, las imágenes y el catálogo de caras de la biblioteca local en un volumen de Amazon EBS montado en esta instancia EC2. Procese los videos para recuperar los metadatos requeridos e insertarlos en la solución MAM, al tiempo que copia los archivos de video en un bucket de Amazon S3.
ResponderDiscusión
Correct Answer: A
Para cumplir con los requisitos de la compañía con la menor cantidad de sobrecarga de administración continua y una interrupción mínima del sistema existente, el uso de un dispositivo de puerta de enlace de archivos de AWS Storage Gateway en las instalaciones es un enfoque adecuado. Esta configuración permite que la solución MAM extraiga videos del archivo actual y los empuje a la puerta de enlace de archivos. La puerta de enlace de archivos almacenará los datos en Amazon S3, donde Amazon Rekognition puede acceder y procesar los videos para recuperar los metadatos requeridos. Esta solución aprovecha los servicios administrados de AWS, lo que reduce la necesidad de una administración extensa y continua al tiempo que garantiza una integración perfecta con el sistema existente.
Question 513 of 529
Una empresa necesita optimizar el costo de un entorno de AWS que contenga varias cuentas en una organización en AWS Organizations. La compañía realizó actividades de optimización de costos hace 3 años y compró instancias reservadas estándar de Amazon EC2 que recientemente expiraron.
La compañía necesita instancias EC2 por 3 años más. Adicionalmente, la compañía ha implementado una nueva carga de trabajo sin servidor.
Qué estrategia proporcionará a la compañía el MÁS ahorro de costos?
A.
Compra las mismas Instancias Reservadas por un plazo adicional de 3 años con el pago All Upfront. Compra un plan de ahorro de cómputos de 3 años con pago inicial total en la cuenta de administración para cubrir cualquier costo adicional de cómputos
B.
Compra un plan de ahorro de cómputos de 1 año sin pago inicial en cada cuenta de miembro. Utilice las recomendaciones de planes de ahorro en la consola de administración de costos de AWS para elegir el Plan de ahorro de cómputos.
C.
Adquiera un plan de ahorro de instancias EC2 de 3 años sin pago inicial en la cuenta de administración para cubrir los costos de EC2 en cada región de AWS. Compra un plan de ahorro de cómputos de 3 años sin pago inicial en la cuenta de administración para cubrir cualquier costo adicional de cómputos.
D.
Adquiera un Plan de Ahorro de Instancia EC2 de 3 años con el pago por adelantado en cada cuenta de miembro. Utilice las recomendaciones de planes de ahorro en la consola de AWS Cost Management para elegir el Plan de ahorro de instancias EC2.
ResponderDiscusión
Correct Answer: A
Para optimizar el costo para los próximos 3 años mientras se considera la nueva carga de trabajo sin servidor, el mejor enfoque es comprar instancias reservadas estándar de Amazon EC2 por otro período de 3 años con el pago All Upfront para aprovechar el descuento máximo. Además, la compra de un plan de ahorro de cómputos de 3 años con pago por adelantado en la cuenta de administración cubrirá cualquier costo adicional de cómputos, incluida la nueva carga de trabajo sin servidor, asegurando que la compañía se beneficie de los mayores ahorros de costos.
Question 514 of 529
Una empresa opera una plataforma de distribución de contenido estático que sirve a los clientes a nivel mundial. Los clientes consumen contenido de sus propias cuentas de AWS.
La compañía sirve su contenido desde un bucket de Amazon S3. La compañía carga el contenido de su entorno local al bucket de S3 mediante una puerta de enlace de archivos S3.
La compañía quiere mejorar el rendimiento y la confiabilidad de la plataforma al servir contenido de la región de AWS que está geográficamente más cercana a los clientes. La empresa debe enrutar los datos locales a Amazon S3 con una latencia mínima y sin exposición pública a Internet.
Qué combinación de pasos cumplirá estos requisitos con la menor sobrecarga operativa? (Elija dos.)
A.
Implementación de puntos de acceso multi-región S3
B.
Uso de S3 Cross-Region Replication (CRR) para copiar contenido a diferentes regiones
C.
Crear una función de AWS Lambda que rastree el enrutamiento de clientes a Regions
D.
Utilice una conexión VPN de sitio a sitio de AWS para conectarse a un punto de acceso de varias regiones.
E.
Utilice AWS PrivateLink y AWS Direct Connect para conectarse a un punto de acceso de varias regiones.
ResponderDiscusión
Correct Answer: A, E
Para cumplir con los requisitos, la compañía debe utilizar S3 Multi-Region Access Points para mejorar el rendimiento y la confiabilidad al servir contenido de la región de AWS que esté geográficamente más cercana a los clientes. Esto asegura baja latencia y alta disponibilidad. Además, AWS PrivateLink y AWS Direct Connect deben utilizarse para conectar de forma segura el entorno local al punto de acceso multirregional S3 sin exponer los datos a Internet pública. Esta configuración minimiza la latencia y mejora la seguridad.
Question 515 of 529
Una empresa está migrando su centro de datos a la nube de AWS y necesita completar la migración lo más rápido posible. La compañía cuenta con muchas aplicaciones que se ejecutan en cientos de VMs de VMware en el centro de datos. Cada VM se configura con una carpeta compartida de Windows que contiene archivos compartidos comunes. El recurso compartido de archivos tiene más de 100 GB de tamaño.
El equipo de cumplimiento de la compañía requiere que una solicitud de cambio sea rechazada y aprobada para cada instalación de software y modificación de cada VM. La compañía cuenta con una conexión AWS Direct Connect con 10 GB de ancho de banda entre AWS y el centro de datos.
Qué conjunto de pasos debe tomar la empresa para completar la migración en la MENOR cantidad de tiempo?
A.
Utilice VM ImporVExport para crear imágenes de cada VM. Utilice AWS Application Migration Service para administrar y ver las imágenes. Copie los datos compartidos de archivos de Windows en un sistema de archivos de Amazon Elastic File System (Amazon EFS). Después de la migración, reasigne el recurso compartido de archivos al sistema de archivos EFS.
B.
Implemente el dispositivo sin agente de AWS Application Discovery Service en VMware vCenter. Revise la cartera de máquinas virtual descubiertas en AWS Migration Hub.
C.
Implemente el dispositivo sin agente de AWS Application Migration Service en VMware vCenter. Copie los datos compartidos de archivos de Windows en un nuevo sistema de archivos de Amazon FSx para Windows File Server. Después de la migración, reasigne el recurso compartido de archivos en cada VM al sistema de archivos FSx para Windows File Server.
C. Crear y revisar una cartera en AWS Migration Hub. Solicite un dispositivo AWS Snowcone. Implementar AWS Application Migration Service en VMware vCenter y exportar todas las máquinas virtuales al dispositivo Snowcone. Copie todos los datos compartidos de archivos de Windows en el dispositivo Snowcone. Envíe el dispositivo Snowcone a AWS. Utilice el Servicio de migración de aplicaciones para implementar todas las instancias migradas.
D.
Implemente el agente de AWS Application Discovery Service y el agente de AWS Application Migration Service Agent en cada hipervisor de VMware directamente. Revise la cartera en AWS Migration Hub. Copie los datos de uso compartido de archivos de cada VM en un nuevo sistema de archivos de Amazon FSx para Windows File Server. Después de la migración, reasigne el recurso compartido de archivos en cada VM al sistema de archivos FSx para Windows File Server.
ResponderDiscusión
Correct Answer: C
Para migrar las máquinas virtuales de VMware de la compañía a AWS en el menor tiempo posible, deben usar una solución sin agente para minimizar el esfuerzo de instalación y configuración en las máquinas virtuales existentes. Al implementar el dispositivo sin agente de AWS Application Migration Service en VMware vCenter, la empresa puede migrar cargas de trabajo sin necesidad de modificar cada VM individualmente. Después de esto, copiar los datos compartidos de archivos de Windows a un nuevo servidor de archivos de Amazon FSx para Windows permitirá a la compañía mantener la compatibilidad con las configuraciones de archivos compartidos existentes. Este enfoque aprovecha el ancho de banda de 10 GB de AWS Direct Connect para una transferencia de datos eficiente y satisface los requisitos de cumplimiento al evitar modificaciones directas en las máquinas virtuales.
Question 516 of 529
Una empresa tiene varias cuentas de AWS que se encuentran en una organización en AWS Organizations. La compañía necesita almacenar la actividad de la cuenta de AWS y consultar los datos desde una ubicación central mediante SQL.
Qué solución cumplirá con estos requisitos?
A.
Cree un rastro de AWS CloudTraii en cada cuenta. Especifique los eventos de administración de CloudTrail para el sendero. Configure CloudTrail para enviar los eventos a Amazon CloudWatch Logs. Configure la observabilidad de cuentas cruzadas de CloudWatch. Consulta los datos en CloudWatch Logs Insights.
B.
Utilice una cuenta de administrador delegado para crear un data store de AWS CloudTrail Lake. Especifique los eventos de administración de CloudTrail para el data store. Habilite el data store para todas las cuentas de la organización. Consulta los datos en CloudTrail Lake.
C.
Utilice una cuenta de administrador delegado para crear un rastro de AWS CloudTral. Especifique los eventos de administración de CloudTrail para el sendero. Habilite el rastro para todas las cuentas de la organización. Mantenga todas las demás configuraciones como predeterminadas. Consulte los datos de CloudTrail desde la página de historial de eventos de CloudTrail.
D.
Utilice AWS CloudFormation StackSets para implementar almacenes de datos de AWS CloudTrail Lake en cada cuenta. Especifique los eventos de administración de CloudTrail para los data stores. Mantenga todas las demás configuraciones por defecto, Consulta los datos en CloudTrail Lake.
ResponderDiscusión
Correct Answer: B
Para cumplir con los requisitos de almacenar la actividad de la cuenta de AWS y consultar los datos desde una ubicación central mediante SQL, la mejor solución es usar una cuenta de administrador delegado para crear un data store de AWS CloudTrail Lake. En CloudTrail Lake, puede especificar eventos de administración de CloudTrail para el data store y habilitarlo para todas las cuentas de la organización. Esto permite la recopilación y almacenamiento centralizados de la actividad de la cuenta, y proporciona la capacidad de consultar estos datos mediante consultas basadas en SQL, que se alinean perfectamente con las necesidades establecidas.
Question 517 of 529
Una empresa está utilizando AWS para desarrollar y administrar su aplicación web de producción. La aplicación incluye una API HTTP de Amazon API Gateway que invoca una función de AWS Lambda. La función Lambda procesa y luego almacena datos en una base de datos.
La empresa quiere implementar la autorización de usuario para la aplicación web de manera integrada. La compañía ya utiliza un proveedor de identidad externo que emite tokens OAuth para las otras aplicaciones de la compañía.
Qué solución cumplirá con estos requisitos?
A.
Integrar el proveedor de identidad de terceros de la compañía con API Gateway. Configure un autorizador API Gateway Lambda para validar los tokens del proveedor de identidad. Requerir el autorizador Lambda en todas las rutas API. Actualice la aplicación web para obtener tokens del proveedor de identidad e incluya los tokens en el encabezado Autorización cuando llame a la API HTTP de API Gateway.
B.
Integrar el proveedor de identidad de terceros de la compañía con AWS Directory Service. Configure Directory Service como un autorizador de API Gateway para validar tokens del proveedor de identidad. Requerir el autorizador de Directory Service en todas las rutas API. Configure AWS IAM Identity Center como proveedor de identidades SAML 2.0. Configure la aplicación web como una aplicación SAML 2.0 personalizada.
C.
Integre el proveedor de identidad externo de la compañía con AWS IAM Identity Center. Configure API Gateway para usar IAM Identity Center para la autenticación y autorización de configuración cero. Actualice la aplicación web para recuperar tokens de AWS Security Token Service (AWS STS) de IAM Identity Center e incluya los tokens en el encabezado de autorización cuando llame a la API HTTP de API Gateway.
D.
Integre el proveedor de identidad externo de la compañía con AWS IAM Identity Center. Configure usuarios de IAM con permisos para llamar a la API HTTP de la puerta de enlace API. Actualice la aplicación web para extraer los parámetros de solicitud de los usuarios de IAM e incluya los parámetros en el encabezado Autorización al llamar a la API HTTP de API Gateway.
ResponderDiscusión
Correct Answer: A
Integrar el proveedor de identidad externo de la compañía con API Gateway y configurar un autorizador API Gateway Lambda para validar tokens del proveedor de identidad es el mejor enfoque. Esto permite una integración perfecta del proveedor de identidad existente, que emite tokens OAuth, con API Gateway. El autorizador Lambda puede validar estos tokens, asegurando una autorización segura del usuario. Requerir el autorizador Lambda en todas las rutas API y actualizar la aplicación web para incluir tokens en el encabezado Autorización garantiza que cada solicitud de API esté debidamente autenticada.
Question 518 of 529
Una empresa ha implementado aplicaciones en miles de instancias de Amazon EC2 en una cuenta de AWS. Una auditoría de seguridad descubre que varios volúmenes no cifrados de Amazon Elastic Block Store (Amazon EBS) están conectados a las instancias EC2. La política de seguridad de la compañía requiere que los volúmenes de EBS estén encriptados.
La compañía necesita implementar una solución automatizada para cifrar los volúmenes de EBS. La solución también debe evitar que los equipos de desarrollo creen volúmenes de EBS sin cifrar.
Qué solución cumplirá con estos requisitos?
A.
Configure la regla administrada de AWS Config que identifica los volúmenes de EBS no cifrados. Configure una acción de corrección automática. Asocie un runbook de AWS Systems Manager Automation que incluya los pasos para crear un nuevo volumen de EBS cifrado. Cree una clave administrada por el cliente de AWS Key Management Service (AWS KMS). En la política de claves, incluya una declaración para denegar la creación de volúmenes de EBS no cifrados.
B.
Utilice AWS Systems Manager Fleet Manager para crear una lista de volúmenes de EBS no cifrados, Crear un runbook de automatización de Systems Manager que incluya los pasos para crear un nuevo volumen de EBS cifrado. Cree un SCP para denegar la creación de volúmenes de EBS sin cifrar.
C.
Utilice AWS Systems Manager Fleet Manager para crear una lista de volúmenes de EBS no cifrados. Cree un runbook de automatización de Systems Manager que incluya los pasos para crear un nuevo volumen de EBS cifrado. Modifique la configuración de la cuenta de AWS para el cifrado de EBS para cifrar siempre los nuevos volúmenes de EBS.
D.
Configure la regla administrada de AWS Config que identifica los volúmenes de EBS no cifrados. Configure una acción de corrección automática. Asocie un runbook de AWS Systems Manager Automation que incluya los pasos para crear un nuevo volumen de EBS cifrado. Modifique la configuración de la cuenta de AWS para el cifrado de EBS para cifrar siempre los nuevos volúmenes de EBS.
ResponderDiscusión
Correct Answer: D
El enfoque correcto implica el uso de la regla administrada de AWS Config para identificar volúmenes de EBS no cifrados, ya que monitorea y evalúa continuamente el cumplimiento de las configuraciones deseadas. La habilitación de la corrección automática y la asociación de un runbook de AWS Systems Manager Automation garantiza que los volúmenes no cifrados que se encuentren se cifren rápidamente. Al modificar la configuración de la cuenta de AWS para el cifrado de EBS de manera predeterminada, evita la creación futura de volúmenes de EBS sin cifrar. Esta solución cumple con los requisitos tanto de identificación como de prevención.
Question 519 of 529
Una empresa está ejecutando una gran carga de trabajo en contenedores en la nube de AWS. La carga de trabajo consiste en aproximadamente 100 servicios diferentes. La compañía utiliza Amazon Elastic Container Service (Amazon ECS) para orquestar la carga de trabajo.
Recientemente, el equipo de desarrollo de la compañía comenzó a usar AWS Fargate en lugar de instancias de Amazon EC2 en el clúster de ECS. En el pasado, la carga de trabajo se ha acercado a ejecutar el número máximo de instancias EC2 que están disponibles en la cuenta.
A la compañía le preocupa que la carga de trabajo pueda alcanzar el número máximo de tareas ECS que se permiten. Un arquitecto de soluciones debe implementar una solución que notifique al equipo de desarrollo cuando Fargate alcance el 80% del número máximo de tareas.
Qué debe hacer el arquitecto de soluciones para cumplir con este requisito?
A.
Utilice Amazon CloudWatch para supervisar la estadística de recuento de muestras para cada servicio del clúster de ECS. Establezca una alarma para cuando la expresión matemática muestra Count/service_quota (service) *100 es mayor que 80. Notificar al equipo de desarrollo mediante Amazon Simple Notification Service (Amazon SNS).
B.
Utilice Amazon CloudWatch para supervisar las cuotas de servicio que se publican en el espacio de nombres de métricas AWS/Usage. Establezca una alarma para cuando la expresión matemática métrica/Service_cuota (métrica) *100 sea mayor que 80. Notificar al equipo de desarrollo mediante Amazon Simple Notification Service (Amazon SNS).
C.
Cree una función de AWS Lambda para sondear métricas detalladas del clúster ECS. Cuando el número de tareas de Fargate en ejecución sea superior a 80, invoque Amazon Simple Email Service (Amazon SES) para notificar al equipo de desarrollo.
D.
Cree una regla de AWS Config para evaluar si Fargate SERVICE_QUOTA es mayor que 80. Utilice Amazon Simple Email Service (Amazon SES) para notificar al equipo de desarrollo cuando la regla de AWS Config no sea compatible.
ResponderDiscusión
Correct Answer: B
En este escenario, el mejor enfoque para monitorear y alertar al equipo de desarrollo es usar Amazon CloudWatch para monitorear las cuotas de servicio publicadas bajo el espacio de nombres de métricas AWS/Usage. Este método permite configurar una alarma para cuando la métrica de uso supera el 80% de la cuota de servicio. El uso de métricas de CloudWatch es una forma confiable y eficiente de rastrear este tipo de datos, y al emplear una expresión matemática que compare la métrica con SERVICE_QUOTA, puede obtener el porcentaje requerido. Además, la integración de esto con Amazon Simple Notification Service (SNS) garantiza que el equipo de desarrollo sea notificado rápidamente. Esta solución es integral y sencilla de implementar, cumpliendo con los requisitos de la compañía de manera efectiva.
Question 520 of 529
Una empresa cuenta con varias funciones de AWS Lambda escritas en Python. Las funciones se implementan con el tipo de implementación de paquete.zip. Las funciones utilizan una capa Lambda que contiene bibliotecas y paquetes comunes en un archivo.zip. Los paquetes Lambda .zip y el archivo.zip de capa Lambda se almacenan en un bucket de Amazon S3.
La compañía debe implementar el escaneo automático de las funciones Lambda y la capa Lambda para identificar CVEs. Un subconjunto de las funciones de Lambda debe recibir escaneos de código automatizados para detectar posibles fugas de datos y otras vulnerabilidades. Los escaneos de código deben ocurrir solo para las funciones Lambda seleccionadas, no todas las funciones Lambda.
Qué combinación de acciones cumplirá con estos requisitos? (Elija tres.)
A.
Activa Amazon Inspector. Inicie escaneos CVE automatizados.
B.
Active el escaneo estándar Lambda y el escaneo de código Lambda en Amazon Inspector.
C.
Habilite Amazon GuardDuty. Habilite la función de protección Lambda en GuardDuty.
D.
Habilite el escaneo en la configuración del Monitor de las funciones Lambda que necesitan escaneos de código.
E.
Etiquetar funciones Lambda que no necesitan escaneos de código. En la etiqueta, incluya una clave de InspectorCodeExclusion y un valor de LambdaCodeDescanning.
F.
Utilice Amazon Inspector para escanear el depósito 3 que contiene los paquetes Lambda .zip y el archivo.zip de capa Lambda para escanear el código.
ResponderDiscusión
Correct Answer: A, B, D
Para cumplir con los requisitos, primero, active Amazon Inspector para iniciar escaneos CVE automatizados. En segundo lugar, active el escaneo estándar Lambda y el escaneo de código Lambda dentro de Amazon Inspector para apuntar específicamente a las funciones de Lambda para el escaneo. En tercer lugar, habilite el escaneo en la configuración del Monitor de las funciones Lambda que necesitan escaneos de código, asegurando que solo las funciones seleccionadas reciban escaneos de código automatizados para detectar posibles fugas de datos y otras vulnerabilidades.
Question 521 of 529
Una empresa está cambiando la forma en que maneja los parches de instancias de Amazon EC2 en su cuenta de aplicación. Actualmente, la compañía parchea instancias a través de Internet mediante el uso de una puerta de enlace NAT en una VPC en la cuenta de la aplicación.
La compañía tiene instancias EC2 establecidas como un repositorio de origen de parches en una VPC privada dedicada en una cuenta principal. La compañía quiere usar AWS Systems Manager Patch Manager y el repositorio de origen de parches en la cuenta principal para aplicar parches a las instancias EC2 en la cuenta de la aplicación. La empresa debe evitar que todas las instancias EC2 en la cuenta de la aplicación accedan a internet.
Las instancias EC2 en la cuenta de la aplicación deben acceder a Amazon S3, donde se almacenan los datos de la aplicación. Estas instancias EC2 necesitan conectividad con Systems Manager y con el repositorio de origen de parches en la VPC privada en la cuenta principal.
Qué solución cumplirá con estos requisitos?
A.
Cree una ACL de red que bloquee el tráfico saliente en el puerto 80. Asociar la ACL de red con todas las subredes en la cuenta de la aplicación. En la cuenta de la aplicación y la cuenta principal, implemente una instancia EC2 que ejecute un servidor VPN personalizado. Cree un túnel VPN para acceder a la VPC privada. Actualizar la tabla de rutas en la cuenta de la aplicación.
B.
Cree VIF privados para Systems Manager y Amazon S3. Elimine la puerta de enlace NAT de la VPC en la cuenta de la aplicación. Cree una puerta de enlace de tránsito para acceder a las instancias EC2 del repositorio de origen de parches en la cuenta principal. Actualizar la tabla de rutas en la cuenta principal.
C.
Cree puntos finales de VPC para Systems Manager y Amazon S3. Elimine la puerta de enlace NAT de la VPC en la cuenta de la aplicación. Cree una conexión de interconexión de VPC para acceder a las instancias EC2 del repositorio de origen de parches en la cuenta principal. Actualizar las tablas de ruta en ambas cuentas.
D.
Cree una ACL de red que bloquee el tráfico entrante en el puerto 80. Asociar la ACL de red con todas las subredes en la cuenta de la aplicación. Cree una puerta de enlace de tránsito para acceder a las instancias EC2 del repositorio de origen de parches en la cuenta principal. Actualizar las tablas de ruta en ambas cuentas.
ResponderDiscusión
Correct Answer: C
La solución correcta implica crear endpoints de VPC tanto para AWS Systems Manager como para Amazon S3, lo que permitirá que las instancias EC2 en la cuenta de la aplicación accedan a estos servicios sin requerir acceso a Internet. La eliminación de la puerta de enlace NAT garantiza que las instancias no tengan acceso a Internet. Además, la creación de una conexión de pares de VPC entre la cuenta de aplicación y la cuenta principal permitirá que las instancias EC2 en la cuenta de aplicación accedan al repositorio de origen de parches en la VPC privada de la cuenta principal. La actualización de las tablas de ruta en ambas cuentas asegurará que el tráfico se enruta correctamente. Esta configuración cumple con todos los requisitos de evitar el acceso a Internet, mantener la conectividad con los servicios de AWS requeridos y acceder al repositorio de parches de forma segura.
Question 522 of 529
Una empresa en Estados Unidos (US) ha adquirido una compañía en Europa. Ambas empresas utilizan la nube de AWS. La compañía estadounidense ha construido una nueva aplicación con una arquitectura de microservicios. La compañía estadounidense está alojando la aplicación en cinco VPC en la región us-east-2. La aplicación debe poder acceder a recursos en una VPC en la región eu-west-1.
Sin embargo, la aplicación no debe poder acceder a ninguna otra VPC.
Las VPC en ambas regiones no tienen rangos CIDR superpuestos. Todas las cuentas ya están consolidadas en una organización en AWS Organizations.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree una puerta de enlace de tránsito en eu-west-1. Conecte las VPC en us-east-2 y la VPC en eu-west-1 a la puerta de enlace de tránsito. Cree las entradas de ruta necesarias en cada VPC para que el tráfico se enruta a través de la puerta de enlace de tránsito.
B.
Cree una puerta de enlace de tránsito en cada región. Adjuntar las subredes involucradas a la pasarela de tránsito regional. Cree las entradas de ruta necesarias en las tablas de rutas asociadas para cada subred para que el tráfico se enruta a través de la puerta de enlace de tránsito regional. Peer las dos pasarelas de tránsito.
C.
Cree una configuración de conexión de interconexión de VPC de malla completa entre todas las VPC. Cree las entradas de ruta necesarias en cada VPC para que el tráfico se enrute a través de la conexión de pares de VPC.
D.
Cree una conexión de interconexión de VPC para cada VPC en us-east-2 a la VPC en eu-west-1. Cree las entradas de ruta necesarias en cada VPC para que el tráfico se enrute a través de la conexión de pares de VPC.
ResponderDiscusión
Correct Answer: D
La solución más rentable es crear una conexión de interconexión de VPC para cada VPC en us-east-2 a la VPC en eu-west-1. Este enfoque permite a la aplicación acceder a recursos en la VPC especificada en eu-west-1 sin necesidad de una configuración compleja y costosa como pasarelas de tránsito, que son más caras y pueden introducir complejidad innecesaria para este caso de uso. Dado que las VPC en ambas regiones no tienen bloques CIDR superpuestos y el requisito es restringir el acceso a una sola VPC, el peering de VPC es un método simple y rentable para cumplir con estos requisitos.
Question 523 of 529
Una empresa de viajes construyó una aplicación web que utiliza Amazon Simple Email Service (Amazon SES) para enviar notificaciones por correo electrónico a los usuarios. La compañía necesita habilitar el registro para ayudar a solucionar problemas de entrega de correo electrónico. La compañía también necesita la capacidad de realizar búsquedas basadas en el destinatario, el tema y el tiempo enviado.
Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Cree un conjunto de configuración de Amazon SES con Amazon Data Firehose como destino. Elija enviar registros a un bucket de Amazon S3.
B.
Habilite el registro de AWS CloudTrail. Especifique un bucket de Amazon S3 como destino para los registros.
C.
Utilice Amazon Athena para consultar los registros en el bucket de Amazon S3 para el destinatario, el asunto y la hora de envío.
D.
Cree un grupo de registros de Amazon CloudWatch. Configure Amazon SES para enviar registros al grupo de registros.
E.
Utilice Amazon Athena para consultar los registros en Amazon CloudWatch para el destinatario, el asunto y la hora de envío.
ResponderDiscusión
Correct Answer: A, C
Para cumplir con los requisitos de registrar los problemas de entrega de correo electrónico y realizar búsquedas basadas en el destinatario, el asunto y la hora de envío, el arquitecto de soluciones debe usar un conjunto de configuración de Amazon SES con Amazon Kinesis Data Firehose como destino para enviar registros a un bucket de Amazon S3. Además, Amazon Athena se puede utilizar para consultar estos registros en el bucket S3 para obtener los detalles necesarios, como destinatario, asunto y hora de envío. Esta combinación garantiza que los registros se almacenen en un formato de búsqueda y que se establezca un método de consulta efectivo.
Question 524 of 529
Una empresa migró a AWS y utiliza AWS Business Support. La compañía quiere monitorear la rentabilidad de las instancias de Amazon EC2 en todas las cuentas de AWS. Las instancias EC2 tienen etiquetas para departamento, unidad de negocio y entorno. Las instancias EC2 de desarrollo tienen un alto costo pero una baja utilización.
La compañía necesita detectar y detener cualquier instancia EC2 de desarrollo infrautilizada. Las instancias están infrautilizadas si tuvieron un 10% o menos de utilización media diaria de la CPU y 5 MB o menos de E/S de red durante al menos 4 de los últimos 14 días.
Qué solución cumplirá estos requisitos con la menor sobrecarga operativa?
A.
Configure los paneles de Amazon CloudWatch para supervisar la utilización de instancias EC2 en función de etiquetas para departamento, unidad de negocio y entorno. Cree una regla de Amazon EventBridge que invoque una función de AWS Lambda para detener las instancias EC2 de desarrollo infrautilizadas.
B.
Configure AWS Systems Manager para realizar un seguimiento de la utilización de instancias EC2 e informar a Amazon CloudWatch de instancias subutilizadas. Filtre los datos de CloudWatch por etiquetas para departamento, unidad de negocio y entorno. Cree una regla de Amazon EventBridge que invoque una función de AWS Lambda para detener las instancias EC2 de desarrollo infrautilizadas.
C.
Cree una regla de Amazon EventBridge para detectar la baja utilización de instancias EC2 notificadas por AWS Trusted Advisor. Configure la regla para invocar una función de AWS Lambda que filtre los datos por etiquetas para departamento, unidad de negocio y entorno y detenga las instancias EC2 de desarrollo infrautilizadas.
D.
Cree una función de AWS Lambda para que se ejecute diariamente y recupere los datos de utilización de todas las instancias EC2. Guarde los datos en una tabla de Amazon DynamoDB. Cree un panel de Amazon QuickSight que utilice la tabla DynamoDB como fuente de datos para identificar y detener las instancias EC2 de desarrollo infrautilizadas.
ResponderDiscusión
Correct Answer: C
Para detectar y detener las instancias EC2 de desarrollo infrautilizadas con la menor sobrecarga operativa, es efectivo aprovechar los informes de baja utilización de AWS Trusted Advisor. Trusted Advisor ya ofrece recomendaciones basadas en métricas de utilización específicas. Al crear una regla de Amazon EventBridge para activar una función de AWS Lambda para filtrar instancias por departamento, unidad de negocio y etiquetas de entorno y detener las instancias subutilizadas, esta solución minimiza la necesidad de monitoreo y administración continuas, reduciendo así la sobrecarga operativa general.
Question 525 of 529
Una empresa está alojando una aplicación en AWS para un proyecto que se ejecutará durante los próximos 3 años. La aplicación consta de 20 instancias bajo demanda de Amazon EC2 que están registradas en un grupo de destino para un balanceador de carga de red (NLB). Las instancias se distribuyen en dos zonas de disponibilidad. La aplicación es apátrida y funciona las 24 horas del día, los 7 días de la semana.
La compañía recibe reportes de usuarios que están experimentando respuestas lentas desde la aplicación. Las métricas de rendimiento muestran que las instancias tienen un 10% de utilización de la CPU durante el uso normal de la aplicación. Sin embargo, la utilización de la CPU aumenta al 100% en momentos ocupados, que suelen durar algunas horas.
La empresa necesita una nueva arquitectura para resolver el problema de las respuestas lentas desde la aplicación.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree un grupo de Auto Scaling. Adjunte el grupo Auto Scaling al grupo objetivo del NLB. Establezca la capacidad mínima en 20 y la capacidad deseada en 28. Compra de Instancias Reservadas para 20 instancias.
B.
Crear una Flota de Spot que tenga un tipo de solicitud de solicitud. Establezca el parámetro TotalTargetCapacity en 20. Establezca el parámetro DefaultTargetCapacityType en On-Demand. Especifique el NLB al crear la Flota de spot.
C.
Crear una Flota de Spot que tenga un tipo de solicitud de mantenimiento. Establezca el parámetro TotalTargetCapacity en 20. Establezca el parámetro DefaultTargetCapacityType en Spot. Reemplace el NLB con un balanceador de carga de aplicaciones.
D.
Cree un grupo de Auto Scaling. Adjunte el grupo Auto Scaling al grupo objetivo del NLB. Establezca la capacidad mínima en 4 y la capacidad máxima en 28. Compra de instancias reservadas para cuatro instancias.
ResponderDiscusión
Correct Answer: D
Para abordar el problema de las respuestas lentas durante periodos de alta utilización, la solución más rentable es crear un grupo Auto Scaling con una capacidad mínima de 4 y una capacidad máxima de 28. Esto permite que la aplicación se escale durante los tiempos ocupados para manejar el aumento de la carga y reducir la escala durante los períodos normales, ahorrando costos. Al comprar instancias reservadas para el número mínimo de instancias (4), la compañía puede reducir aún más los costos, ya que las instancias reservadas son más económicas que las instancias bajo demanda. Esto asegura que la aplicación sea escalable y rentable.
Question 526 of 529
Acompañar está construyendo una aplicación para recopilar y transmitir datos de sensores desde una fábrica. La aplicación utilizará AWS IoT Core para enviar datos desde cientos de dispositivos a un lago de datos de Amazon S3. La empresa debe enriquecer los datos antes de cargarlos en Amazon S3.
La aplicación transmitirá los datos del sensor cada 5 segundos. Los nuevos datos del sensor deben estar disponibles en Amazon S3 menos de 30 minutos después de que la aplicación los recopile. Ninguna otra aplicación está procesando los datos de los sensores de AWS IoT Core.
Qué solución cumplirá con estos requisitos de manera más rentable?
A.
Cree un tema en AWS IoT Core para ingerir los datos del sensor. Cree una función de AWS Lambda para enriquecer los datos y escribirlos en Amazon S3. Configure una acción de regla de AWS IoT para invocar la función Lambda.
B.
Utilice AWS IoT Core Basic Ingest para ingerir los datos del sensor. Configure una acción de regla de AWS IoT para escribir los datos en Amazon Kinesis Data Firehose. Establezca el intervalo de almacenamiento en búfer de Kinesis Data Firehose en 900 segundos. Utilice Kinesis Data Firehose para invocar una función de AWS Lambda para enriquecer los datos, Configurar Kinesis Data Firehose para entregar los datos a Amazon S3.
C.
Cree un tema en AWS IoT Core para ingerir los datos del sensor. Configure una acción de regla de AWS IoT para enviar los datos a una tabla de Amazon Timestream. Cree una función AWS Lambda, para leer los datos de Timestream. Configure la función Lambda para enriquecer los datos y escribirlos en Amazon S3.
D.
Utilice AWS LoT Core Basic Ingest para ingerir los datos del sensor. Configure una acción de regla de AWS IoT para escribir los datos en Amazon Kinesis Data Streams. Cree una función AWS Lambda para el consumidor para procesar los datos de Kinesis Data Stream y enriquecerlos. Llame a la operación S3 PutObject API desde la función Lambda para escribir los datos en Amazon S3.
ResponderDiscusión
Correct Answer: A
La solución más rentable implica los servicios mínimos necesarios que puedan alcanzar los requisitos. Al crear un tema en AWS IoT Core para ingerir los datos de los sensores, aprovecha una plataforma robusta diseñada para manejar los datos de IoT entrantes. El uso de una función de AWS Lambda para enriquecer y escribir los datos en Amazon S3 es sencillo y eficiente. La configuración de una acción de regla de AWS IoT para invocar la función Lambda garantiza que los datos se procesen y almacenen en S3 dentro del plazo requerido, sin la necesidad de servicios adicionales como Kinesis, lo que aumentaría la complejidad y el costo de la solución.
Question 527 of 529
Una empresa está recopilando datos de un gran conjunto de dispositivos IoT. Los datos se almacenan en un lago de datos de Amazon S3. Los científicos de datos realizan análisis en instancias de Amazon EC2 que se ejecutan en dos subredes públicas en una VPC en una cuenta de AWS separada.
Los científicos de datos necesitan acceder al lago de datos desde las instancias EC2. Las instancias EC2 ya tienen un rol asignado con permisos para acceder a Amazon S3.
De acuerdo con las políticas de la compañía, solo se permite que las redes autorizadas tengan acceso a los datos de IoT.
Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)
A.
Cree un punto final de VPC de puerta de enlace para Amazon S3 en la VPC de los científicos de datos.
B.
Cree un punto de acceso S3 en la cuenta de AWS de los científicos de datos para el lago de datos.
C.
Actualice el rol de instancia EC2. Agregue una política con una condición que permita la acción s3:GetObject cuando el valor de la clave de condición s3:DataAccessPointArn es un ARN de punto de acceso válido.
D.
Actualice la tabla de rutas de VPC para enrutar el tráfico S3 a un punto de acceso S3.
E.
Agregue una política de bucket S3 con una condición que permita la acción s3:GetObject cuando el valor de la clave de condición s3:DataAccessPointArn es un ARN de punto de acceso válido.
ResponderDiscusión
Correct Answer: A, E
Para garantizar el acceso seguro al lago de datos de Amazon S3 desde instancias EC2 sin atravesar Internet pública, se debe crear un punto de enlace de VPC de puerta de enlace para Amazon S3. Esto permite una conectividad directa y segura entre las instancias EC2 y S3, adhiriéndose a las políticas de la compañía de que solo las redes autorizadas pueden acceder a los datos de IoT. Además, se debe implementar una política de bucket S3 con una condición que permita la acción s3:GetObject cuando el valor de la clave de condición s3:DataAccessPointArn es un ARN de punto de acceso válido. Esto impone el control de acceso basado en condiciones específicas, asegurando que solo las redes autorizadas tengan acceso a los datos.
Question 528 of 529
Una empresa quiere migrar su sitio web a AWS. El sitio web utiliza contenedores que se implementan en un clúster de Kubernetes local y autoadministrado. Todos los datos del sitio web se almacenan en una base de datos PostgreSQL local.
La compañía ha decidido migrar el clúster local de Kubernetes a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). El clúster EKS utilizará grupos de nodos administrados por EKS con un número estático de nodos. La compañía también migrará la base de datos local a una base de datos de Amazon RDS para PostgreSQL.
Un arquitecto de soluciones necesita estimar el costo total de propiedad (TCO) para esta carga de trabajo antes de la migración.
Qué solución proporcionará la información de TCO requerida?
A.
Solicitar acceso a Evaluador de Migración. Ejecute el recopilador de evaluadores de migración e importe los datos. Configure un escenario. Exporte un informe de Quick Insights de Migration Evaluator.
B.
Inicie AWS Database Migration Service (AWS DMS) para la base de datos local. Generar un informe de evaluación. Cree una estimación en AWS Pricing Calculator para los costos de la migración de EKS.
C.
Inicialice el servicio de migración de aplicaciones de AWS. Agregue los servidores locales como servidores de origen. Lanzar una instancia de prueba. Genere un informe de TCO del Servicio de migración de aplicaciones.
D.
Acceda a la página web de AWS Cloud Economics Center para evaluar el AWS Cloud Value Framework. Cree un informe de costos y uso de AWS desde Cloud Value Framework.
ResponderDiscusión
Correct Answer: A
Para estimar el costo total de propiedad (TCO) para migrar la carga de trabajo a AWS, la solución más adecuada es usar Migration Evaluator. Migration Evaluator proporciona herramientas para analizar el entorno actual y generar informes que incluyen los costos estimados para ejecutar la carga de trabajo en AWS. Al ejecutar Migration Evaluator Collector, configurar un escenario y exportar un informe de Quick Insights, puede obtener un análisis completo del TCO, que abarca tanto la migración de Amazon EKS como la migración de la base de datos de Amazon RDS para PostgreSQL. Otras opciones, como el uso de AWS DMS o AWS Application Migration Service, no ofrecen el mismo nivel de análisis integral del TCO.
Question 529 of 529
Una empresa de eventos dirige una plataforma de venta de entradas en AWS. Los clientes de la compañía configuran y programan sus eventos en la plataforma. Los eventos dan como resultado grandes aumentos de tráfico a la plataforma. La empresa conoce la fecha y hora de los eventos de cada cliente.
La compañía ejecuta la plataforma en un clúster de Amazon Elastic Container Service (Amazon ECS). El clúster de ECS consta de instancias bajo demanda de Amazon EC2 que se encuentran en un grupo de Auto Scaling. El grupo Auto Scaling utiliza una política de escalado predictivo.
El clúster ECS realiza solicitudes frecuentes a un bucket de Amazon S3 para descargar activos de tickets. El clúster ECS y el bucket S3 se encuentran en la misma región de AWS y en la misma cuenta de AWS. El tráfico entre el clúster ECS y el bucket S3 fluye a través de una puerta de enlace NAT.
La compañía necesita optimizar el costo de la plataforma sin disminuir la disponibilidad de la plataforma.
Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)
A.
Cree un punto final de VPC de puerta de enlace para el bucket S3.
B.
Agregue otro proveedor de capacidad ECS que utilice un grupo de instancias puntuales de Auto Scaling. Configure la nueva estrategia de proveedor de capacidad para que tenga el mismo peso que la estrategia de proveedor de capacidad existente.
C.
Cree reservas de capacidad bajo demanda para el tipo de instancia aplicable para el período de tiempo de las políticas de escalado programadas.
D.
Habilite S3 Transfer Acceleration en el bucket S3.
E.
Reemplace la política de escalado predictivo con políticas de escalado programadas para los eventos programados.
ResponderDiscusión
Correct Answer: A, E
La creación de un punto final de VPC de puerta de enlace para el bucket S3 reducirá los costos de transferencia de datos al eliminar la necesidad de que el tráfico pase por la puerta de enlace NAT, que incurre en cargos. Reemplazar la política de escalado predictivo con políticas de escalado programadas garantizará que las operaciones de escalado se basen en las fechas y horas conocidas de los eventos del cliente, optimizando la utilización de recursos y reduciendo los costos asociados con el sobreaprovisionamiento. Juntos, estos pasos optimizarán los costos sin comprometer la disponibilidad.